
Trial 0:
  Value: 0.8246
  num_layers: 2
  units_0: 96
  units_1: 32
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.1
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0005433517533592198

Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 96)                75360     
                                                                 
 batch_normalization (Batch  (None, 96)                384       
 Normalization)                                                  
                                                                 
 dropout (Dropout)           (None, 96)                0         
                                                                 
 dense_1 (Dense)             (None, 32)                3104      
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_2 (Dense)             (None, 26)                858       
                                                                 
=================================================================
Total params: 79706 (311.35 KB)
Trainable params: 79514 (310.60 KB)
Non-trainable params: 192 (768.00 Byte)
_________________________________________________________________



Trial 1:
  Value: 0.5013
  num_layers: 2
  units_0: 288
  units_1: 480
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: True
  optimizer: sgd
  learning_rate: 0.001946758051340456

Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_1 (Flatten)         (None, 784)               0         
                                                                 
 dense_3 (Dense)             (None, 288)               226080    
                                                                 
 dropout_2 (Dropout)         (None, 288)               0         
                                                                 
 dense_4 (Dense)             (None, 480)               138720    
                                                                 
 batch_normalization_1 (Bat  (None, 480)               1920      
 chNormalization)                                                
                                                                 
 dropout_3 (Dropout)         (None, 480)               0         
                                                                 
 dense_5 (Dense)             (None, 26)                12506     
                                                                 
=================================================================
Total params: 379226 (1.45 MB)
Trainable params: 378266 (1.44 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 2:
  Value: 0.7973
  num_layers: 1
  units_0: 448
  activation_0: tanh
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: adamax
  learning_rate: 0.0009803679748889747

Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_2 (Flatten)         (None, 784)               0         
                                                                 
 dense_6 (Dense)             (None, 448)               351680    
                                                                 
 dropout_4 (Dropout)         (None, 448)               0         
                                                                 
 dense_7 (Dense)             (None, 26)                11674     
                                                                 
=================================================================
Total params: 363354 (1.39 MB)
Trainable params: 363354 (1.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 3:
  Value: 0.8504
  num_layers: 2
  units_0: 96
  units_1: 192
  activation_0: tanh
  activation_1: sigmoid
  dropout_0: 0.5
  dropout_1: 0.1
  batch_norm_0: True
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.0014268663479955646

Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_3 (Flatten)         (None, 784)               0         
                                                                 
 dense_8 (Dense)             (None, 96)                75360     
                                                                 
 batch_normalization_2 (Bat  (None, 96)                384       
 chNormalization)                                                
                                                                 
 dropout_5 (Dropout)         (None, 96)                0         
                                                                 
 dense_9 (Dense)             (None, 192)               18624     
                                                                 
 batch_normalization_3 (Bat  (None, 192)               768       
 chNormalization)                                                
                                                                 
 dropout_6 (Dropout)         (None, 192)               0         
                                                                 
 dense_10 (Dense)            (None, 26)                5018      
                                                                 
=================================================================
Total params: 100154 (391.23 KB)
Trainable params: 99578 (388.98 KB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 4:
  Value: 0.6718
  num_layers: 1
  units_0: 352
  activation_0: sigmoid
  dropout_0: 0.2
  batch_norm_0: True
  optimizer: sgd
  learning_rate: 0.0020566783273530793

Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_4 (Flatten)         (None, 784)               0         
                                                                 
 dense_11 (Dense)            (None, 352)               276320    
                                                                 
 batch_normalization_4 (Bat  (None, 352)               1408      
 chNormalization)                                                
                                                                 
 dropout_7 (Dropout)         (None, 352)               0         
                                                                 
 dense_12 (Dense)            (None, 26)                9178      
                                                                 
=================================================================
Total params: 286906 (1.09 MB)
Trainable params: 286202 (1.09 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 5:
  Value: 0.6384
  num_layers: 1
  units_0: 352
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: True
  optimizer: adagrad
  learning_rate: 0.0037860363756901847

Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_5 (Flatten)         (None, 784)               0         
                                                                 
 dense_13 (Dense)            (None, 352)               276320    
                                                                 
 batch_normalization_5 (Bat  (None, 352)               1408      
 chNormalization)                                                
                                                                 
 dropout_8 (Dropout)         (None, 352)               0         
                                                                 
 dense_14 (Dense)            (None, 26)                9178      
                                                                 
=================================================================
Total params: 286906 (1.09 MB)
Trainable params: 286202 (1.09 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 6:
  Value: 0.8663
  num_layers: 2
  units_0: 160
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.005599926147177046

Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_6 (Flatten)         (None, 784)               0         
                                                                 
 dense_15 (Dense)            (None, 160)               125600    
                                                                 
 batch_normalization_6 (Bat  (None, 160)               640       
 chNormalization)                                                
                                                                 
 dropout_9 (Dropout)         (None, 160)               0         
                                                                 
 dense_16 (Dense)            (None, 480)               77280     
                                                                 
 dropout_10 (Dropout)        (None, 480)               0         
                                                                 
 dense_17 (Dense)            (None, 26)                12506     
                                                                 
=================================================================
Total params: 216026 (843.85 KB)
Trainable params: 215706 (842.60 KB)
Non-trainable params: 320 (1.25 KB)
_________________________________________________________________



Trial 7:
  Value: 0.0410
  num_layers: 4
  units_0: 512
  units_1: 160
  units_2: 320
  units_3: 352
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: tanh
  activation_3: relu
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: ftrl
  learning_rate: 0.0012358532542496436

Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_7 (Flatten)         (None, 784)               0         
                                                                 
 dense_18 (Dense)            (None, 512)               401920    
                                                                 
 dropout_11 (Dropout)        (None, 512)               0         
                                                                 
 dense_19 (Dense)            (None, 160)               82080     
                                                                 
 dropout_12 (Dropout)        (None, 160)               0         
                                                                 
 dense_20 (Dense)            (None, 320)               51520     
                                                                 
 batch_normalization_7 (Bat  (None, 320)               1280      
 chNormalization)                                                
                                                                 
 dropout_13 (Dropout)        (None, 320)               0         
                                                                 
 dense_21 (Dense)            (None, 352)               112992    
                                                                 
 batch_normalization_8 (Bat  (None, 352)               1408      
 chNormalization)                                                
                                                                 
 dropout_14 (Dropout)        (None, 352)               0         
                                                                 
 dense_22 (Dense)            (None, 26)                9178      
                                                                 
=================================================================
Total params: 660378 (2.52 MB)
Trainable params: 659034 (2.51 MB)
Non-trainable params: 1344 (5.25 KB)
_________________________________________________________________



Trial 8:
  Value: 0.0417
  num_layers: 1
  units_0: 512
  activation_0: sigmoid
  dropout_0: 0.1
  batch_norm_0: True
  optimizer: ftrl
  learning_rate: 0.00014883023663209738

Model: "sequential_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_8 (Flatten)         (None, 784)               0         
                                                                 
 dense_23 (Dense)            (None, 512)               401920    
                                                                 
 batch_normalization_9 (Bat  (None, 512)               2048      
 chNormalization)                                                
                                                                 
 dropout_15 (Dropout)        (None, 512)               0         
                                                                 
 dense_24 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 417306 (1.59 MB)
Trainable params: 416282 (1.59 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 9:
  Value: 0.0375
  num_layers: 1
  units_0: 224
  activation_0: sigmoid
  dropout_0: 0.5
  batch_norm_0: False
  optimizer: ftrl
  learning_rate: 0.001024468315382975

Model: "sequential_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_9 (Flatten)         (None, 784)               0         
                                                                 
 dense_25 (Dense)            (None, 224)               175840    
                                                                 
 dropout_16 (Dropout)        (None, 224)               0         
                                                                 
 dense_26 (Dense)            (None, 26)                5850      
                                                                 
=================================================================
Total params: 181690 (709.73 KB)
Trainable params: 181690 (709.73 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 10:
  Value: 0.7130
  num_layers: 4
  units_0: 32
  units_1: 480
  units_2: 64
  units_3: 96
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  dropout_2: 0.5
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00882307579792438

Model: "sequential_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_10 (Flatten)        (None, 784)               0         
                                                                 
 dense_27 (Dense)            (None, 32)                25120     
                                                                 
 batch_normalization_10 (Ba  (None, 32)                128       
 tchNormalization)                                               
                                                                 
 dropout_17 (Dropout)        (None, 32)                0         
                                                                 
 dense_28 (Dense)            (None, 480)               15840     
                                                                 
 dropout_18 (Dropout)        (None, 480)               0         
                                                                 
 dense_29 (Dense)            (None, 64)                30784     
                                                                 
 dropout_19 (Dropout)        (None, 64)                0         
                                                                 
 dense_30 (Dense)            (None, 96)                6240      
                                                                 
 dropout_20 (Dropout)        (None, 96)                0         
                                                                 
 dense_31 (Dense)            (None, 26)                2522      
                                                                 
=================================================================
Total params: 80634 (314.98 KB)
Trainable params: 80570 (314.73 KB)
Non-trainable params: 64 (256.00 Byte)
_________________________________________________________________



Trial 11:
  Value: 0.8530
  num_layers: 3
  units_0: 160
  units_1: 288
  units_2: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.007046264963762198

Model: "sequential_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_11 (Flatten)        (None, 784)               0         
                                                                 
 dense_32 (Dense)            (None, 160)               125600    
                                                                 
 batch_normalization_11 (Ba  (None, 160)               640       
 tchNormalization)                                               
                                                                 
 dropout_21 (Dropout)        (None, 160)               0         
                                                                 
 dense_33 (Dense)            (None, 288)               46368     
                                                                 
 batch_normalization_12 (Ba  (None, 288)               1152      
 tchNormalization)                                               
                                                                 
 dropout_22 (Dropout)        (None, 288)               0         
                                                                 
 dense_34 (Dense)            (None, 512)               147968    
                                                                 
 dropout_23 (Dropout)        (None, 512)               0         
                                                                 
 dense_35 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 335066 (1.28 MB)
Trainable params: 334170 (1.27 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 12:
  Value: 0.8986
  num_layers: 3
  units_0: 192
  units_1: 352
  units_2: 512
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.009718560135321052

Model: "sequential_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_12 (Flatten)        (None, 784)               0         
                                                                 
 dense_36 (Dense)            (None, 192)               150720    
                                                                 
 batch_normalization_13 (Ba  (None, 192)               768       
 tchNormalization)                                               
                                                                 
 dropout_24 (Dropout)        (None, 192)               0         
                                                                 
 dense_37 (Dense)            (None, 352)               67936     
                                                                 
 batch_normalization_14 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_25 (Dropout)        (None, 352)               0         
                                                                 
 dense_38 (Dense)            (None, 512)               180736    
                                                                 
 dropout_26 (Dropout)        (None, 512)               0         
                                                                 
 dense_39 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 414906 (1.58 MB)
Trainable params: 413818 (1.58 MB)
Non-trainable params: 1088 (4.25 KB)
_________________________________________________________________



Trial 13:
  Value: 0.8683
  num_layers: 3
  units_0: 192
  units_1: 384
  units_2: 512
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.009054204079654956

Model: "sequential_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_13 (Flatten)        (None, 784)               0         
                                                                 
 dense_40 (Dense)            (None, 192)               150720    
                                                                 
 batch_normalization_15 (Ba  (None, 192)               768       
 tchNormalization)                                               
                                                                 
 dropout_27 (Dropout)        (None, 192)               0         
                                                                 
 dense_41 (Dense)            (None, 384)               74112     
                                                                 
 dropout_28 (Dropout)        (None, 384)               0         
                                                                 
 dense_42 (Dense)            (None, 512)               197120    
                                                                 
 dropout_29 (Dropout)        (None, 512)               0         
                                                                 
 dense_43 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 436058 (1.66 MB)
Trainable params: 435674 (1.66 MB)
Non-trainable params: 384 (1.50 KB)
_________________________________________________________________



Trial 14:
  Value: 0.8952
  num_layers: 3
  units_0: 224
  units_1: 352
  units_2: 512
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.009741475676035498

Model: "sequential_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_14 (Flatten)        (None, 784)               0         
                                                                 
 dense_44 (Dense)            (None, 224)               175840    
                                                                 
 batch_normalization_16 (Ba  (None, 224)               896       
 tchNormalization)                                               
                                                                 
 dropout_30 (Dropout)        (None, 224)               0         
                                                                 
 dense_45 (Dense)            (None, 352)               79200     
                                                                 
 batch_normalization_17 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_31 (Dropout)        (None, 352)               0         
                                                                 
 dense_46 (Dense)            (None, 512)               180736    
                                                                 
 dropout_32 (Dropout)        (None, 512)               0         
                                                                 
 dense_47 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 451418 (1.72 MB)
Trainable params: 450266 (1.72 MB)
Non-trainable params: 1152 (4.50 KB)
_________________________________________________________________



Trial 15:
  Value: 0.8815
  num_layers: 3
  units_0: 288
  units_1: 352
  units_2: 384
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.0043075200828464255

Model: "sequential_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_15 (Flatten)        (None, 784)               0         
                                                                 
 dense_48 (Dense)            (None, 288)               226080    
                                                                 
 batch_normalization_18 (Ba  (None, 288)               1152      
 tchNormalization)                                               
                                                                 
 dropout_33 (Dropout)        (None, 288)               0         
                                                                 
 dense_49 (Dense)            (None, 352)               101728    
                                                                 
 batch_normalization_19 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_34 (Dropout)        (None, 352)               0         
                                                                 
 dense_50 (Dense)            (None, 384)               135552    
                                                                 
 dropout_35 (Dropout)        (None, 384)               0         
                                                                 
 dense_51 (Dense)            (None, 26)                10010     
                                                                 
=================================================================
Total params: 475930 (1.82 MB)
Trainable params: 474650 (1.81 MB)
Non-trainable params: 1280 (5.00 KB)
_________________________________________________________________



Trial 16:
  Value: 0.6607
  num_layers: 3
  units_0: 256
  units_1: 352
  units_2: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.009665654218312924

Model: "sequential_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_16 (Flatten)        (None, 784)               0         
                                                                 
 dense_52 (Dense)            (None, 256)               200960    
                                                                 
 batch_normalization_20 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_36 (Dropout)        (None, 256)               0         
                                                                 
 dense_53 (Dense)            (None, 352)               90464     
                                                                 
 batch_normalization_21 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_37 (Dropout)        (None, 352)               0         
                                                                 
 dense_54 (Dense)            (None, 512)               180736    
                                                                 
 dropout_38 (Dropout)        (None, 512)               0         
                                                                 
 dense_55 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 487930 (1.86 MB)
Trainable params: 486714 (1.86 MB)
Non-trainable params: 1216 (4.75 KB)
_________________________________________________________________



Trial 17:
  Value: 0.0403
  num_layers: 4
  units_0: 352
  units_1: 256
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.5
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0035072025444071665

Model: "sequential_17"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_17 (Flatten)        (None, 784)               0         
                                                                 
 dense_56 (Dense)            (None, 352)               276320    
                                                                 
 batch_normalization_22 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_39 (Dropout)        (None, 352)               0         
                                                                 
 dense_57 (Dense)            (None, 256)               90368     
                                                                 
 batch_normalization_23 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_40 (Dropout)        (None, 256)               0         
                                                                 
 dense_58 (Dense)            (None, 384)               98688     
                                                                 
 batch_normalization_24 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_41 (Dropout)        (None, 384)               0         
                                                                 
 dense_59 (Dense)            (None, 512)               197120    
                                                                 
 dropout_42 (Dropout)        (None, 512)               0         
                                                                 
 dense_60 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 679802 (2.59 MB)
Trainable params: 677818 (2.59 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 18:
  Value: 0.8768
  num_layers: 3
  units_0: 128
  units_1: 384
  units_2: 160
  activation_0: tanh
  activation_1: relu
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.4
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: False
  optimizer: adam
  learning_rate: 0.005417475544020697

Model: "sequential_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_18 (Flatten)        (None, 784)               0         
                                                                 
 dense_61 (Dense)            (None, 128)               100480    
                                                                 
 dropout_43 (Dropout)        (None, 128)               0         
                                                                 
 dense_62 (Dense)            (None, 384)               49536     
                                                                 
 batch_normalization_25 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_44 (Dropout)        (None, 384)               0         
                                                                 
 dense_63 (Dense)            (None, 160)               61600     
                                                                 
 dropout_45 (Dropout)        (None, 160)               0         
                                                                 
 dense_64 (Dense)            (None, 26)                4186      
                                                                 
=================================================================
Total params: 217338 (848.98 KB)
Trainable params: 216570 (845.98 KB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 19:
  Value: 0.6459
  num_layers: 4
  units_0: 32
  units_1: 256
  units_2: 416
  units_3: 32
  activation_0: tanh
  activation_1: relu
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.5
  dropout_2: 0.4
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  batch_norm_3: True
  optimizer: rmsprop
  learning_rate: 0.0027965720878281963

Model: "sequential_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_19 (Flatten)        (None, 784)               0         
                                                                 
 dense_65 (Dense)            (None, 32)                25120     
                                                                 
 batch_normalization_26 (Ba  (None, 32)                128       
 tchNormalization)                                               
                                                                 
 dropout_46 (Dropout)        (None, 32)                0         
                                                                 
 dense_66 (Dense)            (None, 256)               8448      
                                                                 
 batch_normalization_27 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_47 (Dropout)        (None, 256)               0         
                                                                 
 dense_67 (Dense)            (None, 416)               106912    
                                                                 
 dropout_48 (Dropout)        (None, 416)               0         
                                                                 
 dense_68 (Dense)            (None, 32)                13344     
                                                                 
 batch_normalization_28 (Ba  (None, 32)                128       
 tchNormalization)                                               
                                                                 
 dropout_49 (Dropout)        (None, 32)                0         
                                                                 
 dense_69 (Dense)            (None, 26)                858       
                                                                 
=================================================================
Total params: 155962 (609.23 KB)
Trainable params: 155322 (606.73 KB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 20:
  Value: 0.6442
  num_layers: 3
  units_0: 224
  units_1: 416
  units_2: 224
  activation_0: tanh
  activation_1: tanh
  activation_2: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: True
  optimizer: rmsprop
  learning_rate: 0.0052432509795190185

Model: "sequential_20"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_20 (Flatten)        (None, 784)               0         
                                                                 
 dense_70 (Dense)            (None, 224)               175840    
                                                                 
 batch_normalization_29 (Ba  (None, 224)               896       
 tchNormalization)                                               
                                                                 
 dropout_50 (Dropout)        (None, 224)               0         
                                                                 
 dense_71 (Dense)            (None, 416)               93600     
                                                                 
 batch_normalization_30 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_51 (Dropout)        (None, 416)               0         
                                                                 
 dense_72 (Dense)            (None, 224)               93408     
                                                                 
 batch_normalization_31 (Ba  (None, 224)               896       
 tchNormalization)                                               
                                                                 
 dropout_52 (Dropout)        (None, 224)               0         
                                                                 
 dense_73 (Dense)            (None, 26)                5850      
                                                                 
=================================================================
Total params: 372154 (1.42 MB)
Trainable params: 370426 (1.41 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 21:
  Value: 0.8955
  num_layers: 3
  units_0: 288
  units_1: 320
  units_2: 416
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.009856132438547643

Model: "sequential_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_21 (Flatten)        (None, 784)               0         
                                                                 
 dense_74 (Dense)            (None, 288)               226080    
                                                                 
 batch_normalization_32 (Ba  (None, 288)               1152      
 tchNormalization)                                               
                                                                 
 dropout_53 (Dropout)        (None, 288)               0         
                                                                 
 dense_75 (Dense)            (None, 320)               92480     
                                                                 
 batch_normalization_33 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_54 (Dropout)        (None, 320)               0         
                                                                 
 dense_76 (Dense)            (None, 416)               133536    
                                                                 
 dropout_55 (Dropout)        (None, 416)               0         
                                                                 
 dense_77 (Dense)            (None, 26)                10842     
                                                                 
=================================================================
Total params: 465370 (1.78 MB)
Trainable params: 464154 (1.77 MB)
Non-trainable params: 1216 (4.75 KB)
_________________________________________________________________



Trial 22:
  Value: 0.8790
  num_layers: 3
  units_0: 320
  units_1: 320
  units_2: 448
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.009712405434137579

Model: "sequential_22"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_22 (Flatten)        (None, 784)               0         
                                                                 
 dense_78 (Dense)            (None, 320)               251200    
                                                                 
 batch_normalization_34 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_56 (Dropout)        (None, 320)               0         
                                                                 
 dense_79 (Dense)            (None, 320)               102720    
                                                                 
 batch_normalization_35 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_57 (Dropout)        (None, 320)               0         
                                                                 
 dense_80 (Dense)            (None, 448)               143808    
                                                                 
 dropout_58 (Dropout)        (None, 448)               0         
                                                                 
 dense_81 (Dense)            (None, 26)                11674     
                                                                 
=================================================================
Total params: 511962 (1.95 MB)
Trainable params: 510682 (1.95 MB)
Non-trainable params: 1280 (5.00 KB)
_________________________________________________________________



Trial 23:
  Value: 0.6428
  num_layers: 3
  units_0: 416
  units_1: 192
  units_2: 448
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.5
  dropout_1: 0.30000000000000004
  dropout_2: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.005993300633347334

Model: "sequential_23"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_23 (Flatten)        (None, 784)               0         
                                                                 
 dense_82 (Dense)            (None, 416)               326560    
                                                                 
 batch_normalization_36 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_59 (Dropout)        (None, 416)               0         
                                                                 
 dense_83 (Dense)            (None, 192)               80064     
                                                                 
 batch_normalization_37 (Ba  (None, 192)               768       
 tchNormalization)                                               
                                                                 
 dropout_60 (Dropout)        (None, 192)               0         
                                                                 
 dense_84 (Dense)            (None, 448)               86464     
                                                                 
 dropout_61 (Dropout)        (None, 448)               0         
                                                                 
 dense_85 (Dense)            (None, 26)                11674     
                                                                 
=================================================================
Total params: 507194 (1.93 MB)
Trainable params: 505978 (1.93 MB)
Non-trainable params: 1216 (4.75 KB)
_________________________________________________________________



Trial 24:
  Value: 0.8948
  num_layers: 2
  units_0: 224
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.006268282891266567

Model: "sequential_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_24 (Flatten)        (None, 784)               0         
                                                                 
 dense_86 (Dense)            (None, 224)               175840    
                                                                 
 batch_normalization_38 (Ba  (None, 224)               896       
 tchNormalization)                                               
                                                                 
 dropout_62 (Dropout)        (None, 224)               0         
                                                                 
 dense_87 (Dense)            (None, 416)               93600     
                                                                 
 batch_normalization_39 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_63 (Dropout)        (None, 416)               0         
                                                                 
 dense_88 (Dense)            (None, 26)                10842     
                                                                 
=================================================================
Total params: 282842 (1.08 MB)
Trainable params: 281562 (1.07 MB)
Non-trainable params: 1280 (5.00 KB)
_________________________________________________________________



Trial 25:
  Value: 0.8884
  num_layers: 4
  units_0: 256
  units_1: 288
  units_2: 512
  units_3: 256
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.5
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  batch_norm_3: True
  optimizer: rmsprop
  learning_rate: 0.007077363055402811

Model: "sequential_25"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_25 (Flatten)        (None, 784)               0         
                                                                 
 dense_89 (Dense)            (None, 256)               200960    
                                                                 
 batch_normalization_40 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_64 (Dropout)        (None, 256)               0         
                                                                 
 dense_90 (Dense)            (None, 288)               74016     
                                                                 
 batch_normalization_41 (Ba  (None, 288)               1152      
 tchNormalization)                                               
                                                                 
 dropout_65 (Dropout)        (None, 288)               0         
                                                                 
 dense_91 (Dense)            (None, 512)               147968    
                                                                 
 dropout_66 (Dropout)        (None, 512)               0         
                                                                 
 dense_92 (Dense)            (None, 256)               131328    
                                                                 
 batch_normalization_42 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_67 (Dropout)        (None, 256)               0         
                                                                 
 dense_93 (Dense)            (None, 26)                6682      
                                                                 
=================================================================
Total params: 564154 (2.15 MB)
Trainable params: 562554 (2.15 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 26:
  Value: 0.0804
  num_layers: 3
  units_0: 192
  units_1: 416
  units_2: 320
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.4
  dropout_1: 0.5
  dropout_2: 0.2
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: False
  optimizer: adagrad
  learning_rate: 0.0034596261022782327

Model: "sequential_26"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_26 (Flatten)        (None, 784)               0         
                                                                 
 dense_94 (Dense)            (None, 192)               150720    
                                                                 
 dropout_68 (Dropout)        (None, 192)               0         
                                                                 
 dense_95 (Dense)            (None, 416)               80288     
                                                                 
 batch_normalization_43 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_69 (Dropout)        (None, 416)               0         
                                                                 
 dense_96 (Dense)            (None, 320)               133440    
                                                                 
 dropout_70 (Dropout)        (None, 320)               0         
                                                                 
 dense_97 (Dense)            (None, 26)                8346      
                                                                 
=================================================================
Total params: 374458 (1.43 MB)
Trainable params: 373626 (1.43 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 27:
  Value: 0.5907
  num_layers: 2
  units_0: 416
  units_1: 320
  activation_0: tanh
  activation_1: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  batch_norm_0: True
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.009466115408550033

Model: "sequential_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_27 (Flatten)        (None, 784)               0         
                                                                 
 dense_98 (Dense)            (None, 416)               326560    
                                                                 
 batch_normalization_44 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_71 (Dropout)        (None, 416)               0         
                                                                 
 dense_99 (Dense)            (None, 320)               133440    
                                                                 
 batch_normalization_45 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_72 (Dropout)        (None, 320)               0         
                                                                 
 dense_100 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 471290 (1.80 MB)
Trainable params: 469818 (1.79 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 28:
  Value: 0.4606
  num_layers: 3
  units_0: 320
  units_1: 224
  units_2: 448
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  dropout_0: 0.5
  dropout_1: 0.4
  dropout_2: 0.4
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: sgd
  learning_rate: 0.004855976728297997

Model: "sequential_28"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_28 (Flatten)        (None, 784)               0         
                                                                 
 dense_101 (Dense)           (None, 320)               251200    
                                                                 
 batch_normalization_46 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_73 (Dropout)        (None, 320)               0         
                                                                 
 dense_102 (Dense)           (None, 224)               71904     
                                                                 
 batch_normalization_47 (Ba  (None, 224)               896       
 tchNormalization)                                               
                                                                 
 dropout_74 (Dropout)        (None, 224)               0         
                                                                 
 dense_103 (Dense)           (None, 448)               100800    
                                                                 
 dropout_75 (Dropout)        (None, 448)               0         
                                                                 
 dense_104 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 437754 (1.67 MB)
Trainable params: 436666 (1.67 MB)
Non-trainable params: 1088 (4.25 KB)
_________________________________________________________________



Trial 29:
  Value: 0.7715
  num_layers: 4
  units_0: 96
  units_1: 96
  units_2: 352
  units_3: 512
  activation_0: tanh
  activation_1: relu
  activation_2: tanh
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  dropout_2: 0.30000000000000004
  dropout_3: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.00272836095687241

Model: "sequential_29"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_29 (Flatten)        (None, 784)               0         
                                                                 
 dense_105 (Dense)           (None, 96)                75360     
                                                                 
 batch_normalization_48 (Ba  (None, 96)                384       
 tchNormalization)                                               
                                                                 
 dropout_76 (Dropout)        (None, 96)                0         
                                                                 
 dense_106 (Dense)           (None, 96)                9312      
                                                                 
 batch_normalization_49 (Ba  (None, 96)                384       
 tchNormalization)                                               
                                                                 
 dropout_77 (Dropout)        (None, 96)                0         
                                                                 
 dense_107 (Dense)           (None, 352)               34144     
                                                                 
 batch_normalization_50 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_78 (Dropout)        (None, 352)               0         
                                                                 
 dense_108 (Dense)           (None, 512)               180736    
                                                                 
 dropout_79 (Dropout)        (None, 512)               0         
                                                                 
 dense_109 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 315066 (1.20 MB)
Trainable params: 313978 (1.20 MB)
Non-trainable params: 1088 (4.25 KB)
_________________________________________________________________



Trial 30:
  Value: 0.8849
  num_layers: 3
  units_0: 160
  units_1: 320
  units_2: 448
  activation_0: relu
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.0
  dropout_1: 0.1
  dropout_2: 0.1
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.0070262562847919685

Model: "sequential_30"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_30 (Flatten)        (None, 784)               0         
                                                                 
 dense_110 (Dense)           (None, 160)               125600    
                                                                 
 batch_normalization_51 (Ba  (None, 160)               640       
 tchNormalization)                                               
                                                                 
 dropout_80 (Dropout)        (None, 160)               0         
                                                                 
 dense_111 (Dense)           (None, 320)               51520     
                                                                 
 batch_normalization_52 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_81 (Dropout)        (None, 320)               0         
                                                                 
 dense_112 (Dense)           (None, 448)               143808    
                                                                 
 dropout_82 (Dropout)        (None, 448)               0         
                                                                 
 dense_113 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 334522 (1.28 MB)
Trainable params: 333562 (1.27 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 31:
  Value: 0.8997
  num_layers: 2
  units_0: 224
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.006793013051171431

Model: "sequential_31"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_31 (Flatten)        (None, 784)               0         
                                                                 
 dense_114 (Dense)           (None, 224)               175840    
                                                                 
 batch_normalization_53 (Ba  (None, 224)               896       
 tchNormalization)                                               
                                                                 
 dropout_83 (Dropout)        (None, 224)               0         
                                                                 
 dense_115 (Dense)           (None, 416)               93600     
                                                                 
 batch_normalization_54 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_84 (Dropout)        (None, 416)               0         
                                                                 
 dense_116 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 282842 (1.08 MB)
Trainable params: 281562 (1.07 MB)
Non-trainable params: 1280 (5.00 KB)
_________________________________________________________________



Trial 32:
  Value: 0.8886
  num_layers: 2
  units_0: 256
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.007446330081082557

Model: "sequential_32"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_32 (Flatten)        (None, 784)               0         
                                                                 
 dense_117 (Dense)           (None, 256)               200960    
                                                                 
 batch_normalization_55 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_85 (Dropout)        (None, 256)               0         
                                                                 
 dense_118 (Dense)           (None, 448)               115136    
                                                                 
 batch_normalization_56 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_86 (Dropout)        (None, 448)               0         
                                                                 
 dense_119 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 330586 (1.26 MB)
Trainable params: 329178 (1.26 MB)
Non-trainable params: 1408 (5.50 KB)
_________________________________________________________________



Trial 33:
  Value: 0.8896
  num_layers: 2
  units_0: 192
  units_1: 352
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: True
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.009926572895099541

Model: "sequential_33"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_33 (Flatten)        (None, 784)               0         
                                                                 
 dense_120 (Dense)           (None, 192)               150720    
                                                                 
 batch_normalization_57 (Ba  (None, 192)               768       
 tchNormalization)                                               
                                                                 
 dropout_87 (Dropout)        (None, 192)               0         
                                                                 
 dense_121 (Dense)           (None, 352)               67936     
                                                                 
 batch_normalization_58 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_88 (Dropout)        (None, 352)               0         
                                                                 
 dense_122 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 230010 (898.48 KB)
Trainable params: 228922 (894.23 KB)
Non-trainable params: 1088 (4.25 KB)
_________________________________________________________________



Trial 34:
  Value: 0.8993
  num_layers: 2
  units_0: 288
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.004808890743514455

Model: "sequential_34"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_34 (Flatten)        (None, 784)               0         
                                                                 
 dense_123 (Dense)           (None, 288)               226080    
                                                                 
 dropout_89 (Dropout)        (None, 288)               0         
                                                                 
 dense_124 (Dense)           (None, 384)               110976    
                                                                 
 batch_normalization_59 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_90 (Dropout)        (None, 384)               0         
                                                                 
 dense_125 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 348602 (1.33 MB)
Trainable params: 347834 (1.33 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 35:
  Value: 0.8030
  num_layers: 2
  units_0: 320
  units_1: 512
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.004372437285383726

Model: "sequential_35"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_35 (Flatten)        (None, 784)               0         
                                                                 
 dense_126 (Dense)           (None, 320)               251200    
                                                                 
 dropout_91 (Dropout)        (None, 320)               0         
                                                                 
 dense_127 (Dense)           (None, 512)               164352    
                                                                 
 dropout_92 (Dropout)        (None, 512)               0         
                                                                 
 dense_128 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 428890 (1.64 MB)
Trainable params: 428890 (1.64 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 36:
  Value: 0.3838
  num_layers: 2
  units_0: 288
  units_1: 384
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  optimizer: sgd
  learning_rate: 0.006743031693837703

Model: "sequential_36"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_36 (Flatten)        (None, 784)               0         
                                                                 
 dense_129 (Dense)           (None, 288)               226080    
                                                                 
 dropout_93 (Dropout)        (None, 288)               0         
                                                                 
 dense_130 (Dense)           (None, 384)               110976    
                                                                 
 batch_normalization_60 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_94 (Dropout)        (None, 384)               0         
                                                                 
 dense_131 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 348602 (1.33 MB)
Trainable params: 347834 (1.33 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 37:
  Value: 0.6603
  num_layers: 2
  units_0: 384
  units_1: 416
  activation_0: tanh
  activation_1: tanh
  dropout_0: 0.2
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.0018999082288046116

Model: "sequential_37"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_37 (Flatten)        (None, 784)               0         
                                                                 
 dense_132 (Dense)           (None, 384)               301440    
                                                                 
 dropout_95 (Dropout)        (None, 384)               0         
                                                                 
 dense_133 (Dense)           (None, 416)               160160    
                                                                 
 batch_normalization_61 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_96 (Dropout)        (None, 416)               0         
                                                                 
 dense_134 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 474106 (1.81 MB)
Trainable params: 473274 (1.81 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 38:
  Value: 0.4011
  num_layers: 1
  units_0: 288
  activation_0: tanh
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: sgd
  learning_rate: 0.004701954290119465

Model: "sequential_38"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_38 (Flatten)        (None, 784)               0         
                                                                 
 dense_135 (Dense)           (None, 288)               226080    
                                                                 
 dropout_97 (Dropout)        (None, 288)               0         
                                                                 
 dense_136 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 233594 (912.48 KB)
Trainable params: 233594 (912.48 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 39:
  Value: 0.0522
  num_layers: 2
  units_0: 128
  units_1: 448
  activation_0: sigmoid
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adagrad
  learning_rate: 0.0055451711968614635

Model: "sequential_39"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_39 (Flatten)        (None, 784)               0         
                                                                 
 dense_137 (Dense)           (None, 128)               100480    
                                                                 
 dropout_98 (Dropout)        (None, 128)               0         
                                                                 
 dense_138 (Dense)           (None, 448)               57792     
                                                                 
 batch_normalization_62 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_99 (Dropout)        (None, 448)               0         
                                                                 
 dense_139 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 171738 (670.85 KB)
Trainable params: 170842 (667.35 KB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 40:
  Value: 0.0373
  num_layers: 2
  units_0: 320
  units_1: 32
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0037890053588579744

Model: "sequential_40"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_40 (Flatten)        (None, 784)               0         
                                                                 
 dense_140 (Dense)           (None, 320)               251200    
                                                                 
 dropout_100 (Dropout)       (None, 320)               0         
                                                                 
 dense_141 (Dense)           (None, 32)                10272     
                                                                 
 dropout_101 (Dropout)       (None, 32)                0         
                                                                 
 dense_142 (Dense)           (None, 26)                858       
                                                                 
=================================================================
Total params: 262330 (1.00 MB)
Trainable params: 262330 (1.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 41:
  Value: 0.7457
  num_layers: 3
  units_0: 224
  units_1: 352
  units_2: 256
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.5
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.008160628730879409

Model: "sequential_41"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_41 (Flatten)        (None, 784)               0         
                                                                 
 dense_143 (Dense)           (None, 224)               175840    
                                                                 
 batch_normalization_63 (Ba  (None, 224)               896       
 tchNormalization)                                               
                                                                 
 dropout_102 (Dropout)       (None, 224)               0         
                                                                 
 dense_144 (Dense)           (None, 352)               79200     
                                                                 
 batch_normalization_64 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_103 (Dropout)       (None, 352)               0         
                                                                 
 dense_145 (Dense)           (None, 256)               90368     
                                                                 
 dropout_104 (Dropout)       (None, 256)               0         
                                                                 
 dense_146 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 354394 (1.35 MB)
Trainable params: 353242 (1.35 MB)
Non-trainable params: 1152 (4.50 KB)
_________________________________________________________________



Trial 42:
  Value: 0.7953
  num_layers: 3
  units_0: 256
  units_1: 320
  units_2: 480
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  optimizer: rmsprop
  learning_rate: 0.0075145210290853155

Model: "sequential_42"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_42 (Flatten)        (None, 784)               0         
                                                                 
 dense_147 (Dense)           (None, 256)               200960    
                                                                 
 batch_normalization_65 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_105 (Dropout)       (None, 256)               0         
                                                                 
 dense_148 (Dense)           (None, 320)               82240     
                                                                 
 batch_normalization_66 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_106 (Dropout)       (None, 320)               0         
                                                                 
 dense_149 (Dense)           (None, 480)               154080    
                                                                 
 dropout_107 (Dropout)       (None, 480)               0         
                                                                 
 dense_150 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 452090 (1.72 MB)
Trainable params: 450938 (1.72 MB)
Non-trainable params: 1152 (4.50 KB)
_________________________________________________________________



Trial 43:
  Value: 0.8868
  num_layers: 2
  units_0: 192
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.006059786874886311

Model: "sequential_43"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_43 (Flatten)        (None, 784)               0         
                                                                 
 dense_151 (Dense)           (None, 192)               150720    
                                                                 
 batch_normalization_67 (Ba  (None, 192)               768       
 tchNormalization)                                               
                                                                 
 dropout_108 (Dropout)       (None, 192)               0         
                                                                 
 dense_152 (Dense)           (None, 384)               74112     
                                                                 
 batch_normalization_68 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_109 (Dropout)       (None, 384)               0         
                                                                 
 dense_153 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 237146 (926.35 KB)
Trainable params: 235994 (921.85 KB)
Non-trainable params: 1152 (4.50 KB)
_________________________________________________________________



Trial 44:
  Value: 0.8963
  num_layers: 3
  units_0: 224
  units_1: 448
  units_2: 384
  activation_0: tanh
  activation_1: relu
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: rmsprop
  learning_rate: 0.007879267895739136

Model: "sequential_44"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_44 (Flatten)        (None, 784)               0         
                                                                 
 dense_154 (Dense)           (None, 224)               175840    
                                                                 
 dropout_110 (Dropout)       (None, 224)               0         
                                                                 
 dense_155 (Dense)           (None, 448)               100800    
                                                                 
 batch_normalization_69 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_111 (Dropout)       (None, 448)               0         
                                                                 
 dense_156 (Dense)           (None, 384)               172416    
                                                                 
 batch_normalization_70 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_112 (Dropout)       (None, 384)               0         
                                                                 
 dense_157 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 462394 (1.76 MB)
Trainable params: 460730 (1.76 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 45:
  Value: 0.6827
  num_layers: 2
  units_0: 128
  units_1: 448
  activation_0: tanh
  activation_1: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.007503955643111353

Model: "sequential_45"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_45 (Flatten)        (None, 784)               0         
                                                                 
 dense_158 (Dense)           (None, 128)               100480    
                                                                 
 dropout_113 (Dropout)       (None, 128)               0         
                                                                 
 dense_159 (Dense)           (None, 448)               57792     
                                                                 
 dropout_114 (Dropout)       (None, 448)               0         
                                                                 
 dense_160 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 169946 (663.85 KB)
Trainable params: 169946 (663.85 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 46:
  Value: 0.6075
  num_layers: 1
  units_0: 288
  activation_0: sigmoid
  dropout_0: 0.5
  batch_norm_0: False
  optimizer: adamax
  learning_rate: 0.007969203295037211

Model: "sequential_46"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_46 (Flatten)        (None, 784)               0         
                                                                 
 dense_161 (Dense)           (None, 288)               226080    
                                                                 
 dropout_115 (Dropout)       (None, 288)               0         
                                                                 
 dense_162 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 233594 (912.48 KB)
Trainable params: 233594 (912.48 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 47:
  Value: 0.0389
  num_layers: 3
  units_0: 160
  units_1: 512
  units_2: 384
  activation_0: tanh
  activation_1: relu
  activation_2: relu
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.5
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: ftrl
  learning_rate: 0.005797733769060194

Model: "sequential_47"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_47 (Flatten)        (None, 784)               0         
                                                                 
 dense_163 (Dense)           (None, 160)               125600    
                                                                 
 dropout_116 (Dropout)       (None, 160)               0         
                                                                 
 dense_164 (Dense)           (None, 512)               82432     
                                                                 
 batch_normalization_71 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_117 (Dropout)       (None, 512)               0         
                                                                 
 dense_165 (Dense)           (None, 384)               196992    
                                                                 
 batch_normalization_72 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_118 (Dropout)       (None, 384)               0         
                                                                 
 dense_166 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 418618 (1.60 MB)
Trainable params: 416826 (1.59 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 48:
  Value: 0.9003
  num_layers: 3
  units_0: 352
  units_1: 480
  units_2: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.4
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0006140378222818938

Model: "sequential_48"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_48 (Flatten)        (None, 784)               0         
                                                                 
 dense_167 (Dense)           (None, 352)               276320    
                                                                 
 dropout_119 (Dropout)       (None, 352)               0         
                                                                 
 dense_168 (Dense)           (None, 480)               169440    
                                                                 
 batch_normalization_73 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_120 (Dropout)       (None, 480)               0         
                                                                 
 dense_169 (Dense)           (None, 288)               138528    
                                                                 
 batch_normalization_74 (Ba  (None, 288)               1152      
 tchNormalization)                                               
                                                                 
 dropout_121 (Dropout)       (None, 288)               0         
                                                                 
 dense_170 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 594874 (2.27 MB)
Trainable params: 593338 (2.26 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 49:
  Value: 0.7288
  num_layers: 1
  units_0: 64
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0005825257965514094

Model: "sequential_49"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_49 (Flatten)        (None, 784)               0         
                                                                 
 dense_171 (Dense)           (None, 64)                50240     
                                                                 
 dropout_122 (Dropout)       (None, 64)                0         
                                                                 
 dense_172 (Dense)           (None, 26)                1690      
                                                                 
=================================================================
Total params: 51930 (202.85 KB)
Trainable params: 51930 (202.85 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 50:
  Value: 0.8974
  num_layers: 2
  units_0: 352
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009477560264122566

Model: "sequential_50"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_50 (Flatten)        (None, 784)               0         
                                                                 
 dense_173 (Dense)           (None, 352)               276320    
                                                                 
 dropout_123 (Dropout)       (None, 352)               0         
                                                                 
 dense_174 (Dense)           (None, 480)               169440    
                                                                 
 dropout_124 (Dropout)       (None, 480)               0         
                                                                 
 dense_175 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 458266 (1.75 MB)
Trainable params: 458266 (1.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 51:
  Value: 0.9011
  num_layers: 2
  units_0: 352
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006981886980662115

Model: "sequential_51"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_51 (Flatten)        (None, 784)               0         
                                                                 
 dense_176 (Dense)           (None, 352)               276320    
                                                                 
 dropout_125 (Dropout)       (None, 352)               0         
                                                                 
 dense_177 (Dense)           (None, 480)               169440    
                                                                 
 dropout_126 (Dropout)       (None, 480)               0         
                                                                 
 dense_178 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 458266 (1.75 MB)
Trainable params: 458266 (1.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 52:
  Value: 0.9018
  num_layers: 2
  units_0: 384
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007194134358295802

Model: "sequential_52"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_52 (Flatten)        (None, 784)               0         
                                                                 
 dense_179 (Dense)           (None, 384)               301440    
                                                                 
 dropout_127 (Dropout)       (None, 384)               0         
                                                                 
 dense_180 (Dense)           (None, 480)               184800    
                                                                 
 dropout_128 (Dropout)       (None, 480)               0         
                                                                 
 dense_181 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 498746 (1.90 MB)
Trainable params: 498746 (1.90 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 53:
  Value: 0.9032
  num_layers: 2
  units_0: 384
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007207884153190031

Model: "sequential_53"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_53 (Flatten)        (None, 784)               0         
                                                                 
 dense_182 (Dense)           (None, 384)               301440    
                                                                 
 dropout_129 (Dropout)       (None, 384)               0         
                                                                 
 dense_183 (Dense)           (None, 480)               184800    
                                                                 
 dropout_130 (Dropout)       (None, 480)               0         
                                                                 
 dense_184 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 498746 (1.90 MB)
Trainable params: 498746 (1.90 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 54:
  Value: 0.9083
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006286563925491797

Model: "sequential_54"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_54 (Flatten)        (None, 784)               0         
                                                                 
 dense_185 (Dense)           (None, 480)               376800    
                                                                 
 dropout_131 (Dropout)       (None, 480)               0         
                                                                 
 dense_186 (Dense)           (None, 512)               246272    
                                                                 
 dropout_132 (Dropout)       (None, 512)               0         
                                                                 
 dense_187 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 55:
  Value: 0.8990
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006568410501324989

Model: "sequential_55"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_55 (Flatten)        (None, 784)               0         
                                                                 
 dense_188 (Dense)           (None, 480)               376800    
                                                                 
 dropout_133 (Dropout)       (None, 480)               0         
                                                                 
 dense_189 (Dense)           (None, 512)               246272    
                                                                 
 dropout_134 (Dropout)       (None, 512)               0         
                                                                 
 dense_190 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 56:
  Value: 0.9000
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000425089099255038

Model: "sequential_56"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_56 (Flatten)        (None, 784)               0         
                                                                 
 dense_191 (Dense)           (None, 448)               351680    
                                                                 
 dropout_135 (Dropout)       (None, 448)               0         
                                                                 
 dense_192 (Dense)           (None, 480)               215520    
                                                                 
 dropout_136 (Dropout)       (None, 480)               0         
                                                                 
 dense_193 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 57:
  Value: 0.9001
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004430275087439017

Model: "sequential_57"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_57 (Flatten)        (None, 784)               0         
                                                                 
 dense_194 (Dense)           (None, 448)               351680    
                                                                 
 dropout_137 (Dropout)       (None, 448)               0         
                                                                 
 dense_195 (Dense)           (None, 480)               215520    
                                                                 
 dropout_138 (Dropout)       (None, 480)               0         
                                                                 
 dense_196 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 58:
  Value: 0.9018
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00040886149849805994

Model: "sequential_58"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_58 (Flatten)        (None, 784)               0         
                                                                 
 dense_197 (Dense)           (None, 480)               376800    
                                                                 
 dropout_139 (Dropout)       (None, 480)               0         
                                                                 
 dense_198 (Dense)           (None, 480)               230880    
                                                                 
 dropout_140 (Dropout)       (None, 480)               0         
                                                                 
 dense_199 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 59:
  Value: 0.9023
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007388083973087753

Model: "sequential_59"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_59 (Flatten)        (None, 784)               0         
                                                                 
 dense_200 (Dense)           (None, 512)               401920    
                                                                 
 dropout_141 (Dropout)       (None, 512)               0         
                                                                 
 dense_201 (Dense)           (None, 512)               262656    
                                                                 
 dropout_142 (Dropout)       (None, 512)               0         
                                                                 
 dense_202 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 60:
  Value: 0.8738
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.5
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0007492027048491718

Model: "sequential_60"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_60 (Flatten)        (None, 784)               0         
                                                                 
 dense_203 (Dense)           (None, 512)               401920    
                                                                 
 dropout_143 (Dropout)       (None, 512)               0         
                                                                 
 dense_204 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 61:
  Value: 0.9012
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004560542395343119

Model: "sequential_61"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_61 (Flatten)        (None, 784)               0         
                                                                 
 dense_205 (Dense)           (None, 480)               376800    
                                                                 
 dropout_144 (Dropout)       (None, 480)               0         
                                                                 
 dense_206 (Dense)           (None, 512)               246272    
                                                                 
 dropout_145 (Dropout)       (None, 512)               0         
                                                                 
 dense_207 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 62:
  Value: 0.9016
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00048127956445951134

Model: "sequential_62"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_62 (Flatten)        (None, 784)               0         
                                                                 
 dense_208 (Dense)           (None, 480)               376800    
                                                                 
 dropout_146 (Dropout)       (None, 480)               0         
                                                                 
 dense_209 (Dense)           (None, 512)               246272    
                                                                 
 dropout_147 (Dropout)       (None, 512)               0         
                                                                 
 dense_210 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 63:
  Value: 0.9002
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004975462410660243

Model: "sequential_63"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_63 (Flatten)        (None, 784)               0         
                                                                 
 dense_211 (Dense)           (None, 480)               376800    
                                                                 
 dropout_148 (Dropout)       (None, 480)               0         
                                                                 
 dense_212 (Dense)           (None, 512)               246272    
                                                                 
 dropout_149 (Dropout)       (None, 512)               0         
                                                                 
 dense_213 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 64:
  Value: 0.8993
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003652614397544978

Model: "sequential_64"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_64 (Flatten)        (None, 784)               0         
                                                                 
 dense_214 (Dense)           (None, 480)               376800    
                                                                 
 dropout_150 (Dropout)       (None, 480)               0         
                                                                 
 dense_215 (Dense)           (None, 512)               246272    
                                                                 
 dropout_151 (Dropout)       (None, 512)               0         
                                                                 
 dense_216 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 65:
  Value: 0.8931
  num_layers: 2
  units_0: 416
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000312669333151202

Model: "sequential_65"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_65 (Flatten)        (None, 784)               0         
                                                                 
 dense_217 (Dense)           (None, 416)               326560    
                                                                 
 dropout_152 (Dropout)       (None, 416)               0         
                                                                 
 dense_218 (Dense)           (None, 512)               213504    
                                                                 
 dropout_153 (Dropout)       (None, 512)               0         
                                                                 
 dense_219 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 553402 (2.11 MB)
Trainable params: 553402 (2.11 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 66:
  Value: 0.8956
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007550408239125509

Model: "sequential_66"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_66 (Flatten)        (None, 784)               0         
                                                                 
 dense_220 (Dense)           (None, 512)               401920    
                                                                 
 dropout_154 (Dropout)       (None, 512)               0         
                                                                 
 dense_221 (Dense)           (None, 448)               229824    
                                                                 
 dropout_155 (Dropout)       (None, 448)               0         
                                                                 
 dense_222 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 67:
  Value: 0.8987
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005168065902827473

Model: "sequential_67"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_67 (Flatten)        (None, 784)               0         
                                                                 
 dense_223 (Dense)           (None, 480)               376800    
                                                                 
 dropout_156 (Dropout)       (None, 480)               0         
                                                                 
 dense_224 (Dense)           (None, 512)               246272    
                                                                 
 dropout_157 (Dropout)       (None, 512)               0         
                                                                 
 dense_225 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 68:
  Value: 0.8975
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008624509614322566

Model: "sequential_68"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_68 (Flatten)        (None, 784)               0         
                                                                 
 dense_226 (Dense)           (None, 448)               351680    
                                                                 
 dropout_158 (Dropout)       (None, 448)               0         
                                                                 
 dense_227 (Dense)           (None, 480)               215520    
                                                                 
 dropout_159 (Dropout)       (None, 480)               0         
                                                                 
 dense_228 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 69:
  Value: 0.8967
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005722201062368501

Model: "sequential_69"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_69 (Flatten)        (None, 784)               0         
                                                                 
 dense_229 (Dense)           (None, 512)               401920    
                                                                 
 dropout_160 (Dropout)       (None, 512)               0         
                                                                 
 dense_230 (Dense)           (None, 480)               246240    
                                                                 
 dropout_161 (Dropout)       (None, 480)               0         
                                                                 
 dense_231 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 70:
  Value: 0.8981
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012751236213060723

Model: "sequential_70"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_70 (Flatten)        (None, 784)               0         
                                                                 
 dense_232 (Dense)           (None, 480)               376800    
                                                                 
 dropout_162 (Dropout)       (None, 480)               0         
                                                                 
 dense_233 (Dense)           (None, 512)               246272    
                                                                 
 dropout_163 (Dropout)       (None, 512)               0         
                                                                 
 dense_234 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 71:
  Value: 0.8993
  num_layers: 2
  units_0: 384
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006669745514423989

Model: "sequential_71"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_71 (Flatten)        (None, 784)               0         
                                                                 
 dense_235 (Dense)           (None, 384)               301440    
                                                                 
 dropout_164 (Dropout)       (None, 384)               0         
                                                                 
 dense_236 (Dense)           (None, 480)               184800    
                                                                 
 dropout_165 (Dropout)       (None, 480)               0         
                                                                 
 dense_237 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 498746 (1.90 MB)
Trainable params: 498746 (1.90 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 72:
  Value: 0.8985
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007739356171686955

Model: "sequential_72"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_72 (Flatten)        (None, 784)               0         
                                                                 
 dense_238 (Dense)           (None, 416)               326560    
                                                                 
 dropout_166 (Dropout)       (None, 416)               0         
                                                                 
 dense_239 (Dense)           (None, 448)               186816    
                                                                 
 dropout_167 (Dropout)       (None, 448)               0         
                                                                 
 dense_240 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 73:
  Value: 0.8970
  num_layers: 2
  units_0: 384
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010555657972649752

Model: "sequential_73"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_73 (Flatten)        (None, 784)               0         
                                                                 
 dense_241 (Dense)           (None, 384)               301440    
                                                                 
 dropout_168 (Dropout)       (None, 384)               0         
                                                                 
 dense_242 (Dense)           (None, 512)               197120    
                                                                 
 dropout_169 (Dropout)       (None, 512)               0         
                                                                 
 dense_243 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 511898 (1.95 MB)
Trainable params: 511898 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 74:
  Value: 0.8879
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006806848414404472

Model: "sequential_74"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_74 (Flatten)        (None, 784)               0         
                                                                 
 dense_244 (Dense)           (None, 448)               351680    
                                                                 
 dropout_170 (Dropout)       (None, 448)               0         
                                                                 
 dense_245 (Dense)           (None, 448)               201152    
                                                                 
 dropout_171 (Dropout)       (None, 448)               0         
                                                                 
 dense_246 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 75:
  Value: 0.7993
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005272400797825813

Model: "sequential_75"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_75 (Flatten)        (None, 784)               0         
                                                                 
 dense_247 (Dense)           (None, 512)               401920    
                                                                 
 dropout_172 (Dropout)       (None, 512)               0         
                                                                 
 dense_248 (Dense)           (None, 480)               246240    
                                                                 
 dropout_173 (Dropout)       (None, 480)               0         
                                                                 
 dense_249 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 76:
  Value: 0.9010
  num_layers: 2
  units_0: 416
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00045065459257974204

Model: "sequential_76"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_76 (Flatten)        (None, 784)               0         
                                                                 
 dense_250 (Dense)           (None, 416)               326560    
                                                                 
 dropout_174 (Dropout)       (None, 416)               0         
                                                                 
 dense_251 (Dense)           (None, 512)               213504    
                                                                 
 dropout_175 (Dropout)       (None, 512)               0         
                                                                 
 dense_252 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 553402 (2.11 MB)
Trainable params: 553402 (2.11 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 77:
  Value: 0.1885
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.000845530357311009

Model: "sequential_77"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_77 (Flatten)        (None, 784)               0         
                                                                 
 dense_253 (Dense)           (None, 480)               376800    
                                                                 
 dropout_176 (Dropout)       (None, 480)               0         
                                                                 
 dense_254 (Dense)           (None, 480)               230880    
                                                                 
 dropout_177 (Dropout)       (None, 480)               0         
                                                                 
 dense_255 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 78:
  Value: 0.8168
  num_layers: 1
  units_0: 448
  activation_0: relu
  dropout_0: 0.5
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.00033724084657349543

Model: "sequential_78"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_78 (Flatten)        (None, 784)               0         
                                                                 
 dense_256 (Dense)           (None, 448)               351680    
                                                                 
 dropout_178 (Dropout)       (None, 448)               0         
                                                                 
 dense_257 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 363354 (1.39 MB)
Trainable params: 363354 (1.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 79:
  Value: 0.8708
  num_layers: 2
  units_0: 384
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006066103983411583

Model: "sequential_79"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_79 (Flatten)        (None, 784)               0         
                                                                 
 dense_258 (Dense)           (None, 384)               301440    
                                                                 
 dropout_179 (Dropout)       (None, 384)               0         
                                                                 
 dense_259 (Dense)           (None, 480)               184800    
                                                                 
 dropout_180 (Dropout)       (None, 480)               0         
                                                                 
 dense_260 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 498746 (1.90 MB)
Trainable params: 498746 (1.90 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 80:
  Value: 0.7973
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000392472159705521

Model: "sequential_80"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_80 (Flatten)        (None, 784)               0         
                                                                 
 dense_261 (Dense)           (None, 512)               401920    
                                                                 
 dropout_181 (Dropout)       (None, 512)               0         
                                                                 
 dense_262 (Dense)           (None, 448)               229824    
                                                                 
 dropout_182 (Dropout)       (None, 448)               0         
                                                                 
 dense_263 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 81:
  Value: 0.9010
  num_layers: 2
  units_0: 416
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00045948540422209897

Model: "sequential_81"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_81 (Flatten)        (None, 784)               0         
                                                                 
 dense_264 (Dense)           (None, 416)               326560    
                                                                 
 dropout_183 (Dropout)       (None, 416)               0         
                                                                 
 dense_265 (Dense)           (None, 512)               213504    
                                                                 
 dropout_184 (Dropout)       (None, 512)               0         
                                                                 
 dense_266 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 553402 (2.11 MB)
Trainable params: 553402 (2.11 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 82:
  Value: 0.8972
  num_layers: 2
  units_0: 416
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004803162063498206

Model: "sequential_82"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_82 (Flatten)        (None, 784)               0         
                                                                 
 dense_267 (Dense)           (None, 416)               326560    
                                                                 
 dropout_185 (Dropout)       (None, 416)               0         
                                                                 
 dense_268 (Dense)           (None, 512)               213504    
                                                                 
 dropout_186 (Dropout)       (None, 512)               0         
                                                                 
 dense_269 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 553402 (2.11 MB)
Trainable params: 553402 (2.11 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 83:
  Value: 0.8993
  num_layers: 2
  units_0: 448
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005475908949975534

Model: "sequential_83"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_83 (Flatten)        (None, 784)               0         
                                                                 
 dense_270 (Dense)           (None, 448)               351680    
                                                                 
 dropout_187 (Dropout)       (None, 448)               0         
                                                                 
 dense_271 (Dense)           (None, 512)               229888    
                                                                 
 dropout_188 (Dropout)       (None, 512)               0         
                                                                 
 dense_272 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 594906 (2.27 MB)
Trainable params: 594906 (2.27 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 84:
  Value: 0.4167
  num_layers: 2
  units_0: 384
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0003880999909786062

Model: "sequential_84"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_84 (Flatten)        (None, 784)               0         
                                                                 
 dense_273 (Dense)           (None, 384)               301440    
                                                                 
 dropout_189 (Dropout)       (None, 384)               0         
                                                                 
 dense_274 (Dense)           (None, 480)               184800    
                                                                 
 dropout_190 (Dropout)       (None, 480)               0         
                                                                 
 dense_275 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 498746 (1.90 MB)
Trainable params: 498746 (1.90 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 85:
  Value: 0.0385
  num_layers: 2
  units_0: 352
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0003075189673804267

Model: "sequential_85"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_85 (Flatten)        (None, 784)               0         
                                                                 
 dense_276 (Dense)           (None, 352)               276320    
                                                                 
 dropout_191 (Dropout)       (None, 352)               0         
                                                                 
 dense_277 (Dense)           (None, 512)               180736    
                                                                 
 dropout_192 (Dropout)       (None, 512)               0         
                                                                 
 dense_278 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 470394 (1.79 MB)
Trainable params: 470394 (1.79 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 86:
  Value: 0.7477
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006855215325483971

Model: "sequential_86"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_86 (Flatten)        (None, 784)               0         
                                                                 
 dense_279 (Dense)           (None, 480)               376800    
                                                                 
 dropout_193 (Dropout)       (None, 480)               0         
                                                                 
 dense_280 (Dense)           (None, 416)               200096    
                                                                 
 dropout_194 (Dropout)       (None, 416)               0         
                                                                 
 dense_281 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 87:
  Value: 0.7785
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0004943280577383174

Model: "sequential_87"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_87 (Flatten)        (None, 784)               0         
                                                                 
 dense_282 (Dense)           (None, 416)               326560    
                                                                 
 dropout_195 (Dropout)       (None, 416)               0         
                                                                 
 dense_283 (Dense)           (None, 448)               186816    
                                                                 
 dropout_196 (Dropout)       (None, 448)               0         
                                                                 
 dense_284 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 88:
  Value: 0.8283
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.30000000000000004
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0005577230893096123

Model: "sequential_88"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_88 (Flatten)        (None, 784)               0         
                                                                 
 dense_285 (Dense)           (None, 512)               401920    
                                                                 
 dropout_197 (Dropout)       (None, 512)               0         
                                                                 
 dense_286 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 89:
  Value: 0.8601
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00043007616849367593

Model: "sequential_89"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_89 (Flatten)        (None, 784)               0         
                                                                 
 dense_287 (Dense)           (None, 448)               351680    
                                                                 
 dropout_198 (Dropout)       (None, 448)               0         
                                                                 
 dense_288 (Dense)           (None, 480)               215520    
                                                                 
 dropout_199 (Dropout)       (None, 480)               0         
                                                                 
 dense_289 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 90:
  Value: 0.0938
  num_layers: 2
  units_0: 480
  units_1: 128
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0006098040483186078

Model: "sequential_90"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_90 (Flatten)        (None, 784)               0         
                                                                 
 dense_290 (Dense)           (None, 480)               376800    
                                                                 
 dropout_200 (Dropout)       (None, 480)               0         
                                                                 
 dense_291 (Dense)           (None, 128)               61568     
                                                                 
 dropout_201 (Dropout)       (None, 128)               0         
                                                                 
 dense_292 (Dense)           (None, 26)                3354      
                                                                 
=================================================================
Total params: 441722 (1.69 MB)
Trainable params: 441722 (1.69 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 91:
  Value: 0.9002
  num_layers: 2
  units_0: 416
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004583642531142011

Model: "sequential_91"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_91 (Flatten)        (None, 784)               0         
                                                                 
 dense_293 (Dense)           (None, 416)               326560    
                                                                 
 dropout_202 (Dropout)       (None, 416)               0         
                                                                 
 dense_294 (Dense)           (None, 512)               213504    
                                                                 
 dropout_203 (Dropout)       (None, 512)               0         
                                                                 
 dense_295 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 553402 (2.11 MB)
Trainable params: 553402 (2.11 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 92:
  Value: 0.8998
  num_layers: 2
  units_0: 384
  units_1: 512
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004798391678243625

Model: "sequential_92"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_92 (Flatten)        (None, 784)               0         
                                                                 
 dense_296 (Dense)           (None, 384)               301440    
                                                                 
 dropout_204 (Dropout)       (None, 384)               0         
                                                                 
 dense_297 (Dense)           (None, 512)               197120    
                                                                 
 dropout_205 (Dropout)       (None, 512)               0         
                                                                 
 dense_298 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 511898 (1.95 MB)
Trainable params: 511898 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 93:
  Value: 0.9047
  num_layers: 2
  units_0: 416
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005395034559618105

Model: "sequential_93"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_93 (Flatten)        (None, 784)               0         
                                                                 
 dense_299 (Dense)           (None, 416)               326560    
                                                                 
 dropout_206 (Dropout)       (None, 416)               0         
                                                                 
 dense_300 (Dense)           (None, 480)               200160    
                                                                 
 dropout_207 (Dropout)       (None, 480)               0         
                                                                 
 dense_301 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 539226 (2.06 MB)
Trainable params: 539226 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 94:
  Value: 0.8979
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007205975818298189

Model: "sequential_94"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_94 (Flatten)        (None, 784)               0         
                                                                 
 dense_302 (Dense)           (None, 448)               351680    
                                                                 
 dropout_208 (Dropout)       (None, 448)               0         
                                                                 
 dense_303 (Dense)           (None, 480)               215520    
                                                                 
 dropout_209 (Dropout)       (None, 480)               0         
                                                                 
 dense_304 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 95:
  Value: 0.9017
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008279336498078657

Model: "sequential_95"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_95 (Flatten)        (None, 784)               0         
                                                                 
 dense_305 (Dense)           (None, 480)               376800    
                                                                 
 dropout_210 (Dropout)       (None, 480)               0         
                                                                 
 dense_306 (Dense)           (None, 480)               230880    
                                                                 
 dropout_211 (Dropout)       (None, 480)               0         
                                                                 
 dense_307 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 96:
  Value: 0.7532
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008535804305985656

Model: "sequential_96"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_96 (Flatten)        (None, 784)               0         
                                                                 
 dense_308 (Dense)           (None, 480)               376800    
                                                                 
 dropout_212 (Dropout)       (None, 480)               0         
                                                                 
 dense_309 (Dense)           (None, 416)               200096    
                                                                 
 dropout_213 (Dropout)       (None, 416)               0         
                                                                 
 dense_310 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 97:
  Value: 0.9029
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006323023853199035

Model: "sequential_97"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_97 (Flatten)        (None, 784)               0         
                                                                 
 dense_311 (Dense)           (None, 512)               401920    
                                                                 
 dropout_214 (Dropout)       (None, 512)               0         
                                                                 
 dense_312 (Dense)           (None, 448)               229824    
                                                                 
 dropout_215 (Dropout)       (None, 448)               0         
                                                                 
 dense_313 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 98:
  Value: 0.3424
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0006162829259893897

Model: "sequential_98"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_98 (Flatten)        (None, 784)               0         
                                                                 
 dense_314 (Dense)           (None, 512)               401920    
                                                                 
 dropout_216 (Dropout)       (None, 512)               0         
                                                                 
 dense_315 (Dense)           (None, 448)               229824    
                                                                 
 dropout_217 (Dropout)       (None, 448)               0         
                                                                 
 dense_316 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 99:
  Value: 0.0417
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0009618440472024964

Model: "sequential_99"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_99 (Flatten)        (None, 784)               0         
                                                                 
 dense_317 (Dense)           (None, 480)               376800    
                                                                 
 dropout_218 (Dropout)       (None, 480)               0         
                                                                 
 dense_318 (Dense)           (None, 480)               230880    
                                                                 
 dropout_219 (Dropout)       (None, 480)               0         
                                                                 
 dense_319 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 100:
  Value: 0.9009
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005483848040052461

Model: "sequential_100"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_100 (Flatten)       (None, 784)               0         
                                                                 
 dense_320 (Dense)           (None, 512)               401920    
                                                                 
 dropout_220 (Dropout)       (None, 512)               0         
                                                                 
 dense_321 (Dense)           (None, 448)               229824    
                                                                 
 dropout_221 (Dropout)       (None, 448)               0         
                                                                 
 dense_322 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 101:
  Value: 0.9045
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007834646305051983

Model: "sequential_101"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_101 (Flatten)       (None, 784)               0         
                                                                 
 dense_323 (Dense)           (None, 512)               401920    
                                                                 
 dropout_222 (Dropout)       (None, 512)               0         
                                                                 
 dense_324 (Dense)           (None, 480)               246240    
                                                                 
 dropout_223 (Dropout)       (None, 480)               0         
                                                                 
 dense_325 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 102:
  Value: 0.9025
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.5
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000778358961642129

Model: "sequential_102"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_102 (Flatten)       (None, 784)               0         
                                                                 
 dense_326 (Dense)           (None, 512)               401920    
                                                                 
 dropout_224 (Dropout)       (None, 512)               0         
                                                                 
 dense_327 (Dense)           (None, 480)               246240    
                                                                 
 dropout_225 (Dropout)       (None, 480)               0         
                                                                 
 dense_328 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 103:
  Value: 0.9091
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008238532454282662

Model: "sequential_103"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_103 (Flatten)       (None, 784)               0         
                                                                 
 dense_329 (Dense)           (None, 512)               401920    
                                                                 
 dropout_226 (Dropout)       (None, 512)               0         
                                                                 
 dense_330 (Dense)           (None, 480)               246240    
                                                                 
 dropout_227 (Dropout)       (None, 480)               0         
                                                                 
 dense_331 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 104:
  Value: 0.9051
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007995496825536269

Model: "sequential_104"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_104 (Flatten)       (None, 784)               0         
                                                                 
 dense_332 (Dense)           (None, 512)               401920    
                                                                 
 dropout_228 (Dropout)       (None, 512)               0         
                                                                 
 dense_333 (Dense)           (None, 448)               229824    
                                                                 
 dropout_229 (Dropout)       (None, 448)               0         
                                                                 
 dense_334 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 105:
  Value: 0.9042
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010651353980870657

Model: "sequential_105"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_105 (Flatten)       (None, 784)               0         
                                                                 
 dense_335 (Dense)           (None, 512)               401920    
                                                                 
 dropout_230 (Dropout)       (None, 512)               0         
                                                                 
 dense_336 (Dense)           (None, 416)               213408    
                                                                 
 dropout_231 (Dropout)       (None, 416)               0         
                                                                 
 dense_337 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 106:
  Value: 0.9067
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001065092686168483

Model: "sequential_106"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_106 (Flatten)       (None, 784)               0         
                                                                 
 dense_338 (Dense)           (None, 512)               401920    
                                                                 
 dropout_232 (Dropout)       (None, 512)               0         
                                                                 
 dense_339 (Dense)           (None, 416)               213408    
                                                                 
 dropout_233 (Dropout)       (None, 416)               0         
                                                                 
 dense_340 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 107:
  Value: 0.7858
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0010628100369509254

Model: "sequential_107"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_107 (Flatten)       (None, 784)               0         
                                                                 
 dense_341 (Dense)           (None, 512)               401920    
                                                                 
 dropout_234 (Dropout)       (None, 512)               0         
                                                                 
 dense_342 (Dense)           (None, 416)               213408    
                                                                 
 dropout_235 (Dropout)       (None, 416)               0         
                                                                 
 dense_343 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 108:
  Value: 0.9037
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009340964324814067

Model: "sequential_108"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_108 (Flatten)       (None, 784)               0         
                                                                 
 dense_344 (Dense)           (None, 512)               401920    
                                                                 
 dropout_236 (Dropout)       (None, 512)               0         
                                                                 
 dense_345 (Dense)           (None, 416)               213408    
                                                                 
 dropout_237 (Dropout)       (None, 416)               0         
                                                                 
 dense_346 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 109:
  Value: 0.9025
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009220231640842243

Model: "sequential_109"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_109 (Flatten)       (None, 784)               0         
                                                                 
 dense_347 (Dense)           (None, 512)               401920    
                                                                 
 dropout_238 (Dropout)       (None, 512)               0         
                                                                 
 dense_348 (Dense)           (None, 384)               196992    
                                                                 
 dropout_239 (Dropout)       (None, 384)               0         
                                                                 
 dense_349 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 110:
  Value: 0.7504
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011988130837584147

Model: "sequential_110"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_110 (Flatten)       (None, 784)               0         
                                                                 
 dense_350 (Dense)           (None, 512)               401920    
                                                                 
 dropout_240 (Dropout)       (None, 512)               0         
                                                                 
 dense_351 (Dense)           (None, 416)               213408    
                                                                 
 dropout_241 (Dropout)       (None, 416)               0         
                                                                 
 dense_352 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 111:
  Value: 0.9014
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009120938642599561

Model: "sequential_111"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_111 (Flatten)       (None, 784)               0         
                                                                 
 dense_353 (Dense)           (None, 512)               401920    
                                                                 
 dropout_242 (Dropout)       (None, 512)               0         
                                                                 
 dense_354 (Dense)           (None, 384)               196992    
                                                                 
 dropout_243 (Dropout)       (None, 384)               0         
                                                                 
 dense_355 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 112:
  Value: 0.9064
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001014544327928366

Model: "sequential_112"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_112 (Flatten)       (None, 784)               0         
                                                                 
 dense_356 (Dense)           (None, 512)               401920    
                                                                 
 dropout_244 (Dropout)       (None, 512)               0         
                                                                 
 dense_357 (Dense)           (None, 384)               196992    
                                                                 
 dropout_245 (Dropout)       (None, 384)               0         
                                                                 
 dense_358 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 113:
  Value: 0.9007
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001014552866491278

Model: "sequential_113"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_113 (Flatten)       (None, 784)               0         
                                                                 
 dense_359 (Dense)           (None, 512)               401920    
                                                                 
 dropout_246 (Dropout)       (None, 512)               0         
                                                                 
 dense_360 (Dense)           (None, 416)               213408    
                                                                 
 dropout_247 (Dropout)       (None, 416)               0         
                                                                 
 dense_361 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 114:
  Value: 0.9096
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008057401002374183

Model: "sequential_114"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_114 (Flatten)       (None, 784)               0         
                                                                 
 dense_362 (Dense)           (None, 512)               401920    
                                                                 
 dropout_248 (Dropout)       (None, 512)               0         
                                                                 
 dense_363 (Dense)           (None, 448)               229824    
                                                                 
 dropout_249 (Dropout)       (None, 448)               0         
                                                                 
 dense_364 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 115:
  Value: 0.9072
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011697089288246882

Model: "sequential_115"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_115 (Flatten)       (None, 784)               0         
                                                                 
 dense_365 (Dense)           (None, 512)               401920    
                                                                 
 dropout_250 (Dropout)       (None, 512)               0         
                                                                 
 dense_366 (Dense)           (None, 384)               196992    
                                                                 
 dropout_251 (Dropout)       (None, 384)               0         
                                                                 
 dense_367 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 116:
  Value: 0.9080
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001131620994712238

Model: "sequential_116"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_116 (Flatten)       (None, 784)               0         
                                                                 
 dense_368 (Dense)           (None, 512)               401920    
                                                                 
 dropout_252 (Dropout)       (None, 512)               0         
                                                                 
 dense_369 (Dense)           (None, 384)               196992    
                                                                 
 dropout_253 (Dropout)       (None, 384)               0         
                                                                 
 dense_370 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 117:
  Value: 0.1347
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0011296240174770522

Model: "sequential_117"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_117 (Flatten)       (None, 784)               0         
                                                                 
 dense_371 (Dense)           (None, 512)               401920    
                                                                 
 dropout_254 (Dropout)       (None, 512)               0         
                                                                 
 dense_372 (Dense)           (None, 384)               196992    
                                                                 
 dropout_255 (Dropout)       (None, 384)               0         
                                                                 
 dense_373 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 118:
  Value: 0.9081
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013555501560741524

Model: "sequential_118"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_118 (Flatten)       (None, 784)               0         
                                                                 
 dense_374 (Dense)           (None, 512)               401920    
                                                                 
 dropout_256 (Dropout)       (None, 512)               0         
                                                                 
 dense_375 (Dense)           (None, 384)               196992    
                                                                 
 dropout_257 (Dropout)       (None, 384)               0         
                                                                 
 dense_376 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 119:
  Value: 0.9064
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014991011007186655

Model: "sequential_119"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_119 (Flatten)       (None, 784)               0         
                                                                 
 dense_377 (Dense)           (None, 480)               376800    
                                                                 
 dropout_258 (Dropout)       (None, 480)               0         
                                                                 
 dense_378 (Dense)           (None, 352)               169312    
                                                                 
 dropout_259 (Dropout)       (None, 352)               0         
                                                                 
 dense_379 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 120:
  Value: 0.9046
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014249012319324061

Model: "sequential_120"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_120 (Flatten)       (None, 784)               0         
                                                                 
 dense_380 (Dense)           (None, 480)               376800    
                                                                 
 dropout_260 (Dropout)       (None, 480)               0         
                                                                 
 dense_381 (Dense)           (None, 352)               169312    
                                                                 
 dropout_261 (Dropout)       (None, 352)               0         
                                                                 
 dense_382 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 121:
  Value: 0.9110
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00140341802962133

Model: "sequential_121"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_121 (Flatten)       (None, 784)               0         
                                                                 
 dense_383 (Dense)           (None, 480)               376800    
                                                                 
 dropout_262 (Dropout)       (None, 480)               0         
                                                                 
 dense_384 (Dense)           (None, 352)               169312    
                                                                 
 dropout_263 (Dropout)       (None, 352)               0         
                                                                 
 dense_385 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 122:
  Value: 0.9093
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014907502470924436

Model: "sequential_122"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_122 (Flatten)       (None, 784)               0         
                                                                 
 dense_386 (Dense)           (None, 480)               376800    
                                                                 
 dropout_264 (Dropout)       (None, 480)               0         
                                                                 
 dense_387 (Dense)           (None, 352)               169312    
                                                                 
 dropout_265 (Dropout)       (None, 352)               0         
                                                                 
 dense_388 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 123:
  Value: 0.9101
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015843289114890581

Model: "sequential_123"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_123 (Flatten)       (None, 784)               0         
                                                                 
 dense_389 (Dense)           (None, 480)               376800    
                                                                 
 dropout_266 (Dropout)       (None, 480)               0         
                                                                 
 dense_390 (Dense)           (None, 352)               169312    
                                                                 
 dropout_267 (Dropout)       (None, 352)               0         
                                                                 
 dense_391 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 124:
  Value: 0.9087
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016445402631290727

Model: "sequential_124"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_124 (Flatten)       (None, 784)               0         
                                                                 
 dense_392 (Dense)           (None, 480)               376800    
                                                                 
 dropout_268 (Dropout)       (None, 480)               0         
                                                                 
 dense_393 (Dense)           (None, 320)               153920    
                                                                 
 dropout_269 (Dropout)       (None, 320)               0         
                                                                 
 dense_394 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 125:
  Value: 0.9068
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015963875888609072

Model: "sequential_125"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_125 (Flatten)       (None, 784)               0         
                                                                 
 dense_395 (Dense)           (None, 480)               376800    
                                                                 
 dropout_270 (Dropout)       (None, 480)               0         
                                                                 
 dense_396 (Dense)           (None, 320)               153920    
                                                                 
 dropout_271 (Dropout)       (None, 320)               0         
                                                                 
 dense_397 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 126:
  Value: 0.3432
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0016316391494632604

Model: "sequential_126"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_126 (Flatten)       (None, 784)               0         
                                                                 
 dense_398 (Dense)           (None, 480)               376800    
                                                                 
 dropout_272 (Dropout)       (None, 480)               0         
                                                                 
 dense_399 (Dense)           (None, 320)               153920    
                                                                 
 dropout_273 (Dropout)       (None, 320)               0         
                                                                 
 dense_400 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 127:
  Value: 0.8995
  num_layers: 2
  units_0: 448
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013026433573940638

Model: "sequential_127"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_127 (Flatten)       (None, 784)               0         
                                                                 
 dense_401 (Dense)           (None, 448)               351680    
                                                                 
 dropout_274 (Dropout)       (None, 448)               0         
                                                                 
 dense_402 (Dense)           (None, 288)               129312    
                                                                 
 dropout_275 (Dropout)       (None, 288)               0         
                                                                 
 dense_403 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 488506 (1.86 MB)
Trainable params: 488506 (1.86 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 128:
  Value: 0.0387
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0018562523604663144

Model: "sequential_128"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_128 (Flatten)       (None, 784)               0         
                                                                 
 dense_404 (Dense)           (None, 480)               376800    
                                                                 
 dropout_276 (Dropout)       (None, 480)               0         
                                                                 
 dense_405 (Dense)           (None, 320)               153920    
                                                                 
 dropout_277 (Dropout)       (None, 320)               0         
                                                                 
 dense_406 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 129:
  Value: 0.9094
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011823788868693646

Model: "sequential_129"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_129 (Flatten)       (None, 784)               0         
                                                                 
 dense_407 (Dense)           (None, 480)               376800    
                                                                 
 dropout_278 (Dropout)       (None, 480)               0         
                                                                 
 dense_408 (Dense)           (None, 352)               169312    
                                                                 
 dropout_279 (Dropout)       (None, 352)               0         
                                                                 
 dense_409 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 130:
  Value: 0.7950
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0011803499070189175

Model: "sequential_130"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_130 (Flatten)       (None, 784)               0         
                                                                 
 dense_410 (Dense)           (None, 480)               376800    
                                                                 
 dropout_280 (Dropout)       (None, 480)               0         
                                                                 
 dense_411 (Dense)           (None, 352)               169312    
                                                                 
 dropout_281 (Dropout)       (None, 352)               0         
                                                                 
 dense_412 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 131:
  Value: 0.9078
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001343980780144176

Model: "sequential_131"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_131 (Flatten)       (None, 784)               0         
                                                                 
 dense_413 (Dense)           (None, 480)               376800    
                                                                 
 dropout_282 (Dropout)       (None, 480)               0         
                                                                 
 dense_414 (Dense)           (None, 384)               184704    
                                                                 
 dropout_283 (Dropout)       (None, 384)               0         
                                                                 
 dense_415 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 132:
  Value: 0.9017
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013299474853113588

Model: "sequential_132"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_132 (Flatten)       (None, 784)               0         
                                                                 
 dense_416 (Dense)           (None, 448)               351680    
                                                                 
 dropout_284 (Dropout)       (None, 448)               0         
                                                                 
 dense_417 (Dense)           (None, 352)               158048    
                                                                 
 dropout_285 (Dropout)       (None, 352)               0         
                                                                 
 dense_418 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 133:
  Value: 0.9050
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016743723429749027

Model: "sequential_133"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_133 (Flatten)       (None, 784)               0         
                                                                 
 dense_419 (Dense)           (None, 480)               376800    
                                                                 
 dropout_286 (Dropout)       (None, 480)               0         
                                                                 
 dense_420 (Dense)           (None, 320)               153920    
                                                                 
 dropout_287 (Dropout)       (None, 320)               0         
                                                                 
 dense_421 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 134:
  Value: 0.9030
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013911672694662497

Model: "sequential_134"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_134 (Flatten)       (None, 784)               0         
                                                                 
 dense_422 (Dense)           (None, 480)               376800    
                                                                 
 dropout_288 (Dropout)       (None, 480)               0         
                                                                 
 dense_423 (Dense)           (None, 384)               184704    
                                                                 
 dropout_289 (Dropout)       (None, 384)               0         
                                                                 
 dense_424 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 135:
  Value: 0.8592
  num_layers: 2
  units_0: 448
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015431203135093552

Model: "sequential_135"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_135 (Flatten)       (None, 784)               0         
                                                                 
 dense_425 (Dense)           (None, 448)               351680    
                                                                 
 dropout_290 (Dropout)       (None, 448)               0         
                                                                 
 dense_426 (Dense)           (None, 288)               129312    
                                                                 
 dropout_291 (Dropout)       (None, 288)               0         
                                                                 
 dense_427 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 488506 (1.86 MB)
Trainable params: 488506 (1.86 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 136:
  Value: 0.9078
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012471547964315822

Model: "sequential_136"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_136 (Flatten)       (None, 784)               0         
                                                                 
 dense_428 (Dense)           (None, 480)               376800    
                                                                 
 dropout_292 (Dropout)       (None, 480)               0         
                                                                 
 dense_429 (Dense)           (None, 352)               169312    
                                                                 
 dropout_293 (Dropout)       (None, 352)               0         
                                                                 
 dense_430 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 137:
  Value: 0.8996
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012421632797088831

Model: "sequential_137"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_137 (Flatten)       (None, 784)               0         
                                                                 
 dense_431 (Dense)           (None, 448)               351680    
                                                                 
 dropout_294 (Dropout)       (None, 448)               0         
                                                                 
 dense_432 (Dense)           (None, 352)               158048    
                                                                 
 dropout_295 (Dropout)       (None, 352)               0         
                                                                 
 dense_433 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 138:
  Value: 0.6867
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: sigmoid
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014417323500841607

Model: "sequential_138"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_138 (Flatten)       (None, 784)               0         
                                                                 
 dense_434 (Dense)           (None, 480)               376800    
                                                                 
 dropout_296 (Dropout)       (None, 480)               0         
                                                                 
 dense_435 (Dense)           (None, 320)               153920    
                                                                 
 dropout_297 (Dropout)       (None, 320)               0         
                                                                 
 dense_436 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 139:
  Value: 0.9026
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017746083010085304

Model: "sequential_139"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_139 (Flatten)       (None, 784)               0         
                                                                 
 dense_437 (Dense)           (None, 480)               376800    
                                                                 
 dropout_298 (Dropout)       (None, 480)               0         
                                                                 
 dense_438 (Dense)           (None, 352)               169312    
                                                                 
 dropout_299 (Dropout)       (None, 352)               0         
                                                                 
 dense_439 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 140:
  Value: 0.9050
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0020360748907028896

Model: "sequential_140"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_140 (Flatten)       (None, 784)               0         
                                                                 
 dense_440 (Dense)           (None, 480)               376800    
                                                                 
 dropout_300 (Dropout)       (None, 480)               0         
                                                                 
 dense_441 (Dense)           (None, 384)               184704    
                                                                 
 dropout_301 (Dropout)       (None, 384)               0         
                                                                 
 dense_442 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 141:
  Value: 0.9040
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011458692785253537

Model: "sequential_141"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_141 (Flatten)       (None, 784)               0         
                                                                 
 dense_443 (Dense)           (None, 480)               376800    
                                                                 
 dropout_302 (Dropout)       (None, 480)               0         
                                                                 
 dense_444 (Dense)           (None, 352)               169312    
                                                                 
 dropout_303 (Dropout)       (None, 352)               0         
                                                                 
 dense_445 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 142:
  Value: 0.9068
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015712961470057036

Model: "sequential_142"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_142 (Flatten)       (None, 784)               0         
                                                                 
 dense_446 (Dense)           (None, 512)               401920    
                                                                 
 dropout_304 (Dropout)       (None, 512)               0         
                                                                 
 dense_447 (Dense)           (None, 384)               196992    
                                                                 
 dropout_305 (Dropout)       (None, 384)               0         
                                                                 
 dense_448 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 143:
  Value: 0.9069
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00154651072284507

Model: "sequential_143"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_143 (Flatten)       (None, 784)               0         
                                                                 
 dense_449 (Dense)           (None, 480)               376800    
                                                                 
 dropout_306 (Dropout)       (None, 480)               0         
                                                                 
 dense_450 (Dense)           (None, 352)               169312    
                                                                 
 dropout_307 (Dropout)       (None, 352)               0         
                                                                 
 dense_451 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 144:
  Value: 0.9028
  num_layers: 2
  units_0: 480
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013687610601024376

Model: "sequential_144"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_144 (Flatten)       (None, 784)               0         
                                                                 
 dense_452 (Dense)           (None, 480)               376800    
                                                                 
 dropout_308 (Dropout)       (None, 480)               0         
                                                                 
 dense_453 (Dense)           (None, 288)               138528    
                                                                 
 dropout_309 (Dropout)       (None, 288)               0         
                                                                 
 dense_454 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 522842 (1.99 MB)
Trainable params: 522842 (1.99 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 145:
  Value: 0.9073
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017190115608572492

Model: "sequential_145"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_145 (Flatten)       (None, 784)               0         
                                                                 
 dense_455 (Dense)           (None, 448)               351680    
                                                                 
 dropout_310 (Dropout)       (None, 448)               0         
                                                                 
 dense_456 (Dense)           (None, 320)               143680    
                                                                 
 dropout_311 (Dropout)       (None, 320)               0         
                                                                 
 dense_457 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 503706 (1.92 MB)
Trainable params: 503706 (1.92 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 146:
  Value: 0.9032
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012698585818637631

Model: "sequential_146"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_146 (Flatten)       (None, 784)               0         
                                                                 
 dense_458 (Dense)           (None, 448)               351680    
                                                                 
 dropout_312 (Dropout)       (None, 448)               0         
                                                                 
 dense_459 (Dense)           (None, 352)               158048    
                                                                 
 dropout_313 (Dropout)       (None, 352)               0         
                                                                 
 dense_460 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 147:
  Value: 0.1411
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0017136549948467718

Model: "sequential_147"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_147 (Flatten)       (None, 784)               0         
                                                                 
 dense_461 (Dense)           (None, 448)               351680    
                                                                 
 dropout_314 (Dropout)       (None, 448)               0         
                                                                 
 dense_462 (Dense)           (None, 320)               143680    
                                                                 
 dropout_315 (Dropout)       (None, 320)               0         
                                                                 
 dense_463 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 503706 (1.92 MB)
Trainable params: 503706 (1.92 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 148:
  Value: 0.9078
  num_layers: 2
  units_0: 480
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019107852553748971

Model: "sequential_148"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_148 (Flatten)       (None, 784)               0         
                                                                 
 dense_464 (Dense)           (None, 480)               376800    
                                                                 
 dropout_316 (Dropout)       (None, 480)               0         
                                                                 
 dense_465 (Dense)           (None, 256)               123136    
                                                                 
 dropout_317 (Dropout)       (None, 256)               0         
                                                                 
 dense_466 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 506618 (1.93 MB)
Trainable params: 506618 (1.93 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 149:
  Value: 0.9014
  num_layers: 2
  units_0: 512
  units_1: 192
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002014135540686303

Model: "sequential_149"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_149 (Flatten)       (None, 784)               0         
                                                                 
 dense_467 (Dense)           (None, 512)               401920    
                                                                 
 dropout_318 (Dropout)       (None, 512)               0         
                                                                 
 dense_468 (Dense)           (None, 192)               98496     
                                                                 
 dropout_319 (Dropout)       (None, 192)               0         
                                                                 
 dense_469 (Dense)           (None, 26)                5018      
                                                                 
=================================================================
Total params: 505434 (1.93 MB)
Trainable params: 505434 (1.93 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 150:
  Value: 0.8584
  num_layers: 2
  units_0: 480
  units_1: 224
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018243168765132726

Model: "sequential_150"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_150 (Flatten)       (None, 784)               0         
                                                                 
 dense_470 (Dense)           (None, 480)               376800    
                                                                 
 dropout_320 (Dropout)       (None, 480)               0         
                                                                 
 dense_471 (Dense)           (None, 224)               107744    
                                                                 
 dropout_321 (Dropout)       (None, 224)               0         
                                                                 
 dense_472 (Dense)           (None, 26)                5850      
                                                                 
=================================================================
Total params: 490394 (1.87 MB)
Trainable params: 490394 (1.87 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 151:
  Value: 0.9043
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014653418396423552

Model: "sequential_151"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_151 (Flatten)       (None, 784)               0         
                                                                 
 dense_473 (Dense)           (None, 480)               376800    
                                                                 
 dropout_322 (Dropout)       (None, 480)               0         
                                                                 
 dense_474 (Dense)           (None, 384)               184704    
                                                                 
 dropout_323 (Dropout)       (None, 384)               0         
                                                                 
 dense_475 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 152:
  Value: 0.8592
  num_layers: 2
  units_0: 448
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002245753420932246

Model: "sequential_152"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_152 (Flatten)       (None, 784)               0         
                                                                 
 dense_476 (Dense)           (None, 448)               351680    
                                                                 
 dropout_324 (Dropout)       (None, 448)               0         
                                                                 
 dense_477 (Dense)           (None, 256)               114944    
                                                                 
 dropout_325 (Dropout)       (None, 256)               0         
                                                                 
 dense_478 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 473306 (1.81 MB)
Trainable params: 473306 (1.81 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 153:
  Value: 0.9061
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001319762676960283

Model: "sequential_153"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_153 (Flatten)       (None, 784)               0         
                                                                 
 dense_479 (Dense)           (None, 480)               376800    
                                                                 
 dropout_326 (Dropout)       (None, 480)               0         
                                                                 
 dense_480 (Dense)           (None, 352)               169312    
                                                                 
 dropout_327 (Dropout)       (None, 352)               0         
                                                                 
 dense_481 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 154:
  Value: 0.9072
  num_layers: 2
  units_0: 512
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011815346056073175

Model: "sequential_154"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_154 (Flatten)       (None, 784)               0         
                                                                 
 dense_482 (Dense)           (None, 512)               401920    
                                                                 
 dropout_328 (Dropout)       (None, 512)               0         
                                                                 
 dense_483 (Dense)           (None, 256)               131328    
                                                                 
 dropout_329 (Dropout)       (None, 256)               0         
                                                                 
 dense_484 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 539930 (2.06 MB)
Trainable params: 539930 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 155:
  Value: 0.9028
  num_layers: 2
  units_0: 512
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011799919164968964

Model: "sequential_155"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_155 (Flatten)       (None, 784)               0         
                                                                 
 dense_485 (Dense)           (None, 512)               401920    
                                                                 
 dropout_330 (Dropout)       (None, 512)               0         
                                                                 
 dense_486 (Dense)           (None, 256)               131328    
                                                                 
 dropout_331 (Dropout)       (None, 256)               0         
                                                                 
 dense_487 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 539930 (2.06 MB)
Trainable params: 539930 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 156:
  Value: 0.8990
  num_layers: 2
  units_0: 512
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013886058830754843

Model: "sequential_156"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_156 (Flatten)       (None, 784)               0         
                                                                 
 dense_488 (Dense)           (None, 512)               401920    
                                                                 
 dropout_332 (Dropout)       (None, 512)               0         
                                                                 
 dense_489 (Dense)           (None, 256)               131328    
                                                                 
 dropout_333 (Dropout)       (None, 256)               0         
                                                                 
 dense_490 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 539930 (2.06 MB)
Trainable params: 539930 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 157:
  Value: 0.3985
  num_layers: 2
  units_0: 512
  units_1: 224
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.001216343295279044

Model: "sequential_157"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_157 (Flatten)       (None, 784)               0         
                                                                 
 dense_491 (Dense)           (None, 512)               401920    
                                                                 
 batch_normalization_75 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_334 (Dropout)       (None, 512)               0         
                                                                 
 dense_492 (Dense)           (None, 224)               114912    
                                                                 
 dropout_335 (Dropout)       (None, 224)               0         
                                                                 
 dense_493 (Dense)           (None, 26)                5850      
                                                                 
=================================================================
Total params: 524730 (2.00 MB)
Trainable params: 523706 (2.00 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 158:
  Value: 0.9052
  num_layers: 2
  units_0: 512
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00217239796304883

Model: "sequential_158"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_158 (Flatten)       (None, 784)               0         
                                                                 
 dense_494 (Dense)           (None, 512)               401920    
                                                                 
 dropout_336 (Dropout)       (None, 512)               0         
                                                                 
 dense_495 (Dense)           (None, 288)               147744    
                                                                 
 dropout_337 (Dropout)       (None, 288)               0         
                                                                 
 dense_496 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 557178 (2.13 MB)
Trainable params: 557178 (2.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 159:
  Value: 0.0387
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0017384492283412237

Model: "sequential_159"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_159 (Flatten)       (None, 784)               0         
                                                                 
 dense_497 (Dense)           (None, 448)               351680    
                                                                 
 dropout_338 (Dropout)       (None, 448)               0         
                                                                 
 dense_498 (Dense)           (None, 384)               172416    
                                                                 
 dropout_339 (Dropout)       (None, 384)               0         
                                                                 
 dense_499 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 160:
  Value: 0.9064
  num_layers: 2
  units_0: 512
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011285560429398177

Model: "sequential_160"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_160 (Flatten)       (None, 784)               0         
                                                                 
 dense_500 (Dense)           (None, 512)               401920    
                                                                 
 dropout_340 (Dropout)       (None, 512)               0         
                                                                 
 dense_501 (Dense)           (None, 288)               147744    
                                                                 
 dropout_341 (Dropout)       (None, 288)               0         
                                                                 
 dense_502 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 557178 (2.13 MB)
Trainable params: 557178 (2.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 161:
  Value: 0.9078
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015501090329335854

Model: "sequential_161"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_161 (Flatten)       (None, 784)               0         
                                                                 
 dense_503 (Dense)           (None, 480)               376800    
                                                                 
 dropout_342 (Dropout)       (None, 480)               0         
                                                                 
 dense_504 (Dense)           (None, 352)               169312    
                                                                 
 dropout_343 (Dropout)       (None, 352)               0         
                                                                 
 dense_505 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 162:
  Value: 0.9068
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014792365963208975

Model: "sequential_162"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_162 (Flatten)       (None, 784)               0         
                                                                 
 dense_506 (Dense)           (None, 480)               376800    
                                                                 
 dropout_344 (Dropout)       (None, 480)               0         
                                                                 
 dense_507 (Dense)           (None, 352)               169312    
                                                                 
 dropout_345 (Dropout)       (None, 352)               0         
                                                                 
 dense_508 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 163:
  Value: 0.9082
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012989528753667458

Model: "sequential_163"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_163 (Flatten)       (None, 784)               0         
                                                                 
 dense_509 (Dense)           (None, 480)               376800    
                                                                 
 dropout_346 (Dropout)       (None, 480)               0         
                                                                 
 dense_510 (Dense)           (None, 384)               184704    
                                                                 
 dropout_347 (Dropout)       (None, 384)               0         
                                                                 
 dense_511 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 164:
  Value: 0.9104
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016530825513201665

Model: "sequential_164"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_164 (Flatten)       (None, 784)               0         
                                                                 
 dense_512 (Dense)           (None, 480)               376800    
                                                                 
 dropout_348 (Dropout)       (None, 480)               0         
                                                                 
 dense_513 (Dense)           (None, 384)               184704    
                                                                 
 dropout_349 (Dropout)       (None, 384)               0         
                                                                 
 dense_514 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 165:
  Value: 0.9038
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017064722491572054

Model: "sequential_165"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_165 (Flatten)       (None, 784)               0         
                                                                 
 dense_515 (Dense)           (None, 448)               351680    
                                                                 
 dropout_350 (Dropout)       (None, 448)               0         
                                                                 
 dense_516 (Dense)           (None, 384)               172416    
                                                                 
 dropout_351 (Dropout)       (None, 384)               0         
                                                                 
 dense_517 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 166:
  Value: 0.7373
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019080732936540977

Model: "sequential_166"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_166 (Flatten)       (None, 784)               0         
                                                                 
 dense_518 (Dense)           (None, 480)               376800    
                                                                 
 dropout_352 (Dropout)       (None, 480)               0         
                                                                 
 dense_519 (Dense)           (None, 352)               169312    
                                                                 
 dropout_353 (Dropout)       (None, 352)               0         
                                                                 
 dense_520 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 167:
  Value: 0.9049
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013684990827141264

Model: "sequential_167"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_167 (Flatten)       (None, 784)               0         
                                                                 
 dense_521 (Dense)           (None, 480)               376800    
                                                                 
 dropout_354 (Dropout)       (None, 480)               0         
                                                                 
 dense_522 (Dense)           (None, 320)               153920    
                                                                 
 dropout_355 (Dropout)       (None, 320)               0         
                                                                 
 dense_523 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 168:
  Value: 0.9039
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016604315194850491

Model: "sequential_168"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_168 (Flatten)       (None, 784)               0         
                                                                 
 dense_524 (Dense)           (None, 448)               351680    
                                                                 
 dropout_356 (Dropout)       (None, 448)               0         
                                                                 
 dense_525 (Dense)           (None, 352)               158048    
                                                                 
 dropout_357 (Dropout)       (None, 352)               0         
                                                                 
 dense_526 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 169:
  Value: 0.9088
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015300397136855635

Model: "sequential_169"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_169 (Flatten)       (None, 784)               0         
                                                                 
 dense_527 (Dense)           (None, 480)               376800    
                                                                 
 dropout_358 (Dropout)       (None, 480)               0         
                                                                 
 dense_528 (Dense)           (None, 384)               184704    
                                                                 
 dropout_359 (Dropout)       (None, 384)               0         
                                                                 
 dense_529 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 170:
  Value: 0.9062
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015431387165386837

Model: "sequential_170"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_170 (Flatten)       (None, 784)               0         
                                                                 
 dense_530 (Dense)           (None, 480)               376800    
                                                                 
 dropout_360 (Dropout)       (None, 480)               0         
                                                                 
 dense_531 (Dense)           (None, 384)               184704    
                                                                 
 dropout_361 (Dropout)       (None, 384)               0         
                                                                 
 dense_532 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 171:
  Value: 0.7914
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0019045869839354177

Model: "sequential_171"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_171 (Flatten)       (None, 784)               0         
                                                                 
 dense_533 (Dense)           (None, 480)               376800    
                                                                 
 dropout_362 (Dropout)       (None, 480)               0         
                                                                 
 dense_534 (Dense)           (None, 352)               169312    
                                                                 
 dropout_363 (Dropout)       (None, 352)               0         
                                                                 
 dense_535 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 172:
  Value: 0.9053
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013045779501025525

Model: "sequential_172"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_172 (Flatten)       (None, 784)               0         
                                                                 
 dense_536 (Dense)           (None, 480)               376800    
                                                                 
 dropout_364 (Dropout)       (None, 480)               0         
                                                                 
 dense_537 (Dense)           (None, 384)               184704    
                                                                 
 dropout_365 (Dropout)       (None, 384)               0         
                                                                 
 dense_538 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 173:
  Value: 0.9043
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001515522880019425

Model: "sequential_173"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_173 (Flatten)       (None, 784)               0         
                                                                 
 dense_539 (Dense)           (None, 480)               376800    
                                                                 
 dropout_366 (Dropout)       (None, 480)               0         
                                                                 
 dense_540 (Dense)           (None, 352)               169312    
                                                                 
 dropout_367 (Dropout)       (None, 352)               0         
                                                                 
 dense_541 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 174:
  Value: 0.9033
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014212639063847195

Model: "sequential_174"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_174 (Flatten)       (None, 784)               0         
                                                                 
 dense_542 (Dense)           (None, 448)               351680    
                                                                 
 dropout_368 (Dropout)       (None, 448)               0         
                                                                 
 dense_543 (Dense)           (None, 320)               143680    
                                                                 
 dropout_369 (Dropout)       (None, 320)               0         
                                                                 
 dense_544 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 503706 (1.92 MB)
Trainable params: 503706 (1.92 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 175:
  Value: 0.9059
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016748274233372147

Model: "sequential_175"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_175 (Flatten)       (None, 784)               0         
                                                                 
 dense_545 (Dense)           (None, 480)               376800    
                                                                 
 dropout_370 (Dropout)       (None, 480)               0         
                                                                 
 dense_546 (Dense)           (None, 384)               184704    
                                                                 
 dropout_371 (Dropout)       (None, 384)               0         
                                                                 
 dense_547 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 176:
  Value: 0.8597
  num_layers: 4
  units_0: 448
  units_1: 384
  units_2: 32
  units_3: 224
  activation_0: relu
  activation_1: relu
  activation_2: tanh
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.5
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0023446687530122834

Model: "sequential_176"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_176 (Flatten)       (None, 784)               0         
                                                                 
 dense_548 (Dense)           (None, 448)               351680    
                                                                 
 dropout_372 (Dropout)       (None, 448)               0         
                                                                 
 dense_549 (Dense)           (None, 384)               172416    
                                                                 
 dropout_373 (Dropout)       (None, 384)               0         
                                                                 
 dense_550 (Dense)           (None, 32)                12320     
                                                                 
 batch_normalization_76 (Ba  (None, 32)                128       
 tchNormalization)                                               
                                                                 
 dropout_374 (Dropout)       (None, 32)                0         
                                                                 
 dense_551 (Dense)           (None, 224)               7392      
                                                                 
 dropout_375 (Dropout)       (None, 224)               0         
                                                                 
 dense_552 (Dense)           (None, 26)                5850      
                                                                 
=================================================================
Total params: 549786 (2.10 MB)
Trainable params: 549722 (2.10 MB)
Non-trainable params: 64 (256.00 Byte)
_________________________________________________________________



Trial 177:
  Value: 0.9094
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012709687298949712

Model: "sequential_177"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_177 (Flatten)       (None, 784)               0         
                                                                 
 dense_553 (Dense)           (None, 480)               376800    
                                                                 
 dropout_376 (Dropout)       (None, 480)               0         
                                                                 
 dense_554 (Dense)           (None, 352)               169312    
                                                                 
 dropout_377 (Dropout)       (None, 352)               0         
                                                                 
 dense_555 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 178:
  Value: 0.9093
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009882643916793523

Model: "sequential_178"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_178 (Flatten)       (None, 784)               0         
                                                                 
 dense_556 (Dense)           (None, 480)               376800    
                                                                 
 dropout_378 (Dropout)       (None, 480)               0         
                                                                 
 dense_557 (Dense)           (None, 352)               169312    
                                                                 
 dropout_379 (Dropout)       (None, 352)               0         
                                                                 
 dense_558 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 179:
  Value: 0.9053
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000999310191112075

Model: "sequential_179"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_179 (Flatten)       (None, 784)               0         
                                                                 
 dense_559 (Dense)           (None, 480)               376800    
                                                                 
 dropout_380 (Dropout)       (None, 480)               0         
                                                                 
 dense_560 (Dense)           (None, 352)               169312    
                                                                 
 dropout_381 (Dropout)       (None, 352)               0         
                                                                 
 dense_561 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 180:
  Value: 0.2469
  num_layers: 2
  units_0: 512
  units_1: 32
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.00108292229610916

Model: "sequential_180"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_180 (Flatten)       (None, 784)               0         
                                                                 
 dense_562 (Dense)           (None, 512)               401920    
                                                                 
 batch_normalization_77 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_382 (Dropout)       (None, 512)               0         
                                                                 
 dense_563 (Dense)           (None, 32)                16416     
                                                                 
 dropout_383 (Dropout)       (None, 32)                0         
                                                                 
 dense_564 (Dense)           (None, 26)                858       
                                                                 
=================================================================
Total params: 421242 (1.61 MB)
Trainable params: 420218 (1.60 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 181:
  Value: 0.9091
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012433008403787429

Model: "sequential_181"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_181 (Flatten)       (None, 784)               0         
                                                                 
 dense_565 (Dense)           (None, 480)               376800    
                                                                 
 dropout_384 (Dropout)       (None, 480)               0         
                                                                 
 dense_566 (Dense)           (None, 352)               169312    
                                                                 
 dropout_385 (Dropout)       (None, 352)               0         
                                                                 
 dense_567 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 182:
  Value: 0.7747
  num_layers: 2
  units_0: 64
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001241611942386296

Model: "sequential_182"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_182 (Flatten)       (None, 784)               0         
                                                                 
 dense_568 (Dense)           (None, 64)                50240     
                                                                 
 dropout_386 (Dropout)       (None, 64)                0         
                                                                 
 dense_569 (Dense)           (None, 352)               22880     
                                                                 
 dropout_387 (Dropout)       (None, 352)               0         
                                                                 
 dense_570 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 82298 (321.48 KB)
Trainable params: 82298 (321.48 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 183:
  Value: 0.9060
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009870096855624697

Model: "sequential_183"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_183 (Flatten)       (None, 784)               0         
                                                                 
 dense_571 (Dense)           (None, 480)               376800    
                                                                 
 dropout_388 (Dropout)       (None, 480)               0         
                                                                 
 dense_572 (Dense)           (None, 384)               184704    
                                                                 
 dropout_389 (Dropout)       (None, 384)               0         
                                                                 
 dense_573 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 184:
  Value: 0.9091
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012989783460368232

Model: "sequential_184"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_184 (Flatten)       (None, 784)               0         
                                                                 
 dense_574 (Dense)           (None, 480)               376800    
                                                                 
 dropout_390 (Dropout)       (None, 480)               0         
                                                                 
 dense_575 (Dense)           (None, 352)               169312    
                                                                 
 dropout_391 (Dropout)       (None, 352)               0         
                                                                 
 dense_576 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 185:
  Value: 0.9024
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010954592713205724

Model: "sequential_185"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_185 (Flatten)       (None, 784)               0         
                                                                 
 dense_577 (Dense)           (None, 480)               376800    
                                                                 
 dropout_392 (Dropout)       (None, 480)               0         
                                                                 
 dense_578 (Dense)           (None, 352)               169312    
                                                                 
 dropout_393 (Dropout)       (None, 352)               0         
                                                                 
 dense_579 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 186:
  Value: 0.8122
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008931094569781031

Model: "sequential_186"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_186 (Flatten)       (None, 784)               0         
                                                                 
 dense_580 (Dense)           (None, 512)               401920    
                                                                 
 dropout_394 (Dropout)       (None, 512)               0         
                                                                 
 dense_581 (Dense)           (None, 384)               196992    
                                                                 
 dropout_395 (Dropout)       (None, 384)               0         
                                                                 
 dense_582 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 187:
  Value: 0.8967
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013368504936132535

Model: "sequential_187"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_187 (Flatten)       (None, 784)               0         
                                                                 
 dense_583 (Dense)           (None, 480)               376800    
                                                                 
 dropout_396 (Dropout)       (None, 480)               0         
                                                                 
 dense_584 (Dense)           (None, 352)               169312    
                                                                 
 dropout_397 (Dropout)       (None, 352)               0         
                                                                 
 dense_585 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 188:
  Value: 0.9032
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012612065401236482

Model: "sequential_188"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_188 (Flatten)       (None, 784)               0         
                                                                 
 dense_586 (Dense)           (None, 480)               376800    
                                                                 
 dropout_398 (Dropout)       (None, 480)               0         
                                                                 
 dense_587 (Dense)           (None, 384)               184704    
                                                                 
 dropout_399 (Dropout)       (None, 384)               0         
                                                                 
 dense_588 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 189:
  Value: 0.9070
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000989131763569461

Model: "sequential_189"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_189 (Flatten)       (None, 784)               0         
                                                                 
 dense_589 (Dense)           (None, 512)               401920    
                                                                 
 dropout_400 (Dropout)       (None, 512)               0         
                                                                 
 dense_590 (Dense)           (None, 320)               164160    
                                                                 
 dropout_401 (Dropout)       (None, 320)               0         
                                                                 
 dense_591 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 190:
  Value: 0.9053
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011276203280662196

Model: "sequential_190"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_190 (Flatten)       (None, 784)               0         
                                                                 
 dense_592 (Dense)           (None, 480)               376800    
                                                                 
 dropout_402 (Dropout)       (None, 480)               0         
                                                                 
 dense_593 (Dense)           (None, 416)               200096    
                                                                 
 dropout_403 (Dropout)       (None, 416)               0         
                                                                 
 dense_594 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 191:
  Value: 0.9050
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013735443013755922

Model: "sequential_191"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_191 (Flatten)       (None, 784)               0         
                                                                 
 dense_595 (Dense)           (None, 480)               376800    
                                                                 
 dropout_404 (Dropout)       (None, 480)               0         
                                                                 
 dense_596 (Dense)           (None, 352)               169312    
                                                                 
 dropout_405 (Dropout)       (None, 352)               0         
                                                                 
 dense_597 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 192:
  Value: 0.9095
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014683742393886237

Model: "sequential_192"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_192 (Flatten)       (None, 784)               0         
                                                                 
 dense_598 (Dense)           (None, 480)               376800    
                                                                 
 dropout_406 (Dropout)       (None, 480)               0         
                                                                 
 dense_599 (Dense)           (None, 352)               169312    
                                                                 
 dropout_407 (Dropout)       (None, 352)               0         
                                                                 
 dense_600 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 193:
  Value: 0.9032
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012801245732918976

Model: "sequential_193"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_193 (Flatten)       (None, 784)               0         
                                                                 
 dense_601 (Dense)           (None, 448)               351680    
                                                                 
 dropout_408 (Dropout)       (None, 448)               0         
                                                                 
 dense_602 (Dense)           (None, 352)               158048    
                                                                 
 dropout_409 (Dropout)       (None, 352)               0         
                                                                 
 dense_603 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 194:
  Value: 0.9064
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014775746052999236

Model: "sequential_194"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_194 (Flatten)       (None, 784)               0         
                                                                 
 dense_604 (Dense)           (None, 480)               376800    
                                                                 
 dropout_410 (Dropout)       (None, 480)               0         
                                                                 
 dense_605 (Dense)           (None, 384)               184704    
                                                                 
 dropout_411 (Dropout)       (None, 384)               0         
                                                                 
 dense_606 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 195:
  Value: 0.9069
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011870332729771998

Model: "sequential_195"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_195 (Flatten)       (None, 784)               0         
                                                                 
 dense_607 (Dense)           (None, 512)               401920    
                                                                 
 dropout_412 (Dropout)       (None, 512)               0         
                                                                 
 dense_608 (Dense)           (None, 352)               180576    
                                                                 
 dropout_413 (Dropout)       (None, 352)               0         
                                                                 
 dense_609 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 196:
  Value: 0.3331
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0014392820329374673

Model: "sequential_196"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_196 (Flatten)       (None, 784)               0         
                                                                 
 dense_610 (Dense)           (None, 480)               376800    
                                                                 
 dropout_414 (Dropout)       (None, 480)               0         
                                                                 
 dense_611 (Dense)           (None, 320)               153920    
                                                                 
 dropout_415 (Dropout)       (None, 320)               0         
                                                                 
 dense_612 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 197:
  Value: 0.7475
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010671570831561092

Model: "sequential_197"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_197 (Flatten)       (None, 784)               0         
                                                                 
 dense_613 (Dense)           (None, 512)               401920    
                                                                 
 dropout_416 (Dropout)       (None, 512)               0         
                                                                 
 dense_614 (Dense)           (None, 352)               180576    
                                                                 
 dropout_417 (Dropout)       (None, 352)               0         
                                                                 
 dense_615 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 198:
  Value: 0.0392
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0008760367116715536

Model: "sequential_198"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_198 (Flatten)       (None, 784)               0         
                                                                 
 dense_616 (Dense)           (None, 448)               351680    
                                                                 
 dropout_418 (Dropout)       (None, 448)               0         
                                                                 
 dense_617 (Dense)           (None, 352)               158048    
                                                                 
 dropout_419 (Dropout)       (None, 352)               0         
                                                                 
 dense_618 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 199:
  Value: 0.9072
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0012784757137185212

Model: "sequential_199"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_199 (Flatten)       (None, 784)               0         
                                                                 
 dense_619 (Dense)           (None, 480)               376800    
                                                                 
 dropout_420 (Dropout)       (None, 480)               0         
                                                                 
 dense_620 (Dense)           (None, 416)               200096    
                                                                 
 batch_normalization_78 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_421 (Dropout)       (None, 416)               0         
                                                                 
 dense_621 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 589402 (2.25 MB)
Trainable params: 588570 (2.25 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 200:
  Value: 0.9062
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001627585823598296

Model: "sequential_200"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_200 (Flatten)       (None, 784)               0         
                                                                 
 dense_622 (Dense)           (None, 512)               401920    
                                                                 
 dropout_422 (Dropout)       (None, 512)               0         
                                                                 
 dense_623 (Dense)           (None, 384)               196992    
                                                                 
 dropout_423 (Dropout)       (None, 384)               0         
                                                                 
 dense_624 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 201:
  Value: 0.9082
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013885774392462364

Model: "sequential_201"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_201 (Flatten)       (None, 784)               0         
                                                                 
 dense_625 (Dense)           (None, 480)               376800    
                                                                 
 dropout_424 (Dropout)       (None, 480)               0         
                                                                 
 dense_626 (Dense)           (None, 384)               184704    
                                                                 
 dropout_425 (Dropout)       (None, 384)               0         
                                                                 
 dense_627 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 202:
  Value: 0.9065
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015027064268136041

Model: "sequential_202"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_202 (Flatten)       (None, 784)               0         
                                                                 
 dense_628 (Dense)           (None, 480)               376800    
                                                                 
 dropout_426 (Dropout)       (None, 480)               0         
                                                                 
 dense_629 (Dense)           (None, 384)               184704    
                                                                 
 dropout_427 (Dropout)       (None, 384)               0         
                                                                 
 dense_630 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 203:
  Value: 0.9073
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013822690447417383

Model: "sequential_203"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_203 (Flatten)       (None, 784)               0         
                                                                 
 dense_631 (Dense)           (None, 480)               376800    
                                                                 
 dropout_428 (Dropout)       (None, 480)               0         
                                                                 
 dense_632 (Dense)           (None, 384)               184704    
                                                                 
 dropout_429 (Dropout)       (None, 384)               0         
                                                                 
 dense_633 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 204:
  Value: 0.9036
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00122046071283865

Model: "sequential_204"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_204 (Flatten)       (None, 784)               0         
                                                                 
 dense_634 (Dense)           (None, 480)               376800    
                                                                 
 dropout_430 (Dropout)       (None, 480)               0         
                                                                 
 dense_635 (Dense)           (None, 320)               153920    
                                                                 
 dropout_431 (Dropout)       (None, 320)               0         
                                                                 
 dense_636 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 205:
  Value: 0.9061
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013520384320551747

Model: "sequential_205"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_205 (Flatten)       (None, 784)               0         
                                                                 
 dense_637 (Dense)           (None, 512)               401920    
                                                                 
 dropout_432 (Dropout)       (None, 512)               0         
                                                                 
 dense_638 (Dense)           (None, 352)               180576    
                                                                 
 dropout_433 (Dropout)       (None, 352)               0         
                                                                 
 dense_639 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 206:
  Value: 0.7926
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.001133761386284945

Model: "sequential_206"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_206 (Flatten)       (None, 784)               0         
                                                                 
 dense_640 (Dense)           (None, 448)               351680    
                                                                 
 dropout_434 (Dropout)       (None, 448)               0         
                                                                 
 dense_641 (Dense)           (None, 384)               172416    
                                                                 
 dropout_435 (Dropout)       (None, 384)               0         
                                                                 
 dense_642 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 207:
  Value: 0.8971
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015990367112637292

Model: "sequential_207"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_207 (Flatten)       (None, 784)               0         
                                                                 
 dense_643 (Dense)           (None, 480)               376800    
                                                                 
 dropout_436 (Dropout)       (None, 480)               0         
                                                                 
 dense_644 (Dense)           (None, 352)               169312    
                                                                 
 dropout_437 (Dropout)       (None, 352)               0         
                                                                 
 dense_645 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 208:
  Value: 0.9071
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009400084243266615

Model: "sequential_208"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_208 (Flatten)       (None, 784)               0         
                                                                 
 dense_646 (Dense)           (None, 480)               376800    
                                                                 
 dropout_438 (Dropout)       (None, 480)               0         
                                                                 
 dense_647 (Dense)           (None, 416)               200096    
                                                                 
 dropout_439 (Dropout)       (None, 416)               0         
                                                                 
 dense_648 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 209:
  Value: 0.9039
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001463173709406658

Model: "sequential_209"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_209 (Flatten)       (None, 784)               0         
                                                                 
 dense_649 (Dense)           (None, 480)               376800    
                                                                 
 dropout_440 (Dropout)       (None, 480)               0         
                                                                 
 dense_650 (Dense)           (None, 352)               169312    
                                                                 
 dropout_441 (Dropout)       (None, 352)               0         
                                                                 
 dense_651 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 210:
  Value: 0.9066
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012458664224360978

Model: "sequential_210"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_210 (Flatten)       (None, 784)               0         
                                                                 
 dense_652 (Dense)           (None, 512)               401920    
                                                                 
 dropout_442 (Dropout)       (None, 512)               0         
                                                                 
 dense_653 (Dense)           (None, 384)               196992    
                                                                 
 dropout_443 (Dropout)       (None, 384)               0         
                                                                 
 dense_654 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 211:
  Value: 0.9052
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001842966573222226

Model: "sequential_211"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_211 (Flatten)       (None, 784)               0         
                                                                 
 dense_655 (Dense)           (None, 480)               376800    
                                                                 
 dropout_444 (Dropout)       (None, 480)               0         
                                                                 
 dense_656 (Dense)           (None, 352)               169312    
                                                                 
 dropout_445 (Dropout)       (None, 352)               0         
                                                                 
 dense_657 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 212:
  Value: 0.9056
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018503968110913148

Model: "sequential_212"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_212 (Flatten)       (None, 784)               0         
                                                                 
 dense_658 (Dense)           (None, 480)               376800    
                                                                 
 dropout_446 (Dropout)       (None, 480)               0         
                                                                 
 dense_659 (Dense)           (None, 384)               184704    
                                                                 
 dropout_447 (Dropout)       (None, 384)               0         
                                                                 
 dense_660 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 213:
  Value: 0.9112
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001640900262918859

Model: "sequential_213"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_213 (Flatten)       (None, 784)               0         
                                                                 
 dense_661 (Dense)           (None, 448)               351680    
                                                                 
 dropout_448 (Dropout)       (None, 448)               0         
                                                                 
 dense_662 (Dense)           (None, 352)               158048    
                                                                 
 dropout_449 (Dropout)       (None, 352)               0         
                                                                 
 dense_663 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 214:
  Value: 0.9040
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016305413085737684

Model: "sequential_214"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_214 (Flatten)       (None, 784)               0         
                                                                 
 dense_664 (Dense)           (None, 448)               351680    
                                                                 
 dropout_450 (Dropout)       (None, 448)               0         
                                                                 
 dense_665 (Dense)           (None, 352)               158048    
                                                                 
 dropout_451 (Dropout)       (None, 352)               0         
                                                                 
 dense_666 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 215:
  Value: 0.9084
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013474510077919775

Model: "sequential_215"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_215 (Flatten)       (None, 784)               0         
                                                                 
 dense_667 (Dense)           (None, 512)               401920    
                                                                 
 dropout_452 (Dropout)       (None, 512)               0         
                                                                 
 dense_668 (Dense)           (None, 352)               180576    
                                                                 
 dropout_453 (Dropout)       (None, 352)               0         
                                                                 
 dense_669 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 216:
  Value: 0.9071
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014020053650408088

Model: "sequential_216"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_216 (Flatten)       (None, 784)               0         
                                                                 
 dense_670 (Dense)           (None, 512)               401920    
                                                                 
 dropout_454 (Dropout)       (None, 512)               0         
                                                                 
 dense_671 (Dense)           (None, 320)               164160    
                                                                 
 dropout_455 (Dropout)       (None, 320)               0         
                                                                 
 dense_672 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 217:
  Value: 0.8087
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015402571562112548

Model: "sequential_217"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_217 (Flatten)       (None, 784)               0         
                                                                 
 dense_673 (Dense)           (None, 512)               401920    
                                                                 
 dropout_456 (Dropout)       (None, 512)               0         
                                                                 
 dense_674 (Dense)           (None, 352)               180576    
                                                                 
 dropout_457 (Dropout)       (None, 352)               0         
                                                                 
 dense_675 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 218:
  Value: 0.8597
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011018529023464141

Model: "sequential_218"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_218 (Flatten)       (None, 784)               0         
                                                                 
 dense_676 (Dense)           (None, 512)               401920    
                                                                 
 batch_normalization_79 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_458 (Dropout)       (None, 512)               0         
                                                                 
 dense_677 (Dense)           (None, 384)               196992    
                                                                 
 dropout_459 (Dropout)       (None, 384)               0         
                                                                 
 dense_678 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 610970 (2.33 MB)
Trainable params: 609946 (2.33 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 219:
  Value: 0.9062
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013406508122068238

Model: "sequential_219"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_219 (Flatten)       (None, 784)               0         
                                                                 
 dense_679 (Dense)           (None, 512)               401920    
                                                                 
 dropout_460 (Dropout)       (None, 512)               0         
                                                                 
 dense_680 (Dense)           (None, 320)               164160    
                                                                 
 dropout_461 (Dropout)       (None, 320)               0         
                                                                 
 dense_681 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 220:
  Value: 0.7981
  num_layers: 2
  units_0: 512
  units_1: 64
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.00169455549618216

Model: "sequential_220"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_220 (Flatten)       (None, 784)               0         
                                                                 
 dense_682 (Dense)           (None, 512)               401920    
                                                                 
 dropout_462 (Dropout)       (None, 512)               0         
                                                                 
 dense_683 (Dense)           (None, 64)                32832     
                                                                 
 dropout_463 (Dropout)       (None, 64)                0         
                                                                 
 dense_684 (Dense)           (None, 26)                1690      
                                                                 
=================================================================
Total params: 436442 (1.66 MB)
Trainable params: 436442 (1.66 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 221:
  Value: 0.8838
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012348844505030568

Model: "sequential_221"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_221 (Flatten)       (None, 784)               0         
                                                                 
 dense_685 (Dense)           (None, 480)               376800    
                                                                 
 dropout_464 (Dropout)       (None, 480)               0         
                                                                 
 dense_686 (Dense)           (None, 352)               169312    
                                                                 
 dropout_465 (Dropout)       (None, 352)               0         
                                                                 
 dense_687 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 222:
  Value: 0.9062
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001467654217450341

Model: "sequential_222"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_222 (Flatten)       (None, 784)               0         
                                                                 
 dense_688 (Dense)           (None, 480)               376800    
                                                                 
 dropout_466 (Dropout)       (None, 480)               0         
                                                                 
 dense_689 (Dense)           (None, 352)               169312    
                                                                 
 dropout_467 (Dropout)       (None, 352)               0         
                                                                 
 dense_690 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 223:
  Value: 0.9071
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010247251415349623

Model: "sequential_223"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_223 (Flatten)       (None, 784)               0         
                                                                 
 dense_691 (Dense)           (None, 480)               376800    
                                                                 
 dropout_468 (Dropout)       (None, 480)               0         
                                                                 
 dense_692 (Dense)           (None, 352)               169312    
                                                                 
 dropout_469 (Dropout)       (None, 352)               0         
                                                                 
 dense_693 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 224:
  Value: 0.9044
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013131007461621464

Model: "sequential_224"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_224 (Flatten)       (None, 784)               0         
                                                                 
 dense_694 (Dense)           (None, 448)               351680    
                                                                 
 dropout_470 (Dropout)       (None, 448)               0         
                                                                 
 dense_695 (Dense)           (None, 384)               172416    
                                                                 
 dropout_471 (Dropout)       (None, 384)               0         
                                                                 
 dense_696 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 225:
  Value: 0.9084
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011614522882507218

Model: "sequential_225"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_225 (Flatten)       (None, 784)               0         
                                                                 
 dense_697 (Dense)           (None, 480)               376800    
                                                                 
 dropout_472 (Dropout)       (None, 480)               0         
                                                                 
 dense_698 (Dense)           (None, 352)               169312    
                                                                 
 dropout_473 (Dropout)       (None, 352)               0         
                                                                 
 dense_699 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 226:
  Value: 0.9037
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007994913494989693

Model: "sequential_226"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_226 (Flatten)       (None, 784)               0         
                                                                 
 dense_700 (Dense)           (None, 480)               376800    
                                                                 
 dropout_474 (Dropout)       (None, 480)               0         
                                                                 
 dense_701 (Dense)           (None, 352)               169312    
                                                                 
 dropout_475 (Dropout)       (None, 352)               0         
                                                                 
 dense_702 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 227:
  Value: 0.9067
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011130574414759291

Model: "sequential_227"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_227 (Flatten)       (None, 784)               0         
                                                                 
 dense_703 (Dense)           (None, 480)               376800    
                                                                 
 dropout_476 (Dropout)       (None, 480)               0         
                                                                 
 dense_704 (Dense)           (None, 384)               184704    
                                                                 
 dropout_477 (Dropout)       (None, 384)               0         
                                                                 
 dense_705 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 228:
  Value: 0.1073
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0014406333738533057

Model: "sequential_228"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_228 (Flatten)       (None, 784)               0         
                                                                 
 dense_706 (Dense)           (None, 512)               401920    
                                                                 
 dropout_478 (Dropout)       (None, 512)               0         
                                                                 
 dense_707 (Dense)           (None, 352)               180576    
                                                                 
 dropout_479 (Dropout)       (None, 352)               0         
                                                                 
 dense_708 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 229:
  Value: 0.9047
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011805114992163193

Model: "sequential_229"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_229 (Flatten)       (None, 784)               0         
                                                                 
 dense_709 (Dense)           (None, 480)               376800    
                                                                 
 dropout_480 (Dropout)       (None, 480)               0         
                                                                 
 dense_710 (Dense)           (None, 416)               200096    
                                                                 
 dropout_481 (Dropout)       (None, 416)               0         
                                                                 
 dense_711 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 230:
  Value: 0.9060
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015869826660091567

Model: "sequential_230"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_230 (Flatten)       (None, 784)               0         
                                                                 
 dense_712 (Dense)           (None, 512)               401920    
                                                                 
 dropout_482 (Dropout)       (None, 512)               0         
                                                                 
 dense_713 (Dense)           (None, 320)               164160    
                                                                 
 dropout_483 (Dropout)       (None, 320)               0         
                                                                 
 dense_714 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 231:
  Value: 0.9031
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012887744255721185

Model: "sequential_231"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_231 (Flatten)       (None, 784)               0         
                                                                 
 dense_715 (Dense)           (None, 480)               376800    
                                                                 
 dropout_484 (Dropout)       (None, 480)               0         
                                                                 
 dense_716 (Dense)           (None, 352)               169312    
                                                                 
 dropout_485 (Dropout)       (None, 352)               0         
                                                                 
 dense_717 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 232:
  Value: 0.9066
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001010001192312229

Model: "sequential_232"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_232 (Flatten)       (None, 784)               0         
                                                                 
 dense_718 (Dense)           (None, 480)               376800    
                                                                 
 dropout_486 (Dropout)       (None, 480)               0         
                                                                 
 dense_719 (Dense)           (None, 352)               169312    
                                                                 
 dropout_487 (Dropout)       (None, 352)               0         
                                                                 
 dense_720 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 233:
  Value: 0.9081
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012054941310151242

Model: "sequential_233"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_233 (Flatten)       (None, 784)               0         
                                                                 
 dense_721 (Dense)           (None, 480)               376800    
                                                                 
 dropout_488 (Dropout)       (None, 480)               0         
                                                                 
 dense_722 (Dense)           (None, 384)               184704    
                                                                 
 dropout_489 (Dropout)       (None, 384)               0         
                                                                 
 dense_723 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 234:
  Value: 0.8508
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008728071190561448

Model: "sequential_234"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_234 (Flatten)       (None, 784)               0         
                                                                 
 dense_724 (Dense)           (None, 480)               376800    
                                                                 
 dropout_490 (Dropout)       (None, 480)               0         
                                                                 
 dense_725 (Dense)           (None, 384)               184704    
                                                                 
 dropout_491 (Dropout)       (None, 384)               0         
                                                                 
 dense_726 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 235:
  Value: 0.8645
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011522855894165326

Model: "sequential_235"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_235 (Flatten)       (None, 784)               0         
                                                                 
 dense_727 (Dense)           (None, 480)               376800    
                                                                 
 dropout_492 (Dropout)       (None, 480)               0         
                                                                 
 dense_728 (Dense)           (None, 384)               184704    
                                                                 
 dropout_493 (Dropout)       (None, 384)               0         
                                                                 
 dense_729 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 236:
  Value: 0.9053
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0013738679932824623

Model: "sequential_236"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_236 (Flatten)       (None, 784)               0         
                                                                 
 dense_730 (Dense)           (None, 448)               351680    
                                                                 
 dropout_494 (Dropout)       (None, 448)               0         
                                                                 
 dense_731 (Dense)           (None, 384)               172416    
                                                                 
 batch_normalization_80 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_495 (Dropout)       (None, 384)               0         
                                                                 
 dense_732 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 535642 (2.04 MB)
Trainable params: 534874 (2.04 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 237:
  Value: 0.7457
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015378994560261844

Model: "sequential_237"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_237 (Flatten)       (None, 784)               0         
                                                                 
 dense_733 (Dense)           (None, 512)               401920    
                                                                 
 dropout_496 (Dropout)       (None, 512)               0         
                                                                 
 dense_734 (Dense)           (None, 384)               196992    
                                                                 
 dropout_497 (Dropout)       (None, 384)               0         
                                                                 
 dense_735 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 238:
  Value: 0.9044
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010578455125998792

Model: "sequential_238"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_238 (Flatten)       (None, 784)               0         
                                                                 
 dense_736 (Dense)           (None, 480)               376800    
                                                                 
 dropout_498 (Dropout)       (None, 480)               0         
                                                                 
 dense_737 (Dense)           (None, 416)               200096    
                                                                 
 dropout_499 (Dropout)       (None, 416)               0         
                                                                 
 dense_738 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 239:
  Value: 0.3083
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0017775816334402172

Model: "sequential_239"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_239 (Flatten)       (None, 784)               0         
                                                                 
 dense_739 (Dense)           (None, 448)               351680    
                                                                 
 dropout_500 (Dropout)       (None, 448)               0         
                                                                 
 dense_740 (Dense)           (None, 352)               158048    
                                                                 
 dropout_501 (Dropout)       (None, 352)               0         
                                                                 
 dense_741 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 240:
  Value: 0.9078
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012316010627157015

Model: "sequential_240"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_240 (Flatten)       (None, 784)               0         
                                                                 
 dense_742 (Dense)           (None, 512)               401920    
                                                                 
 dropout_502 (Dropout)       (None, 512)               0         
                                                                 
 dense_743 (Dense)           (None, 384)               196992    
                                                                 
 dropout_503 (Dropout)       (None, 384)               0         
                                                                 
 dense_744 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 241:
  Value: 0.9109
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012281523394804363

Model: "sequential_241"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_241 (Flatten)       (None, 784)               0         
                                                                 
 dense_745 (Dense)           (None, 512)               401920    
                                                                 
 dropout_504 (Dropout)       (None, 512)               0         
                                                                 
 dense_746 (Dense)           (None, 384)               196992    
                                                                 
 dropout_505 (Dropout)       (None, 384)               0         
                                                                 
 dense_747 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 242:
  Value: 0.9059
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012069447263684276

Model: "sequential_242"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_242 (Flatten)       (None, 784)               0         
                                                                 
 dense_748 (Dense)           (None, 512)               401920    
                                                                 
 dropout_506 (Dropout)       (None, 512)               0         
                                                                 
 dense_749 (Dense)           (None, 384)               196992    
                                                                 
 dropout_507 (Dropout)       (None, 384)               0         
                                                                 
 dense_750 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 243:
  Value: 0.8997
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009491046150460591

Model: "sequential_243"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_243 (Flatten)       (None, 784)               0         
                                                                 
 dense_751 (Dense)           (None, 512)               401920    
                                                                 
 dropout_508 (Dropout)       (None, 512)               0         
                                                                 
 dense_752 (Dense)           (None, 384)               196992    
                                                                 
 dropout_509 (Dropout)       (None, 384)               0         
                                                                 
 dense_753 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 244:
  Value: 0.9065
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000712141962607364

Model: "sequential_244"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_244 (Flatten)       (None, 784)               0         
                                                                 
 dense_754 (Dense)           (None, 512)               401920    
                                                                 
 dropout_510 (Dropout)       (None, 512)               0         
                                                                 
 dense_755 (Dense)           (None, 352)               180576    
                                                                 
 dropout_511 (Dropout)       (None, 352)               0         
                                                                 
 dense_756 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 245:
  Value: 0.9079
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001293321029567638

Model: "sequential_245"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_245 (Flatten)       (None, 784)               0         
                                                                 
 dense_757 (Dense)           (None, 512)               401920    
                                                                 
 dropout_512 (Dropout)       (None, 512)               0         
                                                                 
 dense_758 (Dense)           (None, 384)               196992    
                                                                 
 dropout_513 (Dropout)       (None, 384)               0         
                                                                 
 dense_759 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 246:
  Value: 0.9087
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001369575327837638

Model: "sequential_246"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_246 (Flatten)       (None, 784)               0         
                                                                 
 dense_760 (Dense)           (None, 512)               401920    
                                                                 
 dropout_514 (Dropout)       (None, 512)               0         
                                                                 
 dense_761 (Dense)           (None, 384)               196992    
                                                                 
 dropout_515 (Dropout)       (None, 384)               0         
                                                                 
 dense_762 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 247:
  Value: 0.0393
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0014017584015909364

Model: "sequential_247"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_247 (Flatten)       (None, 784)               0         
                                                                 
 dense_763 (Dense)           (None, 512)               401920    
                                                                 
 dropout_516 (Dropout)       (None, 512)               0         
                                                                 
 dense_764 (Dense)           (None, 352)               180576    
                                                                 
 dropout_517 (Dropout)       (None, 352)               0         
                                                                 
 dense_765 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 248:
  Value: 0.8636
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001602571502348155

Model: "sequential_248"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_248 (Flatten)       (None, 784)               0         
                                                                 
 dense_766 (Dense)           (None, 480)               376800    
                                                                 
 dropout_518 (Dropout)       (None, 480)               0         
                                                                 
 dense_767 (Dense)           (None, 320)               153920    
                                                                 
 dropout_519 (Dropout)       (None, 320)               0         
                                                                 
 dense_768 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 249:
  Value: 0.9032
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011304569808281246

Model: "sequential_249"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_249 (Flatten)       (None, 784)               0         
                                                                 
 dense_769 (Dense)           (None, 512)               401920    
                                                                 
 dropout_520 (Dropout)       (None, 512)               0         
                                                                 
 dense_770 (Dense)           (None, 352)               180576    
                                                                 
 dropout_521 (Dropout)       (None, 352)               0         
                                                                 
 dense_771 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 250:
  Value: 0.8905
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014276910611001879

Model: "sequential_250"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_250 (Flatten)       (None, 784)               0         
                                                                 
 dense_772 (Dense)           (None, 480)               376800    
                                                                 
 dropout_522 (Dropout)       (None, 480)               0         
                                                                 
 dense_773 (Dense)           (None, 416)               200096    
                                                                 
 dropout_523 (Dropout)       (None, 416)               0         
                                                                 
 dense_774 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 251:
  Value: 0.8098
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0010457105359118536

Model: "sequential_251"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_251 (Flatten)       (None, 784)               0         
                                                                 
 dense_775 (Dense)           (None, 512)               401920    
                                                                 
 batch_normalization_81 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_524 (Dropout)       (None, 512)               0         
                                                                 
 dense_776 (Dense)           (None, 384)               196992    
                                                                 
 dropout_525 (Dropout)       (None, 384)               0         
                                                                 
 dense_777 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 610970 (2.33 MB)
Trainable params: 609946 (2.33 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 252:
  Value: 0.8067
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00011264859957863923

Model: "sequential_252"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_252 (Flatten)       (None, 784)               0         
                                                                 
 dense_778 (Dense)           (None, 480)               376800    
                                                                 
 dropout_526 (Dropout)       (None, 480)               0         
                                                                 
 dense_779 (Dense)           (None, 352)               169312    
                                                                 
 dropout_527 (Dropout)       (None, 352)               0         
                                                                 
 dense_780 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 253:
  Value: 0.8611
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008181485877610846

Model: "sequential_253"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_253 (Flatten)       (None, 784)               0         
                                                                 
 dense_781 (Dense)           (None, 480)               376800    
                                                                 
 dropout_528 (Dropout)       (None, 480)               0         
                                                                 
 dense_782 (Dense)           (None, 352)               169312    
                                                                 
 dropout_529 (Dropout)       (None, 352)               0         
                                                                 
 dense_783 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 254:
  Value: 0.8524
  num_layers: 2
  units_0: 512
  units_1: 160
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014942035904541488

Model: "sequential_254"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_254 (Flatten)       (None, 784)               0         
                                                                 
 dense_784 (Dense)           (None, 512)               401920    
                                                                 
 dropout_530 (Dropout)       (None, 512)               0         
                                                                 
 dense_785 (Dense)           (None, 160)               82080     
                                                                 
 dropout_531 (Dropout)       (None, 160)               0         
                                                                 
 dense_786 (Dense)           (None, 26)                4186      
                                                                 
=================================================================
Total params: 488186 (1.86 MB)
Trainable params: 488186 (1.86 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 255:
  Value: 0.9107
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012983859584288137

Model: "sequential_255"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_255 (Flatten)       (None, 784)               0         
                                                                 
 dense_787 (Dense)           (None, 480)               376800    
                                                                 
 dropout_532 (Dropout)       (None, 480)               0         
                                                                 
 dense_788 (Dense)           (None, 384)               184704    
                                                                 
 dropout_533 (Dropout)       (None, 384)               0         
                                                                 
 dense_789 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 256:
  Value: 0.8769
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013350253419029143

Model: "sequential_256"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_256 (Flatten)       (None, 784)               0         
                                                                 
 dense_790 (Dense)           (None, 480)               376800    
                                                                 
 dropout_534 (Dropout)       (None, 480)               0         
                                                                 
 dense_791 (Dense)           (None, 320)               153920    
                                                                 
 dropout_535 (Dropout)       (None, 320)               0         
                                                                 
 dense_792 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 257:
  Value: 0.9066
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017404107627342219

Model: "sequential_257"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_257 (Flatten)       (None, 784)               0         
                                                                 
 dense_793 (Dense)           (None, 480)               376800    
                                                                 
 dropout_536 (Dropout)       (None, 480)               0         
                                                                 
 dense_794 (Dense)           (None, 416)               200096    
                                                                 
 dropout_537 (Dropout)       (None, 416)               0         
                                                                 
 dense_795 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 258:
  Value: 0.9073
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015366241238842955

Model: "sequential_258"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_258 (Flatten)       (None, 784)               0         
                                                                 
 dense_796 (Dense)           (None, 480)               376800    
                                                                 
 dropout_538 (Dropout)       (None, 480)               0         
                                                                 
 dense_797 (Dense)           (None, 352)               169312    
                                                                 
 dropout_539 (Dropout)       (None, 352)               0         
                                                                 
 dense_798 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 259:
  Value: 0.9050
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001246716081184178

Model: "sequential_259"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_259 (Flatten)       (None, 784)               0         
                                                                 
 dense_799 (Dense)           (None, 448)               351680    
                                                                 
 dropout_540 (Dropout)       (None, 448)               0         
                                                                 
 dense_800 (Dense)           (None, 384)               172416    
                                                                 
 dropout_541 (Dropout)       (None, 384)               0         
                                                                 
 dense_801 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 260:
  Value: 0.9047
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0020167583314272064

Model: "sequential_260"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_260 (Flatten)       (None, 784)               0         
                                                                 
 dense_802 (Dense)           (None, 480)               376800    
                                                                 
 dropout_542 (Dropout)       (None, 480)               0         
                                                                 
 dense_803 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_82 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_543 (Dropout)       (None, 320)               0         
                                                                 
 dense_804 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 540346 (2.06 MB)
Trainable params: 539706 (2.06 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 261:
  Value: 0.8426
  num_layers: 2
  units_0: 320
  units_1: 352
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006407326756916736

Model: "sequential_261"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_261 (Flatten)       (None, 784)               0         
                                                                 
 dense_805 (Dense)           (None, 320)               251200    
                                                                 
 dropout_544 (Dropout)       (None, 320)               0         
                                                                 
 dense_806 (Dense)           (None, 352)               112992    
                                                                 
 dropout_545 (Dropout)       (None, 352)               0         
                                                                 
 dense_807 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 373370 (1.42 MB)
Trainable params: 373370 (1.42 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 262:
  Value: 0.1186
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0013796294499896662

Model: "sequential_262"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_262 (Flatten)       (None, 784)               0         
                                                                 
 dense_808 (Dense)           (None, 480)               376800    
                                                                 
 dropout_546 (Dropout)       (None, 480)               0         
                                                                 
 dense_809 (Dense)           (None, 384)               184704    
                                                                 
 dropout_547 (Dropout)       (None, 384)               0         
                                                                 
 dense_810 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 263:
  Value: 0.8595
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016733339916101956

Model: "sequential_263"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_263 (Flatten)       (None, 784)               0         
                                                                 
 dense_811 (Dense)           (None, 480)               376800    
                                                                 
 dropout_548 (Dropout)       (None, 480)               0         
                                                                 
 dense_812 (Dense)           (None, 352)               169312    
                                                                 
 dropout_549 (Dropout)       (None, 352)               0         
                                                                 
 dense_813 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 264:
  Value: 0.7472
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012387144094824908

Model: "sequential_264"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_264 (Flatten)       (None, 784)               0         
                                                                 
 dense_814 (Dense)           (None, 448)               351680    
                                                                 
 dropout_550 (Dropout)       (None, 448)               0         
                                                                 
 dense_815 (Dense)           (None, 384)               172416    
                                                                 
 dropout_551 (Dropout)       (None, 384)               0         
                                                                 
 dense_816 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 265:
  Value: 0.8080
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.0014750987593443105

Model: "sequential_265"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_265 (Flatten)       (None, 784)               0         
                                                                 
 dense_817 (Dense)           (None, 480)               376800    
                                                                 
 dropout_552 (Dropout)       (None, 480)               0         
                                                                 
 dense_818 (Dense)           (None, 352)               169312    
                                                                 
 dropout_553 (Dropout)       (None, 352)               0         
                                                                 
 dense_819 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 266:
  Value: 0.9076
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011236402774157327

Model: "sequential_266"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_266 (Flatten)       (None, 784)               0         
                                                                 
 dense_820 (Dense)           (None, 480)               376800    
                                                                 
 dropout_554 (Dropout)       (None, 480)               0         
                                                                 
 dense_821 (Dense)           (None, 352)               169312    
                                                                 
 dropout_555 (Dropout)       (None, 352)               0         
                                                                 
 dense_822 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 267:
  Value: 0.9078
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009199406530540958

Model: "sequential_267"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_267 (Flatten)       (None, 784)               0         
                                                                 
 dense_823 (Dense)           (None, 512)               401920    
                                                                 
 dropout_556 (Dropout)       (None, 512)               0         
                                                                 
 dense_824 (Dense)           (None, 384)               196992    
                                                                 
 dropout_557 (Dropout)       (None, 384)               0         
                                                                 
 dense_825 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 268:
  Value: 0.9062
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012993443336069609

Model: "sequential_268"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_268 (Flatten)       (None, 784)               0         
                                                                 
 dense_826 (Dense)           (None, 480)               376800    
                                                                 
 dropout_558 (Dropout)       (None, 480)               0         
                                                                 
 dense_827 (Dense)           (None, 384)               184704    
                                                                 
 dropout_559 (Dropout)       (None, 384)               0         
                                                                 
 dense_828 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 269:
  Value: 0.8937
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015957026733389053

Model: "sequential_269"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_269 (Flatten)       (None, 784)               0         
                                                                 
 dense_829 (Dense)           (None, 448)               351680    
                                                                 
 dropout_560 (Dropout)       (None, 448)               0         
                                                                 
 dense_830 (Dense)           (None, 416)               186784    
                                                                 
 dropout_561 (Dropout)       (None, 416)               0         
                                                                 
 dense_831 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 270:
  Value: 0.8626
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001448023322982133

Model: "sequential_270"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_270 (Flatten)       (None, 784)               0         
                                                                 
 dense_832 (Dense)           (None, 480)               376800    
                                                                 
 batch_normalization_83 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_562 (Dropout)       (None, 480)               0         
                                                                 
 dense_833 (Dense)           (None, 352)               169312    
                                                                 
 dropout_563 (Dropout)       (None, 352)               0         
                                                                 
 dense_834 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 557210 (2.13 MB)
Trainable params: 556250 (2.12 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 271:
  Value: 0.9077
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007433512054852815

Model: "sequential_271"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_271 (Flatten)       (None, 784)               0         
                                                                 
 dense_835 (Dense)           (None, 512)               401920    
                                                                 
 dropout_564 (Dropout)       (None, 512)               0         
                                                                 
 dense_836 (Dense)           (None, 448)               229824    
                                                                 
 dropout_565 (Dropout)       (None, 448)               0         
                                                                 
 dense_837 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 272:
  Value: 0.3306
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0018099876882340655

Model: "sequential_272"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_272 (Flatten)       (None, 784)               0         
                                                                 
 dense_838 (Dense)           (None, 480)               376800    
                                                                 
 dropout_566 (Dropout)       (None, 480)               0         
                                                                 
 dense_839 (Dense)           (None, 352)               169312    
                                                                 
 dropout_567 (Dropout)       (None, 352)               0         
                                                                 
 dense_840 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 273:
  Value: 0.8154
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 128
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0011667404905518475

Model: "sequential_273"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_273 (Flatten)       (None, 784)               0         
                                                                 
 dense_841 (Dense)           (None, 512)               401920    
                                                                 
 dropout_568 (Dropout)       (None, 512)               0         
                                                                 
 dense_842 (Dense)           (None, 384)               196992    
                                                                 
 dropout_569 (Dropout)       (None, 384)               0         
                                                                 
 dense_843 (Dense)           (None, 128)               49280     
                                                                 
 batch_normalization_84 (Ba  (None, 128)               512       
 tchNormalization)                                               
                                                                 
 dropout_570 (Dropout)       (None, 128)               0         
                                                                 
 dense_844 (Dense)           (None, 384)               49536     
                                                                 
 batch_normalization_85 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_571 (Dropout)       (None, 384)               0         
                                                                 
 dense_845 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 709786 (2.71 MB)
Trainable params: 708762 (2.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 274:
  Value: 0.8646
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001319163994350121

Model: "sequential_274"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_274 (Flatten)       (None, 784)               0         
                                                                 
 dense_846 (Dense)           (None, 448)               351680    
                                                                 
 dropout_572 (Dropout)       (None, 448)               0         
                                                                 
 dense_847 (Dense)           (None, 320)               143680    
                                                                 
 dropout_573 (Dropout)       (None, 320)               0         
                                                                 
 dense_848 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 503706 (1.92 MB)
Trainable params: 503706 (1.92 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 275:
  Value: 0.0389
  num_layers: 1
  units_0: 480
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: ftrl
  learning_rate: 0.00026064596263196676

Model: "sequential_275"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_275 (Flatten)       (None, 784)               0         
                                                                 
 dense_849 (Dense)           (None, 480)               376800    
                                                                 
 dropout_574 (Dropout)       (None, 480)               0         
                                                                 
 dense_850 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 276:
  Value: 0.9093
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010300615270373466

Model: "sequential_276"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_276 (Flatten)       (None, 784)               0         
                                                                 
 dense_851 (Dense)           (None, 480)               376800    
                                                                 
 dropout_575 (Dropout)       (None, 480)               0         
                                                                 
 dense_852 (Dense)           (None, 352)               169312    
                                                                 
 dropout_576 (Dropout)       (None, 352)               0         
                                                                 
 dense_853 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 277:
  Value: 0.9048
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009648022665369846

Model: "sequential_277"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_277 (Flatten)       (None, 784)               0         
                                                                 
 dense_854 (Dense)           (None, 512)               401920    
                                                                 
 dropout_577 (Dropout)       (None, 512)               0         
                                                                 
 dense_855 (Dense)           (None, 352)               180576    
                                                                 
 dropout_578 (Dropout)       (None, 352)               0         
                                                                 
 dense_856 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 278:
  Value: 0.8983
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010485435693649984

Model: "sequential_278"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_278 (Flatten)       (None, 784)               0         
                                                                 
 dense_857 (Dense)           (None, 480)               376800    
                                                                 
 dropout_579 (Dropout)       (None, 480)               0         
                                                                 
 dense_858 (Dense)           (None, 352)               169312    
                                                                 
 dropout_580 (Dropout)       (None, 352)               0         
                                                                 
 dense_859 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 279:
  Value: 0.7964
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0009050490468100307

Model: "sequential_279"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_279 (Flatten)       (None, 784)               0         
                                                                 
 dense_860 (Dense)           (None, 512)               401920    
                                                                 
 dropout_581 (Dropout)       (None, 512)               0         
                                                                 
 dense_861 (Dense)           (None, 352)               180576    
                                                                 
 dropout_582 (Dropout)       (None, 352)               0         
                                                                 
 dense_862 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 280:
  Value: 0.8621
  num_layers: 2
  units_0: 256
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0008117937733059505

Model: "sequential_280"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_280 (Flatten)       (None, 784)               0         
                                                                 
 dense_863 (Dense)           (None, 256)               200960    
                                                                 
 dropout_583 (Dropout)       (None, 256)               0         
                                                                 
 dense_864 (Dense)           (None, 320)               82240     
                                                                 
 batch_normalization_86 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_584 (Dropout)       (None, 320)               0         
                                                                 
 dense_865 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 292826 (1.12 MB)
Trainable params: 292186 (1.11 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 281:
  Value: 0.9092
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016942975555998868

Model: "sequential_281"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_281 (Flatten)       (None, 784)               0         
                                                                 
 dense_866 (Dense)           (None, 480)               376800    
                                                                 
 dropout_585 (Dropout)       (None, 480)               0         
                                                                 
 dense_867 (Dense)           (None, 352)               169312    
                                                                 
 dropout_586 (Dropout)       (None, 352)               0         
                                                                 
 dense_868 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 282:
  Value: 0.9050
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0020516977822318365

Model: "sequential_282"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_282 (Flatten)       (None, 784)               0         
                                                                 
 dense_869 (Dense)           (None, 448)               351680    
                                                                 
 dropout_587 (Dropout)       (None, 448)               0         
                                                                 
 dense_870 (Dense)           (None, 352)               158048    
                                                                 
 dropout_588 (Dropout)       (None, 352)               0         
                                                                 
 dense_871 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 283:
  Value: 0.8468
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017064176418278554

Model: "sequential_283"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_283 (Flatten)       (None, 784)               0         
                                                                 
 dense_872 (Dense)           (None, 480)               376800    
                                                                 
 dropout_589 (Dropout)       (None, 480)               0         
                                                                 
 dense_873 (Dense)           (None, 352)               169312    
                                                                 
 dropout_590 (Dropout)       (None, 352)               0         
                                                                 
 dense_874 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 284:
  Value: 0.8636
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016126877755786085

Model: "sequential_284"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_284 (Flatten)       (None, 784)               0         
                                                                 
 dense_875 (Dense)           (None, 480)               376800    
                                                                 
 dropout_591 (Dropout)       (None, 480)               0         
                                                                 
 dense_876 (Dense)           (None, 320)               153920    
                                                                 
 dropout_592 (Dropout)       (None, 320)               0         
                                                                 
 dense_877 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 285:
  Value: 0.8760
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0039408003887235685

Model: "sequential_285"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_285 (Flatten)       (None, 784)               0         
                                                                 
 dense_878 (Dense)           (None, 448)               351680    
                                                                 
 dropout_593 (Dropout)       (None, 448)               0         
                                                                 
 dense_879 (Dense)           (None, 352)               158048    
                                                                 
 dropout_594 (Dropout)       (None, 352)               0         
                                                                 
 dense_880 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 286:
  Value: 0.8637
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018066096519917785

Model: "sequential_286"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_286 (Flatten)       (None, 784)               0         
                                                                 
 dense_881 (Dense)           (None, 480)               376800    
                                                                 
 dropout_595 (Dropout)       (None, 480)               0         
                                                                 
 dense_882 (Dense)           (None, 352)               169312    
                                                                 
 dropout_596 (Dropout)       (None, 352)               0         
                                                                 
 dense_883 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 287:
  Value: 0.7406
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005539916591146528

Model: "sequential_287"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_287 (Flatten)       (None, 784)               0         
                                                                 
 dense_884 (Dense)           (None, 480)               376800    
                                                                 
 dropout_597 (Dropout)       (None, 480)               0         
                                                                 
 dense_885 (Dense)           (None, 352)               169312    
                                                                 
 dropout_598 (Dropout)       (None, 352)               0         
                                                                 
 dense_886 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 288:
  Value: 0.9081
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015056417101249808

Model: "sequential_288"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_288 (Flatten)       (None, 784)               0         
                                                                 
 dense_887 (Dense)           (None, 480)               376800    
                                                                 
 dropout_599 (Dropout)       (None, 480)               0         
                                                                 
 dense_888 (Dense)           (None, 512)               246272    
                                                                 
 dropout_600 (Dropout)       (None, 512)               0         
                                                                 
 dense_889 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 289:
  Value: 0.8214
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.0010209630019263783

Model: "sequential_289"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_289 (Flatten)       (None, 784)               0         
                                                                 
 dense_890 (Dense)           (None, 480)               376800    
                                                                 
 dropout_601 (Dropout)       (None, 480)               0         
                                                                 
 dense_891 (Dense)           (None, 352)               169312    
                                                                 
 dropout_602 (Dropout)       (None, 352)               0         
                                                                 
 dense_892 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 290:
  Value: 0.8598
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0022531277010710738

Model: "sequential_290"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_290 (Flatten)       (None, 784)               0         
                                                                 
 dense_893 (Dense)           (None, 448)               351680    
                                                                 
 batch_normalization_87 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_603 (Dropout)       (None, 448)               0         
                                                                 
 dense_894 (Dense)           (None, 320)               143680    
                                                                 
 dropout_604 (Dropout)       (None, 320)               0         
                                                                 
 dense_895 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 505498 (1.93 MB)
Trainable params: 504602 (1.92 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 291:
  Value: 0.9073
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006441038760764135

Model: "sequential_291"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_291 (Flatten)       (None, 784)               0         
                                                                 
 dense_896 (Dense)           (None, 480)               376800    
                                                                 
 dropout_605 (Dropout)       (None, 480)               0         
                                                                 
 dense_897 (Dense)           (None, 352)               169312    
                                                                 
 dropout_606 (Dropout)       (None, 352)               0         
                                                                 
 dense_898 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 292:
  Value: 0.9054
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018865560096966022

Model: "sequential_292"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_292 (Flatten)       (None, 784)               0         
                                                                 
 dense_899 (Dense)           (None, 480)               376800    
                                                                 
 dropout_607 (Dropout)       (None, 480)               0         
                                                                 
 dense_900 (Dense)           (None, 352)               169312    
                                                                 
 dropout_608 (Dropout)       (None, 352)               0         
                                                                 
 dense_901 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 293:
  Value: 0.1490
  num_layers: 2
  units_0: 512
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0005879643704458688

Model: "sequential_293"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_293 (Flatten)       (None, 784)               0         
                                                                 
 dense_902 (Dense)           (None, 512)               401920    
                                                                 
 dropout_609 (Dropout)       (None, 512)               0         
                                                                 
 dense_903 (Dense)           (None, 288)               147744    
                                                                 
 dropout_610 (Dropout)       (None, 288)               0         
                                                                 
 dense_904 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 557178 (2.13 MB)
Trainable params: 557178 (2.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 294:
  Value: 0.8643
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0028526419508523772

Model: "sequential_294"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_294 (Flatten)       (None, 784)               0         
                                                                 
 dense_905 (Dense)           (None, 480)               376800    
                                                                 
 dropout_611 (Dropout)       (None, 480)               0         
                                                                 
 dense_906 (Dense)           (None, 320)               153920    
                                                                 
 dropout_612 (Dropout)       (None, 320)               0         
                                                                 
 dense_907 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 295:
  Value: 0.9052
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014093240574832289

Model: "sequential_295"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_295 (Flatten)       (None, 784)               0         
                                                                 
 dense_908 (Dense)           (None, 480)               376800    
                                                                 
 dropout_613 (Dropout)       (None, 480)               0         
                                                                 
 dense_909 (Dense)           (None, 352)               169312    
                                                                 
 dropout_614 (Dropout)       (None, 352)               0         
                                                                 
 dense_910 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 296:
  Value: 0.8065
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008681287849943871

Model: "sequential_296"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_296 (Flatten)       (None, 784)               0         
                                                                 
 dense_911 (Dense)           (None, 480)               376800    
                                                                 
 dropout_615 (Dropout)       (None, 480)               0         
                                                                 
 dense_912 (Dense)           (None, 384)               184704    
                                                                 
 dropout_616 (Dropout)       (None, 384)               0         
                                                                 
 dense_913 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 297:
  Value: 0.8652
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011255870643402048

Model: "sequential_297"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_297 (Flatten)       (None, 784)               0         
                                                                 
 dense_914 (Dense)           (None, 448)               351680    
                                                                 
 dropout_617 (Dropout)       (None, 448)               0         
                                                                 
 dense_915 (Dense)           (None, 384)               172416    
                                                                 
 dropout_618 (Dropout)       (None, 384)               0         
                                                                 
 dense_916 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 298:
  Value: 0.9073
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007305565616137816

Model: "sequential_298"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_298 (Flatten)       (None, 784)               0         
                                                                 
 dense_917 (Dense)           (None, 512)               401920    
                                                                 
 dropout_619 (Dropout)       (None, 512)               0         
                                                                 
 dense_918 (Dense)           (None, 448)               229824    
                                                                 
 dropout_620 (Dropout)       (None, 448)               0         
                                                                 
 dense_919 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 299:
  Value: 0.9093
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016470058608242994

Model: "sequential_299"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_299 (Flatten)       (None, 784)               0         
                                                                 
 dense_920 (Dense)           (None, 480)               376800    
                                                                 
 dropout_621 (Dropout)       (None, 480)               0         
                                                                 
 dense_921 (Dense)           (None, 416)               200096    
                                                                 
 dropout_622 (Dropout)       (None, 416)               0         
                                                                 
 dense_922 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 300:
  Value: 0.6050
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: sgd
  learning_rate: 0.0017072741259902865

Model: "sequential_300"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_300 (Flatten)       (None, 784)               0         
                                                                 
 dense_923 (Dense)           (None, 512)               401920    
                                                                 
 dropout_623 (Dropout)       (None, 512)               0         
                                                                 
 dense_924 (Dense)           (None, 416)               213408    
                                                                 
 batch_normalization_88 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_624 (Dropout)       (None, 416)               0         
                                                                 
 dense_925 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 627834 (2.39 MB)
Trainable params: 627002 (2.39 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 301:
  Value: 0.9010
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006359116466679444

Model: "sequential_301"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_301 (Flatten)       (None, 784)               0         
                                                                 
 dense_926 (Dense)           (None, 480)               376800    
                                                                 
 dropout_625 (Dropout)       (None, 480)               0         
                                                                 
 dense_927 (Dense)           (None, 448)               215488    
                                                                 
 dropout_626 (Dropout)       (None, 448)               0         
                                                                 
 dense_928 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 302:
  Value: 0.8613
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015790685405528944

Model: "sequential_302"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_302 (Flatten)       (None, 784)               0         
                                                                 
 dense_929 (Dense)           (None, 448)               351680    
                                                                 
 dropout_627 (Dropout)       (None, 448)               0         
                                                                 
 dense_930 (Dense)           (None, 320)               143680    
                                                                 
 dropout_628 (Dropout)       (None, 320)               0         
                                                                 
 dense_931 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 503706 (1.92 MB)
Trainable params: 503706 (1.92 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 303:
  Value: 0.0378
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0016146322381987808

Model: "sequential_303"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_303 (Flatten)       (None, 784)               0         
                                                                 
 dense_932 (Dense)           (None, 480)               376800    
                                                                 
 dropout_629 (Dropout)       (None, 480)               0         
                                                                 
 dense_933 (Dense)           (None, 416)               200096    
                                                                 
 dropout_630 (Dropout)       (None, 416)               0         
                                                                 
 dense_934 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 304:
  Value: 0.9068
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018611615089455984

Model: "sequential_304"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_304 (Flatten)       (None, 784)               0         
                                                                 
 dense_935 (Dense)           (None, 512)               401920    
                                                                 
 dropout_631 (Dropout)       (None, 512)               0         
                                                                 
 dense_936 (Dense)           (None, 448)               229824    
                                                                 
 dropout_632 (Dropout)       (None, 448)               0         
                                                                 
 dense_937 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 305:
  Value: 0.8641
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0020768489581859876

Model: "sequential_305"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_305 (Flatten)       (None, 784)               0         
                                                                 
 dense_938 (Dense)           (None, 480)               376800    
                                                                 
 dropout_633 (Dropout)       (None, 480)               0         
                                                                 
 dense_939 (Dense)           (None, 352)               169312    
                                                                 
 dropout_634 (Dropout)       (None, 352)               0         
                                                                 
 dense_940 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 306:
  Value: 0.9070
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009715478968028475

Model: "sequential_306"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_306 (Flatten)       (None, 784)               0         
                                                                 
 dense_941 (Dense)           (None, 512)               401920    
                                                                 
 dropout_635 (Dropout)       (None, 512)               0         
                                                                 
 dense_942 (Dense)           (None, 480)               246240    
                                                                 
 dropout_636 (Dropout)       (None, 480)               0         
                                                                 
 dense_943 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 307:
  Value: 0.8637
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012565076372277766

Model: "sequential_307"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_307 (Flatten)       (None, 784)               0         
                                                                 
 dense_944 (Dense)           (None, 448)               351680    
                                                                 
 dropout_637 (Dropout)       (None, 448)               0         
                                                                 
 dense_945 (Dense)           (None, 352)               158048    
                                                                 
 dropout_638 (Dropout)       (None, 352)               0         
                                                                 
 dense_946 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 308:
  Value: 0.8519
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014765906702293035

Model: "sequential_308"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_308 (Flatten)       (None, 784)               0         
                                                                 
 dense_947 (Dense)           (None, 480)               376800    
                                                                 
 dropout_639 (Dropout)       (None, 480)               0         
                                                                 
 dense_948 (Dense)           (None, 416)               200096    
                                                                 
 dropout_640 (Dropout)       (None, 416)               0         
                                                                 
 dense_949 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 309:
  Value: 0.9082
  num_layers: 3
  units_0: 480
  units_1: 352
  units_2: 192
  activation_0: relu
  activation_1: relu
  activation_2: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0010749512480985055

Model: "sequential_309"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_309 (Flatten)       (None, 784)               0         
                                                                 
 dense_950 (Dense)           (None, 480)               376800    
                                                                 
 dropout_641 (Dropout)       (None, 480)               0         
                                                                 
 dense_951 (Dense)           (None, 352)               169312    
                                                                 
 dropout_642 (Dropout)       (None, 352)               0         
                                                                 
 dense_952 (Dense)           (None, 192)               67776     
                                                                 
 batch_normalization_89 (Ba  (None, 192)               768       
 tchNormalization)                                               
                                                                 
 dropout_643 (Dropout)       (None, 192)               0         
                                                                 
 dense_953 (Dense)           (None, 26)                5018      
                                                                 
=================================================================
Total params: 619674 (2.36 MB)
Trainable params: 619290 (2.36 MB)
Non-trainable params: 384 (1.50 KB)
_________________________________________________________________



Trial 310:
  Value: 0.6569
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0013452047838598245

Model: "sequential_310"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_310 (Flatten)       (None, 784)               0         
                                                                 
 dense_954 (Dense)           (None, 512)               401920    
                                                                 
 dropout_644 (Dropout)       (None, 512)               0         
                                                                 
 dense_955 (Dense)           (None, 352)               180576    
                                                                 
 dropout_645 (Dropout)       (None, 352)               0         
                                                                 
 dense_956 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 311:
  Value: 0.8771
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007916014423069103

Model: "sequential_311"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_311 (Flatten)       (None, 784)               0         
                                                                 
 dense_957 (Dense)           (None, 480)               376800    
                                                                 
 batch_normalization_90 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_646 (Dropout)       (None, 480)               0         
                                                                 
 dense_958 (Dense)           (None, 352)               169312    
                                                                 
 dropout_647 (Dropout)       (None, 352)               0         
                                                                 
 dense_959 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 557210 (2.13 MB)
Trainable params: 556250 (2.12 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 312:
  Value: 0.8559
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006923187377167512

Model: "sequential_312"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_312 (Flatten)       (None, 784)               0         
                                                                 
 dense_960 (Dense)           (None, 448)               351680    
                                                                 
 dropout_648 (Dropout)       (None, 448)               0         
                                                                 
 dense_961 (Dense)           (None, 320)               143680    
                                                                 
 dropout_649 (Dropout)       (None, 320)               0         
                                                                 
 dense_962 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 503706 (1.92 MB)
Trainable params: 503706 (1.92 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 313:
  Value: 0.8369
  num_layers: 2
  units_0: 224
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017177139903151678

Model: "sequential_313"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_313 (Flatten)       (None, 784)               0         
                                                                 
 dense_963 (Dense)           (None, 224)               175840    
                                                                 
 dropout_650 (Dropout)       (None, 224)               0         
                                                                 
 dense_964 (Dense)           (None, 384)               86400     
                                                                 
 dropout_651 (Dropout)       (None, 384)               0         
                                                                 
 dense_965 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 272250 (1.04 MB)
Trainable params: 272250 (1.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 314:
  Value: 0.9077
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011642366738515812

Model: "sequential_314"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_314 (Flatten)       (None, 784)               0         
                                                                 
 dense_966 (Dense)           (None, 480)               376800    
                                                                 
 dropout_652 (Dropout)       (None, 480)               0         
                                                                 
 dense_967 (Dense)           (None, 352)               169312    
                                                                 
 dropout_653 (Dropout)       (None, 352)               0         
                                                                 
 dense_968 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 315:
  Value: 0.9050
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015403647877705708

Model: "sequential_315"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_315 (Flatten)       (None, 784)               0         
                                                                 
 dense_969 (Dense)           (None, 512)               401920    
                                                                 
 dropout_654 (Dropout)       (None, 512)               0         
                                                                 
 dense_970 (Dense)           (None, 384)               196992    
                                                                 
 dropout_655 (Dropout)       (None, 384)               0         
                                                                 
 dense_971 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 316:
  Value: 0.9073
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001254466511072275

Model: "sequential_316"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_316 (Flatten)       (None, 784)               0         
                                                                 
 dense_972 (Dense)           (None, 480)               376800    
                                                                 
 dropout_656 (Dropout)       (None, 480)               0         
                                                                 
 dense_973 (Dense)           (None, 416)               200096    
                                                                 
 dropout_657 (Dropout)       (None, 416)               0         
                                                                 
 dense_974 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 317:
  Value: 0.8095
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001365575488785151

Model: "sequential_317"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_317 (Flatten)       (None, 784)               0         
                                                                 
 dense_975 (Dense)           (None, 512)               401920    
                                                                 
 dropout_658 (Dropout)       (None, 512)               0         
                                                                 
 dense_976 (Dense)           (None, 320)               164160    
                                                                 
 dropout_659 (Dropout)       (None, 320)               0         
                                                                 
 dense_977 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 318:
  Value: 0.9062
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019922389681253727

Model: "sequential_318"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_318 (Flatten)       (None, 784)               0         
                                                                 
 dense_978 (Dense)           (None, 480)               376800    
                                                                 
 dropout_660 (Dropout)       (None, 480)               0         
                                                                 
 dense_979 (Dense)           (None, 384)               184704    
                                                                 
 dropout_661 (Dropout)       (None, 384)               0         
                                                                 
 dense_980 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 319:
  Value: 0.8195
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.0010000168512353449

Model: "sequential_319"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_319 (Flatten)       (None, 784)               0         
                                                                 
 dense_981 (Dense)           (None, 480)               376800    
                                                                 
 dropout_662 (Dropout)       (None, 480)               0         
                                                                 
 dense_982 (Dense)           (None, 352)               169312    
                                                                 
 dropout_663 (Dropout)       (None, 352)               0         
                                                                 
 dense_983 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 320:
  Value: 0.4376
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adagrad
  learning_rate: 0.0016881165554223083

Model: "sequential_320"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_320 (Flatten)       (None, 784)               0         
                                                                 
 dense_984 (Dense)           (None, 512)               401920    
                                                                 
 dropout_664 (Dropout)       (None, 512)               0         
                                                                 
 dense_985 (Dense)           (None, 352)               180576    
                                                                 
 batch_normalization_91 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_665 (Dropout)       (None, 352)               0         
                                                                 
 dense_986 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 593082 (2.26 MB)
Trainable params: 592378 (2.26 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 321:
  Value: 0.8647
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008876641109088107

Model: "sequential_321"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_321 (Flatten)       (None, 784)               0         
                                                                 
 dense_987 (Dense)           (None, 448)               351680    
                                                                 
 dropout_666 (Dropout)       (None, 448)               0         
                                                                 
 dense_988 (Dense)           (None, 384)               172416    
                                                                 
 dropout_667 (Dropout)       (None, 384)               0         
                                                                 
 dense_989 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 322:
  Value: 0.8650
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014562996335496599

Model: "sequential_322"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_322 (Flatten)       (None, 784)               0         
                                                                 
 dense_990 (Dense)           (None, 480)               376800    
                                                                 
 dropout_668 (Dropout)       (None, 480)               0         
                                                                 
 dense_991 (Dense)           (None, 352)               169312    
                                                                 
 dropout_669 (Dropout)       (None, 352)               0         
                                                                 
 dense_992 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 323:
  Value: 0.8305
  num_layers: 2
  units_0: 160
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011954685781911131

Model: "sequential_323"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_323 (Flatten)       (None, 784)               0         
                                                                 
 dense_993 (Dense)           (None, 160)               125600    
                                                                 
 dropout_670 (Dropout)       (None, 160)               0         
                                                                 
 dense_994 (Dense)           (None, 480)               77280     
                                                                 
 dropout_671 (Dropout)       (None, 480)               0         
                                                                 
 dense_995 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 215386 (841.35 KB)
Trainable params: 215386 (841.35 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 324:
  Value: 0.8553
  num_layers: 2
  units_0: 288
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005745529842609478

Model: "sequential_324"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_324 (Flatten)       (None, 784)               0         
                                                                 
 dense_996 (Dense)           (None, 288)               226080    
                                                                 
 dropout_672 (Dropout)       (None, 288)               0         
                                                                 
 dense_997 (Dense)           (None, 448)               129472    
                                                                 
 dropout_673 (Dropout)       (None, 448)               0         
                                                                 
 dense_998 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 367226 (1.40 MB)
Trainable params: 367226 (1.40 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 325:
  Value: 0.8612
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015320260092828977

Model: "sequential_325"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_325 (Flatten)       (None, 784)               0         
                                                                 
 dense_999 (Dense)           (None, 512)               401920    
                                                                 
 dropout_674 (Dropout)       (None, 512)               0         
                                                                 
 dense_1000 (Dense)          (None, 320)               164160    
                                                                 
 dropout_675 (Dropout)       (None, 320)               0         
                                                                 
 dense_1001 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 326:
  Value: 0.8847
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010988599374292486

Model: "sequential_326"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_326 (Flatten)       (None, 784)               0         
                                                                 
 dense_1002 (Dense)          (None, 480)               376800    
                                                                 
 dropout_676 (Dropout)       (None, 480)               0         
                                                                 
 dense_1003 (Dense)          (None, 384)               184704    
                                                                 
 dropout_677 (Dropout)       (None, 384)               0         
                                                                 
 dense_1004 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 327:
  Value: 0.8089
  num_layers: 2
  units_0: 96
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009813198309306445

Model: "sequential_327"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_327 (Flatten)       (None, 784)               0         
                                                                 
 dense_1005 (Dense)          (None, 96)                75360     
                                                                 
 dropout_678 (Dropout)       (None, 96)                0         
                                                                 
 dense_1006 (Dense)          (None, 416)               40352     
                                                                 
 dropout_679 (Dropout)       (None, 416)               0         
                                                                 
 dense_1007 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 126554 (494.35 KB)
Trainable params: 126554 (494.35 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 328:
  Value: 0.4203
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0013050698638175943

Model: "sequential_328"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_328 (Flatten)       (None, 784)               0         
                                                                 
 dense_1008 (Dense)          (None, 480)               376800    
                                                                 
 dropout_680 (Dropout)       (None, 480)               0         
                                                                 
 dense_1009 (Dense)          (None, 352)               169312    
                                                                 
 dropout_681 (Dropout)       (None, 352)               0         
                                                                 
 dense_1010 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 329:
  Value: 0.8650
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001814690571423224

Model: "sequential_329"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_329 (Flatten)       (None, 784)               0         
                                                                 
 dense_1011 (Dense)          (None, 448)               351680    
                                                                 
 dropout_682 (Dropout)       (None, 448)               0         
                                                                 
 dense_1012 (Dense)          (None, 352)               158048    
                                                                 
 dropout_683 (Dropout)       (None, 352)               0         
                                                                 
 dense_1013 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 330:
  Value: 0.8915
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006739413584970365

Model: "sequential_330"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_330 (Flatten)       (None, 784)               0         
                                                                 
 dense_1014 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_92 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_684 (Dropout)       (None, 512)               0         
                                                                 
 dense_1015 (Dense)          (None, 512)               262656    
                                                                 
 dropout_685 (Dropout)       (None, 512)               0         
                                                                 
 dense_1016 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 679962 (2.59 MB)
Trainable params: 678938 (2.59 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 331:
  Value: 0.9055
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008422415301921447

Model: "sequential_331"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_331 (Flatten)       (None, 784)               0         
                                                                 
 dense_1017 (Dense)          (None, 480)               376800    
                                                                 
 dropout_686 (Dropout)       (None, 480)               0         
                                                                 
 dense_1018 (Dense)          (None, 384)               184704    
                                                                 
 dropout_687 (Dropout)       (None, 384)               0         
                                                                 
 dense_1019 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 332:
  Value: 0.9083
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014095017879926861

Model: "sequential_332"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_332 (Flatten)       (None, 784)               0         
                                                                 
 dense_1020 (Dense)          (None, 480)               376800    
                                                                 
 dropout_688 (Dropout)       (None, 480)               0         
                                                                 
 dense_1021 (Dense)          (None, 320)               153920    
                                                                 
 dropout_689 (Dropout)       (None, 320)               0         
                                                                 
 dense_1022 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 333:
  Value: 0.0385
  num_layers: 2
  units_0: 448
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.00157897004838508

Model: "sequential_333"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_333 (Flatten)       (None, 784)               0         
                                                                 
 dense_1023 (Dense)          (None, 448)               351680    
                                                                 
 dropout_690 (Dropout)       (None, 448)               0         
                                                                 
 dense_1024 (Dense)          (None, 320)               143680    
                                                                 
 dropout_691 (Dropout)       (None, 320)               0         
                                                                 
 dense_1025 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 503706 (1.92 MB)
Trainable params: 503706 (1.92 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 334:
  Value: 0.8631
  num_layers: 2
  units_0: 480
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001441251088905151

Model: "sequential_334"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_334 (Flatten)       (None, 784)               0         
                                                                 
 dense_1026 (Dense)          (None, 480)               376800    
                                                                 
 dropout_692 (Dropout)       (None, 480)               0         
                                                                 
 dense_1027 (Dense)          (None, 288)               138528    
                                                                 
 dropout_693 (Dropout)       (None, 288)               0         
                                                                 
 dense_1028 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 522842 (1.99 MB)
Trainable params: 522842 (1.99 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 335:
  Value: 0.8640
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017564744183495966

Model: "sequential_335"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_335 (Flatten)       (None, 784)               0         
                                                                 
 dense_1029 (Dense)          (None, 512)               401920    
                                                                 
 dropout_694 (Dropout)       (None, 512)               0         
                                                                 
 dense_1030 (Dense)          (None, 320)               164160    
                                                                 
 dropout_695 (Dropout)       (None, 320)               0         
                                                                 
 dense_1031 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 336:
  Value: 0.7956
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.005059120580661507

Model: "sequential_336"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_336 (Flatten)       (None, 784)               0         
                                                                 
 dense_1032 (Dense)          (None, 512)               401920    
                                                                 
 dropout_696 (Dropout)       (None, 512)               0         
                                                                 
 dense_1033 (Dense)          (None, 320)               164160    
                                                                 
 dropout_697 (Dropout)       (None, 320)               0         
                                                                 
 dense_1034 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 337:
  Value: 0.7331
  num_layers: 2
  units_0: 192
  units_1: 352
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011911148659292468

Model: "sequential_337"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_337 (Flatten)       (None, 784)               0         
                                                                 
 dense_1035 (Dense)          (None, 192)               150720    
                                                                 
 dropout_698 (Dropout)       (None, 192)               0         
                                                                 
 dense_1036 (Dense)          (None, 352)               67936     
                                                                 
 dropout_699 (Dropout)       (None, 352)               0         
                                                                 
 dense_1037 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 227834 (889.98 KB)
Trainable params: 227834 (889.98 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 338:
  Value: 0.9030
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000980302970744945

Model: "sequential_338"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_338 (Flatten)       (None, 784)               0         
                                                                 
 dense_1038 (Dense)          (None, 480)               376800    
                                                                 
 dropout_700 (Dropout)       (None, 480)               0         
                                                                 
 dense_1039 (Dense)          (None, 352)               169312    
                                                                 
 dropout_701 (Dropout)       (None, 352)               0         
                                                                 
 dense_1040 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 339:
  Value: 0.4532
  num_layers: 3
  units_0: 64
  units_1: 320
  units_2: 96
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.5
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0013993944511107488

Model: "sequential_339"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_339 (Flatten)       (None, 784)               0         
                                                                 
 dense_1041 (Dense)          (None, 64)                50240     
                                                                 
 dropout_702 (Dropout)       (None, 64)                0         
                                                                 
 dense_1042 (Dense)          (None, 320)               20800     
                                                                 
 batch_normalization_93 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_703 (Dropout)       (None, 320)               0         
                                                                 
 dense_1043 (Dense)          (None, 96)                30816     
                                                                 
 batch_normalization_94 (Ba  (None, 96)                384       
 tchNormalization)                                               
                                                                 
 dropout_704 (Dropout)       (None, 96)                0         
                                                                 
 dense_1044 (Dense)          (None, 26)                2522      
                                                                 
=================================================================
Total params: 106042 (414.23 KB)
Trainable params: 105210 (410.98 KB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 340:
  Value: 0.8316
  num_layers: 1
  units_0: 480
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0019699530519843916

Model: "sequential_340"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_340 (Flatten)       (None, 784)               0         
                                                                 
 dense_1045 (Dense)          (None, 480)               376800    
                                                                 
 dropout_705 (Dropout)       (None, 480)               0         
                                                                 
 dense_1046 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 341:
  Value: 0.8947
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0024258247818232806

Model: "sequential_341"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_341 (Flatten)       (None, 784)               0         
                                                                 
 dense_1047 (Dense)          (None, 480)               376800    
                                                                 
 dropout_706 (Dropout)       (None, 480)               0         
                                                                 
 dense_1048 (Dense)          (None, 352)               169312    
                                                                 
 dropout_707 (Dropout)       (None, 352)               0         
                                                                 
 dense_1049 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 342:
  Value: 0.9074
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016347805285746664

Model: "sequential_342"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_342 (Flatten)       (None, 784)               0         
                                                                 
 dense_1050 (Dense)          (None, 512)               401920    
                                                                 
 dropout_708 (Dropout)       (None, 512)               0         
                                                                 
 dense_1051 (Dense)          (None, 352)               180576    
                                                                 
 dropout_709 (Dropout)       (None, 352)               0         
                                                                 
 dense_1052 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 343:
  Value: 0.8465
  num_layers: 2
  units_0: 320
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0044071905007734636

Model: "sequential_343"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_343 (Flatten)       (None, 784)               0         
                                                                 
 dense_1053 (Dense)          (None, 320)               251200    
                                                                 
 dropout_710 (Dropout)       (None, 320)               0         
                                                                 
 dense_1054 (Dense)          (None, 352)               112992    
                                                                 
 dropout_711 (Dropout)       (None, 352)               0         
                                                                 
 dense_1055 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 373370 (1.42 MB)
Trainable params: 373370 (1.42 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 344:
  Value: 0.8601
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00753939044116744

Model: "sequential_344"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_344 (Flatten)       (None, 784)               0         
                                                                 
 dense_1056 (Dense)          (None, 448)               351680    
                                                                 
 dropout_712 (Dropout)       (None, 448)               0         
                                                                 
 dense_1057 (Dense)          (None, 352)               158048    
                                                                 
 dropout_713 (Dropout)       (None, 352)               0         
                                                                 
 dense_1058 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 345:
  Value: 0.9062
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010959535329804408

Model: "sequential_345"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_345 (Flatten)       (None, 784)               0         
                                                                 
 dense_1059 (Dense)          (None, 480)               376800    
                                                                 
 dropout_714 (Dropout)       (None, 480)               0         
                                                                 
 dense_1060 (Dense)          (None, 480)               230880    
                                                                 
 dropout_715 (Dropout)       (None, 480)               0         
                                                                 
 dense_1061 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 346:
  Value: 0.8249
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.001357935095690881

Model: "sequential_346"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_346 (Flatten)       (None, 784)               0         
                                                                 
 dense_1062 (Dense)          (None, 512)               401920    
                                                                 
 dropout_716 (Dropout)       (None, 512)               0         
                                                                 
 dense_1063 (Dense)          (None, 320)               164160    
                                                                 
 dropout_717 (Dropout)       (None, 320)               0         
                                                                 
 dense_1064 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 347:
  Value: 0.8975
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0033509724733057993

Model: "sequential_347"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_347 (Flatten)       (None, 784)               0         
                                                                 
 dense_1065 (Dense)          (None, 448)               351680    
                                                                 
 dropout_718 (Dropout)       (None, 448)               0         
                                                                 
 dense_1066 (Dense)          (None, 352)               158048    
                                                                 
 dropout_719 (Dropout)       (None, 352)               0         
                                                                 
 dense_1067 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 348:
  Value: 0.1393
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0007520411624584097

Model: "sequential_348"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_348 (Flatten)       (None, 784)               0         
                                                                 
 dense_1068 (Dense)          (None, 480)               376800    
                                                                 
 dropout_720 (Dropout)       (None, 480)               0         
                                                                 
 dense_1069 (Dense)          (None, 448)               215488    
                                                                 
 dropout_721 (Dropout)       (None, 448)               0         
                                                                 
 dense_1070 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 349:
  Value: 0.8980
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015096615355228093

Model: "sequential_349"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_349 (Flatten)       (None, 784)               0         
                                                                 
 dense_1071 (Dense)          (None, 480)               376800    
                                                                 
 dropout_722 (Dropout)       (None, 480)               0         
                                                                 
 dense_1072 (Dense)          (None, 352)               169312    
                                                                 
 dropout_723 (Dropout)       (None, 352)               0         
                                                                 
 dense_1073 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 350:
  Value: 0.8536
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00025490907214436963

Model: "sequential_350"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_350 (Flatten)       (None, 784)               0         
                                                                 
 dense_1074 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_95 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_724 (Dropout)       (None, 512)               0         
                                                                 
 dense_1075 (Dense)          (None, 384)               196992    
                                                                 
 dropout_725 (Dropout)       (None, 384)               0         
                                                                 
 dense_1076 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 610970 (2.33 MB)
Trainable params: 609946 (2.33 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 351:
  Value: 0.8391
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001268265356115309

Model: "sequential_351"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_351 (Flatten)       (None, 784)               0         
                                                                 
 dense_1077 (Dense)          (None, 480)               376800    
                                                                 
 dropout_726 (Dropout)       (None, 480)               0         
                                                                 
 dense_1078 (Dense)          (None, 320)               153920    
                                                                 
 dropout_727 (Dropout)       (None, 320)               0         
                                                                 
 dense_1079 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 352:
  Value: 0.8627
  num_layers: 2
  units_0: 480
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016554976269133712

Model: "sequential_352"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_352 (Flatten)       (None, 784)               0         
                                                                 
 dense_1080 (Dense)          (None, 480)               376800    
                                                                 
 dropout_728 (Dropout)       (None, 480)               0         
                                                                 
 dense_1081 (Dense)          (None, 288)               138528    
                                                                 
 dropout_729 (Dropout)       (None, 288)               0         
                                                                 
 dense_1082 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 522842 (1.99 MB)
Trainable params: 522842 (1.99 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 353:
  Value: 0.8613
  num_layers: 2
  units_0: 416
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012007159525775435

Model: "sequential_353"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_353 (Flatten)       (None, 784)               0         
                                                                 
 dense_1083 (Dense)          (None, 416)               326560    
                                                                 
 dropout_730 (Dropout)       (None, 416)               0         
                                                                 
 dense_1084 (Dense)          (None, 352)               146784    
                                                                 
 dropout_731 (Dropout)       (None, 352)               0         
                                                                 
 dense_1085 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 482522 (1.84 MB)
Trainable params: 482522 (1.84 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 354:
  Value: 0.9062
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009189869841207927

Model: "sequential_354"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_354 (Flatten)       (None, 784)               0         
                                                                 
 dense_1086 (Dense)          (None, 512)               401920    
                                                                 
 dropout_732 (Dropout)       (None, 512)               0         
                                                                 
 dense_1087 (Dense)          (None, 384)               196992    
                                                                 
 dropout_733 (Dropout)       (None, 384)               0         
                                                                 
 dense_1088 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 355:
  Value: 0.7295
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018750318687477496

Model: "sequential_355"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_355 (Flatten)       (None, 784)               0         
                                                                 
 dense_1089 (Dense)          (None, 480)               376800    
                                                                 
 dropout_734 (Dropout)       (None, 480)               0         
                                                                 
 dense_1090 (Dense)          (None, 512)               246272    
                                                                 
 dropout_735 (Dropout)       (None, 512)               0         
                                                                 
 dense_1091 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 356:
  Value: 0.3225
  num_layers: 2
  units_0: 448
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0010624274669276846

Model: "sequential_356"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_356 (Flatten)       (None, 784)               0         
                                                                 
 dense_1092 (Dense)          (None, 448)               351680    
                                                                 
 dropout_736 (Dropout)       (None, 448)               0         
                                                                 
 dense_1093 (Dense)          (None, 352)               158048    
                                                                 
 dropout_737 (Dropout)       (None, 352)               0         
                                                                 
 dense_1094 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 518906 (1.98 MB)
Trainable params: 518906 (1.98 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 357:
  Value: 0.9085
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014895749506309282

Model: "sequential_357"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_357 (Flatten)       (None, 784)               0         
                                                                 
 dense_1095 (Dense)          (None, 512)               401920    
                                                                 
 dropout_738 (Dropout)       (None, 512)               0         
                                                                 
 dense_1096 (Dense)          (None, 416)               213408    
                                                                 
 dropout_739 (Dropout)       (None, 416)               0         
                                                                 
 dense_1097 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 358:
  Value: 0.9105
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00212763898415829

Model: "sequential_358"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_358 (Flatten)       (None, 784)               0         
                                                                 
 dense_1098 (Dense)          (None, 512)               401920    
                                                                 
 dropout_740 (Dropout)       (None, 512)               0         
                                                                 
 dense_1099 (Dense)          (None, 416)               213408    
                                                                 
 dropout_741 (Dropout)       (None, 416)               0         
                                                                 
 dense_1100 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 359:
  Value: 0.9085
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002239162832328358

Model: "sequential_359"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_359 (Flatten)       (None, 784)               0         
                                                                 
 dense_1101 (Dense)          (None, 512)               401920    
                                                                 
 dropout_742 (Dropout)       (None, 512)               0         
                                                                 
 dense_1102 (Dense)          (None, 416)               213408    
                                                                 
 dropout_743 (Dropout)       (None, 416)               0         
                                                                 
 dense_1103 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 360:
  Value: 0.0385
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0019737543939305473

Model: "sequential_360"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_360 (Flatten)       (None, 784)               0         
                                                                 
 dense_1104 (Dense)          (None, 512)               401920    
                                                                 
 dropout_744 (Dropout)       (None, 512)               0         
                                                                 
 dense_1105 (Dense)          (None, 416)               213408    
                                                                 
 dropout_745 (Dropout)       (None, 416)               0         
                                                                 
 dense_1106 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 361:
  Value: 0.9049
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0021844523205139027

Model: "sequential_361"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_361 (Flatten)       (None, 784)               0         
                                                                 
 dense_1107 (Dense)          (None, 512)               401920    
                                                                 
 dropout_746 (Dropout)       (None, 512)               0         
                                                                 
 dense_1108 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_96 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_747 (Dropout)       (None, 416)               0         
                                                                 
 dense_1109 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 627834 (2.39 MB)
Trainable params: 627002 (2.39 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 362:
  Value: 0.9082
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002456759882927423

Model: "sequential_362"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_362 (Flatten)       (None, 784)               0         
                                                                 
 dense_1110 (Dense)          (None, 512)               401920    
                                                                 
 dropout_748 (Dropout)       (None, 512)               0         
                                                                 
 dense_1111 (Dense)          (None, 416)               213408    
                                                                 
 dropout_749 (Dropout)       (None, 416)               0         
                                                                 
 dense_1112 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 363:
  Value: 0.9086
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0020452675271472875

Model: "sequential_363"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_363 (Flatten)       (None, 784)               0         
                                                                 
 dense_1113 (Dense)          (None, 512)               401920    
                                                                 
 dropout_750 (Dropout)       (None, 512)               0         
                                                                 
 dense_1114 (Dense)          (None, 416)               213408    
                                                                 
 dropout_751 (Dropout)       (None, 416)               0         
                                                                 
 dense_1115 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 364:
  Value: 0.9067
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002227483794321659

Model: "sequential_364"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_364 (Flatten)       (None, 784)               0         
                                                                 
 dense_1116 (Dense)          (None, 512)               401920    
                                                                 
 dropout_752 (Dropout)       (None, 512)               0         
                                                                 
 dense_1117 (Dense)          (None, 416)               213408    
                                                                 
 dropout_753 (Dropout)       (None, 416)               0         
                                                                 
 dense_1118 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 365:
  Value: 0.8087
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002069319781062185

Model: "sequential_365"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_365 (Flatten)       (None, 784)               0         
                                                                 
 dense_1119 (Dense)          (None, 512)               401920    
                                                                 
 dropout_754 (Dropout)       (None, 512)               0         
                                                                 
 dense_1120 (Dense)          (None, 416)               213408    
                                                                 
 dropout_755 (Dropout)       (None, 416)               0         
                                                                 
 dense_1121 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 366:
  Value: 0.8890
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0023006115263940674

Model: "sequential_366"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_366 (Flatten)       (None, 784)               0         
                                                                 
 dense_1122 (Dense)          (None, 512)               401920    
                                                                 
 dropout_756 (Dropout)       (None, 512)               0         
                                                                 
 dense_1123 (Dense)          (None, 416)               213408    
                                                                 
 dropout_757 (Dropout)       (None, 416)               0         
                                                                 
 dense_1124 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 367:
  Value: 0.9042
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002108791235866325

Model: "sequential_367"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_367 (Flatten)       (None, 784)               0         
                                                                 
 dense_1125 (Dense)          (None, 512)               401920    
                                                                 
 dropout_758 (Dropout)       (None, 512)               0         
                                                                 
 dense_1126 (Dense)          (None, 416)               213408    
                                                                 
 dropout_759 (Dropout)       (None, 416)               0         
                                                                 
 dense_1127 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 368:
  Value: 0.7999
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.002602480846375073

Model: "sequential_368"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_368 (Flatten)       (None, 784)               0         
                                                                 
 dense_1128 (Dense)          (None, 512)               401920    
                                                                 
 dropout_760 (Dropout)       (None, 512)               0         
                                                                 
 dense_1129 (Dense)          (None, 448)               229824    
                                                                 
 dropout_761 (Dropout)       (None, 448)               0         
                                                                 
 dense_1130 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 369:
  Value: 0.8649
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018830709418278665

Model: "sequential_369"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_369 (Flatten)       (None, 784)               0         
                                                                 
 dense_1131 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_97 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_762 (Dropout)       (None, 512)               0         
                                                                 
 dense_1132 (Dense)          (None, 416)               213408    
                                                                 
 dropout_763 (Dropout)       (None, 416)               0         
                                                                 
 dense_1133 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 628218 (2.40 MB)
Trainable params: 627194 (2.39 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 370:
  Value: 0.9099
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0022097911900149352

Model: "sequential_370"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_370 (Flatten)       (None, 784)               0         
                                                                 
 dense_1134 (Dense)          (None, 512)               401920    
                                                                 
 dropout_764 (Dropout)       (None, 512)               0         
                                                                 
 dense_1135 (Dense)          (None, 416)               213408    
                                                                 
 dropout_765 (Dropout)       (None, 416)               0         
                                                                 
 dense_1136 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 371:
  Value: 0.9096
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002786002320509896

Model: "sequential_371"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_371 (Flatten)       (None, 784)               0         
                                                                 
 dense_1137 (Dense)          (None, 512)               401920    
                                                                 
 dropout_766 (Dropout)       (None, 512)               0         
                                                                 
 dense_1138 (Dense)          (None, 448)               229824    
                                                                 
 dropout_767 (Dropout)       (None, 448)               0         
                                                                 
 dense_1139 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 372:
  Value: 0.9047
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002860734098044385

Model: "sequential_372"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_372 (Flatten)       (None, 784)               0         
                                                                 
 dense_1140 (Dense)          (None, 512)               401920    
                                                                 
 dropout_768 (Dropout)       (None, 512)               0         
                                                                 
 dense_1141 (Dense)          (None, 448)               229824    
                                                                 
 dropout_769 (Dropout)       (None, 448)               0         
                                                                 
 dense_1142 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 373:
  Value: 0.9054
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0030372029516529124

Model: "sequential_373"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_373 (Flatten)       (None, 784)               0         
                                                                 
 dense_1143 (Dense)          (None, 512)               401920    
                                                                 
 dropout_770 (Dropout)       (None, 512)               0         
                                                                 
 dense_1144 (Dense)          (None, 448)               229824    
                                                                 
 dropout_771 (Dropout)       (None, 448)               0         
                                                                 
 dense_1145 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 374:
  Value: 0.8534
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0024202600774059736

Model: "sequential_374"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_374 (Flatten)       (None, 784)               0         
                                                                 
 dense_1146 (Dense)          (None, 512)               401920    
                                                                 
 dropout_772 (Dropout)       (None, 512)               0         
                                                                 
 dense_1147 (Dense)          (None, 448)               229824    
                                                                 
 dropout_773 (Dropout)       (None, 448)               0         
                                                                 
 dense_1148 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 375:
  Value: 0.9073
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002166654800387258

Model: "sequential_375"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_375 (Flatten)       (None, 784)               0         
                                                                 
 dense_1149 (Dense)          (None, 512)               401920    
                                                                 
 dropout_774 (Dropout)       (None, 512)               0         
                                                                 
 dense_1150 (Dense)          (None, 416)               213408    
                                                                 
 dropout_775 (Dropout)       (None, 416)               0         
                                                                 
 dense_1151 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 376:
  Value: 0.8255
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.003407367747654453

Model: "sequential_376"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_376 (Flatten)       (None, 784)               0         
                                                                 
 dense_1152 (Dense)          (None, 512)               401920    
                                                                 
 dropout_776 (Dropout)       (None, 512)               0         
                                                                 
 dense_1153 (Dense)          (None, 448)               229824    
                                                                 
 dropout_777 (Dropout)       (None, 448)               0         
                                                                 
 dense_1154 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 377:
  Value: 0.9074
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002494069689026414

Model: "sequential_377"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_377 (Flatten)       (None, 784)               0         
                                                                 
 dense_1155 (Dense)          (None, 512)               401920    
                                                                 
 dropout_778 (Dropout)       (None, 512)               0         
                                                                 
 dense_1156 (Dense)          (None, 448)               229824    
                                                                 
 dropout_779 (Dropout)       (None, 448)               0         
                                                                 
 dense_1157 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 378:
  Value: 0.0417
  num_layers: 2
  units_0: 32
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0025488548718413336

Model: "sequential_378"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_378 (Flatten)       (None, 784)               0         
                                                                 
 dense_1158 (Dense)          (None, 32)                25120     
                                                                 
 dropout_780 (Dropout)       (None, 32)                0         
                                                                 
 dense_1159 (Dense)          (None, 384)               12672     
                                                                 
 dropout_781 (Dropout)       (None, 384)               0         
                                                                 
 dense_1160 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 47802 (186.73 KB)
Trainable params: 47802 (186.73 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 379:
  Value: 0.7220
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.008787291539618387

Model: "sequential_379"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_379 (Flatten)       (None, 784)               0         
                                                                 
 dense_1161 (Dense)          (None, 512)               401920    
                                                                 
 dropout_782 (Dropout)       (None, 512)               0         
                                                                 
 dense_1162 (Dense)          (None, 384)               196992    
                                                                 
 dropout_783 (Dropout)       (None, 384)               0         
                                                                 
 dense_1163 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 380:
  Value: 0.8920
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0027910325461294014

Model: "sequential_380"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_380 (Flatten)       (None, 784)               0         
                                                                 
 dense_1164 (Dense)          (None, 480)               376800    
                                                                 
 dropout_784 (Dropout)       (None, 480)               0         
                                                                 
 dense_1165 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_98 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_785 (Dropout)       (None, 416)               0         
                                                                 
 dense_1166 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 589402 (2.25 MB)
Trainable params: 588570 (2.25 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 381:
  Value: 0.8852
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0026215379009004347

Model: "sequential_381"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_381 (Flatten)       (None, 784)               0         
                                                                 
 dense_1167 (Dense)          (None, 480)               376800    
                                                                 
 dropout_786 (Dropout)       (None, 480)               0         
                                                                 
 dense_1168 (Dense)          (None, 416)               200096    
                                                                 
 dropout_787 (Dropout)       (None, 416)               0         
                                                                 
 dense_1169 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 382:
  Value: 0.9090
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018307400350525411

Model: "sequential_382"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_382 (Flatten)       (None, 784)               0         
                                                                 
 dense_1170 (Dense)          (None, 512)               401920    
                                                                 
 dropout_788 (Dropout)       (None, 512)               0         
                                                                 
 dense_1171 (Dense)          (None, 384)               196992    
                                                                 
 dropout_789 (Dropout)       (None, 384)               0         
                                                                 
 dense_1172 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 383:
  Value: 0.9075
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018436037992507544

Model: "sequential_383"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_383 (Flatten)       (None, 784)               0         
                                                                 
 dense_1173 (Dense)          (None, 480)               376800    
                                                                 
 dropout_790 (Dropout)       (None, 480)               0         
                                                                 
 dense_1174 (Dense)          (None, 384)               184704    
                                                                 
 dropout_791 (Dropout)       (None, 384)               0         
                                                                 
 dense_1175 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 384:
  Value: 0.9035
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017466552181217576

Model: "sequential_384"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_384 (Flatten)       (None, 784)               0         
                                                                 
 dense_1176 (Dense)          (None, 512)               401920    
                                                                 
 dropout_792 (Dropout)       (None, 512)               0         
                                                                 
 dense_1177 (Dense)          (None, 384)               196992    
                                                                 
 dropout_793 (Dropout)       (None, 384)               0         
                                                                 
 dense_1178 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 385:
  Value: 0.9047
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001729007411175407

Model: "sequential_385"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_385 (Flatten)       (None, 784)               0         
                                                                 
 dense_1179 (Dense)          (None, 480)               376800    
                                                                 
 dropout_794 (Dropout)       (None, 480)               0         
                                                                 
 dense_1180 (Dense)          (None, 384)               184704    
                                                                 
 dropout_795 (Dropout)       (None, 384)               0         
                                                                 
 dense_1181 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 386:
  Value: 0.1578
  num_layers: 2
  units_0: 352
  units_1: 384
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0019480514875530246

Model: "sequential_386"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_386 (Flatten)       (None, 784)               0         
                                                                 
 dense_1182 (Dense)          (None, 352)               276320    
                                                                 
 dropout_796 (Dropout)       (None, 352)               0         
                                                                 
 dense_1183 (Dense)          (None, 384)               135552    
                                                                 
 dropout_797 (Dropout)       (None, 384)               0         
                                                                 
 dense_1184 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 421882 (1.61 MB)
Trainable params: 421882 (1.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 387:
  Value: 0.8648
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001604744409631644

Model: "sequential_387"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_387 (Flatten)       (None, 784)               0         
                                                                 
 dense_1185 (Dense)          (None, 480)               376800    
                                                                 
 dropout_798 (Dropout)       (None, 480)               0         
                                                                 
 dense_1186 (Dense)          (None, 384)               184704    
                                                                 
 dropout_799 (Dropout)       (None, 384)               0         
                                                                 
 dense_1187 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 388:
  Value: 0.8845
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018057926605348454

Model: "sequential_388"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_388 (Flatten)       (None, 784)               0         
                                                                 
 dense_1188 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_99 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_800 (Dropout)       (None, 512)               0         
                                                                 
 dense_1189 (Dense)          (None, 480)               246240    
                                                                 
 dropout_801 (Dropout)       (None, 480)               0         
                                                                 
 dense_1190 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 662714 (2.53 MB)
Trainable params: 661690 (2.52 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 389:
  Value: 0.8649
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0029120297502130614

Model: "sequential_389"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_389 (Flatten)       (None, 784)               0         
                                                                 
 dense_1191 (Dense)          (None, 448)               351680    
                                                                 
 dropout_802 (Dropout)       (None, 448)               0         
                                                                 
 dense_1192 (Dense)          (None, 384)               172416    
                                                                 
 dropout_803 (Dropout)       (None, 384)               0         
                                                                 
 dense_1193 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 390:
  Value: 0.9069
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016555279995870188

Model: "sequential_390"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_390 (Flatten)       (None, 784)               0         
                                                                 
 dense_1194 (Dense)          (None, 480)               376800    
                                                                 
 dropout_804 (Dropout)       (None, 480)               0         
                                                                 
 dense_1195 (Dense)          (None, 384)               184704    
                                                                 
 dropout_805 (Dropout)       (None, 384)               0         
                                                                 
 dense_1196 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 391:
  Value: 0.9086
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003802883027447211

Model: "sequential_391"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_391 (Flatten)       (None, 784)               0         
                                                                 
 dense_1197 (Dense)          (None, 512)               401920    
                                                                 
 dropout_806 (Dropout)       (None, 512)               0         
                                                                 
 dense_1198 (Dense)          (None, 384)               196992    
                                                                 
 dropout_807 (Dropout)       (None, 384)               0         
                                                                 
 dense_1199 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 392:
  Value: 0.0389
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.002355081857368259

Model: "sequential_392"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_392 (Flatten)       (None, 784)               0         
                                                                 
 dense_1200 (Dense)          (None, 480)               376800    
                                                                 
 dropout_808 (Dropout)       (None, 480)               0         
                                                                 
 dense_1201 (Dense)          (None, 384)               184704    
                                                                 
 dropout_809 (Dropout)       (None, 384)               0         
                                                                 
 dense_1202 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 393:
  Value: 0.7902
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.003019077139168297

Model: "sequential_393"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_393 (Flatten)       (None, 784)               0         
                                                                 
 dense_1203 (Dense)          (None, 480)               376800    
                                                                 
 dropout_810 (Dropout)       (None, 480)               0         
                                                                 
 dense_1204 (Dense)          (None, 352)               169312    
                                                                 
 dropout_811 (Dropout)       (None, 352)               0         
                                                                 
 dense_1205 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 394:
  Value: 0.8441
  num_layers: 2
  units_0: 512
  units_1: 128
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00019484952236361388

Model: "sequential_394"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_394 (Flatten)       (None, 784)               0         
                                                                 
 dense_1206 (Dense)          (None, 512)               401920    
                                                                 
 dropout_812 (Dropout)       (None, 512)               0         
                                                                 
 dense_1207 (Dense)          (None, 128)               65664     
                                                                 
 dropout_813 (Dropout)       (None, 128)               0         
                                                                 
 dense_1208 (Dense)          (None, 26)                3354      
                                                                 
=================================================================
Total params: 470938 (1.80 MB)
Trainable params: 470938 (1.80 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 395:
  Value: 0.9103
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0020173909541969146

Model: "sequential_395"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_395 (Flatten)       (None, 784)               0         
                                                                 
 dense_1209 (Dense)          (None, 448)               351680    
                                                                 
 dropout_814 (Dropout)       (None, 448)               0         
                                                                 
 dense_1210 (Dense)          (None, 448)               201152    
                                                                 
 dropout_815 (Dropout)       (None, 448)               0         
                                                                 
 dense_1211 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 396:
  Value: 0.9036
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002058124209434825

Model: "sequential_396"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_396 (Flatten)       (None, 784)               0         
                                                                 
 dense_1212 (Dense)          (None, 448)               351680    
                                                                 
 dropout_816 (Dropout)       (None, 448)               0         
                                                                 
 dense_1213 (Dense)          (None, 448)               201152    
                                                                 
 dropout_817 (Dropout)       (None, 448)               0         
                                                                 
 dense_1214 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 397:
  Value: 0.9039
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0022372187060556675

Model: "sequential_397"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_397 (Flatten)       (None, 784)               0         
                                                                 
 dense_1215 (Dense)          (None, 448)               351680    
                                                                 
 dropout_818 (Dropout)       (None, 448)               0         
                                                                 
 dense_1216 (Dense)          (None, 448)               201152    
                                                                 
 dropout_819 (Dropout)       (None, 448)               0         
                                                                 
 dense_1217 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 398:
  Value: 0.8564
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001881051780724607

Model: "sequential_398"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_398 (Flatten)       (None, 784)               0         
                                                                 
 dense_1218 (Dense)          (None, 448)               351680    
                                                                 
 dropout_820 (Dropout)       (None, 448)               0         
                                                                 
 dense_1219 (Dense)          (None, 448)               201152    
                                                                 
 dropout_821 (Dropout)       (None, 448)               0         
                                                                 
 dense_1220 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 399:
  Value: 0.9016
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.00036813844175235237

Model: "sequential_399"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_399 (Flatten)       (None, 784)               0         
                                                                 
 dense_1221 (Dense)          (None, 480)               376800    
                                                                 
 dropout_822 (Dropout)       (None, 480)               0         
                                                                 
 dense_1222 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_100 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_823 (Dropout)       (None, 480)               0         
                                                                 
 dense_1223 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 622106 (2.37 MB)
Trainable params: 621146 (2.37 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 400:
  Value: 0.8779
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017762069876417728

Model: "sequential_400"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_400 (Flatten)       (None, 784)               0         
                                                                 
 dense_1224 (Dense)          (None, 480)               376800    
                                                                 
 dropout_824 (Dropout)       (None, 480)               0         
                                                                 
 dense_1225 (Dense)          (None, 448)               215488    
                                                                 
 dropout_825 (Dropout)       (None, 448)               0         
                                                                 
 dense_1226 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 401:
  Value: 0.8631
  num_layers: 2
  units_0: 416
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001578592999060736

Model: "sequential_401"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_401 (Flatten)       (None, 784)               0         
                                                                 
 dense_1227 (Dense)          (None, 416)               326560    
                                                                 
 dropout_826 (Dropout)       (None, 416)               0         
                                                                 
 dense_1228 (Dense)          (None, 352)               146784    
                                                                 
 dropout_827 (Dropout)       (None, 352)               0         
                                                                 
 dense_1229 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 482522 (1.84 MB)
Trainable params: 482522 (1.84 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 402:
  Value: 0.7281
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019888187391412645

Model: "sequential_402"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_402 (Flatten)       (None, 784)               0         
                                                                 
 dense_1230 (Dense)          (None, 448)               351680    
                                                                 
 dropout_828 (Dropout)       (None, 448)               0         
                                                                 
 dense_1231 (Dense)          (None, 480)               215520    
                                                                 
 dropout_829 (Dropout)       (None, 480)               0         
                                                                 
 dense_1232 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 403:
  Value: 0.8231
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.0007835057469244136

Model: "sequential_403"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_403 (Flatten)       (None, 784)               0         
                                                                 
 dense_1233 (Dense)          (None, 480)               376800    
                                                                 
 dropout_830 (Dropout)       (None, 480)               0         
                                                                 
 dense_1234 (Dense)          (None, 448)               215488    
                                                                 
 dropout_831 (Dropout)       (None, 448)               0         
                                                                 
 dense_1235 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 404:
  Value: 0.9024
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008484698212358872

Model: "sequential_404"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_404 (Flatten)       (None, 784)               0         
                                                                 
 dense_1236 (Dense)          (None, 480)               376800    
                                                                 
 dropout_832 (Dropout)       (None, 480)               0         
                                                                 
 dense_1237 (Dense)          (None, 352)               169312    
                                                                 
 dropout_833 (Dropout)       (None, 352)               0         
                                                                 
 dense_1238 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 405:
  Value: 0.9049
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 32
  units_3: 160
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0021128886322587075

Model: "sequential_405"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_405 (Flatten)       (None, 784)               0         
                                                                 
 dense_1239 (Dense)          (None, 480)               376800    
                                                                 
 dropout_834 (Dropout)       (None, 480)               0         
                                                                 
 dense_1240 (Dense)          (None, 352)               169312    
                                                                 
 dropout_835 (Dropout)       (None, 352)               0         
                                                                 
 dense_1241 (Dense)          (None, 32)                11296     
                                                                 
 batch_normalization_101 (B  (None, 32)                128       
 atchNormalization)                                              
                                                                 
 dropout_836 (Dropout)       (None, 32)                0         
                                                                 
 dense_1242 (Dense)          (None, 160)               5280      
                                                                 
 dropout_837 (Dropout)       (None, 160)               0         
                                                                 
 dense_1243 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 567002 (2.16 MB)
Trainable params: 566938 (2.16 MB)
Non-trainable params: 64 (256.00 Byte)
_________________________________________________________________



Trial 406:
  Value: 0.8220
  num_layers: 1
  units_0: 448
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0016750042904885491

Model: "sequential_406"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_406 (Flatten)       (None, 784)               0         
                                                                 
 dense_1244 (Dense)          (None, 448)               351680    
                                                                 
 dropout_838 (Dropout)       (None, 448)               0         
                                                                 
 dense_1245 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 363354 (1.39 MB)
Trainable params: 363354 (1.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 407:
  Value: 0.8862
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002531144236763155

Model: "sequential_407"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_407 (Flatten)       (None, 784)               0         
                                                                 
 dense_1246 (Dense)          (None, 480)               376800    
                                                                 
 dropout_839 (Dropout)       (None, 480)               0         
                                                                 
 dense_1247 (Dense)          (None, 448)               215488    
                                                                 
 dropout_840 (Dropout)       (None, 448)               0         
                                                                 
 dense_1248 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 408:
  Value: 0.3625
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0005264757521529533

Model: "sequential_408"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_408 (Flatten)       (None, 784)               0         
                                                                 
 dense_1249 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_102 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_841 (Dropout)       (None, 480)               0         
                                                                 
 dense_1250 (Dense)          (None, 416)               200096    
                                                                 
 dropout_842 (Dropout)       (None, 416)               0         
                                                                 
 dense_1251 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 589658 (2.25 MB)
Trainable params: 588698 (2.25 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 409:
  Value: 0.8632
  num_layers: 2
  units_0: 416
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003412289749137902

Model: "sequential_409"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_409 (Flatten)       (None, 784)               0         
                                                                 
 dense_1252 (Dense)          (None, 416)               326560    
                                                                 
 dropout_843 (Dropout)       (None, 416)               0         
                                                                 
 dense_1253 (Dense)          (None, 352)               146784    
                                                                 
 dropout_844 (Dropout)       (None, 352)               0         
                                                                 
 dense_1254 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 482522 (1.84 MB)
Trainable params: 482522 (1.84 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 410:
  Value: 0.7995
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019008075167173848

Model: "sequential_410"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_410 (Flatten)       (None, 784)               0         
                                                                 
 dense_1255 (Dense)          (None, 480)               376800    
                                                                 
 dropout_845 (Dropout)       (None, 480)               0         
                                                                 
 dense_1256 (Dense)          (None, 352)               169312    
                                                                 
 dropout_846 (Dropout)       (None, 352)               0         
                                                                 
 dense_1257 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 411:
  Value: 0.8653
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009920413230233428

Model: "sequential_411"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_411 (Flatten)       (None, 784)               0         
                                                                 
 dense_1258 (Dense)          (None, 480)               376800    
                                                                 
 dropout_847 (Dropout)       (None, 480)               0         
                                                                 
 dense_1259 (Dense)          (None, 352)               169312    
                                                                 
 dropout_848 (Dropout)       (None, 352)               0         
                                                                 
 dense_1260 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 412:
  Value: 0.9015
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0023087285105188268

Model: "sequential_412"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_412 (Flatten)       (None, 784)               0         
                                                                 
 dense_1261 (Dense)          (None, 448)               351680    
                                                                 
 dropout_849 (Dropout)       (None, 448)               0         
                                                                 
 dense_1262 (Dense)          (None, 480)               215520    
                                                                 
 dropout_850 (Dropout)       (None, 480)               0         
                                                                 
 dense_1263 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 413:
  Value: 0.9078
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001519493779950054

Model: "sequential_413"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_413 (Flatten)       (None, 784)               0         
                                                                 
 dense_1264 (Dense)          (None, 512)               401920    
                                                                 
 dropout_851 (Dropout)       (None, 512)               0         
                                                                 
 dense_1265 (Dense)          (None, 320)               164160    
                                                                 
 dropout_852 (Dropout)       (None, 320)               0         
                                                                 
 dense_1266 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 414:
  Value: 0.9063
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0027043590158271425

Model: "sequential_414"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_414 (Flatten)       (None, 784)               0         
                                                                 
 dense_1267 (Dense)          (None, 480)               376800    
                                                                 
 dropout_853 (Dropout)       (None, 480)               0         
                                                                 
 dense_1268 (Dense)          (None, 448)               215488    
                                                                 
 dropout_854 (Dropout)       (None, 448)               0         
                                                                 
 dense_1269 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 415:
  Value: 0.2739
  num_layers: 2
  units_0: 512
  units_1: 64
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.003956900988506524

Model: "sequential_415"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_415 (Flatten)       (None, 784)               0         
                                                                 
 dense_1270 (Dense)          (None, 512)               401920    
                                                                 
 dropout_855 (Dropout)       (None, 512)               0         
                                                                 
 dense_1271 (Dense)          (None, 64)                32832     
                                                                 
 dropout_856 (Dropout)       (None, 64)                0         
                                                                 
 dense_1272 (Dense)          (None, 26)                1690      
                                                                 
=================================================================
Total params: 436442 (1.66 MB)
Trainable params: 436442 (1.66 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 416:
  Value: 0.9109
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0032373412197936125

Model: "sequential_416"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_416 (Flatten)       (None, 784)               0         
                                                                 
 dense_1273 (Dense)          (None, 480)               376800    
                                                                 
 dropout_857 (Dropout)       (None, 480)               0         
                                                                 
 dense_1274 (Dense)          (None, 416)               200096    
                                                                 
 dropout_858 (Dropout)       (None, 416)               0         
                                                                 
 dense_1275 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 417:
  Value: 0.9013
  num_layers: 3
  units_0: 416
  units_1: 416
  units_2: 96
  activation_0: relu
  activation_1: relu
  activation_2: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.00040993884309563995

Model: "sequential_417"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_417 (Flatten)       (None, 784)               0         
                                                                 
 dense_1276 (Dense)          (None, 416)               326560    
                                                                 
 dropout_859 (Dropout)       (None, 416)               0         
                                                                 
 dense_1277 (Dense)          (None, 416)               173472    
                                                                 
 dropout_860 (Dropout)       (None, 416)               0         
                                                                 
 dense_1278 (Dense)          (None, 96)                40032     
                                                                 
 batch_normalization_103 (B  (None, 96)                384       
 atchNormalization)                                              
                                                                 
 dropout_861 (Dropout)       (None, 96)                0         
                                                                 
 dense_1279 (Dense)          (None, 26)                2522      
                                                                 
=================================================================
Total params: 542970 (2.07 MB)
Trainable params: 542778 (2.07 MB)
Non-trainable params: 192 (768.00 Byte)
_________________________________________________________________



Trial 418:
  Value: 0.0381
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0029822316528607586

Model: "sequential_418"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_418 (Flatten)       (None, 784)               0         
                                                                 
 dense_1280 (Dense)          (None, 480)               376800    
                                                                 
 dropout_862 (Dropout)       (None, 480)               0         
                                                                 
 dense_1281 (Dense)          (None, 416)               200096    
                                                                 
 dropout_863 (Dropout)       (None, 416)               0         
                                                                 
 dense_1282 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 419:
  Value: 0.8660
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003220496397943629

Model: "sequential_419"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_419 (Flatten)       (None, 784)               0         
                                                                 
 dense_1283 (Dense)          (None, 448)               351680    
                                                                 
 dropout_864 (Dropout)       (None, 448)               0         
                                                                 
 dense_1284 (Dense)          (None, 416)               186784    
                                                                 
 dropout_865 (Dropout)       (None, 416)               0         
                                                                 
 dense_1285 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 420:
  Value: 0.8391
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.003277241165215568

Model: "sequential_420"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_420 (Flatten)       (None, 784)               0         
                                                                 
 dense_1286 (Dense)          (None, 512)               401920    
                                                                 
 dropout_866 (Dropout)       (None, 512)               0         
                                                                 
 dense_1287 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_104 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_867 (Dropout)       (None, 416)               0         
                                                                 
 dense_1288 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 627834 (2.39 MB)
Trainable params: 627002 (2.39 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 421:
  Value: 0.8914
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009312509350900476

Model: "sequential_421"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_421 (Flatten)       (None, 784)               0         
                                                                 
 dense_1289 (Dense)          (None, 480)               376800    
                                                                 
 dropout_868 (Dropout)       (None, 480)               0         
                                                                 
 dense_1290 (Dense)          (None, 448)               215488    
                                                                 
 dropout_869 (Dropout)       (None, 448)               0         
                                                                 
 dense_1291 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 422:
  Value: 0.7991
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.002697311952123658

Model: "sequential_422"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_422 (Flatten)       (None, 784)               0         
                                                                 
 dense_1292 (Dense)          (None, 512)               401920    
                                                                 
 dropout_870 (Dropout)       (None, 512)               0         
                                                                 
 dense_1293 (Dense)          (None, 416)               213408    
                                                                 
 dropout_871 (Dropout)       (None, 416)               0         
                                                                 
 dense_1294 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 423:
  Value: 0.8628
  num_layers: 2
  units_0: 384
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00321069874229021

Model: "sequential_423"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_423 (Flatten)       (None, 784)               0         
                                                                 
 dense_1295 (Dense)          (None, 384)               301440    
                                                                 
 dropout_872 (Dropout)       (None, 384)               0         
                                                                 
 dense_1296 (Dense)          (None, 384)               147840    
                                                                 
 dropout_873 (Dropout)       (None, 384)               0         
                                                                 
 dense_1297 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 459290 (1.75 MB)
Trainable params: 459290 (1.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 424:
  Value: 0.7422
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0036509511667155736

Model: "sequential_424"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_424 (Flatten)       (None, 784)               0         
                                                                 
 dense_1298 (Dense)          (None, 480)               376800    
                                                                 
 dropout_874 (Dropout)       (None, 480)               0         
                                                                 
 dense_1299 (Dense)          (None, 416)               200096    
                                                                 
 dropout_875 (Dropout)       (None, 416)               0         
                                                                 
 dense_1300 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 425:
  Value: 0.9087
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017581767362769184

Model: "sequential_425"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_425 (Flatten)       (None, 784)               0         
                                                                 
 dense_1301 (Dense)          (None, 512)               401920    
                                                                 
 dropout_876 (Dropout)       (None, 512)               0         
                                                                 
 dense_1302 (Dense)          (None, 384)               196992    
                                                                 
 dropout_877 (Dropout)       (None, 384)               0         
                                                                 
 dense_1303 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 426:
  Value: 0.9084
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001075963032671259

Model: "sequential_426"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_426 (Flatten)       (None, 784)               0         
                                                                 
 dense_1304 (Dense)          (None, 480)               376800    
                                                                 
 dropout_878 (Dropout)       (None, 480)               0         
                                                                 
 dense_1305 (Dense)          (None, 448)               215488    
                                                                 
 dropout_879 (Dropout)       (None, 448)               0         
                                                                 
 dense_1306 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 427:
  Value: 0.8955
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004020452935797423

Model: "sequential_427"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_427 (Flatten)       (None, 784)               0         
                                                                 
 dense_1307 (Dense)          (None, 448)               351680    
                                                                 
 dropout_880 (Dropout)       (None, 448)               0         
                                                                 
 dense_1308 (Dense)          (None, 416)               186784    
                                                                 
 dropout_881 (Dropout)       (None, 416)               0         
                                                                 
 dense_1309 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 428:
  Value: 0.9078
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013158951849832963

Model: "sequential_428"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_428 (Flatten)       (None, 784)               0         
                                                                 
 dense_1310 (Dense)          (None, 512)               401920    
                                                                 
 dropout_882 (Dropout)       (None, 512)               0         
                                                                 
 dense_1311 (Dense)          (None, 384)               196992    
                                                                 
 dropout_883 (Dropout)       (None, 384)               0         
                                                                 
 dense_1312 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 429:
  Value: 0.8900
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002085773913050469

Model: "sequential_429"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_429 (Flatten)       (None, 784)               0         
                                                                 
 dense_1313 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_105 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_884 (Dropout)       (None, 480)               0         
                                                                 
 dense_1314 (Dense)          (None, 480)               230880    
                                                                 
 dropout_885 (Dropout)       (None, 480)               0         
                                                                 
 dense_1315 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 622106 (2.37 MB)
Trainable params: 621146 (2.37 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 430:
  Value: 0.9051
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002411193369472119

Model: "sequential_430"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_430 (Flatten)       (None, 784)               0         
                                                                 
 dense_1316 (Dense)          (None, 480)               376800    
                                                                 
 dropout_886 (Dropout)       (None, 480)               0         
                                                                 
 dense_1317 (Dense)          (None, 352)               169312    
                                                                 
 dropout_887 (Dropout)       (None, 352)               0         
                                                                 
 dense_1318 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 431:
  Value: 0.8350
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.001480242059579376

Model: "sequential_431"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_431 (Flatten)       (None, 784)               0         
                                                                 
 dense_1319 (Dense)          (None, 512)               401920    
                                                                 
 dropout_888 (Dropout)       (None, 512)               0         
                                                                 
 dense_1320 (Dense)          (None, 384)               196992    
                                                                 
 dropout_889 (Dropout)       (None, 384)               0         
                                                                 
 dense_1321 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 432:
  Value: 0.9093
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00082090660725188

Model: "sequential_432"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_432 (Flatten)       (None, 784)               0         
                                                                 
 dense_1322 (Dense)          (None, 480)               376800    
                                                                 
 dropout_890 (Dropout)       (None, 480)               0         
                                                                 
 dense_1323 (Dense)          (None, 448)               215488    
                                                                 
 dropout_891 (Dropout)       (None, 448)               0         
                                                                 
 dense_1324 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 433:
  Value: 0.9108
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008170119931145446

Model: "sequential_433"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_433 (Flatten)       (None, 784)               0         
                                                                 
 dense_1325 (Dense)          (None, 448)               351680    
                                                                 
 dropout_892 (Dropout)       (None, 448)               0         
                                                                 
 dense_1326 (Dense)          (None, 448)               201152    
                                                                 
 dropout_893 (Dropout)       (None, 448)               0         
                                                                 
 dense_1327 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 434:
  Value: 0.8022
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008267618240414233

Model: "sequential_434"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_434 (Flatten)       (None, 784)               0         
                                                                 
 dense_1328 (Dense)          (None, 416)               326560    
                                                                 
 dropout_894 (Dropout)       (None, 416)               0         
                                                                 
 dense_1329 (Dense)          (None, 448)               186816    
                                                                 
 dropout_895 (Dropout)       (None, 448)               0         
                                                                 
 dense_1330 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 435:
  Value: 0.1059
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0006896556416102661

Model: "sequential_435"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_435 (Flatten)       (None, 784)               0         
                                                                 
 dense_1331 (Dense)          (None, 448)               351680    
                                                                 
 dropout_896 (Dropout)       (None, 448)               0         
                                                                 
 dense_1332 (Dense)          (None, 448)               201152    
                                                                 
 dropout_897 (Dropout)       (None, 448)               0         
                                                                 
 dense_1333 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 436:
  Value: 0.8658
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004594056990238795

Model: "sequential_436"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_436 (Flatten)       (None, 784)               0         
                                                                 
 dense_1334 (Dense)          (None, 448)               351680    
                                                                 
 dropout_898 (Dropout)       (None, 448)               0         
                                                                 
 dense_1335 (Dense)          (None, 448)               201152    
                                                                 
 dropout_899 (Dropout)       (None, 448)               0         
                                                                 
 dense_1336 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 437:
  Value: 0.8952
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008442669019248158

Model: "sequential_437"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_437 (Flatten)       (None, 784)               0         
                                                                 
 dense_1337 (Dense)          (None, 448)               351680    
                                                                 
 dropout_900 (Dropout)       (None, 448)               0         
                                                                 
 dense_1338 (Dense)          (None, 448)               201152    
                                                                 
 dropout_901 (Dropout)       (None, 448)               0         
                                                                 
 dense_1339 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 438:
  Value: 0.9100
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007207001626744694

Model: "sequential_438"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_438 (Flatten)       (None, 784)               0         
                                                                 
 dense_1340 (Dense)          (None, 448)               351680    
                                                                 
 dropout_902 (Dropout)       (None, 448)               0         
                                                                 
 dense_1341 (Dense)          (None, 448)               201152    
                                                                 
 dropout_903 (Dropout)       (None, 448)               0         
                                                                 
 dense_1342 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 439:
  Value: 0.9061
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007470134839067539

Model: "sequential_439"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_439 (Flatten)       (None, 784)               0         
                                                                 
 dense_1343 (Dense)          (None, 448)               351680    
                                                                 
 dropout_904 (Dropout)       (None, 448)               0         
                                                                 
 dense_1344 (Dense)          (None, 448)               201152    
                                                                 
 dropout_905 (Dropout)       (None, 448)               0         
                                                                 
 dense_1345 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 440:
  Value: 0.9052
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0006644188809516391

Model: "sequential_440"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_440 (Flatten)       (None, 784)               0         
                                                                 
 dense_1346 (Dense)          (None, 416)               326560    
                                                                 
 dropout_906 (Dropout)       (None, 416)               0         
                                                                 
 dense_1347 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_106 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_907 (Dropout)       (None, 448)               0         
                                                                 
 dense_1348 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 526842 (2.01 MB)
Trainable params: 525946 (2.01 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 441:
  Value: 0.8657
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008089454585791606

Model: "sequential_441"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_441 (Flatten)       (None, 784)               0         
                                                                 
 dense_1349 (Dense)          (None, 448)               351680    
                                                                 
 dropout_908 (Dropout)       (None, 448)               0         
                                                                 
 dense_1350 (Dense)          (None, 448)               201152    
                                                                 
 dropout_909 (Dropout)       (None, 448)               0         
                                                                 
 dense_1351 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 442:
  Value: 0.8529
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007356459871434802

Model: "sequential_442"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_442 (Flatten)       (None, 784)               0         
                                                                 
 dense_1352 (Dense)          (None, 448)               351680    
                                                                 
 dropout_910 (Dropout)       (None, 448)               0         
                                                                 
 dense_1353 (Dense)          (None, 480)               215520    
                                                                 
 dropout_911 (Dropout)       (None, 480)               0         
                                                                 
 dense_1354 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 443:
  Value: 0.3820
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0009400553146758076

Model: "sequential_443"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_443 (Flatten)       (None, 784)               0         
                                                                 
 dense_1355 (Dense)          (None, 448)               351680    
                                                                 
 dropout_912 (Dropout)       (None, 448)               0         
                                                                 
 dense_1356 (Dense)          (None, 448)               201152    
                                                                 
 dropout_913 (Dropout)       (None, 448)               0         
                                                                 
 dense_1357 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 444:
  Value: 0.9055
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007360864595147681

Model: "sequential_444"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_444 (Flatten)       (None, 784)               0         
                                                                 
 dense_1358 (Dense)          (None, 448)               351680    
                                                                 
 dropout_914 (Dropout)       (None, 448)               0         
                                                                 
 dense_1359 (Dense)          (None, 448)               201152    
                                                                 
 dropout_915 (Dropout)       (None, 448)               0         
                                                                 
 dense_1360 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 445:
  Value: 0.8662
  num_layers: 2
  units_0: 384
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006207645396324494

Model: "sequential_445"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_445 (Flatten)       (None, 784)               0         
                                                                 
 dense_1361 (Dense)          (None, 384)               301440    
                                                                 
 dropout_916 (Dropout)       (None, 384)               0         
                                                                 
 dense_1362 (Dense)          (None, 480)               184800    
                                                                 
 dropout_917 (Dropout)       (None, 480)               0         
                                                                 
 dense_1363 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 498746 (1.90 MB)
Trainable params: 498746 (1.90 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 446:
  Value: 0.9127
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000855477548680163

Model: "sequential_446"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_446 (Flatten)       (None, 784)               0         
                                                                 
 dense_1364 (Dense)          (None, 448)               351680    
                                                                 
 dropout_918 (Dropout)       (None, 448)               0         
                                                                 
 dense_1365 (Dense)          (None, 448)               201152    
                                                                 
 dropout_919 (Dropout)       (None, 448)               0         
                                                                 
 dense_1366 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 447:
  Value: 0.0389
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0007874724139676906

Model: "sequential_447"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_447 (Flatten)       (None, 784)               0         
                                                                 
 dense_1367 (Dense)          (None, 416)               326560    
                                                                 
 dropout_920 (Dropout)       (None, 416)               0         
                                                                 
 dense_1368 (Dense)          (None, 448)               186816    
                                                                 
 dropout_921 (Dropout)       (None, 448)               0         
                                                                 
 dense_1369 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 448:
  Value: 0.5042
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008760010297314997

Model: "sequential_448"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_448 (Flatten)       (None, 784)               0         
                                                                 
 dense_1370 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_107 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_922 (Dropout)       (None, 448)               0         
                                                                 
 dense_1371 (Dense)          (None, 448)               201152    
                                                                 
 dropout_923 (Dropout)       (None, 448)               0         
                                                                 
 dense_1372 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 449:
  Value: 0.9012
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009144619599651239

Model: "sequential_449"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_449 (Flatten)       (None, 784)               0         
                                                                 
 dense_1373 (Dense)          (None, 448)               351680    
                                                                 
 dropout_924 (Dropout)       (None, 448)               0         
                                                                 
 dense_1374 (Dense)          (None, 448)               201152    
                                                                 
 dropout_925 (Dropout)       (None, 448)               0         
                                                                 
 dense_1375 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 450:
  Value: 0.9007
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007890211760855576

Model: "sequential_450"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_450 (Flatten)       (None, 784)               0         
                                                                 
 dense_1376 (Dense)          (None, 416)               326560    
                                                                 
 dropout_926 (Dropout)       (None, 416)               0         
                                                                 
 dense_1377 (Dense)          (None, 448)               186816    
                                                                 
 dropout_927 (Dropout)       (None, 448)               0         
                                                                 
 dense_1378 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 451:
  Value: 0.9093
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005262698083141433

Model: "sequential_451"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_451 (Flatten)       (None, 784)               0         
                                                                 
 dense_1379 (Dense)          (None, 448)               351680    
                                                                 
 dropout_928 (Dropout)       (None, 448)               0         
                                                                 
 dense_1380 (Dense)          (None, 480)               215520    
                                                                 
 dropout_929 (Dropout)       (None, 480)               0         
                                                                 
 dense_1381 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 452:
  Value: 0.9015
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005463263801917693

Model: "sequential_452"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_452 (Flatten)       (None, 784)               0         
                                                                 
 dense_1382 (Dense)          (None, 448)               351680    
                                                                 
 dropout_930 (Dropout)       (None, 448)               0         
                                                                 
 dense_1383 (Dense)          (None, 480)               215520    
                                                                 
 dropout_931 (Dropout)       (None, 480)               0         
                                                                 
 dense_1384 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 453:
  Value: 0.7969
  num_layers: 2
  units_0: 416
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0040857680604749185

Model: "sequential_453"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_453 (Flatten)       (None, 784)               0         
                                                                 
 dense_1385 (Dense)          (None, 416)               326560    
                                                                 
 dropout_932 (Dropout)       (None, 416)               0         
                                                                 
 dense_1386 (Dense)          (None, 480)               200160    
                                                                 
 dropout_933 (Dropout)       (None, 480)               0         
                                                                 
 dense_1387 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 539226 (2.06 MB)
Trainable params: 539226 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 454:
  Value: 0.8582
  num_layers: 2
  units_0: 448
  units_1: 224
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005041703512593215

Model: "sequential_454"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_454 (Flatten)       (None, 784)               0         
                                                                 
 dense_1388 (Dense)          (None, 448)               351680    
                                                                 
 dropout_934 (Dropout)       (None, 448)               0         
                                                                 
 dense_1389 (Dense)          (None, 224)               100576    
                                                                 
 dropout_935 (Dropout)       (None, 224)               0         
                                                                 
 dense_1390 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 458106 (1.75 MB)
Trainable params: 458106 (1.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 455:
  Value: 0.8239
  num_layers: 1
  units_0: 448
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0036048756852235047

Model: "sequential_455"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_455 (Flatten)       (None, 784)               0         
                                                                 
 dense_1391 (Dense)          (None, 448)               351680    
                                                                 
 dropout_936 (Dropout)       (None, 448)               0         
                                                                 
 dense_1392 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 363354 (1.39 MB)
Trainable params: 363354 (1.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 456:
  Value: 0.9088
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005220905364030694

Model: "sequential_456"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_456 (Flatten)       (None, 784)               0         
                                                                 
 dense_1393 (Dense)          (None, 448)               351680    
                                                                 
 dropout_937 (Dropout)       (None, 448)               0         
                                                                 
 dense_1394 (Dense)          (None, 448)               201152    
                                                                 
 dropout_938 (Dropout)       (None, 448)               0         
                                                                 
 dense_1395 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 457:
  Value: 0.8910
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0038758319537482164

Model: "sequential_457"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_457 (Flatten)       (None, 784)               0         
                                                                 
 dense_1396 (Dense)          (None, 416)               326560    
                                                                 
 dropout_939 (Dropout)       (None, 416)               0         
                                                                 
 dense_1397 (Dense)          (None, 448)               186816    
                                                                 
 dropout_940 (Dropout)       (None, 448)               0         
                                                                 
 dense_1398 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 458:
  Value: 0.9074
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006312467347735262

Model: "sequential_458"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_458 (Flatten)       (None, 784)               0         
                                                                 
 dense_1399 (Dense)          (None, 448)               351680    
                                                                 
 dropout_941 (Dropout)       (None, 448)               0         
                                                                 
 dense_1400 (Dense)          (None, 416)               186784    
                                                                 
 dropout_942 (Dropout)       (None, 416)               0         
                                                                 
 dense_1401 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 459:
  Value: 0.8658
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004278628754841517

Model: "sequential_459"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_459 (Flatten)       (None, 784)               0         
                                                                 
 dense_1402 (Dense)          (None, 448)               351680    
                                                                 
 dropout_943 (Dropout)       (None, 448)               0         
                                                                 
 dense_1403 (Dense)          (None, 448)               201152    
                                                                 
 dropout_944 (Dropout)       (None, 448)               0         
                                                                 
 dense_1404 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 460:
  Value: 0.8859
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003138015518683127

Model: "sequential_460"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_460 (Flatten)       (None, 784)               0         
                                                                 
 dense_1405 (Dense)          (None, 448)               351680    
                                                                 
 dropout_945 (Dropout)       (None, 448)               0         
                                                                 
 dense_1406 (Dense)          (None, 448)               201152    
                                                                 
 dropout_946 (Dropout)       (None, 448)               0         
                                                                 
 dense_1407 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 461:
  Value: 0.8472
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.0023805757993994774

Model: "sequential_461"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_461 (Flatten)       (None, 784)               0         
                                                                 
 dense_1408 (Dense)          (None, 416)               326560    
                                                                 
 dropout_947 (Dropout)       (None, 416)               0         
                                                                 
 dense_1409 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_108 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_948 (Dropout)       (None, 416)               0         
                                                                 
 dense_1410 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 512538 (1.96 MB)
Trainable params: 511706 (1.95 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 462:
  Value: 0.9047
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005992932822663685

Model: "sequential_462"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_462 (Flatten)       (None, 784)               0         
                                                                 
 dense_1411 (Dense)          (None, 448)               351680    
                                                                 
 dropout_949 (Dropout)       (None, 448)               0         
                                                                 
 dense_1412 (Dense)          (None, 480)               215520    
                                                                 
 dropout_950 (Dropout)       (None, 480)               0         
                                                                 
 dense_1413 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 463:
  Value: 0.8043
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004757037005948607

Model: "sequential_463"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_463 (Flatten)       (None, 784)               0         
                                                                 
 dense_1414 (Dense)          (None, 448)               351680    
                                                                 
 dropout_951 (Dropout)       (None, 448)               0         
                                                                 
 dense_1415 (Dense)          (None, 448)               201152    
                                                                 
 dropout_952 (Dropout)       (None, 448)               0         
                                                                 
 dense_1416 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 464:
  Value: 0.1464
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.006471766049236153

Model: "sequential_464"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_464 (Flatten)       (None, 784)               0         
                                                                 
 dense_1417 (Dense)          (None, 448)               351680    
                                                                 
 dropout_953 (Dropout)       (None, 448)               0         
                                                                 
 dense_1418 (Dense)          (None, 416)               186784    
                                                                 
 dropout_954 (Dropout)       (None, 416)               0         
                                                                 
 dense_1419 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 465:
  Value: 0.9110
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.008121509908082917

Model: "sequential_465"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_465 (Flatten)       (None, 784)               0         
                                                                 
 dense_1420 (Dense)          (None, 448)               351680    
                                                                 
 dropout_955 (Dropout)       (None, 448)               0         
                                                                 
 dense_1421 (Dense)          (None, 416)               186784    
                                                                 
 dropout_956 (Dropout)       (None, 416)               0         
                                                                 
 dense_1422 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 466:
  Value: 0.8573
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005194292638273523

Model: "sequential_466"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_466 (Flatten)       (None, 784)               0         
                                                                 
 dense_1423 (Dense)          (None, 448)               351680    
                                                                 
 dropout_957 (Dropout)       (None, 448)               0         
                                                                 
 dense_1424 (Dense)          (None, 416)               186784    
                                                                 
 dropout_958 (Dropout)       (None, 416)               0         
                                                                 
 dense_1425 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 467:
  Value: 0.8380
  num_layers: 2
  units_0: 160
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.008341929875047312

Model: "sequential_467"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_467 (Flatten)       (None, 784)               0         
                                                                 
 dense_1426 (Dense)          (None, 160)               125600    
                                                                 
 dropout_959 (Dropout)       (None, 160)               0         
                                                                 
 dense_1427 (Dense)          (None, 416)               66976     
                                                                 
 dropout_960 (Dropout)       (None, 416)               0         
                                                                 
 dense_1428 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 203418 (794.60 KB)
Trainable params: 203418 (794.60 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 468:
  Value: 0.8666
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0028283860655600604

Model: "sequential_468"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_468 (Flatten)       (None, 784)               0         
                                                                 
 dense_1429 (Dense)          (None, 416)               326560    
                                                                 
 batch_normalization_109 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_961 (Dropout)       (None, 416)               0         
                                                                 
 dense_1430 (Dense)          (None, 416)               173472    
                                                                 
 dropout_962 (Dropout)       (None, 416)               0         
                                                                 
 dense_1431 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 512538 (1.96 MB)
Trainable params: 511706 (1.95 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 469:
  Value: 0.9030
  num_layers: 3
  units_0: 448
  units_1: 416
  units_2: 256
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0034791160867839598

Model: "sequential_469"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_469 (Flatten)       (None, 784)               0         
                                                                 
 dense_1432 (Dense)          (None, 448)               351680    
                                                                 
 dropout_963 (Dropout)       (None, 448)               0         
                                                                 
 dense_1433 (Dense)          (None, 416)               186784    
                                                                 
 dropout_964 (Dropout)       (None, 416)               0         
                                                                 
 dense_1434 (Dense)          (None, 256)               106752    
                                                                 
 batch_normalization_110 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_965 (Dropout)       (None, 256)               0         
                                                                 
 dense_1435 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 652922 (2.49 MB)
Trainable params: 652410 (2.49 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________



Trial 470:
  Value: 0.8600
  num_layers: 2
  units_0: 320
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007412760750820107

Model: "sequential_470"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_470 (Flatten)       (None, 784)               0         
                                                                 
 dense_1436 (Dense)          (None, 320)               251200    
                                                                 
 dropout_966 (Dropout)       (None, 320)               0         
                                                                 
 dense_1437 (Dense)          (None, 448)               143808    
                                                                 
 dropout_967 (Dropout)       (None, 448)               0         
                                                                 
 dense_1438 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 406682 (1.55 MB)
Trainable params: 406682 (1.55 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 471:
  Value: 0.9018
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00884470511090505

Model: "sequential_471"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_471 (Flatten)       (None, 784)               0         
                                                                 
 dense_1439 (Dense)          (None, 448)               351680    
                                                                 
 dropout_968 (Dropout)       (None, 448)               0         
                                                                 
 dense_1440 (Dense)          (None, 416)               186784    
                                                                 
 dropout_969 (Dropout)       (None, 416)               0         
                                                                 
 dense_1441 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 472:
  Value: 0.7484
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007467114661138472

Model: "sequential_472"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_472 (Flatten)       (None, 784)               0         
                                                                 
 dense_1442 (Dense)          (None, 448)               351680    
                                                                 
 dropout_970 (Dropout)       (None, 448)               0         
                                                                 
 dense_1443 (Dense)          (None, 448)               201152    
                                                                 
 dropout_971 (Dropout)       (None, 448)               0         
                                                                 
 dense_1444 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 473:
  Value: 0.4160
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.005529688248164442

Model: "sequential_473"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_473 (Flatten)       (None, 784)               0         
                                                                 
 dense_1445 (Dense)          (None, 416)               326560    
                                                                 
 dropout_972 (Dropout)       (None, 416)               0         
                                                                 
 dense_1446 (Dense)          (None, 448)               186816    
                                                                 
 dropout_973 (Dropout)       (None, 448)               0         
                                                                 
 dense_1447 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 474:
  Value: 0.9033
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003618097849100158

Model: "sequential_474"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_474 (Flatten)       (None, 784)               0         
                                                                 
 dense_1448 (Dense)          (None, 416)               326560    
                                                                 
 dropout_974 (Dropout)       (None, 416)               0         
                                                                 
 dense_1449 (Dense)          (None, 416)               173472    
                                                                 
 dropout_975 (Dropout)       (None, 416)               0         
                                                                 
 dense_1450 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 475:
  Value: 0.9025
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.008890603277478306

Model: "sequential_475"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_475 (Flatten)       (None, 784)               0         
                                                                 
 dense_1451 (Dense)          (None, 448)               351680    
                                                                 
 dropout_976 (Dropout)       (None, 448)               0         
                                                                 
 dense_1452 (Dense)          (None, 480)               215520    
                                                                 
 dropout_977 (Dropout)       (None, 480)               0         
                                                                 
 dense_1453 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 476:
  Value: 0.9095
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005110526881543486

Model: "sequential_476"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_476 (Flatten)       (None, 784)               0         
                                                                 
 dense_1454 (Dense)          (None, 448)               351680    
                                                                 
 dropout_978 (Dropout)       (None, 448)               0         
                                                                 
 dense_1455 (Dense)          (None, 448)               201152    
                                                                 
 dropout_979 (Dropout)       (None, 448)               0         
                                                                 
 dense_1456 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 477:
  Value: 0.8855
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006297161497403187

Model: "sequential_477"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_477 (Flatten)       (None, 784)               0         
                                                                 
 dense_1457 (Dense)          (None, 448)               351680    
                                                                 
 dropout_980 (Dropout)       (None, 448)               0         
                                                                 
 dense_1458 (Dense)          (None, 448)               201152    
                                                                 
 dropout_981 (Dropout)       (None, 448)               0         
                                                                 
 dense_1459 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 478:
  Value: 0.0393
  num_layers: 2
  units_0: 128
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.007012863493597476

Model: "sequential_478"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_478 (Flatten)       (None, 784)               0         
                                                                 
 dense_1460 (Dense)          (None, 128)               100480    
                                                                 
 dropout_982 (Dropout)       (None, 128)               0         
                                                                 
 dense_1461 (Dense)          (None, 448)               57792     
                                                                 
 dropout_983 (Dropout)       (None, 448)               0         
                                                                 
 dense_1462 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 169946 (663.85 KB)
Trainable params: 169946 (663.85 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 479:
  Value: 0.9066
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006887100859827294

Model: "sequential_479"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_479 (Flatten)       (None, 784)               0         
                                                                 
 dense_1463 (Dense)          (None, 448)               351680    
                                                                 
 dropout_984 (Dropout)       (None, 448)               0         
                                                                 
 dense_1464 (Dense)          (None, 448)               201152    
                                                                 
 dropout_985 (Dropout)       (None, 448)               0         
                                                                 
 dense_1465 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 480:
  Value: 0.9072
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009786774679742176

Model: "sequential_480"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_480 (Flatten)       (None, 784)               0         
                                                                 
 dense_1466 (Dense)          (None, 448)               351680    
                                                                 
 dropout_986 (Dropout)       (None, 448)               0         
                                                                 
 dense_1467 (Dense)          (None, 416)               186784    
                                                                 
 dropout_987 (Dropout)       (None, 416)               0         
                                                                 
 dense_1468 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 481:
  Value: 0.6840
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.008287444520581687

Model: "sequential_481"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_481 (Flatten)       (None, 784)               0         
                                                                 
 dense_1469 (Dense)          (None, 448)               351680    
                                                                 
 dropout_988 (Dropout)       (None, 448)               0         
                                                                 
 dense_1470 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_111 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_989 (Dropout)       (None, 480)               0         
                                                                 
 dense_1471 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 581626 (2.22 MB)
Trainable params: 580666 (2.22 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 482:
  Value: 0.7972
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.004545132197256139

Model: "sequential_482"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_482 (Flatten)       (None, 784)               0         
                                                                 
 dense_1472 (Dense)          (None, 448)               351680    
                                                                 
 dropout_990 (Dropout)       (None, 448)               0         
                                                                 
 dense_1473 (Dense)          (None, 448)               201152    
                                                                 
 dropout_991 (Dropout)       (None, 448)               0         
                                                                 
 dense_1474 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 483:
  Value: 0.8654
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009712706535082657

Model: "sequential_483"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_483 (Flatten)       (None, 784)               0         
                                                                 
 dense_1475 (Dense)          (None, 416)               326560    
                                                                 
 dropout_992 (Dropout)       (None, 416)               0         
                                                                 
 dense_1476 (Dense)          (None, 416)               173472    
                                                                 
 dropout_993 (Dropout)       (None, 416)               0         
                                                                 
 dense_1477 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 484:
  Value: 0.8618
  num_layers: 2
  units_0: 352
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005392434651337248

Model: "sequential_484"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_484 (Flatten)       (None, 784)               0         
                                                                 
 dense_1478 (Dense)          (None, 352)               276320    
                                                                 
 dropout_994 (Dropout)       (None, 352)               0         
                                                                 
 dense_1479 (Dense)          (None, 448)               158144    
                                                                 
 dropout_995 (Dropout)       (None, 448)               0         
                                                                 
 dense_1480 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 446138 (1.70 MB)
Trainable params: 446138 (1.70 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 485:
  Value: 0.9109
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005471646000077654

Model: "sequential_485"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_485 (Flatten)       (None, 784)               0         
                                                                 
 dense_1481 (Dense)          (None, 448)               351680    
                                                                 
 dropout_996 (Dropout)       (None, 448)               0         
                                                                 
 dense_1482 (Dense)          (None, 416)               186784    
                                                                 
 dropout_997 (Dropout)       (None, 416)               0         
                                                                 
 dense_1483 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 486:
  Value: 0.8670
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004735188314657815

Model: "sequential_486"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_486 (Flatten)       (None, 784)               0         
                                                                 
 dense_1484 (Dense)          (None, 416)               326560    
                                                                 
 dropout_998 (Dropout)       (None, 416)               0         
                                                                 
 dense_1485 (Dense)          (None, 416)               173472    
                                                                 
 dropout_999 (Dropout)       (None, 416)               0         
                                                                 
 dense_1486 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 487:
  Value: 0.9076
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 192
  units_3: 384
  activation_0: relu
  activation_1: relu
  activation_2: tanh
  activation_3: relu
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.4
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.004761294087250545

Model: "sequential_487"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_487 (Flatten)       (None, 784)               0         
                                                                 
 dense_1487 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1000 (Dropout)      (None, 448)               0         
                                                                 
 dense_1488 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1001 (Dropout)      (None, 416)               0         
                                                                 
 dense_1489 (Dense)          (None, 192)               80064     
                                                                 
 batch_normalization_112 (B  (None, 192)               768       
 atchNormalization)                                              
                                                                 
 dropout_1002 (Dropout)      (None, 192)               0         
                                                                 
 dense_1490 (Dense)          (None, 384)               74112     
                                                                 
 batch_normalization_113 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1003 (Dropout)      (None, 384)               0         
                                                                 
 dense_1491 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 704954 (2.69 MB)
Trainable params: 703802 (2.68 MB)
Non-trainable params: 1152 (4.50 KB)
_________________________________________________________________



Trial 488:
  Value: 0.8592
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002984540312360649

Model: "sequential_488"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_488 (Flatten)       (None, 784)               0         
                                                                 
 dense_1492 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_114 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1004 (Dropout)      (None, 480)               0         
                                                                 
 dense_1493 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1005 (Dropout)      (None, 416)               0         
                                                                 
 dense_1494 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 589658 (2.25 MB)
Trainable params: 588698 (2.25 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 489:
  Value: 0.9125
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005835085322789482

Model: "sequential_489"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_489 (Flatten)       (None, 784)               0         
                                                                 
 dense_1495 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1006 (Dropout)      (None, 448)               0         
                                                                 
 dense_1496 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1007 (Dropout)      (None, 448)               0         
                                                                 
 dense_1497 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 490:
  Value: 0.8537
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0060716396104793435

Model: "sequential_490"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_490 (Flatten)       (None, 784)               0         
                                                                 
 dense_1498 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1008 (Dropout)      (None, 448)               0         
                                                                 
 dense_1499 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1009 (Dropout)      (None, 416)               0         
                                                                 
 dense_1500 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 491:
  Value: 0.9023
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005780346308526763

Model: "sequential_491"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_491 (Flatten)       (None, 784)               0         
                                                                 
 dense_1501 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1010 (Dropout)      (None, 448)               0         
                                                                 
 dense_1502 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1011 (Dropout)      (None, 448)               0         
                                                                 
 dense_1503 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 492:
  Value: 0.1234
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.007804333486382678

Model: "sequential_492"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_492 (Flatten)       (None, 784)               0         
                                                                 
 dense_1504 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1012 (Dropout)      (None, 416)               0         
                                                                 
 dense_1505 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1013 (Dropout)      (None, 416)               0         
                                                                 
 dense_1506 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 493:
  Value: 0.8178
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.006850490666514046

Model: "sequential_493"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_493 (Flatten)       (None, 784)               0         
                                                                 
 dense_1507 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1014 (Dropout)      (None, 448)               0         
                                                                 
 dense_1508 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1015 (Dropout)      (None, 448)               0         
                                                                 
 dense_1509 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 494:
  Value: 0.7291
  num_layers: 2
  units_0: 288
  units_1: 416
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00441281129606715

Model: "sequential_494"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_494 (Flatten)       (None, 784)               0         
                                                                 
 dense_1510 (Dense)          (None, 288)               226080    
                                                                 
 dropout_1016 (Dropout)      (None, 288)               0         
                                                                 
 dense_1511 (Dense)          (None, 416)               120224    
                                                                 
 dropout_1017 (Dropout)      (None, 416)               0         
                                                                 
 dense_1512 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 357146 (1.36 MB)
Trainable params: 357146 (1.36 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 495:
  Value: 0.9100
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005843139899505792

Model: "sequential_495"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_495 (Flatten)       (None, 784)               0         
                                                                 
 dense_1513 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1018 (Dropout)      (None, 448)               0         
                                                                 
 dense_1514 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1019 (Dropout)      (None, 448)               0         
                                                                 
 dense_1515 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 496:
  Value: 0.9024
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006908529425360754

Model: "sequential_496"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_496 (Flatten)       (None, 784)               0         
                                                                 
 dense_1516 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1020 (Dropout)      (None, 448)               0         
                                                                 
 dense_1517 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1021 (Dropout)      (None, 448)               0         
                                                                 
 dense_1518 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 497:
  Value: 0.8804
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00630765444149188

Model: "sequential_497"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_497 (Flatten)       (None, 784)               0         
                                                                 
 dense_1519 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1022 (Dropout)      (None, 448)               0         
                                                                 
 dense_1520 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1023 (Dropout)      (None, 448)               0         
                                                                 
 dense_1521 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 498:
  Value: 0.8954
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005504044464182486

Model: "sequential_498"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_498 (Flatten)       (None, 784)               0         
                                                                 
 dense_1522 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1024 (Dropout)      (None, 416)               0         
                                                                 
 dense_1523 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1025 (Dropout)      (None, 448)               0         
                                                                 
 dense_1524 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 499:
  Value: 0.8671
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006885491778618184

Model: "sequential_499"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_499 (Flatten)       (None, 784)               0         
                                                                 
 dense_1525 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1026 (Dropout)      (None, 448)               0         
                                                                 
 dense_1526 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1027 (Dropout)      (None, 448)               0         
                                                                 
 dense_1527 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 500:
  Value: 0.9032
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005844289862847978

Model: "sequential_500"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_500 (Flatten)       (None, 784)               0         
                                                                 
 dense_1528 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1028 (Dropout)      (None, 448)               0         
                                                                 
 dense_1529 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1029 (Dropout)      (None, 448)               0         
                                                                 
 dense_1530 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 501:
  Value: 0.6169
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: sgd
  learning_rate: 0.008146828905754303

Model: "sequential_501"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_501 (Flatten)       (None, 784)               0         
                                                                 
 dense_1531 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1030 (Dropout)      (None, 448)               0         
                                                                 
 dense_1532 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_115 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1031 (Dropout)      (None, 448)               0         
                                                                 
 dense_1533 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 502:
  Value: 0.8893
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005628750156753847

Model: "sequential_502"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_502 (Flatten)       (None, 784)               0         
                                                                 
 dense_1534 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1032 (Dropout)      (None, 416)               0         
                                                                 
 dense_1535 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1033 (Dropout)      (None, 448)               0         
                                                                 
 dense_1536 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 503:
  Value: 0.8990
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007431017615362722

Model: "sequential_503"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_503 (Flatten)       (None, 784)               0         
                                                                 
 dense_1537 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1034 (Dropout)      (None, 448)               0         
                                                                 
 dense_1538 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1035 (Dropout)      (None, 448)               0         
                                                                 
 dense_1539 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 504:
  Value: 0.8064
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0043526386945775195

Model: "sequential_504"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_504 (Flatten)       (None, 784)               0         
                                                                 
 dense_1540 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1036 (Dropout)      (None, 448)               0         
                                                                 
 dense_1541 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1037 (Dropout)      (None, 448)               0         
                                                                 
 dense_1542 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 505:
  Value: 0.9064
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006009882516807872

Model: "sequential_505"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_505 (Flatten)       (None, 784)               0         
                                                                 
 dense_1543 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1038 (Dropout)      (None, 448)               0         
                                                                 
 dense_1544 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1039 (Dropout)      (None, 416)               0         
                                                                 
 dense_1545 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 506:
  Value: 0.0410
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.005169498835700102

Model: "sequential_506"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_506 (Flatten)       (None, 784)               0         
                                                                 
 dense_1546 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1040 (Dropout)      (None, 448)               0         
                                                                 
 dense_1547 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1041 (Dropout)      (None, 448)               0         
                                                                 
 dense_1548 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 507:
  Value: 0.8765
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006384612727759622

Model: "sequential_507"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_507 (Flatten)       (None, 784)               0         
                                                                 
 dense_1549 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1042 (Dropout)      (None, 416)               0         
                                                                 
 dense_1550 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1043 (Dropout)      (None, 416)               0         
                                                                 
 dense_1551 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 508:
  Value: 0.8659
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0050247008322122505

Model: "sequential_508"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_508 (Flatten)       (None, 784)               0         
                                                                 
 dense_1552 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_116 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1044 (Dropout)      (None, 448)               0         
                                                                 
 dense_1553 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1045 (Dropout)      (None, 448)               0         
                                                                 
 dense_1554 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 509:
  Value: 0.8033
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.008011224700523033

Model: "sequential_509"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_509 (Flatten)       (None, 784)               0         
                                                                 
 dense_1555 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1046 (Dropout)      (None, 448)               0         
                                                                 
 dense_1556 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1047 (Dropout)      (None, 480)               0         
                                                                 
 dense_1557 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 510:
  Value: 0.9112
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004372708535421679

Model: "sequential_510"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_510 (Flatten)       (None, 784)               0         
                                                                 
 dense_1558 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1048 (Dropout)      (None, 480)               0         
                                                                 
 dense_1559 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1049 (Dropout)      (None, 416)               0         
                                                                 
 dense_1560 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 511:
  Value: 0.8523
  num_layers: 2
  units_0: 256
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004174954840277884

Model: "sequential_511"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_511 (Flatten)       (None, 784)               0         
                                                                 
 dense_1561 (Dense)          (None, 256)               200960    
                                                                 
 dropout_1050 (Dropout)      (None, 256)               0         
                                                                 
 dense_1562 (Dense)          (None, 416)               106912    
                                                                 
 dropout_1051 (Dropout)      (None, 416)               0         
                                                                 
 dense_1563 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 318714 (1.22 MB)
Trainable params: 318714 (1.22 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 512:
  Value: 0.8529
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005048203458691879

Model: "sequential_512"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_512 (Flatten)       (None, 784)               0         
                                                                 
 dense_1564 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1052 (Dropout)      (None, 448)               0         
                                                                 
 dense_1565 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1053 (Dropout)      (None, 416)               0         
                                                                 
 dense_1566 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 513:
  Value: 0.9091
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004417592932291005

Model: "sequential_513"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_513 (Flatten)       (None, 784)               0         
                                                                 
 dense_1567 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1054 (Dropout)      (None, 480)               0         
                                                                 
 dense_1568 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1055 (Dropout)      (None, 416)               0         
                                                                 
 dense_1569 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 514:
  Value: 0.8644
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002633260266457395

Model: "sequential_514"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_514 (Flatten)       (None, 784)               0         
                                                                 
 dense_1570 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1056 (Dropout)      (None, 416)               0         
                                                                 
 dense_1571 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1057 (Dropout)      (None, 416)               0         
                                                                 
 dense_1572 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 515:
  Value: 0.8920
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004713466885587015

Model: "sequential_515"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_515 (Flatten)       (None, 784)               0         
                                                                 
 dense_1573 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1058 (Dropout)      (None, 448)               0         
                                                                 
 dense_1574 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1059 (Dropout)      (None, 448)               0         
                                                                 
 dense_1575 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 516:
  Value: 0.9106
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005827135945409087

Model: "sequential_516"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_516 (Flatten)       (None, 784)               0         
                                                                 
 dense_1576 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1060 (Dropout)      (None, 480)               0         
                                                                 
 dense_1577 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1061 (Dropout)      (None, 416)               0         
                                                                 
 dense_1578 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 517:
  Value: 0.7312
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005812240058678174

Model: "sequential_517"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_517 (Flatten)       (None, 784)               0         
                                                                 
 dense_1579 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1062 (Dropout)      (None, 480)               0         
                                                                 
 dense_1580 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1063 (Dropout)      (None, 416)               0         
                                                                 
 dense_1581 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 518:
  Value: 0.9053
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005776590355154281

Model: "sequential_518"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_518 (Flatten)       (None, 784)               0         
                                                                 
 dense_1582 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1064 (Dropout)      (None, 480)               0         
                                                                 
 dense_1583 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1065 (Dropout)      (None, 416)               0         
                                                                 
 dense_1584 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 519:
  Value: 0.8142
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.00634474655672512

Model: "sequential_519"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_519 (Flatten)       (None, 784)               0         
                                                                 
 dense_1585 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1066 (Dropout)      (None, 448)               0         
                                                                 
 dense_1586 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1067 (Dropout)      (None, 416)               0         
                                                                 
 dense_1587 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 520:
  Value: 0.8954
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00475772750055765

Model: "sequential_520"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_520 (Flatten)       (None, 784)               0         
                                                                 
 dense_1588 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1068 (Dropout)      (None, 448)               0         
                                                                 
 dense_1589 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1069 (Dropout)      (None, 416)               0         
                                                                 
 dense_1590 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 521:
  Value: 0.9100
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003628967848977073

Model: "sequential_521"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_521 (Flatten)       (None, 784)               0         
                                                                 
 dense_1591 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1070 (Dropout)      (None, 480)               0         
                                                                 
 dense_1592 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1071 (Dropout)      (None, 448)               0         
                                                                 
 dense_1593 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 522:
  Value: 0.9078
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0032497325774430196

Model: "sequential_522"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_522 (Flatten)       (None, 784)               0         
                                                                 
 dense_1594 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1072 (Dropout)      (None, 480)               0         
                                                                 
 dense_1595 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1073 (Dropout)      (None, 448)               0         
                                                                 
 dense_1596 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 523:
  Value: 0.4383
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adagrad
  learning_rate: 0.0038351078015385048

Model: "sequential_523"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_523 (Flatten)       (None, 784)               0         
                                                                 
 dense_1597 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1074 (Dropout)      (None, 416)               0         
                                                                 
 dense_1598 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_117 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1075 (Dropout)      (None, 448)               0         
                                                                 
 dense_1599 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 526842 (2.01 MB)
Trainable params: 525946 (2.01 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 524:
  Value: 0.8663
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003383989122034252

Model: "sequential_524"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_524 (Flatten)       (None, 784)               0         
                                                                 
 dense_1600 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1076 (Dropout)      (None, 448)               0         
                                                                 
 dense_1601 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1077 (Dropout)      (None, 448)               0         
                                                                 
 dense_1602 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 525:
  Value: 0.9034
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0040687974037178515

Model: "sequential_525"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_525 (Flatten)       (None, 784)               0         
                                                                 
 dense_1603 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1078 (Dropout)      (None, 480)               0         
                                                                 
 dense_1604 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1079 (Dropout)      (None, 416)               0         
                                                                 
 dense_1605 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 526:
  Value: 0.8269
  num_layers: 1
  units_0: 480
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.005098631161947714

Model: "sequential_526"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_526 (Flatten)       (None, 784)               0         
                                                                 
 dense_1606 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1080 (Dropout)      (None, 480)               0         
                                                                 
 dense_1607 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 527:
  Value: 0.9074
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0035643527277782225

Model: "sequential_527"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_527 (Flatten)       (None, 784)               0         
                                                                 
 dense_1608 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1081 (Dropout)      (None, 448)               0         
                                                                 
 dense_1609 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1082 (Dropout)      (None, 448)               0         
                                                                 
 dense_1610 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 528:
  Value: 0.9071
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005659417827543586

Model: "sequential_528"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_528 (Flatten)       (None, 784)               0         
                                                                 
 dense_1611 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1083 (Dropout)      (None, 480)               0         
                                                                 
 dense_1612 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1084 (Dropout)      (None, 480)               0         
                                                                 
 dense_1613 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 529:
  Value: 0.8632
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006658691962430015

Model: "sequential_529"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_529 (Flatten)       (None, 784)               0         
                                                                 
 dense_1614 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_118 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1085 (Dropout)      (None, 512)               0         
                                                                 
 dense_1615 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1086 (Dropout)      (None, 416)               0         
                                                                 
 dense_1616 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 628218 (2.40 MB)
Trainable params: 627194 (2.39 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 530:
  Value: 0.9093
  num_layers: 3
  units_0: 448
  units_1: 448
  units_2: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.004228665892595748

Model: "sequential_530"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_530 (Flatten)       (None, 784)               0         
                                                                 
 dense_1617 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1087 (Dropout)      (None, 448)               0         
                                                                 
 dense_1618 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1088 (Dropout)      (None, 448)               0         
                                                                 
 dense_1619 (Dense)          (None, 288)               129312    
                                                                 
 batch_normalization_119 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_1089 (Dropout)      (None, 288)               0         
                                                                 
 dense_1620 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 690810 (2.64 MB)
Trainable params: 690234 (2.63 MB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 531:
  Value: 0.1407
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.004947050473338003

Model: "sequential_531"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_531 (Flatten)       (None, 784)               0         
                                                                 
 dense_1621 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1090 (Dropout)      (None, 416)               0         
                                                                 
 dense_1622 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1091 (Dropout)      (None, 448)               0         
                                                                 
 dense_1623 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 532:
  Value: 0.8664
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005647375126801072

Model: "sequential_532"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_532 (Flatten)       (None, 784)               0         
                                                                 
 dense_1624 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1092 (Dropout)      (None, 480)               0         
                                                                 
 dense_1625 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1093 (Dropout)      (None, 416)               0         
                                                                 
 dense_1626 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 533:
  Value: 0.9064
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00048567169006853364

Model: "sequential_533"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_533 (Flatten)       (None, 784)               0         
                                                                 
 dense_1627 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1094 (Dropout)      (None, 512)               0         
                                                                 
 dense_1628 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1095 (Dropout)      (None, 448)               0         
                                                                 
 dense_1629 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 534:
  Value: 0.0393
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.003731852915095754

Model: "sequential_534"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_534 (Flatten)       (None, 784)               0         
                                                                 
 dense_1630 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1096 (Dropout)      (None, 448)               0         
                                                                 
 dense_1631 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1097 (Dropout)      (None, 480)               0         
                                                                 
 dense_1632 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 535:
  Value: 0.8578
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009026006406117693

Model: "sequential_535"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_535 (Flatten)       (None, 784)               0         
                                                                 
 dense_1633 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1098 (Dropout)      (None, 480)               0         
                                                                 
 dense_1634 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1099 (Dropout)      (None, 448)               0         
                                                                 
 dense_1635 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 536:
  Value: 0.9064
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007315382294063564

Model: "sequential_536"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_536 (Flatten)       (None, 784)               0         
                                                                 
 dense_1636 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1100 (Dropout)      (None, 480)               0         
                                                                 
 dense_1637 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1101 (Dropout)      (None, 416)               0         
                                                                 
 dense_1638 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 537:
  Value: 0.9042
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002737306749961386

Model: "sequential_537"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_537 (Flatten)       (None, 784)               0         
                                                                 
 dense_1639 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1102 (Dropout)      (None, 512)               0         
                                                                 
 dense_1640 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1103 (Dropout)      (None, 416)               0         
                                                                 
 dense_1641 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 538:
  Value: 0.8785
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001146553955470899

Model: "sequential_538"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_538 (Flatten)       (None, 784)               0         
                                                                 
 dense_1642 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1104 (Dropout)      (None, 480)               0         
                                                                 
 dense_1643 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1105 (Dropout)      (None, 448)               0         
                                                                 
 dense_1644 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 539:
  Value: 0.7950
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.005407393401837808

Model: "sequential_539"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_539 (Flatten)       (None, 784)               0         
                                                                 
 dense_1645 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1106 (Dropout)      (None, 448)               0         
                                                                 
 dense_1646 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1107 (Dropout)      (None, 416)               0         
                                                                 
 dense_1647 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 540:
  Value: 0.9092
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004406983120120768

Model: "sequential_540"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_540 (Flatten)       (None, 784)               0         
                                                                 
 dense_1648 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1108 (Dropout)      (None, 480)               0         
                                                                 
 dense_1649 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1109 (Dropout)      (None, 448)               0         
                                                                 
 dense_1650 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 541:
  Value: 0.7445
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0060347181732061175

Model: "sequential_541"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_541 (Flatten)       (None, 784)               0         
                                                                 
 dense_1651 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1110 (Dropout)      (None, 448)               0         
                                                                 
 dense_1652 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1111 (Dropout)      (None, 448)               0         
                                                                 
 dense_1653 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 542:
  Value: 0.9022
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0006923339901846755

Model: "sequential_542"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_542 (Flatten)       (None, 784)               0         
                                                                 
 dense_1654 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1112 (Dropout)      (None, 512)               0         
                                                                 
 dense_1655 (Dense)          (None, 480)               246240    
                                                                 
 batch_normalization_120 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1113 (Dropout)      (None, 480)               0         
                                                                 
 dense_1656 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 662586 (2.53 MB)
Trainable params: 661626 (2.52 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 543:
  Value: 0.8785
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00010214017366503253

Model: "sequential_543"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_543 (Flatten)       (None, 784)               0         
                                                                 
 dense_1657 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1114 (Dropout)      (None, 416)               0         
                                                                 
 dense_1658 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1115 (Dropout)      (None, 416)               0         
                                                                 
 dense_1659 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 544:
  Value: 0.8863
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003261261332326638

Model: "sequential_544"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_544 (Flatten)       (None, 784)               0         
                                                                 
 dense_1660 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1116 (Dropout)      (None, 448)               0         
                                                                 
 dense_1661 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1117 (Dropout)      (None, 416)               0         
                                                                 
 dense_1662 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 545:
  Value: 0.9092
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0030547394326615558

Model: "sequential_545"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_545 (Flatten)       (None, 784)               0         
                                                                 
 dense_1663 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1118 (Dropout)      (None, 512)               0         
                                                                 
 dense_1664 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1119 (Dropout)      (None, 448)               0         
                                                                 
 dense_1665 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 546:
  Value: 0.9094
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004829383066793943

Model: "sequential_546"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_546 (Flatten)       (None, 784)               0         
                                                                 
 dense_1666 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1120 (Dropout)      (None, 480)               0         
                                                                 
 dense_1667 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1121 (Dropout)      (None, 448)               0         
                                                                 
 dense_1668 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 547:
  Value: 0.8503
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.000621300118562176

Model: "sequential_547"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_547 (Flatten)       (None, 784)               0         
                                                                 
 dense_1669 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_121 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1122 (Dropout)      (None, 448)               0         
                                                                 
 dense_1670 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1123 (Dropout)      (None, 416)               0         
                                                                 
 dense_1671 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 551098 (2.10 MB)
Trainable params: 550202 (2.10 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 548:
  Value: 0.9121
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006772682326179917

Model: "sequential_548"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_548 (Flatten)       (None, 784)               0         
                                                                 
 dense_1672 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1124 (Dropout)      (None, 480)               0         
                                                                 
 dense_1673 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1125 (Dropout)      (None, 448)               0         
                                                                 
 dense_1674 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 549:
  Value: 0.9105
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007639884129045281

Model: "sequential_549"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_549 (Flatten)       (None, 784)               0         
                                                                 
 dense_1675 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1126 (Dropout)      (None, 480)               0         
                                                                 
 dense_1676 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1127 (Dropout)      (None, 448)               0         
                                                                 
 dense_1677 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 550:
  Value: 0.8674
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007118049971276004

Model: "sequential_550"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_550 (Flatten)       (None, 784)               0         
                                                                 
 dense_1678 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1128 (Dropout)      (None, 480)               0         
                                                                 
 dense_1679 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1129 (Dropout)      (None, 480)               0         
                                                                 
 dense_1680 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 551:
  Value: 0.9063
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006819554457832069

Model: "sequential_551"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_551 (Flatten)       (None, 784)               0         
                                                                 
 dense_1681 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1130 (Dropout)      (None, 480)               0         
                                                                 
 dense_1682 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1131 (Dropout)      (None, 480)               0         
                                                                 
 dense_1683 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 552:
  Value: 0.9077
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007695973275781701

Model: "sequential_552"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_552 (Flatten)       (None, 784)               0         
                                                                 
 dense_1684 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1132 (Dropout)      (None, 512)               0         
                                                                 
 dense_1685 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1133 (Dropout)      (None, 448)               0         
                                                                 
 dense_1686 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 553:
  Value: 0.8016
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.008152008936703661

Model: "sequential_553"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_553 (Flatten)       (None, 784)               0         
                                                                 
 dense_1687 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1134 (Dropout)      (None, 480)               0         
                                                                 
 dense_1688 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1135 (Dropout)      (None, 448)               0         
                                                                 
 dense_1689 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 554:
  Value: 0.1420
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.008650124119429685

Model: "sequential_554"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_554 (Flatten)       (None, 784)               0         
                                                                 
 dense_1690 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1136 (Dropout)      (None, 480)               0         
                                                                 
 dense_1691 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1137 (Dropout)      (None, 448)               0         
                                                                 
 dense_1692 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 555:
  Value: 0.8628
  num_layers: 2
  units_0: 384
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006607359643304026

Model: "sequential_555"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_555 (Flatten)       (None, 784)               0         
                                                                 
 dense_1693 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1138 (Dropout)      (None, 384)               0         
                                                                 
 dense_1694 (Dense)          (None, 416)               160160    
                                                                 
 dropout_1139 (Dropout)      (None, 416)               0         
                                                                 
 dense_1695 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 472442 (1.80 MB)
Trainable params: 472442 (1.80 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 556:
  Value: 0.8566
  num_layers: 2
  units_0: 512
  units_1: 192
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007537853902336575

Model: "sequential_556"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_556 (Flatten)       (None, 784)               0         
                                                                 
 dense_1696 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1140 (Dropout)      (None, 512)               0         
                                                                 
 dense_1697 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1141 (Dropout)      (None, 192)               0         
                                                                 
 dense_1698 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 505434 (1.93 MB)
Trainable params: 505434 (1.93 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 557:
  Value: 0.9076
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0022182723081295578

Model: "sequential_557"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_557 (Flatten)       (None, 784)               0         
                                                                 
 dense_1699 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1142 (Dropout)      (None, 480)               0         
                                                                 
 dense_1700 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1143 (Dropout)      (None, 448)               0         
                                                                 
 dense_1701 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 558:
  Value: 0.8521
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0026612437308554497

Model: "sequential_558"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_558 (Flatten)       (None, 784)               0         
                                                                 
 dense_1702 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1144 (Dropout)      (None, 480)               0         
                                                                 
 dense_1703 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1145 (Dropout)      (None, 448)               0         
                                                                 
 dense_1704 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 559:
  Value: 0.3475
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.006383233118667933

Model: "sequential_559"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_559 (Flatten)       (None, 784)               0         
                                                                 
 dense_1705 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1146 (Dropout)      (None, 512)               0         
                                                                 
 dense_1706 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1147 (Dropout)      (None, 416)               0         
                                                                 
 dense_1707 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 560:
  Value: 0.9057
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0024670587610646504

Model: "sequential_560"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_560 (Flatten)       (None, 784)               0         
                                                                 
 dense_1708 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1148 (Dropout)      (None, 512)               0         
                                                                 
 dense_1709 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1149 (Dropout)      (None, 448)               0         
                                                                 
 dense_1710 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 561:
  Value: 0.8661
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0030494797185437288

Model: "sequential_561"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_561 (Flatten)       (None, 784)               0         
                                                                 
 dense_1711 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1150 (Dropout)      (None, 480)               0         
                                                                 
 dense_1712 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1151 (Dropout)      (None, 416)               0         
                                                                 
 dense_1713 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 562:
  Value: 0.9041
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0002918418508814848

Model: "sequential_562"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_562 (Flatten)       (None, 784)               0         
                                                                 
 dense_1714 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1152 (Dropout)      (None, 480)               0         
                                                                 
 dense_1715 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_122 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1153 (Dropout)      (None, 480)               0         
                                                                 
 dense_1716 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 622106 (2.37 MB)
Trainable params: 621146 (2.37 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 563:
  Value: 0.0373
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: sigmoid
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.00040908754577919114

Model: "sequential_563"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_563 (Flatten)       (None, 784)               0         
                                                                 
 dense_1717 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1154 (Dropout)      (None, 480)               0         
                                                                 
 dense_1718 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1155 (Dropout)      (None, 448)               0         
                                                                 
 dense_1719 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 564:
  Value: 0.8483
  num_layers: 2
  units_0: 512
  units_1: 160
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0070625794535886625

Model: "sequential_564"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_564 (Flatten)       (None, 784)               0         
                                                                 
 dense_1720 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1156 (Dropout)      (None, 512)               0         
                                                                 
 dense_1721 (Dense)          (None, 160)               82080     
                                                                 
 dropout_1157 (Dropout)      (None, 160)               0         
                                                                 
 dense_1722 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 488186 (1.86 MB)
Trainable params: 488186 (1.86 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 565:
  Value: 0.9074
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0035843380561931533

Model: "sequential_565"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_565 (Flatten)       (None, 784)               0         
                                                                 
 dense_1723 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1158 (Dropout)      (None, 480)               0         
                                                                 
 dense_1724 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1159 (Dropout)      (None, 416)               0         
                                                                 
 dense_1725 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 566:
  Value: 0.9082
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.008145871241072996

Model: "sequential_566"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_566 (Flatten)       (None, 784)               0         
                                                                 
 dense_1726 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1160 (Dropout)      (None, 512)               0         
                                                                 
 dense_1727 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1161 (Dropout)      (None, 448)               0         
                                                                 
 dense_1728 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 567:
  Value: 0.8672
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006859702426926726

Model: "sequential_567"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_567 (Flatten)       (None, 784)               0         
                                                                 
 dense_1729 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_123 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1162 (Dropout)      (None, 480)               0         
                                                                 
 dense_1730 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1163 (Dropout)      (None, 480)               0         
                                                                 
 dense_1731 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 622106 (2.37 MB)
Trainable params: 621146 (2.37 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 568:
  Value: 0.9060
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002242294179538898

Model: "sequential_568"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_568 (Flatten)       (None, 784)               0         
                                                                 
 dense_1732 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1164 (Dropout)      (None, 512)               0         
                                                                 
 dense_1733 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1165 (Dropout)      (None, 416)               0         
                                                                 
 dense_1734 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 569:
  Value: 0.7991
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.00601866563745689

Model: "sequential_569"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_569 (Flatten)       (None, 784)               0         
                                                                 
 dense_1735 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1166 (Dropout)      (None, 480)               0         
                                                                 
 dense_1736 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1167 (Dropout)      (None, 448)               0         
                                                                 
 dense_1737 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 570:
  Value: 0.8675
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0033380427579080296

Model: "sequential_570"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_570 (Flatten)       (None, 784)               0         
                                                                 
 dense_1738 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1168 (Dropout)      (None, 448)               0         
                                                                 
 dense_1739 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1169 (Dropout)      (None, 416)               0         
                                                                 
 dense_1740 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 571:
  Value: 0.9076
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007421312896718382

Model: "sequential_571"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_571 (Flatten)       (None, 784)               0         
                                                                 
 dense_1741 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1170 (Dropout)      (None, 512)               0         
                                                                 
 dense_1742 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1171 (Dropout)      (None, 448)               0         
                                                                 
 dense_1743 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 572:
  Value: 0.8791
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009037047948166337

Model: "sequential_572"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_572 (Flatten)       (None, 784)               0         
                                                                 
 dense_1744 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1172 (Dropout)      (None, 480)               0         
                                                                 
 dense_1745 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1173 (Dropout)      (None, 416)               0         
                                                                 
 dense_1746 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 573:
  Value: 0.9094
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0028575168201664886

Model: "sequential_573"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_573 (Flatten)       (None, 784)               0         
                                                                 
 dense_1747 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1174 (Dropout)      (None, 480)               0         
                                                                 
 dense_1748 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1175 (Dropout)      (None, 448)               0         
                                                                 
 dense_1749 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 574:
  Value: 0.8924
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019949556704166997

Model: "sequential_574"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_574 (Flatten)       (None, 784)               0         
                                                                 
 dense_1750 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1176 (Dropout)      (None, 448)               0         
                                                                 
 dense_1751 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1177 (Dropout)      (None, 448)               0         
                                                                 
 dense_1752 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 575:
  Value: 0.9064
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0066226272208226335

Model: "sequential_575"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_575 (Flatten)       (None, 784)               0         
                                                                 
 dense_1753 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1178 (Dropout)      (None, 480)               0         
                                                                 
 dense_1754 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1179 (Dropout)      (None, 416)               0         
                                                                 
 dense_1755 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 576:
  Value: 0.8303
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.0006457022918172388

Model: "sequential_576"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_576 (Flatten)       (None, 784)               0         
                                                                 
 dense_1756 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1180 (Dropout)      (None, 448)               0         
                                                                 
 dense_1757 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1181 (Dropout)      (None, 448)               0         
                                                                 
 dense_1758 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 577:
  Value: 0.8093
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00045778753286537235

Model: "sequential_577"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_577 (Flatten)       (None, 784)               0         
                                                                 
 dense_1759 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1182 (Dropout)      (None, 512)               0         
                                                                 
 dense_1760 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1183 (Dropout)      (None, 416)               0         
                                                                 
 dense_1761 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 578:
  Value: 0.8535
  num_layers: 2
  units_0: 256
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0038249651591369758

Model: "sequential_578"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_578 (Flatten)       (None, 784)               0         
                                                                 
 dense_1762 (Dense)          (None, 256)               200960    
                                                                 
 dropout_1184 (Dropout)      (None, 256)               0         
                                                                 
 dense_1763 (Dense)          (None, 480)               123360    
                                                                 
 dropout_1185 (Dropout)      (None, 480)               0         
                                                                 
 dense_1764 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 336826 (1.28 MB)
Trainable params: 336826 (1.28 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 579:
  Value: 0.9103
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005794233481594478

Model: "sequential_579"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_579 (Flatten)       (None, 784)               0         
                                                                 
 dense_1765 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1186 (Dropout)      (None, 512)               0         
                                                                 
 dense_1766 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1187 (Dropout)      (None, 448)               0         
                                                                 
 dense_1767 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 580:
  Value: 0.1928
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.005844199211797071

Model: "sequential_580"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_580 (Flatten)       (None, 784)               0         
                                                                 
 dense_1768 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1188 (Dropout)      (None, 512)               0         
                                                                 
 dense_1769 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1189 (Dropout)      (None, 448)               0         
                                                                 
 dense_1770 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 581:
  Value: 0.9026
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0055383414254582645

Model: "sequential_581"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_581 (Flatten)       (None, 784)               0         
                                                                 
 dense_1771 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1190 (Dropout)      (None, 512)               0         
                                                                 
 dense_1772 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1191 (Dropout)      (None, 448)               0         
                                                                 
 dense_1773 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 582:
  Value: 0.9099
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.007489910465635387

Model: "sequential_582"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_582 (Flatten)       (None, 784)               0         
                                                                 
 dense_1774 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1192 (Dropout)      (None, 512)               0         
                                                                 
 dense_1775 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_124 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1193 (Dropout)      (None, 448)               0         
                                                                 
 dense_1776 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 645210 (2.46 MB)
Trainable params: 644314 (2.46 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 583:
  Value: 0.8991
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.006511033949210591

Model: "sequential_583"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_583 (Flatten)       (None, 784)               0         
                                                                 
 dense_1777 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1194 (Dropout)      (None, 512)               0         
                                                                 
 dense_1778 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_125 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1195 (Dropout)      (None, 448)               0         
                                                                 
 dense_1779 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 645210 (2.46 MB)
Trainable params: 644314 (2.46 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 584:
  Value: 0.9020
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0073380962972168125

Model: "sequential_584"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_584 (Flatten)       (None, 784)               0         
                                                                 
 dense_1780 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1196 (Dropout)      (None, 512)               0         
                                                                 
 dense_1781 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_126 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1197 (Dropout)      (None, 416)               0         
                                                                 
 dense_1782 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 627834 (2.39 MB)
Trainable params: 627002 (2.39 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 585:
  Value: 0.9062
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.00782381223723195

Model: "sequential_585"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_585 (Flatten)       (None, 784)               0         
                                                                 
 dense_1783 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1198 (Dropout)      (None, 512)               0         
                                                                 
 dense_1784 (Dense)          (None, 480)               246240    
                                                                 
 batch_normalization_127 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1199 (Dropout)      (None, 480)               0         
                                                                 
 dense_1785 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 662586 (2.53 MB)
Trainable params: 661626 (2.52 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 586:
  Value: 0.7611
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.007076981830149062

Model: "sequential_586"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_586 (Flatten)       (None, 784)               0         
                                                                 
 dense_1786 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1200 (Dropout)      (None, 512)               0         
                                                                 
 dense_1787 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_128 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1201 (Dropout)      (None, 448)               0         
                                                                 
 dense_1788 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 645210 (2.46 MB)
Trainable params: 644314 (2.46 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 587:
  Value: 0.7774
  num_layers: 1
  units_0: 192
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.006527545992146148

Model: "sequential_587"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_587 (Flatten)       (None, 784)               0         
                                                                 
 dense_1789 (Dense)          (None, 192)               150720    
                                                                 
 dropout_1202 (Dropout)      (None, 192)               0         
                                                                 
 dense_1790 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 155738 (608.35 KB)
Trainable params: 155738 (608.35 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 588:
  Value: 0.8789
  num_layers: 2
  units_0: 288
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0060273107338791754

Model: "sequential_588"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_588 (Flatten)       (None, 784)               0         
                                                                 
 dense_1791 (Dense)          (None, 288)               226080    
                                                                 
 dropout_1203 (Dropout)      (None, 288)               0         
                                                                 
 dense_1792 (Dense)          (None, 448)               129472    
                                                                 
 batch_normalization_129 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1204 (Dropout)      (None, 448)               0         
                                                                 
 dense_1793 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 369018 (1.41 MB)
Trainable params: 368122 (1.40 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 589:
  Value: 0.7969
  num_layers: 2
  units_0: 96
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.005550858519179156

Model: "sequential_589"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_589 (Flatten)       (None, 784)               0         
                                                                 
 dense_1794 (Dense)          (None, 96)                75360     
                                                                 
 batch_normalization_130 (B  (None, 96)                384       
 atchNormalization)                                              
                                                                 
 dropout_1205 (Dropout)      (None, 96)                0         
                                                                 
 dense_1795 (Dense)          (None, 416)               40352     
                                                                 
 batch_normalization_131 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1206 (Dropout)      (None, 416)               0         
                                                                 
 dense_1796 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 128602 (502.35 KB)
Trainable params: 127578 (498.35 KB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 590:
  Value: 0.6202
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: sgd
  learning_rate: 0.008339645405622258

Model: "sequential_590"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_590 (Flatten)       (None, 784)               0         
                                                                 
 dense_1797 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1207 (Dropout)      (None, 512)               0         
                                                                 
 dense_1798 (Dense)          (None, 480)               246240    
                                                                 
 batch_normalization_132 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1208 (Dropout)      (None, 480)               0         
                                                                 
 dense_1799 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 662586 (2.53 MB)
Trainable params: 661626 (2.52 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 591:
  Value: 0.0389
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: ftrl
  learning_rate: 0.0005114940907407941

Model: "sequential_591"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_591 (Flatten)       (None, 784)               0         
                                                                 
 dense_1800 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1209 (Dropout)      (None, 416)               0         
                                                                 
 dense_1801 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_133 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1210 (Dropout)      (None, 448)               0         
                                                                 
 dense_1802 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 526842 (2.01 MB)
Trainable params: 525946 (2.01 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 592:
  Value: 0.9058
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004658194549543423

Model: "sequential_592"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_592 (Flatten)       (None, 784)               0         
                                                                 
 dense_1803 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1211 (Dropout)      (None, 448)               0         
                                                                 
 dense_1804 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1212 (Dropout)      (None, 416)               0         
                                                                 
 dense_1805 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 593:
  Value: 0.9053
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0002092452676654825

Model: "sequential_593"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_593 (Flatten)       (None, 784)               0         
                                                                 
 dense_1806 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1213 (Dropout)      (None, 512)               0         
                                                                 
 dense_1807 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_134 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1214 (Dropout)      (None, 448)               0         
                                                                 
 dense_1808 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 645210 (2.46 MB)
Trainable params: 644314 (2.46 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 594:
  Value: 0.8983
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.007598249935549719

Model: "sequential_594"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_594 (Flatten)       (None, 784)               0         
                                                                 
 dense_1809 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1215 (Dropout)      (None, 448)               0         
                                                                 
 dense_1810 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_135 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1216 (Dropout)      (None, 448)               0         
                                                                 
 dense_1811 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 595:
  Value: 0.9078
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.00914015259487129

Model: "sequential_595"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_595 (Flatten)       (None, 784)               0         
                                                                 
 dense_1812 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1217 (Dropout)      (None, 416)               0         
                                                                 
 dense_1813 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_136 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1218 (Dropout)      (None, 416)               0         
                                                                 
 dense_1814 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 512538 (1.96 MB)
Trainable params: 511706 (1.95 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 596:
  Value: 0.9028
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.006315842992878853

Model: "sequential_596"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_596 (Flatten)       (None, 784)               0         
                                                                 
 dense_1815 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1219 (Dropout)      (None, 512)               0         
                                                                 
 dense_1816 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_137 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1220 (Dropout)      (None, 416)               0         
                                                                 
 dense_1817 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 627834 (2.39 MB)
Trainable params: 627002 (2.39 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 597:
  Value: 0.8052
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.005243403999290292

Model: "sequential_597"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_597 (Flatten)       (None, 784)               0         
                                                                 
 dense_1818 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1221 (Dropout)      (None, 480)               0         
                                                                 
 dense_1819 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1222 (Dropout)      (None, 480)               0         
                                                                 
 dense_1820 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 598:
  Value: 0.8141
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005494614133035036

Model: "sequential_598"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_598 (Flatten)       (None, 784)               0         
                                                                 
 dense_1821 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1223 (Dropout)      (None, 512)               0         
                                                                 
 dense_1822 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1224 (Dropout)      (None, 448)               0         
                                                                 
 dense_1823 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 599:
  Value: 0.8658
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0039918288298465415

Model: "sequential_599"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_599 (Flatten)       (None, 784)               0         
                                                                 
 dense_1824 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1225 (Dropout)      (None, 448)               0         
                                                                 
 dense_1825 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1226 (Dropout)      (None, 384)               0         
                                                                 
 dense_1826 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 600:
  Value: 0.8948
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00692204812439098

Model: "sequential_600"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_600 (Flatten)       (None, 784)               0         
                                                                 
 dense_1827 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1227 (Dropout)      (None, 480)               0         
                                                                 
 dense_1828 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1228 (Dropout)      (None, 416)               0         
                                                                 
 dense_1829 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 601:
  Value: 0.9080
  num_layers: 3
  units_0: 448
  units_1: 448
  units_2: 64
  activation_0: relu
  activation_1: relu
  activation_2: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  optimizer: adam
  learning_rate: 0.0003500359773256593

Model: "sequential_601"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_601 (Flatten)       (None, 784)               0         
                                                                 
 dense_1830 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1229 (Dropout)      (None, 448)               0         
                                                                 
 dense_1831 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1230 (Dropout)      (None, 448)               0         
                                                                 
 dense_1832 (Dense)          (None, 64)                28736     
                                                                 
 dropout_1231 (Dropout)      (None, 64)                0         
                                                                 
 dense_1833 (Dense)          (None, 26)                1690      
                                                                 
=================================================================
Total params: 583258 (2.22 MB)
Trainable params: 583258 (2.22 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 602:
  Value: 0.9076
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0057289996142570665

Model: "sequential_602"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_602 (Flatten)       (None, 784)               0         
                                                                 
 dense_1834 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1232 (Dropout)      (None, 512)               0         
                                                                 
 dense_1835 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1233 (Dropout)      (None, 416)               0         
                                                                 
 dense_1836 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 603:
  Value: 0.9073
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004265805100886735

Model: "sequential_603"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_603 (Flatten)       (None, 784)               0         
                                                                 
 dense_1837 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1234 (Dropout)      (None, 480)               0         
                                                                 
 dense_1838 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1235 (Dropout)      (None, 480)               0         
                                                                 
 dense_1839 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 604:
  Value: 0.8431
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.009915456760730672

Model: "sequential_604"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_604 (Flatten)       (None, 784)               0         
                                                                 
 dense_1840 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1236 (Dropout)      (None, 480)               0         
                                                                 
 dense_1841 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1237 (Dropout)      (None, 448)               0         
                                                                 
 dense_1842 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 605:
  Value: 0.8551
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00824022002332669

Model: "sequential_605"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_605 (Flatten)       (None, 784)               0         
                                                                 
 dense_1843 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1238 (Dropout)      (None, 512)               0         
                                                                 
 dense_1844 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1239 (Dropout)      (None, 384)               0         
                                                                 
 dense_1845 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 606:
  Value: 0.9110
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008581532296754804

Model: "sequential_606"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_606 (Flatten)       (None, 784)               0         
                                                                 
 dense_1846 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1240 (Dropout)      (None, 448)               0         
                                                                 
 dense_1847 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1241 (Dropout)      (None, 448)               0         
                                                                 
 dense_1848 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 607:
  Value: 0.8635
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008726886315875414

Model: "sequential_607"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_607 (Flatten)       (None, 784)               0         
                                                                 
 dense_1849 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_138 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1242 (Dropout)      (None, 448)               0         
                                                                 
 dense_1850 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1243 (Dropout)      (None, 448)               0         
                                                                 
 dense_1851 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 608:
  Value: 0.8670
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005926907794467138

Model: "sequential_608"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_608 (Flatten)       (None, 784)               0         
                                                                 
 dense_1852 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1244 (Dropout)      (None, 448)               0         
                                                                 
 dense_1853 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1245 (Dropout)      (None, 416)               0         
                                                                 
 dense_1854 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 609:
  Value: 0.1047
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adagrad
  learning_rate: 0.007201530290001294

Model: "sequential_609"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_609 (Flatten)       (None, 784)               0         
                                                                 
 dense_1855 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1246 (Dropout)      (None, 416)               0         
                                                                 
 dense_1856 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_139 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1247 (Dropout)      (None, 448)               0         
                                                                 
 dense_1857 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 526842 (2.01 MB)
Trainable params: 525946 (2.01 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 610:
  Value: 0.8871
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004662798263135791

Model: "sequential_610"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_610 (Flatten)       (None, 784)               0         
                                                                 
 dense_1858 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1248 (Dropout)      (None, 448)               0         
                                                                 
 dense_1859 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1249 (Dropout)      (None, 416)               0         
                                                                 
 dense_1860 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 611:
  Value: 0.9044
  num_layers: 4
  units_0: 416
  units_1: 448
  units_2: 320
  units_3: 160
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.5
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00039024550939852434

Model: "sequential_611"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_611 (Flatten)       (None, 784)               0         
                                                                 
 dense_1861 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1250 (Dropout)      (None, 416)               0         
                                                                 
 dense_1862 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1251 (Dropout)      (None, 448)               0         
                                                                 
 dense_1863 (Dense)          (None, 320)               143680    
                                                                 
 batch_normalization_140 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_1252 (Dropout)      (None, 320)               0         
                                                                 
 dense_1864 (Dense)          (None, 160)               51360     
                                                                 
 dropout_1253 (Dropout)      (None, 160)               0         
                                                                 
 dense_1865 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 713882 (2.72 MB)
Trainable params: 713242 (2.72 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 612:
  Value: 0.8225
  num_layers: 2
  units_0: 448
  units_1: 64
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005369399537197859

Model: "sequential_612"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_612 (Flatten)       (None, 784)               0         
                                                                 
 dense_1866 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1254 (Dropout)      (None, 448)               0         
                                                                 
 dense_1867 (Dense)          (None, 64)                28736     
                                                                 
 dropout_1255 (Dropout)      (None, 64)                0         
                                                                 
 dense_1868 (Dense)          (None, 26)                1690      
                                                                 
=================================================================
Total params: 382106 (1.46 MB)
Trainable params: 382106 (1.46 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 613:
  Value: 0.8675
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0020085940503509025

Model: "sequential_613"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_613 (Flatten)       (None, 784)               0         
                                                                 
 dense_1869 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1256 (Dropout)      (None, 448)               0         
                                                                 
 dense_1870 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1257 (Dropout)      (None, 384)               0         
                                                                 
 dense_1871 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 614:
  Value: 0.8925
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0024959772888608653

Model: "sequential_614"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_614 (Flatten)       (None, 784)               0         
                                                                 
 dense_1872 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1258 (Dropout)      (None, 448)               0         
                                                                 
 dense_1873 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1259 (Dropout)      (None, 448)               0         
                                                                 
 dense_1874 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 615:
  Value: 0.8677
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007620309101569879

Model: "sequential_615"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_615 (Flatten)       (None, 784)               0         
                                                                 
 dense_1875 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1260 (Dropout)      (None, 448)               0         
                                                                 
 dense_1876 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1261 (Dropout)      (None, 416)               0         
                                                                 
 dense_1877 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 616:
  Value: 0.8676
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00024967885966742343

Model: "sequential_616"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_616 (Flatten)       (None, 784)               0         
                                                                 
 dense_1878 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1262 (Dropout)      (None, 448)               0         
                                                                 
 dense_1879 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1263 (Dropout)      (None, 480)               0         
                                                                 
 dense_1880 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 617:
  Value: 0.3611
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.00030646802764265965

Model: "sequential_617"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_617 (Flatten)       (None, 784)               0         
                                                                 
 dense_1881 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1264 (Dropout)      (None, 480)               0         
                                                                 
 dense_1882 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1265 (Dropout)      (None, 448)               0         
                                                                 
 dense_1883 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 618:
  Value: 0.8480
  num_layers: 2
  units_0: 224
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006285843072531832

Model: "sequential_618"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_618 (Flatten)       (None, 784)               0         
                                                                 
 dense_1884 (Dense)          (None, 224)               175840    
                                                                 
 dropout_1266 (Dropout)      (None, 224)               0         
                                                                 
 dense_1885 (Dense)          (None, 448)               100800    
                                                                 
 dropout_1267 (Dropout)      (None, 448)               0         
                                                                 
 dense_1886 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 288314 (1.10 MB)
Trainable params: 288314 (1.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 619:
  Value: 0.8658
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0038062296622068874

Model: "sequential_619"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_619 (Flatten)       (None, 784)               0         
                                                                 
 dense_1887 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1268 (Dropout)      (None, 448)               0         
                                                                 
 dense_1888 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1269 (Dropout)      (None, 384)               0         
                                                                 
 dense_1889 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 620:
  Value: 0.0387
  num_layers: 2
  units_0: 384
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.000770011681520647

Model: "sequential_620"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_620 (Flatten)       (None, 784)               0         
                                                                 
 dense_1890 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1270 (Dropout)      (None, 384)               0         
                                                                 
 dense_1891 (Dense)          (None, 416)               160160    
                                                                 
 dropout_1271 (Dropout)      (None, 416)               0         
                                                                 
 dense_1892 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 472442 (1.80 MB)
Trainable params: 472442 (1.80 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 621:
  Value: 0.8119
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002064341455412617

Model: "sequential_621"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_621 (Flatten)       (None, 784)               0         
                                                                 
 dense_1893 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1272 (Dropout)      (None, 480)               0         
                                                                 
 dense_1894 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1273 (Dropout)      (None, 480)               0         
                                                                 
 dense_1895 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 622:
  Value: 0.9015
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0023088328557049277

Model: "sequential_622"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_622 (Flatten)       (None, 784)               0         
                                                                 
 dense_1896 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1274 (Dropout)      (None, 448)               0         
                                                                 
 dense_1897 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_141 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1275 (Dropout)      (None, 448)               0         
                                                                 
 dense_1898 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 623:
  Value: 0.8679
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004903685486506719

Model: "sequential_623"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_623 (Flatten)       (None, 784)               0         
                                                                 
 dense_1899 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1276 (Dropout)      (None, 416)               0         
                                                                 
 dense_1900 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1277 (Dropout)      (None, 416)               0         
                                                                 
 dense_1901 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 624:
  Value: 0.8830
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006778040337713087

Model: "sequential_624"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_624 (Flatten)       (None, 784)               0         
                                                                 
 dense_1902 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1278 (Dropout)      (None, 480)               0         
                                                                 
 dense_1903 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1279 (Dropout)      (None, 416)               0         
                                                                 
 dense_1904 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 625:
  Value: 0.8514
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00013317133668603755

Model: "sequential_625"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_625 (Flatten)       (None, 784)               0         
                                                                 
 dense_1905 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1280 (Dropout)      (None, 480)               0         
                                                                 
 dense_1906 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1281 (Dropout)      (None, 384)               0         
                                                                 
 dense_1907 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 626:
  Value: 0.7551
  num_layers: 2
  units_0: 128
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.00089122135271503

Model: "sequential_626"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_626 (Flatten)       (None, 784)               0         
                                                                 
 dense_1908 (Dense)          (None, 128)               100480    
                                                                 
 batch_normalization_142 (B  (None, 128)               512       
 atchNormalization)                                              
                                                                 
 dropout_1282 (Dropout)      (None, 128)               0         
                                                                 
 dense_1909 (Dense)          (None, 448)               57792     
                                                                 
 dropout_1283 (Dropout)      (None, 448)               0         
                                                                 
 dense_1910 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 170458 (665.85 KB)
Trainable params: 170202 (664.85 KB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________



Trial 627:
  Value: 0.8924
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006045186806682176

Model: "sequential_627"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_627 (Flatten)       (None, 784)               0         
                                                                 
 dense_1911 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1284 (Dropout)      (None, 448)               0         
                                                                 
 dense_1912 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1285 (Dropout)      (None, 416)               0         
                                                                 
 dense_1913 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 628:
  Value: 0.9023
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00861114251716092

Model: "sequential_628"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_628 (Flatten)       (None, 784)               0         
                                                                 
 dense_1914 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1286 (Dropout)      (None, 480)               0         
                                                                 
 dense_1915 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1287 (Dropout)      (None, 448)               0         
                                                                 
 dense_1916 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 629:
  Value: 0.9071
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0018467039113060975

Model: "sequential_629"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_629 (Flatten)       (None, 784)               0         
                                                                 
 dense_1917 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1288 (Dropout)      (None, 448)               0         
                                                                 
 dense_1918 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1289 (Dropout)      (None, 448)               0         
                                                                 
 dense_1919 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 630:
  Value: 0.8786
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005789044253636936

Model: "sequential_630"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_630 (Flatten)       (None, 784)               0         
                                                                 
 dense_1920 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1290 (Dropout)      (None, 416)               0         
                                                                 
 dense_1921 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1291 (Dropout)      (None, 416)               0         
                                                                 
 dense_1922 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 631:
  Value: 0.9067
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004332435719309379

Model: "sequential_631"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_631 (Flatten)       (None, 784)               0         
                                                                 
 dense_1923 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1292 (Dropout)      (None, 480)               0         
                                                                 
 dense_1924 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1293 (Dropout)      (None, 480)               0         
                                                                 
 dense_1925 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 632:
  Value: 0.9031
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002205120225879341

Model: "sequential_632"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_632 (Flatten)       (None, 784)               0         
                                                                 
 dense_1926 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1294 (Dropout)      (None, 448)               0         
                                                                 
 dense_1927 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1295 (Dropout)      (None, 384)               0         
                                                                 
 dense_1928 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 633:
  Value: 0.8847
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.007616744653514518

Model: "sequential_633"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_633 (Flatten)       (None, 784)               0         
                                                                 
 dense_1929 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1296 (Dropout)      (None, 480)               0         
                                                                 
 dense_1930 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_143 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1297 (Dropout)      (None, 448)               0         
                                                                 
 dense_1931 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 605754 (2.31 MB)
Trainable params: 604858 (2.31 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 634:
  Value: 0.7489
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007227736883800072

Model: "sequential_634"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_634 (Flatten)       (None, 784)               0         
                                                                 
 dense_1932 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1298 (Dropout)      (None, 416)               0         
                                                                 
 dense_1933 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1299 (Dropout)      (None, 416)               0         
                                                                 
 dense_1934 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 635:
  Value: 0.9064
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003261250004090202

Model: "sequential_635"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_635 (Flatten)       (None, 784)               0         
                                                                 
 dense_1935 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1300 (Dropout)      (None, 448)               0         
                                                                 
 dense_1936 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1301 (Dropout)      (None, 448)               0         
                                                                 
 dense_1937 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 636:
  Value: 0.1228
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.003552673175079463

Model: "sequential_636"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_636 (Flatten)       (None, 784)               0         
                                                                 
 dense_1938 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1302 (Dropout)      (None, 480)               0         
                                                                 
 dense_1939 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1303 (Dropout)      (None, 416)               0         
                                                                 
 dense_1940 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 637:
  Value: 0.9055
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00046550964524557753

Model: "sequential_637"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_637 (Flatten)       (None, 784)               0         
                                                                 
 dense_1941 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1304 (Dropout)      (None, 480)               0         
                                                                 
 dense_1942 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1305 (Dropout)      (None, 480)               0         
                                                                 
 dense_1943 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 638:
  Value: 0.8781
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004059826748234556

Model: "sequential_638"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_638 (Flatten)       (None, 784)               0         
                                                                 
 dense_1944 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1306 (Dropout)      (None, 448)               0         
                                                                 
 dense_1945 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1307 (Dropout)      (None, 384)               0         
                                                                 
 dense_1946 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 639:
  Value: 0.8627
  num_layers: 2
  units_0: 320
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009675027993023467

Model: "sequential_639"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_639 (Flatten)       (None, 784)               0         
                                                                 
 dense_1947 (Dense)          (None, 320)               251200    
                                                                 
 dropout_1308 (Dropout)      (None, 320)               0         
                                                                 
 dense_1948 (Dense)          (None, 448)               143808    
                                                                 
 dropout_1309 (Dropout)      (None, 448)               0         
                                                                 
 dense_1949 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 406682 (1.55 MB)
Trainable params: 406682 (1.55 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 640:
  Value: 0.9099
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005320313391261664

Model: "sequential_640"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_640 (Flatten)       (None, 784)               0         
                                                                 
 dense_1950 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1310 (Dropout)      (None, 448)               0         
                                                                 
 dense_1951 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1311 (Dropout)      (None, 448)               0         
                                                                 
 dense_1952 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 641:
  Value: 0.9019
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000849351808370076

Model: "sequential_641"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_641 (Flatten)       (None, 784)               0         
                                                                 
 dense_1953 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1312 (Dropout)      (None, 480)               0         
                                                                 
 dense_1954 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1313 (Dropout)      (None, 416)               0         
                                                                 
 dense_1955 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 642:
  Value: 0.9042
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006664138885293541

Model: "sequential_642"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_642 (Flatten)       (None, 784)               0         
                                                                 
 dense_1956 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1314 (Dropout)      (None, 480)               0         
                                                                 
 dense_1957 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1315 (Dropout)      (None, 448)               0         
                                                                 
 dense_1958 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 643:
  Value: 0.8860
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017720854739127717

Model: "sequential_643"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_643 (Flatten)       (None, 784)               0         
                                                                 
 dense_1959 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1316 (Dropout)      (None, 448)               0         
                                                                 
 dense_1960 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1317 (Dropout)      (None, 416)               0         
                                                                 
 dense_1961 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 644:
  Value: 0.3753
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: sgd
  learning_rate: 0.006074549694225205

Model: "sequential_644"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_644 (Flatten)       (None, 784)               0         
                                                                 
 dense_1962 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1318 (Dropout)      (None, 480)               0         
                                                                 
 dense_1963 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_144 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1319 (Dropout)      (None, 448)               0         
                                                                 
 dense_1964 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 605754 (2.31 MB)
Trainable params: 604858 (2.31 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 645:
  Value: 0.8664
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0030834628633333687

Model: "sequential_645"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_645 (Flatten)       (None, 784)               0         
                                                                 
 dense_1965 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_145 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1320 (Dropout)      (None, 448)               0         
                                                                 
 dense_1966 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1321 (Dropout)      (None, 480)               0         
                                                                 
 dense_1967 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 581498 (2.22 MB)
Trainable params: 580602 (2.21 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 646:
  Value: 0.8669
  num_layers: 2
  units_0: 416
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0025448845158172785

Model: "sequential_646"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_646 (Flatten)       (None, 784)               0         
                                                                 
 dense_1968 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1322 (Dropout)      (None, 416)               0         
                                                                 
 dense_1969 (Dense)          (None, 384)               160128    
                                                                 
 dropout_1323 (Dropout)      (None, 384)               0         
                                                                 
 dense_1970 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 496698 (1.89 MB)
Trainable params: 496698 (1.89 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 647:
  Value: 0.8523
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019548276913996378

Model: "sequential_647"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_647 (Flatten)       (None, 784)               0         
                                                                 
 dense_1971 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1324 (Dropout)      (None, 480)               0         
                                                                 
 dense_1972 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1325 (Dropout)      (None, 416)               0         
                                                                 
 dense_1973 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 648:
  Value: 0.0392
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.008835906332249713

Model: "sequential_648"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_648 (Flatten)       (None, 784)               0         
                                                                 
 dense_1974 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1326 (Dropout)      (None, 448)               0         
                                                                 
 dense_1975 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1327 (Dropout)      (None, 448)               0         
                                                                 
 dense_1976 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 649:
  Value: 0.8615
  num_layers: 2
  units_0: 480
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005026387326816226

Model: "sequential_649"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_649 (Flatten)       (None, 784)               0         
                                                                 
 dense_1977 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1328 (Dropout)      (None, 480)               0         
                                                                 
 dense_1978 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1329 (Dropout)      (None, 256)               0         
                                                                 
 dense_1979 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 506618 (1.93 MB)
Trainable params: 506618 (1.93 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 650:
  Value: 0.9085
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007169386439301191

Model: "sequential_650"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_650 (Flatten)       (None, 784)               0         
                                                                 
 dense_1980 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1330 (Dropout)      (None, 512)               0         
                                                                 
 dense_1981 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1331 (Dropout)      (None, 384)               0         
                                                                 
 dense_1982 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 651:
  Value: 0.8656
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007849609049704996

Model: "sequential_651"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_651 (Flatten)       (None, 784)               0         
                                                                 
 dense_1983 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1332 (Dropout)      (None, 448)               0         
                                                                 
 dense_1984 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1333 (Dropout)      (None, 416)               0         
                                                                 
 dense_1985 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 652:
  Value: 0.8006
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.004505501663658022

Model: "sequential_652"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_652 (Flatten)       (None, 784)               0         
                                                                 
 dense_1986 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1334 (Dropout)      (None, 480)               0         
                                                                 
 dense_1987 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1335 (Dropout)      (None, 448)               0         
                                                                 
 dense_1988 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 653:
  Value: 0.7500
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005420897828918447

Model: "sequential_653"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_653 (Flatten)       (None, 784)               0         
                                                                 
 dense_1989 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1336 (Dropout)      (None, 448)               0         
                                                                 
 dense_1990 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1337 (Dropout)      (None, 448)               0         
                                                                 
 dense_1991 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 654:
  Value: 0.8511
  num_layers: 2
  units_0: 512
  units_1: 96
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00793006726512978

Model: "sequential_654"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_654 (Flatten)       (None, 784)               0         
                                                                 
 dense_1992 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1338 (Dropout)      (None, 512)               0         
                                                                 
 dense_1993 (Dense)          (None, 96)                49248     
                                                                 
 dropout_1339 (Dropout)      (None, 96)                0         
                                                                 
 dense_1994 (Dense)          (None, 26)                2522      
                                                                 
=================================================================
Total params: 453690 (1.73 MB)
Trainable params: 453690 (1.73 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 655:
  Value: 0.8627
  num_layers: 2
  units_0: 352
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0021772454348581416

Model: "sequential_655"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_655 (Flatten)       (None, 784)               0         
                                                                 
 dense_1995 (Dense)          (None, 352)               276320    
                                                                 
 dropout_1340 (Dropout)      (None, 352)               0         
                                                                 
 dense_1996 (Dense)          (None, 416)               146848    
                                                                 
 dropout_1341 (Dropout)      (None, 416)               0         
                                                                 
 dense_1997 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 434010 (1.66 MB)
Trainable params: 434010 (1.66 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 656:
  Value: 0.8680
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017324685040752264

Model: "sequential_656"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_656 (Flatten)       (None, 784)               0         
                                                                 
 dense_1998 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1342 (Dropout)      (None, 480)               0         
                                                                 
 dense_1999 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1343 (Dropout)      (None, 384)               0         
                                                                 
 dense_2000 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 657:
  Value: 0.8990
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.006209952111339772

Model: "sequential_657"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_657 (Flatten)       (None, 784)               0         
                                                                 
 dense_2001 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1344 (Dropout)      (None, 448)               0         
                                                                 
 dense_2002 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_146 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1345 (Dropout)      (None, 448)               0         
                                                                 
 dense_2003 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 658:
  Value: 0.8852
  num_layers: 2
  units_0: 416
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00015338327704448964

Model: "sequential_658"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_658 (Flatten)       (None, 784)               0         
                                                                 
 dense_2004 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1346 (Dropout)      (None, 416)               0         
                                                                 
 dense_2005 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1347 (Dropout)      (None, 480)               0         
                                                                 
 dense_2006 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 539226 (2.06 MB)
Trainable params: 539226 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 659:
  Value: 0.9078
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0017431870549159984

Model: "sequential_659"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_659 (Flatten)       (None, 784)               0         
                                                                 
 dense_2007 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1348 (Dropout)      (None, 512)               0         
                                                                 
 dense_2008 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1349 (Dropout)      (None, 416)               0         
                                                                 
 dense_2009 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 660:
  Value: 0.8224
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.003436268889027452

Model: "sequential_660"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_660 (Flatten)       (None, 784)               0         
                                                                 
 dense_2010 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1350 (Dropout)      (None, 480)               0         
                                                                 
 dense_2011 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1351 (Dropout)      (None, 416)               0         
                                                                 
 dense_2012 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 661:
  Value: 0.7933
  num_layers: 2
  units_0: 64
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006239989407490318

Model: "sequential_661"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_661 (Flatten)       (None, 784)               0         
                                                                 
 dense_2013 (Dense)          (None, 64)                50240     
                                                                 
 dropout_1352 (Dropout)      (None, 64)                0         
                                                                 
 dense_2014 (Dense)          (None, 448)               29120     
                                                                 
 dropout_1353 (Dropout)      (None, 448)               0         
                                                                 
 dense_2015 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 91034 (355.60 KB)
Trainable params: 91034 (355.60 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 662:
  Value: 0.8874
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009501789686817835

Model: "sequential_662"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_662 (Flatten)       (None, 784)               0         
                                                                 
 dense_2016 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1354 (Dropout)      (None, 480)               0         
                                                                 
 dense_2017 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1355 (Dropout)      (None, 448)               0         
                                                                 
 dense_2018 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 663:
  Value: 0.8642
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015721618730595674

Model: "sequential_663"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_663 (Flatten)       (None, 784)               0         
                                                                 
 dense_2019 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1356 (Dropout)      (None, 448)               0         
                                                                 
 dense_2020 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1357 (Dropout)      (None, 416)               0         
                                                                 
 dense_2021 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 664:
  Value: 0.1211
  num_layers: 3
  units_0: 480
  units_1: 480
  units_2: 160
  activation_0: relu
  activation_1: relu
  activation_2: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  optimizer: adagrad
  learning_rate: 0.0006941260066814423

Model: "sequential_664"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_664 (Flatten)       (None, 784)               0         
                                                                 
 dense_2022 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1358 (Dropout)      (None, 480)               0         
                                                                 
 dense_2023 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1359 (Dropout)      (None, 480)               0         
                                                                 
 dense_2024 (Dense)          (None, 160)               76960     
                                                                 
 dropout_1360 (Dropout)      (None, 160)               0         
                                                                 
 dense_2025 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 688826 (2.63 MB)
Trainable params: 688826 (2.63 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 665:
  Value: 0.8468
  num_layers: 2
  units_0: 512
  units_1: 192
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006887095682509983

Model: "sequential_665"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_665 (Flatten)       (None, 784)               0         
                                                                 
 dense_2026 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_147 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1361 (Dropout)      (None, 512)               0         
                                                                 
 dense_2027 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1362 (Dropout)      (None, 192)               0         
                                                                 
 dense_2028 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 507482 (1.94 MB)
Trainable params: 506458 (1.93 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 666:
  Value: 0.9016
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0040074360677980515

Model: "sequential_666"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_666 (Flatten)       (None, 784)               0         
                                                                 
 dense_2029 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1363 (Dropout)      (None, 448)               0         
                                                                 
 dense_2030 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1364 (Dropout)      (None, 448)               0         
                                                                 
 dense_2031 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 667:
  Value: 0.8361
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0019284577714285638

Model: "sequential_667"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_667 (Flatten)       (None, 784)               0         
                                                                 
 dense_2032 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1365 (Dropout)      (None, 512)               0         
                                                                 
 dense_2033 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 668:
  Value: 0.8988
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0029283912653910848

Model: "sequential_668"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_668 (Flatten)       (None, 784)               0         
                                                                 
 dense_2034 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1366 (Dropout)      (None, 480)               0         
                                                                 
 dense_2035 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_148 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1367 (Dropout)      (None, 416)               0         
                                                                 
 dense_2036 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 589402 (2.25 MB)
Trainable params: 588570 (2.25 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 669:
  Value: 0.8568
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009912722091294169

Model: "sequential_669"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_669 (Flatten)       (None, 784)               0         
                                                                 
 dense_2037 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1368 (Dropout)      (None, 480)               0         
                                                                 
 dense_2038 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1369 (Dropout)      (None, 384)               0         
                                                                 
 dense_2039 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 670:
  Value: 0.9109
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005065266713698066

Model: "sequential_670"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_670 (Flatten)       (None, 784)               0         
                                                                 
 dense_2040 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1370 (Dropout)      (None, 448)               0         
                                                                 
 dense_2041 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1371 (Dropout)      (None, 448)               0         
                                                                 
 dense_2042 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 671:
  Value: 0.8671
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005587818598473161

Model: "sequential_671"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_671 (Flatten)       (None, 784)               0         
                                                                 
 dense_2043 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1372 (Dropout)      (None, 416)               0         
                                                                 
 dense_2044 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1373 (Dropout)      (None, 448)               0         
                                                                 
 dense_2045 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 672:
  Value: 0.8791
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005563678478690631

Model: "sequential_672"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_672 (Flatten)       (None, 784)               0         
                                                                 
 dense_2046 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1374 (Dropout)      (None, 448)               0         
                                                                 
 dense_2047 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1375 (Dropout)      (None, 416)               0         
                                                                 
 dense_2048 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 673:
  Value: 0.3656
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0005272925252114624

Model: "sequential_673"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_673 (Flatten)       (None, 784)               0         
                                                                 
 dense_2049 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1376 (Dropout)      (None, 448)               0         
                                                                 
 dense_2050 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1377 (Dropout)      (None, 384)               0         
                                                                 
 dense_2051 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 674:
  Value: 0.8620
  num_layers: 2
  units_0: 448
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00046805602825635695

Model: "sequential_674"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_674 (Flatten)       (None, 784)               0         
                                                                 
 dense_2052 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1378 (Dropout)      (None, 448)               0         
                                                                 
 dense_2053 (Dense)          (None, 288)               129312    
                                                                 
 dropout_1379 (Dropout)      (None, 288)               0         
                                                                 
 dense_2054 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 488506 (1.86 MB)
Trainable params: 488506 (1.86 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 675:
  Value: 0.8679
  num_layers: 2
  units_0: 416
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005806273646980164

Model: "sequential_675"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_675 (Flatten)       (None, 784)               0         
                                                                 
 dense_2055 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1380 (Dropout)      (None, 416)               0         
                                                                 
 dense_2056 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1381 (Dropout)      (None, 480)               0         
                                                                 
 dense_2057 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 539226 (2.06 MB)
Trainable params: 539226 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 676:
  Value: 0.0387
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.00042642542294006423

Model: "sequential_676"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_676 (Flatten)       (None, 784)               0         
                                                                 
 dense_2058 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1382 (Dropout)      (None, 448)               0         
                                                                 
 dense_2059 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1383 (Dropout)      (None, 448)               0         
                                                                 
 dense_2060 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 677:
  Value: 0.8789
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010544272848247952

Model: "sequential_677"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_677 (Flatten)       (None, 784)               0         
                                                                 
 dense_2061 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1384 (Dropout)      (None, 448)               0         
                                                                 
 dense_2062 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1385 (Dropout)      (None, 416)               0         
                                                                 
 dense_2063 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 678:
  Value: 0.8683
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003691834190648384

Model: "sequential_678"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_678 (Flatten)       (None, 784)               0         
                                                                 
 dense_2064 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1386 (Dropout)      (None, 448)               0         
                                                                 
 dense_2065 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1387 (Dropout)      (None, 448)               0         
                                                                 
 dense_2066 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 679:
  Value: 0.8659
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008034342705421181

Model: "sequential_679"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_679 (Flatten)       (None, 784)               0         
                                                                 
 dense_2067 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1388 (Dropout)      (None, 448)               0         
                                                                 
 dense_2068 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1389 (Dropout)      (None, 416)               0         
                                                                 
 dense_2069 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 680:
  Value: 0.7929
  num_layers: 2
  units_0: 416
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.000877932605574174

Model: "sequential_680"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_680 (Flatten)       (None, 784)               0         
                                                                 
 dense_2070 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1390 (Dropout)      (None, 416)               0         
                                                                 
 dense_2071 (Dense)          (None, 384)               160128    
                                                                 
 dropout_1391 (Dropout)      (None, 384)               0         
                                                                 
 dense_2072 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 496698 (1.89 MB)
Trainable params: 496698 (1.89 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 681:
  Value: 0.8923
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010050919631370467

Model: "sequential_681"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_681 (Flatten)       (None, 784)               0         
                                                                 
 dense_2073 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1392 (Dropout)      (None, 448)               0         
                                                                 
 dense_2074 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1393 (Dropout)      (None, 448)               0         
                                                                 
 dense_2075 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 682:
  Value: 0.8977
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00023222272452474123

Model: "sequential_682"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_682 (Flatten)       (None, 784)               0         
                                                                 
 dense_2076 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1394 (Dropout)      (None, 448)               0         
                                                                 
 dense_2077 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1395 (Dropout)      (None, 416)               0         
                                                                 
 dense_2078 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 683:
  Value: 0.8659
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00045436763331341805

Model: "sequential_683"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_683 (Flatten)       (None, 784)               0         
                                                                 
 dense_2079 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_149 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1396 (Dropout)      (None, 448)               0         
                                                                 
 dense_2080 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1397 (Dropout)      (None, 448)               0         
                                                                 
 dense_2081 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 684:
  Value: 0.8681
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00038791209171246463

Model: "sequential_684"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_684 (Flatten)       (None, 784)               0         
                                                                 
 dense_2082 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1398 (Dropout)      (None, 480)               0         
                                                                 
 dense_2083 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1399 (Dropout)      (None, 448)               0         
                                                                 
 dense_2084 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 685:
  Value: 0.9072
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004945348281941654

Model: "sequential_685"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_685 (Flatten)       (None, 784)               0         
                                                                 
 dense_2085 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1400 (Dropout)      (None, 448)               0         
                                                                 
 dense_2086 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1401 (Dropout)      (None, 416)               0         
                                                                 
 dense_2087 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 686:
  Value: 0.8979
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006798934920449327

Model: "sequential_686"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_686 (Flatten)       (None, 784)               0         
                                                                 
 dense_2088 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1402 (Dropout)      (None, 416)               0         
                                                                 
 dense_2089 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1403 (Dropout)      (None, 448)               0         
                                                                 
 dense_2090 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 687:
  Value: 0.9038
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006509319482188618

Model: "sequential_687"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_687 (Flatten)       (None, 784)               0         
                                                                 
 dense_2091 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1404 (Dropout)      (None, 480)               0         
                                                                 
 dense_2092 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1405 (Dropout)      (None, 384)               0         
                                                                 
 dense_2093 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 688:
  Value: 0.7187
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.00036486727639837717

Model: "sequential_688"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_688 (Flatten)       (None, 784)               0         
                                                                 
 dense_2094 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1406 (Dropout)      (None, 480)               0         
                                                                 
 dense_2095 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1407 (Dropout)      (None, 480)               0         
                                                                 
 dense_2096 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 689:
  Value: 0.9055
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 224
  units_3: 32
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.30000000000000004
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00028737023699735594

Model: "sequential_689"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_689 (Flatten)       (None, 784)               0         
                                                                 
 dense_2097 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1408 (Dropout)      (None, 448)               0         
                                                                 
 dense_2098 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1409 (Dropout)      (None, 416)               0         
                                                                 
 dense_2099 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1410 (Dropout)      (None, 224)               0         
                                                                 
 dense_2100 (Dense)          (None, 32)                7200      
                                                                 
 batch_normalization_150 (B  (None, 32)                128       
 atchNormalization)                                              
                                                                 
 dropout_1411 (Dropout)      (None, 32)                0         
                                                                 
 dense_2101 (Dense)          (None, 26)                858       
                                                                 
=================================================================
Total params: 640058 (2.44 MB)
Trainable params: 639994 (2.44 MB)
Non-trainable params: 64 (256.00 Byte)
_________________________________________________________________



Trial 690:
  Value: 0.9109
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0024103029883423797

Model: "sequential_690"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_690 (Flatten)       (None, 784)               0         
                                                                 
 dense_2102 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1412 (Dropout)      (None, 480)               0         
                                                                 
 dense_2103 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1413 (Dropout)      (None, 448)               0         
                                                                 
 dense_2104 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 691:
  Value: 0.9067
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007209012419247404

Model: "sequential_691"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_691 (Flatten)       (None, 784)               0         
                                                                 
 dense_2105 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1414 (Dropout)      (None, 480)               0         
                                                                 
 dense_2106 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1415 (Dropout)      (None, 480)               0         
                                                                 
 dense_2107 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 692:
  Value: 0.1669
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.000297969236005963

Model: "sequential_692"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_692 (Flatten)       (None, 784)               0         
                                                                 
 dense_2108 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1416 (Dropout)      (None, 480)               0         
                                                                 
 dense_2109 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1417 (Dropout)      (None, 448)               0         
                                                                 
 dense_2110 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 693:
  Value: 0.8969
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00243289509237178

Model: "sequential_693"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_693 (Flatten)       (None, 784)               0         
                                                                 
 dense_2111 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1418 (Dropout)      (None, 480)               0         
                                                                 
 dense_2112 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1419 (Dropout)      (None, 448)               0         
                                                                 
 dense_2113 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 694:
  Value: 0.9067
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008933195797045291

Model: "sequential_694"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_694 (Flatten)       (None, 784)               0         
                                                                 
 dense_2114 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1420 (Dropout)      (None, 448)               0         
                                                                 
 dense_2115 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1421 (Dropout)      (None, 448)               0         
                                                                 
 dense_2116 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 695:
  Value: 0.9065
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000339273094890546

Model: "sequential_695"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_695 (Flatten)       (None, 784)               0         
                                                                 
 dense_2117 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1422 (Dropout)      (None, 480)               0         
                                                                 
 dense_2118 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1423 (Dropout)      (None, 480)               0         
                                                                 
 dense_2119 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 696:
  Value: 0.9070
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004951182628349476

Model: "sequential_696"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_696 (Flatten)       (None, 784)               0         
                                                                 
 dense_2120 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1424 (Dropout)      (None, 448)               0         
                                                                 
 dense_2121 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1425 (Dropout)      (None, 448)               0         
                                                                 
 dense_2122 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 697:
  Value: 0.7421
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00033450235859518813

Model: "sequential_697"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_697 (Flatten)       (None, 784)               0         
                                                                 
 dense_2123 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1426 (Dropout)      (None, 480)               0         
                                                                 
 dense_2124 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1427 (Dropout)      (None, 448)               0         
                                                                 
 dense_2125 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 698:
  Value: 0.9047
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006182150949690581

Model: "sequential_698"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_698 (Flatten)       (None, 784)               0         
                                                                 
 dense_2126 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1428 (Dropout)      (None, 448)               0         
                                                                 
 dense_2127 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1429 (Dropout)      (None, 480)               0         
                                                                 
 dense_2128 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 699:
  Value: 0.8892
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007658557511797404

Model: "sequential_699"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_699 (Flatten)       (None, 784)               0         
                                                                 
 dense_2129 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1430 (Dropout)      (None, 480)               0         
                                                                 
 dense_2130 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1431 (Dropout)      (None, 448)               0         
                                                                 
 dense_2131 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 700:
  Value: 0.9065
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002853966744135213

Model: "sequential_700"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_700 (Flatten)       (None, 784)               0         
                                                                 
 dense_2132 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1432 (Dropout)      (None, 448)               0         
                                                                 
 dense_2133 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1433 (Dropout)      (None, 448)               0         
                                                                 
 dense_2134 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 701:
  Value: 0.3505
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.001100942838978199

Model: "sequential_701"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_701 (Flatten)       (None, 784)               0         
                                                                 
 dense_2135 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1434 (Dropout)      (None, 480)               0         
                                                                 
 dense_2136 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1435 (Dropout)      (None, 448)               0         
                                                                 
 dense_2137 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 702:
  Value: 0.8619
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001339331231415637

Model: "sequential_702"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_702 (Flatten)       (None, 784)               0         
                                                                 
 dense_2138 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_151 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1436 (Dropout)      (None, 448)               0         
                                                                 
 dense_2139 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1437 (Dropout)      (None, 448)               0         
                                                                 
 dense_2140 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 566298 (2.16 MB)
Trainable params: 565402 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 703:
  Value: 0.0410
  num_layers: 3
  units_0: 480
  units_1: 448
  units_2: 128
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  dropout_2: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: ftrl
  learning_rate: 0.00470699931448489

Model: "sequential_703"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_703 (Flatten)       (None, 784)               0         
                                                                 
 dense_2141 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1438 (Dropout)      (None, 480)               0         
                                                                 
 dense_2142 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1439 (Dropout)      (None, 448)               0         
                                                                 
 dense_2143 (Dense)          (None, 128)               57472     
                                                                 
 batch_normalization_152 (B  (None, 128)               512       
 atchNormalization)                                              
                                                                 
 dropout_1440 (Dropout)      (None, 128)               0         
                                                                 
 dense_2144 (Dense)          (None, 26)                3354      
                                                                 
=================================================================
Total params: 653626 (2.49 MB)
Trainable params: 653370 (2.49 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________



Trial 704:
  Value: 0.8671
  num_layers: 2
  units_0: 480
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004306869770814014

Model: "sequential_704"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_704 (Flatten)       (None, 784)               0         
                                                                 
 dense_2145 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1441 (Dropout)      (None, 480)               0         
                                                                 
 dense_2146 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1442 (Dropout)      (None, 288)               0         
                                                                 
 dense_2147 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 522842 (1.99 MB)
Trainable params: 522842 (1.99 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 705:
  Value: 0.9051
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002063340584189981

Model: "sequential_705"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_705 (Flatten)       (None, 784)               0         
                                                                 
 dense_2148 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1443 (Dropout)      (None, 448)               0         
                                                                 
 dense_2149 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1444 (Dropout)      (None, 480)               0         
                                                                 
 dense_2150 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 706:
  Value: 0.9013
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005557701546041377

Model: "sequential_706"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_706 (Flatten)       (None, 784)               0         
                                                                 
 dense_2151 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1445 (Dropout)      (None, 480)               0         
                                                                 
 dense_2152 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1446 (Dropout)      (None, 448)               0         
                                                                 
 dense_2153 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 707:
  Value: 0.8650
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0025932941560085207

Model: "sequential_707"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_707 (Flatten)       (None, 784)               0         
                                                                 
 dense_2154 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1447 (Dropout)      (None, 416)               0         
                                                                 
 dense_2155 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1448 (Dropout)      (None, 448)               0         
                                                                 
 dense_2156 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 708:
  Value: 0.8674
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004499942473007524

Model: "sequential_708"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_708 (Flatten)       (None, 784)               0         
                                                                 
 dense_2157 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1449 (Dropout)      (None, 448)               0         
                                                                 
 dense_2158 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1450 (Dropout)      (None, 384)               0         
                                                                 
 dense_2159 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 709:
  Value: 0.7998
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0036095080125134746

Model: "sequential_709"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_709 (Flatten)       (None, 784)               0         
                                                                 
 dense_2160 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1451 (Dropout)      (None, 448)               0         
                                                                 
 dense_2161 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1452 (Dropout)      (None, 448)               0         
                                                                 
 dense_2162 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 710:
  Value: 0.7969
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009615833061591676

Model: "sequential_710"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_710 (Flatten)       (None, 784)               0         
                                                                 
 dense_2163 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1453 (Dropout)      (None, 416)               0         
                                                                 
 dense_2164 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1454 (Dropout)      (None, 448)               0         
                                                                 
 dense_2165 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 711:
  Value: 0.8683
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0027592278177800277

Model: "sequential_711"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_711 (Flatten)       (None, 784)               0         
                                                                 
 dense_2166 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1455 (Dropout)      (None, 480)               0         
                                                                 
 dense_2167 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1456 (Dropout)      (None, 416)               0         
                                                                 
 dense_2168 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 712:
  Value: 0.9097
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003201884488422223

Model: "sequential_712"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_712 (Flatten)       (None, 784)               0         
                                                                 
 dense_2169 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1457 (Dropout)      (None, 480)               0         
                                                                 
 dense_2170 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1458 (Dropout)      (None, 384)               0         
                                                                 
 dense_2171 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 713:
  Value: 0.8794
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005628526922162658

Model: "sequential_713"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_713 (Flatten)       (None, 784)               0         
                                                                 
 dense_2172 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1459 (Dropout)      (None, 448)               0         
                                                                 
 dense_2173 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1460 (Dropout)      (None, 448)               0         
                                                                 
 dense_2174 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 714:
  Value: 0.9056
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005282492199298521

Model: "sequential_714"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_714 (Flatten)       (None, 784)               0         
                                                                 
 dense_2175 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1461 (Dropout)      (None, 480)               0         
                                                                 
 dense_2176 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1462 (Dropout)      (None, 480)               0         
                                                                 
 dense_2177 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 715:
  Value: 0.8574
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00039612983660832884

Model: "sequential_715"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_715 (Flatten)       (None, 784)               0         
                                                                 
 dense_2178 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1463 (Dropout)      (None, 448)               0         
                                                                 
 dense_2179 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1464 (Dropout)      (None, 416)               0         
                                                                 
 dense_2180 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 716:
  Value: 0.8432
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.001651914247208054

Model: "sequential_716"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_716 (Flatten)       (None, 784)               0         
                                                                 
 dense_2181 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1465 (Dropout)      (None, 480)               0         
                                                                 
 dense_2182 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1466 (Dropout)      (None, 448)               0         
                                                                 
 dense_2183 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 717:
  Value: 0.9035
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00026756453376150855

Model: "sequential_717"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_717 (Flatten)       (None, 784)               0         
                                                                 
 dense_2184 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1467 (Dropout)      (None, 448)               0         
                                                                 
 dense_2185 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1468 (Dropout)      (None, 416)               0         
                                                                 
 dense_2186 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 718:
  Value: 0.8469
  num_layers: 2
  units_0: 480
  units_1: 128
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014093144006536932

Model: "sequential_718"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_718 (Flatten)       (None, 784)               0         
                                                                 
 dense_2187 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1469 (Dropout)      (None, 480)               0         
                                                                 
 dense_2188 (Dense)          (None, 128)               61568     
                                                                 
 dropout_1470 (Dropout)      (None, 128)               0         
                                                                 
 dense_2189 (Dense)          (None, 26)                3354      
                                                                 
=================================================================
Total params: 441722 (1.69 MB)
Trainable params: 441722 (1.69 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 719:
  Value: 0.0933
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0008614363787366676

Model: "sequential_719"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_719 (Flatten)       (None, 784)               0         
                                                                 
 dense_2190 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1471 (Dropout)      (None, 448)               0         
                                                                 
 dense_2191 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1472 (Dropout)      (None, 448)               0         
                                                                 
 dense_2192 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 720:
  Value: 0.8788
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011790623145660124

Model: "sequential_720"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_720 (Flatten)       (None, 784)               0         
                                                                 
 dense_2193 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1473 (Dropout)      (None, 480)               0         
                                                                 
 dense_2194 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1474 (Dropout)      (None, 384)               0         
                                                                 
 dense_2195 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 721:
  Value: 0.6809
  num_layers: 2
  units_0: 416
  units_1: 480
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005098202982248415

Model: "sequential_721"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_721 (Flatten)       (None, 784)               0         
                                                                 
 dense_2196 (Dense)          (None, 416)               326560    
                                                                 
 batch_normalization_153 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1475 (Dropout)      (None, 416)               0         
                                                                 
 dense_2197 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1476 (Dropout)      (None, 480)               0         
                                                                 
 dense_2198 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 540890 (2.06 MB)
Trainable params: 540058 (2.06 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 722:
  Value: 0.9041
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002086887432492922

Model: "sequential_722"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_722 (Flatten)       (None, 784)               0         
                                                                 
 dense_2199 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1477 (Dropout)      (None, 480)               0         
                                                                 
 dense_2200 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1478 (Dropout)      (None, 416)               0         
                                                                 
 dense_2201 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 723:
  Value: 0.8873
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005968421143960001

Model: "sequential_723"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_723 (Flatten)       (None, 784)               0         
                                                                 
 dense_2202 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1479 (Dropout)      (None, 448)               0         
                                                                 
 dense_2203 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1480 (Dropout)      (None, 448)               0         
                                                                 
 dense_2204 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 724:
  Value: 0.8682
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004322174296503823

Model: "sequential_724"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_724 (Flatten)       (None, 784)               0         
                                                                 
 dense_2205 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1481 (Dropout)      (None, 448)               0         
                                                                 
 dense_2206 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1482 (Dropout)      (None, 416)               0         
                                                                 
 dense_2207 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 725:
  Value: 0.9071
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00041464660372885094

Model: "sequential_725"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_725 (Flatten)       (None, 784)               0         
                                                                 
 dense_2208 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1483 (Dropout)      (None, 480)               0         
                                                                 
 dense_2209 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1484 (Dropout)      (None, 448)               0         
                                                                 
 dense_2210 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 726:
  Value: 0.8670
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008027638031830553

Model: "sequential_726"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_726 (Flatten)       (None, 784)               0         
                                                                 
 dense_2211 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1485 (Dropout)      (None, 416)               0         
                                                                 
 dense_2212 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1486 (Dropout)      (None, 448)               0         
                                                                 
 dense_2213 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 727:
  Value: 0.3758
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0017492635418377028

Model: "sequential_727"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_727 (Flatten)       (None, 784)               0         
                                                                 
 dense_2214 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1487 (Dropout)      (None, 480)               0         
                                                                 
 dense_2215 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1488 (Dropout)      (None, 384)               0         
                                                                 
 dense_2216 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 728:
  Value: 0.9070
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003785078492624302

Model: "sequential_728"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_728 (Flatten)       (None, 784)               0         
                                                                 
 dense_2217 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1489 (Dropout)      (None, 448)               0         
                                                                 
 dense_2218 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1490 (Dropout)      (None, 416)               0         
                                                                 
 dense_2219 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 729:
  Value: 0.9062
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014920407256242706

Model: "sequential_729"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_729 (Flatten)       (None, 784)               0         
                                                                 
 dense_2220 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1491 (Dropout)      (None, 448)               0         
                                                                 
 dense_2221 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1492 (Dropout)      (None, 480)               0         
                                                                 
 dense_2222 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 730:
  Value: 0.8011
  num_layers: 2
  units_0: 480
  units_1: 32
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006269535577814856

Model: "sequential_730"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_730 (Flatten)       (None, 784)               0         
                                                                 
 dense_2223 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1493 (Dropout)      (None, 480)               0         
                                                                 
 dense_2224 (Dense)          (None, 32)                15392     
                                                                 
 dropout_1494 (Dropout)      (None, 32)                0         
                                                                 
 dense_2225 (Dense)          (None, 26)                858       
                                                                 
=================================================================
Total params: 393050 (1.50 MB)
Trainable params: 393050 (1.50 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 731:
  Value: 0.9068
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012858954196161181

Model: "sequential_731"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_731 (Flatten)       (None, 784)               0         
                                                                 
 dense_2226 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1495 (Dropout)      (None, 480)               0         
                                                                 
 dense_2227 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1496 (Dropout)      (None, 448)               0         
                                                                 
 dense_2228 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 732:
  Value: 0.8238
  num_layers: 1
  units_0: 448
  activation_0: relu
  dropout_0: 0.30000000000000004
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0006966323102466103

Model: "sequential_732"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_732 (Flatten)       (None, 784)               0         
                                                                 
 dense_2229 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1497 (Dropout)      (None, 448)               0         
                                                                 
 dense_2230 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 363354 (1.39 MB)
Trainable params: 363354 (1.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 733:
  Value: 0.8667
  num_layers: 2
  units_0: 384
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017510369570488692

Model: "sequential_733"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_733 (Flatten)       (None, 784)               0         
                                                                 
 dense_2231 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1498 (Dropout)      (None, 384)               0         
                                                                 
 dense_2232 (Dense)          (None, 416)               160160    
                                                                 
 dropout_1499 (Dropout)      (None, 416)               0         
                                                                 
 dense_2233 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 472442 (1.80 MB)
Trainable params: 472442 (1.80 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 734:
  Value: 0.0378
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.002361101585264644

Model: "sequential_734"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_734 (Flatten)       (None, 784)               0         
                                                                 
 dense_2234 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1500 (Dropout)      (None, 480)               0         
                                                                 
 dense_2235 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1501 (Dropout)      (None, 480)               0         
                                                                 
 dense_2236 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 735:
  Value: 0.8794
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005697364538094568

Model: "sequential_735"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_735 (Flatten)       (None, 784)               0         
                                                                 
 dense_2237 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1502 (Dropout)      (None, 448)               0         
                                                                 
 dense_2238 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1503 (Dropout)      (None, 448)               0         
                                                                 
 dense_2239 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 736:
  Value: 0.8551
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010519648655113424

Model: "sequential_736"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_736 (Flatten)       (None, 784)               0         
                                                                 
 dense_2240 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1504 (Dropout)      (None, 480)               0         
                                                                 
 dense_2241 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1505 (Dropout)      (None, 384)               0         
                                                                 
 dense_2242 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 737:
  Value: 0.8868
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00627554111590015

Model: "sequential_737"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_737 (Flatten)       (None, 784)               0         
                                                                 
 dense_2243 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1506 (Dropout)      (None, 448)               0         
                                                                 
 dense_2244 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1507 (Dropout)      (None, 416)               0         
                                                                 
 dense_2245 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 738:
  Value: 0.8682
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009231736596519599

Model: "sequential_738"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_738 (Flatten)       (None, 784)               0         
                                                                 
 dense_2246 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1508 (Dropout)      (None, 416)               0         
                                                                 
 dense_2247 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1509 (Dropout)      (None, 448)               0         
                                                                 
 dense_2248 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 739:
  Value: 0.9047
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003466146071452554

Model: "sequential_739"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_739 (Flatten)       (None, 784)               0         
                                                                 
 dense_2249 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1510 (Dropout)      (None, 480)               0         
                                                                 
 dense_2250 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1511 (Dropout)      (None, 448)               0         
                                                                 
 dense_2251 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 740:
  Value: 0.7983
  num_layers: 2
  units_0: 448
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.001878497695934851

Model: "sequential_740"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_740 (Flatten)       (None, 784)               0         
                                                                 
 dense_2252 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_154 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1512 (Dropout)      (None, 448)               0         
                                                                 
 dense_2253 (Dense)          (None, 256)               114944    
                                                                 
 dropout_1513 (Dropout)      (None, 256)               0         
                                                                 
 dense_2254 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 475098 (1.81 MB)
Trainable params: 474202 (1.81 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 741:
  Value: 0.7420
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.005000846107120337

Model: "sequential_741"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_741 (Flatten)       (None, 784)               0         
                                                                 
 dense_2255 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1514 (Dropout)      (None, 480)               0         
                                                                 
 dense_2256 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1515 (Dropout)      (None, 416)               0         
                                                                 
 dense_2257 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 742:
  Value: 0.9072
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005066764921362293

Model: "sequential_742"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_742 (Flatten)       (None, 784)               0         
                                                                 
 dense_2258 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1516 (Dropout)      (None, 448)               0         
                                                                 
 dense_2259 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1517 (Dropout)      (None, 448)               0         
                                                                 
 dense_2260 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 743:
  Value: 0.9070
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004079971242000479

Model: "sequential_743"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_743 (Flatten)       (None, 784)               0         
                                                                 
 dense_2261 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1518 (Dropout)      (None, 480)               0         
                                                                 
 dense_2262 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1519 (Dropout)      (None, 416)               0         
                                                                 
 dense_2263 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 744:
  Value: 0.8324
  num_layers: 2
  units_0: 416
  units_1: 384
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.4
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.002807841444131504

Model: "sequential_744"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_744 (Flatten)       (None, 784)               0         
                                                                 
 dense_2264 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1520 (Dropout)      (None, 416)               0         
                                                                 
 dense_2265 (Dense)          (None, 384)               160128    
                                                                 
 dropout_1521 (Dropout)      (None, 384)               0         
                                                                 
 dense_2266 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 496698 (1.89 MB)
Trainable params: 496698 (1.89 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 745:
  Value: 0.9126
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00024146963395151885

Model: "sequential_745"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_745 (Flatten)       (None, 784)               0         
                                                                 
 dense_2267 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1522 (Dropout)      (None, 480)               0         
                                                                 
 dense_2268 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1523 (Dropout)      (None, 480)               0         
                                                                 
 dense_2269 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 746:
  Value: 0.9025
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017479969471081224

Model: "sequential_746"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_746 (Flatten)       (None, 784)               0         
                                                                 
 dense_2270 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1524 (Dropout)      (None, 448)               0         
                                                                 
 dense_2271 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1525 (Dropout)      (None, 480)               0         
                                                                 
 dense_2272 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 747:
  Value: 0.9081
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007852940307498152

Model: "sequential_747"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_747 (Flatten)       (None, 784)               0         
                                                                 
 dense_2273 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1526 (Dropout)      (None, 480)               0         
                                                                 
 dense_2274 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1527 (Dropout)      (None, 480)               0         
                                                                 
 dense_2275 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 748:
  Value: 0.9065
  num_layers: 2
  units_0: 448
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002422586168518337

Model: "sequential_748"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_748 (Flatten)       (None, 784)               0         
                                                                 
 dense_2276 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1528 (Dropout)      (None, 448)               0         
                                                                 
 dense_2277 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1529 (Dropout)      (None, 512)               0         
                                                                 
 dense_2278 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 594906 (2.27 MB)
Trainable params: 594906 (2.27 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 749:
  Value: 0.9084
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002552883415880576

Model: "sequential_749"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_749 (Flatten)       (None, 784)               0         
                                                                 
 dense_2279 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1530 (Dropout)      (None, 480)               0         
                                                                 
 dense_2280 (Dense)          (None, 512)               246272    
                                                                 
 dropout_1531 (Dropout)      (None, 512)               0         
                                                                 
 dense_2281 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 750:
  Value: 0.1076
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0006563889645865605

Model: "sequential_750"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_750 (Flatten)       (None, 784)               0         
                                                                 
 dense_2282 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1532 (Dropout)      (None, 448)               0         
                                                                 
 dense_2283 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1533 (Dropout)      (None, 480)               0         
                                                                 
 dense_2284 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 751:
  Value: 0.9093
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00018156343746663354

Model: "sequential_751"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_751 (Flatten)       (None, 784)               0         
                                                                 
 dense_2285 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1534 (Dropout)      (None, 480)               0         
                                                                 
 dense_2286 (Dense)          (None, 512)               246272    
                                                                 
 dropout_1535 (Dropout)      (None, 512)               0         
                                                                 
 dense_2287 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 752:
  Value: 0.8667
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009678841346048835

Model: "sequential_752"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_752 (Flatten)       (None, 784)               0         
                                                                 
 dense_2288 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1536 (Dropout)      (None, 448)               0         
                                                                 
 dense_2289 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1537 (Dropout)      (None, 384)               0         
                                                                 
 dense_2290 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 753:
  Value: 0.8686
  num_layers: 2
  units_0: 416
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003566657667798916

Model: "sequential_753"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_753 (Flatten)       (None, 784)               0         
                                                                 
 dense_2291 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1538 (Dropout)      (None, 416)               0         
                                                                 
 dense_2292 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1539 (Dropout)      (None, 480)               0         
                                                                 
 dense_2293 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 539226 (2.06 MB)
Trainable params: 539226 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 754:
  Value: 0.9029
  num_layers: 2
  units_0: 480
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00028050653933838366

Model: "sequential_754"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_754 (Flatten)       (None, 784)               0         
                                                                 
 dense_2294 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1540 (Dropout)      (None, 480)               0         
                                                                 
 dense_2295 (Dense)          (None, 512)               246272    
                                                                 
 dropout_1541 (Dropout)      (None, 512)               0         
                                                                 
 dense_2296 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 636410 (2.43 MB)
Trainable params: 636410 (2.43 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 755:
  Value: 0.3532
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.00023218461329971423

Model: "sequential_755"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_755 (Flatten)       (None, 784)               0         
                                                                 
 dense_2297 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1542 (Dropout)      (None, 480)               0         
                                                                 
 dense_2298 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1543 (Dropout)      (None, 416)               0         
                                                                 
 dense_2299 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 756:
  Value: 0.8055
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00022422533739566372

Model: "sequential_756"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_756 (Flatten)       (None, 784)               0         
                                                                 
 dense_2300 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1544 (Dropout)      (None, 448)               0         
                                                                 
 dense_2301 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1545 (Dropout)      (None, 480)               0         
                                                                 
 dense_2302 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 757:
  Value: 0.9056
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013967275580569133

Model: "sequential_757"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_757 (Flatten)       (None, 784)               0         
                                                                 
 dense_2303 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1546 (Dropout)      (None, 480)               0         
                                                                 
 dense_2304 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1547 (Dropout)      (None, 384)               0         
                                                                 
 dense_2305 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 758:
  Value: 0.8685
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011953751381326245

Model: "sequential_758"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_758 (Flatten)       (None, 784)               0         
                                                                 
 dense_2306 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1548 (Dropout)      (None, 448)               0         
                                                                 
 dense_2307 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1549 (Dropout)      (None, 416)               0         
                                                                 
 dense_2308 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 759:
  Value: 0.8000
  num_layers: 2
  units_0: 384
  units_1: 512
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00023278557769030675

Model: "sequential_759"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_759 (Flatten)       (None, 784)               0         
                                                                 
 dense_2309 (Dense)          (None, 384)               301440    
                                                                 
 batch_normalization_155 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1550 (Dropout)      (None, 384)               0         
                                                                 
 dense_2310 (Dense)          (None, 512)               197120    
                                                                 
 dropout_1551 (Dropout)      (None, 512)               0         
                                                                 
 dense_2311 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 513434 (1.96 MB)
Trainable params: 512666 (1.96 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 760:
  Value: 0.8680
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008394311091646756

Model: "sequential_760"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_760 (Flatten)       (None, 784)               0         
                                                                 
 dense_2312 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1552 (Dropout)      (None, 448)               0         
                                                                 
 dense_2313 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1553 (Dropout)      (None, 384)               0         
                                                                 
 dense_2314 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 761:
  Value: 0.9083
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00020464723599514042

Model: "sequential_761"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_761 (Flatten)       (None, 784)               0         
                                                                 
 dense_2315 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1554 (Dropout)      (None, 512)               0         
                                                                 
 dense_2316 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1555 (Dropout)      (None, 480)               0         
                                                                 
 dense_2317 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 762:
  Value: 0.8027
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.00019223713141146954

Model: "sequential_762"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_762 (Flatten)       (None, 784)               0         
                                                                 
 dense_2318 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1556 (Dropout)      (None, 480)               0         
                                                                 
 dense_2319 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1557 (Dropout)      (None, 416)               0         
                                                                 
 dense_2320 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 763:
  Value: 0.8681
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007340310828942384

Model: "sequential_763"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_763 (Flatten)       (None, 784)               0         
                                                                 
 dense_2321 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1558 (Dropout)      (None, 480)               0         
                                                                 
 dense_2322 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1559 (Dropout)      (None, 416)               0         
                                                                 
 dense_2323 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 764:
  Value: 0.7256
  num_layers: 2
  units_0: 448
  units_1: 224
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003114692891606071

Model: "sequential_764"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_764 (Flatten)       (None, 784)               0         
                                                                 
 dense_2324 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1560 (Dropout)      (None, 448)               0         
                                                                 
 dense_2325 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1561 (Dropout)      (None, 224)               0         
                                                                 
 dense_2326 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 458106 (1.75 MB)
Trainable params: 458106 (1.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 765:
  Value: 0.9114
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003116148338397936

Model: "sequential_765"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_765 (Flatten)       (None, 784)               0         
                                                                 
 dense_2327 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1562 (Dropout)      (None, 512)               0         
                                                                 
 dense_2328 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1563 (Dropout)      (None, 480)               0         
                                                                 
 dense_2329 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 766:
  Value: 0.8662
  num_layers: 2
  units_0: 352
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004500548648980049

Model: "sequential_766"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_766 (Flatten)       (None, 784)               0         
                                                                 
 dense_2330 (Dense)          (None, 352)               276320    
                                                                 
 dropout_1564 (Dropout)      (None, 352)               0         
                                                                 
 dense_2331 (Dense)          (None, 512)               180736    
                                                                 
 dropout_1565 (Dropout)      (None, 512)               0         
                                                                 
 dense_2332 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 470394 (1.79 MB)
Trainable params: 470394 (1.79 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 767:
  Value: 0.0410
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0004729928854351893

Model: "sequential_767"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_767 (Flatten)       (None, 784)               0         
                                                                 
 dense_2333 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1566 (Dropout)      (None, 512)               0         
                                                                 
 dense_2334 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1567 (Dropout)      (None, 512)               0         
                                                                 
 dense_2335 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 768:
  Value: 0.8571
  num_layers: 2
  units_0: 256
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003675882100342411

Model: "sequential_768"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_768 (Flatten)       (None, 784)               0         
                                                                 
 dense_2336 (Dense)          (None, 256)               200960    
                                                                 
 dropout_1568 (Dropout)      (None, 256)               0         
                                                                 
 dense_2337 (Dense)          (None, 480)               123360    
                                                                 
 dropout_1569 (Dropout)      (None, 480)               0         
                                                                 
 dense_2338 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 336826 (1.28 MB)
Trainable params: 336826 (1.28 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 769:
  Value: 0.9101
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003082989259643833

Model: "sequential_769"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_769 (Flatten)       (None, 784)               0         
                                                                 
 dense_2339 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1570 (Dropout)      (None, 512)               0         
                                                                 
 dense_2340 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1571 (Dropout)      (None, 480)               0         
                                                                 
 dense_2341 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 770:
  Value: 0.9093
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002650781643312144

Model: "sequential_770"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_770 (Flatten)       (None, 784)               0         
                                                                 
 dense_2342 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1572 (Dropout)      (None, 512)               0         
                                                                 
 dense_2343 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1573 (Dropout)      (None, 512)               0         
                                                                 
 dense_2344 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 771:
  Value: 0.9061
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00040163620494307366

Model: "sequential_771"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_771 (Flatten)       (None, 784)               0         
                                                                 
 dense_2345 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1574 (Dropout)      (None, 512)               0         
                                                                 
 dense_2346 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1575 (Dropout)      (None, 480)               0         
                                                                 
 dense_2347 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 772:
  Value: 0.8970
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00027027319715311997

Model: "sequential_772"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_772 (Flatten)       (None, 784)               0         
                                                                 
 dense_2348 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1576 (Dropout)      (None, 512)               0         
                                                                 
 dense_2349 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1577 (Dropout)      (None, 480)               0         
                                                                 
 dense_2350 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 773:
  Value: 0.8281
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.000222394411047166

Model: "sequential_773"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_773 (Flatten)       (None, 784)               0         
                                                                 
 dense_2351 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1578 (Dropout)      (None, 512)               0         
                                                                 
 dense_2352 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1579 (Dropout)      (None, 480)               0         
                                                                 
 dense_2353 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 774:
  Value: 0.9050
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002557727437628995

Model: "sequential_774"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_774 (Flatten)       (None, 784)               0         
                                                                 
 dense_2354 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1580 (Dropout)      (None, 512)               0         
                                                                 
 dense_2355 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1581 (Dropout)      (None, 480)               0         
                                                                 
 dense_2356 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 775:
  Value: 0.9089
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00025435633753349775

Model: "sequential_775"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_775 (Flatten)       (None, 784)               0         
                                                                 
 dense_2357 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1582 (Dropout)      (None, 512)               0         
                                                                 
 dense_2358 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1583 (Dropout)      (None, 480)               0         
                                                                 
 dense_2359 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 776:
  Value: 0.1475
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.00030430820707741315

Model: "sequential_776"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_776 (Flatten)       (None, 784)               0         
                                                                 
 dense_2360 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1584 (Dropout)      (None, 512)               0         
                                                                 
 dense_2361 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1585 (Dropout)      (None, 480)               0         
                                                                 
 dense_2362 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 777:
  Value: 0.9103
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002716610405143954

Model: "sequential_777"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_777 (Flatten)       (None, 784)               0         
                                                                 
 dense_2363 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1586 (Dropout)      (None, 512)               0         
                                                                 
 dense_2364 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1587 (Dropout)      (None, 480)               0         
                                                                 
 dense_2365 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 778:
  Value: 0.9033
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00014801548691179928

Model: "sequential_778"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_778 (Flatten)       (None, 784)               0         
                                                                 
 dense_2366 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1588 (Dropout)      (None, 512)               0         
                                                                 
 dense_2367 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1589 (Dropout)      (None, 480)               0         
                                                                 
 dense_2368 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 779:
  Value: 0.8525
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.4
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002736073035710612

Model: "sequential_779"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_779 (Flatten)       (None, 784)               0         
                                                                 
 dense_2369 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_156 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1590 (Dropout)      (None, 512)               0         
                                                                 
 dense_2370 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1591 (Dropout)      (None, 480)               0         
                                                                 
 dense_2371 (Dense)          (None, 352)               169312    
                                                                 
 dropout_1592 (Dropout)      (None, 352)               0         
                                                                 
 dense_2372 (Dense)          (None, 320)               112960    
                                                                 
 dropout_1593 (Dropout)      (None, 320)               0         
                                                                 
 dense_2373 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 940826 (3.59 MB)
Trainable params: 939802 (3.59 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 780:
  Value: 0.9020
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000227148724690521

Model: "sequential_780"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_780 (Flatten)       (None, 784)               0         
                                                                 
 dense_2374 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1594 (Dropout)      (None, 512)               0         
                                                                 
 dense_2375 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1595 (Dropout)      (None, 512)               0         
                                                                 
 dense_2376 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 781:
  Value: 0.8418
  num_layers: 2
  units_0: 224
  units_1: 480
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00033495587895736366

Model: "sequential_781"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_781 (Flatten)       (None, 784)               0         
                                                                 
 dense_2377 (Dense)          (None, 224)               175840    
                                                                 
 dropout_1596 (Dropout)      (None, 224)               0         
                                                                 
 dense_2378 (Dense)          (None, 480)               108000    
                                                                 
 dropout_1597 (Dropout)      (None, 480)               0         
                                                                 
 dense_2379 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 296346 (1.13 MB)
Trainable params: 296346 (1.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 782:
  Value: 0.9099
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000271176582174741

Model: "sequential_782"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_782 (Flatten)       (None, 784)               0         
                                                                 
 dense_2380 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1598 (Dropout)      (None, 512)               0         
                                                                 
 dense_2381 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1599 (Dropout)      (None, 512)               0         
                                                                 
 dense_2382 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 783:
  Value: 0.9060
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00030978968141679965

Model: "sequential_783"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_783 (Flatten)       (None, 784)               0         
                                                                 
 dense_2383 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1600 (Dropout)      (None, 512)               0         
                                                                 
 dense_2384 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1601 (Dropout)      (None, 384)               0         
                                                                 
 dense_2385 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 784:
  Value: 0.3591
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.00020781563143174375

Model: "sequential_784"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_784 (Flatten)       (None, 784)               0         
                                                                 
 dense_2386 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1602 (Dropout)      (None, 512)               0         
                                                                 
 dense_2387 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1603 (Dropout)      (None, 480)               0         
                                                                 
 dense_2388 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 785:
  Value: 0.9075
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000312804795432337

Model: "sequential_785"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_785 (Flatten)       (None, 784)               0         
                                                                 
 dense_2389 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1604 (Dropout)      (None, 512)               0         
                                                                 
 dense_2390 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1605 (Dropout)      (None, 480)               0         
                                                                 
 dense_2391 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 786:
  Value: 0.7461
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000413313245794051

Model: "sequential_786"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_786 (Flatten)       (None, 784)               0         
                                                                 
 dense_2392 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1606 (Dropout)      (None, 512)               0         
                                                                 
 dense_2393 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1607 (Dropout)      (None, 384)               0         
                                                                 
 dense_2394 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 787:
  Value: 0.0389
  num_layers: 3
  units_0: 512
  units_1: 480
  units_2: 64
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  optimizer: ftrl
  learning_rate: 0.00023967323129081797

Model: "sequential_787"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_787 (Flatten)       (None, 784)               0         
                                                                 
 dense_2395 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1608 (Dropout)      (None, 512)               0         
                                                                 
 dense_2396 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1609 (Dropout)      (None, 480)               0         
                                                                 
 dense_2397 (Dense)          (None, 64)                30784     
                                                                 
 dropout_1610 (Dropout)      (None, 64)                0         
                                                                 
 dense_2398 (Dense)          (None, 26)                1690      
                                                                 
=================================================================
Total params: 680634 (2.60 MB)
Trainable params: 680634 (2.60 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 788:
  Value: 0.9108
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00031954806838762224

Model: "sequential_788"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_788 (Flatten)       (None, 784)               0         
                                                                 
 dense_2399 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1611 (Dropout)      (None, 512)               0         
                                                                 
 dense_2400 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1612 (Dropout)      (None, 480)               0         
                                                                 
 dense_2401 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 789:
  Value: 0.9065
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00029180688704173415

Model: "sequential_789"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_789 (Flatten)       (None, 784)               0         
                                                                 
 dense_2402 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1613 (Dropout)      (None, 512)               0         
                                                                 
 dense_2403 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1614 (Dropout)      (None, 512)               0         
                                                                 
 dense_2404 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 790:
  Value: 0.9089
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003578168079323015

Model: "sequential_790"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_790 (Flatten)       (None, 784)               0         
                                                                 
 dense_2405 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1615 (Dropout)      (None, 512)               0         
                                                                 
 dense_2406 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1616 (Dropout)      (None, 480)               0         
                                                                 
 dense_2407 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 791:
  Value: 0.8996
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002462655026810279

Model: "sequential_791"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_791 (Flatten)       (None, 784)               0         
                                                                 
 dense_2408 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1617 (Dropout)      (None, 512)               0         
                                                                 
 dense_2409 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1618 (Dropout)      (None, 480)               0         
                                                                 
 dense_2410 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 792:
  Value: 0.9054
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002857235445357058

Model: "sequential_792"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_792 (Flatten)       (None, 784)               0         
                                                                 
 dense_2411 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1619 (Dropout)      (None, 512)               0         
                                                                 
 dense_2412 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1620 (Dropout)      (None, 480)               0         
                                                                 
 dense_2413 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 793:
  Value: 0.8045
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.00037866086332614274

Model: "sequential_793"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_793 (Flatten)       (None, 784)               0         
                                                                 
 dense_2414 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1621 (Dropout)      (None, 512)               0         
                                                                 
 dense_2415 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1622 (Dropout)      (None, 416)               0         
                                                                 
 dense_2416 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 794:
  Value: 0.7179
  num_layers: 2
  units_0: 32
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00030987236895834455

Model: "sequential_794"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_794 (Flatten)       (None, 784)               0         
                                                                 
 dense_2417 (Dense)          (None, 32)                25120     
                                                                 
 dropout_1623 (Dropout)      (None, 32)                0         
                                                                 
 dense_2418 (Dense)          (None, 480)               15840     
                                                                 
 dropout_1624 (Dropout)      (None, 480)               0         
                                                                 
 dense_2419 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 53466 (208.85 KB)
Trainable params: 53466 (208.85 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 795:
  Value: 0.9020
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00028003962319863115

Model: "sequential_795"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_795 (Flatten)       (None, 784)               0         
                                                                 
 dense_2420 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1625 (Dropout)      (None, 512)               0         
                                                                 
 dense_2421 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1626 (Dropout)      (None, 512)               0         
                                                                 
 dense_2422 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 796:
  Value: 0.8311
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.00024319875582461378

Model: "sequential_796"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_796 (Flatten)       (None, 784)               0         
                                                                 
 dense_2423 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1627 (Dropout)      (None, 512)               0         
                                                                 
 dense_2424 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 797:
  Value: 0.9062
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003459983099232119

Model: "sequential_797"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_797 (Flatten)       (None, 784)               0         
                                                                 
 dense_2425 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1628 (Dropout)      (None, 512)               0         
                                                                 
 dense_2426 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1629 (Dropout)      (None, 480)               0         
                                                                 
 dense_2427 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 798:
  Value: 0.9087
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00032903502642113805

Model: "sequential_798"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_798 (Flatten)       (None, 784)               0         
                                                                 
 dense_2428 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1630 (Dropout)      (None, 512)               0         
                                                                 
 dense_2429 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1631 (Dropout)      (None, 480)               0         
                                                                 
 dense_2430 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 799:
  Value: 0.9071
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00022655778749139458

Model: "sequential_799"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_799 (Flatten)       (None, 784)               0         
                                                                 
 dense_2431 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1632 (Dropout)      (None, 512)               0         
                                                                 
 dense_2432 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1633 (Dropout)      (None, 480)               0         
                                                                 
 dense_2433 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 800:
  Value: 0.8768
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00028804249527058644

Model: "sequential_800"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_800 (Flatten)       (None, 784)               0         
                                                                 
 dense_2434 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_157 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1634 (Dropout)      (None, 512)               0         
                                                                 
 dense_2435 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1635 (Dropout)      (None, 480)               0         
                                                                 
 dense_2436 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 662714 (2.53 MB)
Trainable params: 661690 (2.52 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 801:
  Value: 0.9092
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002661710881375869

Model: "sequential_801"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_801 (Flatten)       (None, 784)               0         
                                                                 
 dense_2437 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1636 (Dropout)      (None, 512)               0         
                                                                 
 dense_2438 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1637 (Dropout)      (None, 512)               0         
                                                                 
 dense_2439 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 802:
  Value: 0.8120
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001865552042731518

Model: "sequential_802"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_802 (Flatten)       (None, 784)               0         
                                                                 
 dense_2440 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1638 (Dropout)      (None, 512)               0         
                                                                 
 dense_2441 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1639 (Dropout)      (None, 480)               0         
                                                                 
 dense_2442 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 803:
  Value: 0.2068
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.00020028958547706378

Model: "sequential_803"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_803 (Flatten)       (None, 784)               0         
                                                                 
 dense_2443 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1640 (Dropout)      (None, 512)               0         
                                                                 
 dense_2444 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1641 (Dropout)      (None, 416)               0         
                                                                 
 dense_2445 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 804:
  Value: 0.8044
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.0005462919682215647

Model: "sequential_804"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_804 (Flatten)       (None, 784)               0         
                                                                 
 dense_2446 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1642 (Dropout)      (None, 480)               0         
                                                                 
 dense_2447 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1643 (Dropout)      (None, 480)               0         
                                                                 
 dense_2448 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 805:
  Value: 0.8500
  num_layers: 2
  units_0: 192
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00034441387932842644

Model: "sequential_805"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_805 (Flatten)       (None, 784)               0         
                                                                 
 dense_2449 (Dense)          (None, 192)               150720    
                                                                 
 dropout_1644 (Dropout)      (None, 192)               0         
                                                                 
 dense_2450 (Dense)          (None, 480)               92640     
                                                                 
 dropout_1645 (Dropout)      (None, 480)               0         
                                                                 
 dense_2451 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 255866 (999.48 KB)
Trainable params: 255866 (999.48 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 806:
  Value: 0.9115
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003232008635834615

Model: "sequential_806"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_806 (Flatten)       (None, 784)               0         
                                                                 
 dense_2452 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1646 (Dropout)      (None, 512)               0         
                                                                 
 dense_2453 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1647 (Dropout)      (None, 416)               0         
                                                                 
 dense_2454 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 807:
  Value: 0.8688
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003483425990856445

Model: "sequential_807"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_807 (Flatten)       (None, 784)               0         
                                                                 
 dense_2455 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1648 (Dropout)      (None, 480)               0         
                                                                 
 dense_2456 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1649 (Dropout)      (None, 416)               0         
                                                                 
 dense_2457 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 808:
  Value: 0.8991
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00045441154635101266

Model: "sequential_808"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_808 (Flatten)       (None, 784)               0         
                                                                 
 dense_2458 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1650 (Dropout)      (None, 512)               0         
                                                                 
 dense_2459 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1651 (Dropout)      (None, 416)               0         
                                                                 
 dense_2460 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 809:
  Value: 0.9025
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000327843691935297

Model: "sequential_809"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_809 (Flatten)       (None, 784)               0         
                                                                 
 dense_2461 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1652 (Dropout)      (None, 480)               0         
                                                                 
 dense_2462 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1653 (Dropout)      (None, 416)               0         
                                                                 
 dense_2463 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 810:
  Value: 0.8666
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00021545395136801068

Model: "sequential_810"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_810 (Flatten)       (None, 784)               0         
                                                                 
 dense_2464 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1654 (Dropout)      (None, 480)               0         
                                                                 
 dense_2465 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1655 (Dropout)      (None, 416)               0         
                                                                 
 dense_2466 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 811:
  Value: 0.7432
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000330347768335563

Model: "sequential_811"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_811 (Flatten)       (None, 784)               0         
                                                                 
 dense_2467 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1656 (Dropout)      (None, 480)               0         
                                                                 
 dense_2468 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1657 (Dropout)      (None, 416)               0         
                                                                 
 dense_2469 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 812:
  Value: 0.3488
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.00016574454994996518

Model: "sequential_812"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_812 (Flatten)       (None, 784)               0         
                                                                 
 dense_2470 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1658 (Dropout)      (None, 512)               0         
                                                                 
 dense_2471 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1659 (Dropout)      (None, 384)               0         
                                                                 
 dense_2472 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 813:
  Value: 0.8855
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003213452262827216

Model: "sequential_813"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_813 (Flatten)       (None, 784)               0         
                                                                 
 dense_2473 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1660 (Dropout)      (None, 512)               0         
                                                                 
 dense_2474 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1661 (Dropout)      (None, 416)               0         
                                                                 
 dense_2475 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 814:
  Value: 0.8931
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004199788483644376

Model: "sequential_814"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_814 (Flatten)       (None, 784)               0         
                                                                 
 dense_2476 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1662 (Dropout)      (None, 480)               0         
                                                                 
 dense_2477 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1663 (Dropout)      (None, 416)               0         
                                                                 
 dense_2478 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 815:
  Value: 0.8689
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003739236801546556

Model: "sequential_815"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_815 (Flatten)       (None, 784)               0         
                                                                 
 dense_2479 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1664 (Dropout)      (None, 480)               0         
                                                                 
 dense_2480 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1665 (Dropout)      (None, 384)               0         
                                                                 
 dense_2481 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 816:
  Value: 0.0373
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.00018616645269936837

Model: "sequential_816"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_816 (Flatten)       (None, 784)               0         
                                                                 
 dense_2482 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1666 (Dropout)      (None, 512)               0         
                                                                 
 dense_2483 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1667 (Dropout)      (None, 416)               0         
                                                                 
 dense_2484 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 817:
  Value: 0.8456
  num_layers: 2
  units_0: 160
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00020094722445480892

Model: "sequential_817"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_817 (Flatten)       (None, 784)               0         
                                                                 
 dense_2485 (Dense)          (None, 160)               125600    
                                                                 
 batch_normalization_158 (B  (None, 160)               640       
 atchNormalization)                                              
                                                                 
 dropout_1668 (Dropout)      (None, 160)               0         
                                                                 
 dense_2486 (Dense)          (None, 416)               66976     
                                                                 
 dropout_1669 (Dropout)      (None, 416)               0         
                                                                 
 dense_2487 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 204058 (797.10 KB)
Trainable params: 203738 (795.85 KB)
Non-trainable params: 320 (1.25 KB)
_________________________________________________________________



Trial 818:
  Value: 0.8680
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005931858000986606

Model: "sequential_818"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_818 (Flatten)       (None, 784)               0         
                                                                 
 dense_2488 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1670 (Dropout)      (None, 480)               0         
                                                                 
 dense_2489 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1671 (Dropout)      (None, 448)               0         
                                                                 
 dense_2490 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 819:
  Value: 0.8676
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004306552739142627

Model: "sequential_819"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_819 (Flatten)       (None, 784)               0         
                                                                 
 dense_2491 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1672 (Dropout)      (None, 480)               0         
                                                                 
 dense_2492 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1673 (Dropout)      (None, 384)               0         
                                                                 
 dense_2493 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 820:
  Value: 0.7970
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.001157105301967617

Model: "sequential_820"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_820 (Flatten)       (None, 784)               0         
                                                                 
 dense_2494 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1674 (Dropout)      (None, 512)               0         
                                                                 
 dense_2495 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1675 (Dropout)      (None, 416)               0         
                                                                 
 dense_2496 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 821:
  Value: 0.8688
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00010981024391361646

Model: "sequential_821"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_821 (Flatten)       (None, 784)               0         
                                                                 
 dense_2497 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1676 (Dropout)      (None, 480)               0         
                                                                 
 dense_2498 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1677 (Dropout)      (None, 448)               0         
                                                                 
 dense_2499 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 822:
  Value: 0.8673
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0021557216651169873

Model: "sequential_822"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_822 (Flatten)       (None, 784)               0         
                                                                 
 dense_2500 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1678 (Dropout)      (None, 512)               0         
                                                                 
 dense_2501 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1679 (Dropout)      (None, 416)               0         
                                                                 
 dense_2502 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 823:
  Value: 0.9030
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.000514150929773987

Model: "sequential_823"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_823 (Flatten)       (None, 784)               0         
                                                                 
 dense_2503 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1680 (Dropout)      (None, 480)               0         
                                                                 
 dense_2504 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1681 (Dropout)      (None, 448)               0         
                                                                 
 dense_2505 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 824:
  Value: 0.8097
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00233860544392064

Model: "sequential_824"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_824 (Flatten)       (None, 784)               0         
                                                                 
 dense_2506 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1682 (Dropout)      (None, 480)               0         
                                                                 
 dense_2507 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1683 (Dropout)      (None, 416)               0         
                                                                 
 dense_2508 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 825:
  Value: 0.9114
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001378680749645419

Model: "sequential_825"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_825 (Flatten)       (None, 784)               0         
                                                                 
 dense_2509 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1684 (Dropout)      (None, 512)               0         
                                                                 
 dense_2510 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1685 (Dropout)      (None, 384)               0         
                                                                 
 dense_2511 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 826:
  Value: 0.8525
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00012157599214161637

Model: "sequential_826"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_826 (Flatten)       (None, 784)               0         
                                                                 
 dense_2512 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1686 (Dropout)      (None, 512)               0         
                                                                 
 dense_2513 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1687 (Dropout)      (None, 384)               0         
                                                                 
 dense_2514 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 827:
  Value: 0.8681
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00015621845698073736

Model: "sequential_827"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_827 (Flatten)       (None, 784)               0         
                                                                 
 dense_2515 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1688 (Dropout)      (None, 480)               0         
                                                                 
 dense_2516 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1689 (Dropout)      (None, 384)               0         
                                                                 
 dense_2517 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 828:
  Value: 0.8334
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.00019647745711145185

Model: "sequential_828"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_828 (Flatten)       (None, 784)               0         
                                                                 
 dense_2518 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1690 (Dropout)      (None, 480)               0         
                                                                 
 dense_2519 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1691 (Dropout)      (None, 384)               0         
                                                                 
 dense_2520 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 829:
  Value: 0.8787
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001373298898687358

Model: "sequential_829"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_829 (Flatten)       (None, 784)               0         
                                                                 
 dense_2521 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1692 (Dropout)      (None, 512)               0         
                                                                 
 dense_2522 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1693 (Dropout)      (None, 384)               0         
                                                                 
 dense_2523 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 830:
  Value: 0.8772
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00016502627447941733

Model: "sequential_830"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_830 (Flatten)       (None, 784)               0         
                                                                 
 dense_2524 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1694 (Dropout)      (None, 480)               0         
                                                                 
 dense_2525 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1695 (Dropout)      (None, 384)               0         
                                                                 
 dense_2526 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 831:
  Value: 0.7491
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003835093180788592

Model: "sequential_831"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_831 (Flatten)       (None, 784)               0         
                                                                 
 dense_2527 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1696 (Dropout)      (None, 512)               0         
                                                                 
 dense_2528 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1697 (Dropout)      (None, 384)               0         
                                                                 
 dense_2529 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 832:
  Value: 0.0998
  num_layers: 2
  units_0: 288
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.00018926464106294334

Model: "sequential_832"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_832 (Flatten)       (None, 784)               0         
                                                                 
 dense_2530 (Dense)          (None, 288)               226080    
                                                                 
 dropout_1698 (Dropout)      (None, 288)               0         
                                                                 
 dense_2531 (Dense)          (None, 384)               110976    
                                                                 
 dropout_1699 (Dropout)      (None, 384)               0         
                                                                 
 dense_2532 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 347066 (1.32 MB)
Trainable params: 347066 (1.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 833:
  Value: 0.8780
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00010067706214638751

Model: "sequential_833"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_833 (Flatten)       (None, 784)               0         
                                                                 
 dense_2533 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1700 (Dropout)      (None, 480)               0         
                                                                 
 dense_2534 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1701 (Dropout)      (None, 384)               0         
                                                                 
 dense_2535 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 834:
  Value: 0.9074
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002314326584847747

Model: "sequential_834"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_834 (Flatten)       (None, 784)               0         
                                                                 
 dense_2536 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1702 (Dropout)      (None, 512)               0         
                                                                 
 dense_2537 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1703 (Dropout)      (None, 384)               0         
                                                                 
 dense_2538 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 835:
  Value: 0.8293
  num_layers: 1
  units_0: 480
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0001579095980250105

Model: "sequential_835"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_835 (Flatten)       (None, 784)               0         
                                                                 
 dense_2539 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1704 (Dropout)      (None, 480)               0         
                                                                 
 dense_2540 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 836:
  Value: 0.8468
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00012855193002142627

Model: "sequential_836"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_836 (Flatten)       (None, 784)               0         
                                                                 
 dense_2541 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_159 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1705 (Dropout)      (None, 512)               0         
                                                                 
 dense_2542 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1706 (Dropout)      (None, 384)               0         
                                                                 
 dense_2543 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 610970 (2.33 MB)
Trainable params: 609946 (2.33 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 837:
  Value: 0.8874
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00015750333797562025

Model: "sequential_837"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_837 (Flatten)       (None, 784)               0         
                                                                 
 dense_2544 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1707 (Dropout)      (None, 480)               0         
                                                                 
 dense_2545 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1708 (Dropout)      (None, 384)               0         
                                                                 
 dense_2546 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 838:
  Value: 0.8783
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001322374332930196

Model: "sequential_838"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_838 (Flatten)       (None, 784)               0         
                                                                 
 dense_2547 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1709 (Dropout)      (None, 480)               0         
                                                                 
 dense_2548 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1710 (Dropout)      (None, 416)               0         
                                                                 
 dense_2549 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 839:
  Value: 0.8670
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00011988247505826123

Model: "sequential_839"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_839 (Flatten)       (None, 784)               0         
                                                                 
 dense_2550 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1711 (Dropout)      (None, 512)               0         
                                                                 
 dense_2551 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1712 (Dropout)      (None, 416)               0         
                                                                 
 dense_2552 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 840:
  Value: 0.2984
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.5
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.00016476461545506657

Model: "sequential_840"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_840 (Flatten)       (None, 784)               0         
                                                                 
 dense_2553 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1713 (Dropout)      (None, 480)               0         
                                                                 
 dense_2554 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1714 (Dropout)      (None, 416)               0         
                                                                 
 dense_2555 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 841:
  Value: 0.8958
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004131081639596344

Model: "sequential_841"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_841 (Flatten)       (None, 784)               0         
                                                                 
 dense_2556 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1715 (Dropout)      (None, 512)               0         
                                                                 
 dense_2557 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1716 (Dropout)      (None, 384)               0         
                                                                 
 dense_2558 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 842:
  Value: 0.8657
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003782724248232821

Model: "sequential_842"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_842 (Flatten)       (None, 784)               0         
                                                                 
 dense_2559 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1717 (Dropout)      (None, 416)               0         
                                                                 
 dense_2560 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1718 (Dropout)      (None, 416)               0         
                                                                 
 dense_2561 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 843:
  Value: 0.8629
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00011876682623993481

Model: "sequential_843"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_843 (Flatten)       (None, 784)               0         
                                                                 
 dense_2562 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1719 (Dropout)      (None, 480)               0         
                                                                 
 dense_2563 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1720 (Dropout)      (None, 416)               0         
                                                                 
 dense_2564 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 844:
  Value: 0.0378
  num_layers: 2
  units_0: 128
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.00011790991108964435

Model: "sequential_844"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_844 (Flatten)       (None, 784)               0         
                                                                 
 dense_2565 (Dense)          (None, 128)               100480    
                                                                 
 dropout_1721 (Dropout)      (None, 128)               0         
                                                                 
 dense_2566 (Dense)          (None, 288)               37152     
                                                                 
 dropout_1722 (Dropout)      (None, 288)               0         
                                                                 
 dense_2567 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 145146 (566.98 KB)
Trainable params: 145146 (566.98 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 845:
  Value: 0.8676
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00030077262267298743

Model: "sequential_845"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_845 (Flatten)       (None, 784)               0         
                                                                 
 dense_2568 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1723 (Dropout)      (None, 480)               0         
                                                                 
 dense_2569 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1724 (Dropout)      (None, 384)               0         
                                                                 
 dense_2570 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 846:
  Value: 0.9030
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00014136298190304785

Model: "sequential_846"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_846 (Flatten)       (None, 784)               0         
                                                                 
 dense_2571 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1725 (Dropout)      (None, 512)               0         
                                                                 
 dense_2572 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1726 (Dropout)      (None, 416)               0         
                                                                 
 dense_2573 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 847:
  Value: 0.7751
  num_layers: 2
  units_0: 320
  units_1: 384
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00024350678323252636

Model: "sequential_847"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_847 (Flatten)       (None, 784)               0         
                                                                 
 dense_2574 (Dense)          (None, 320)               251200    
                                                                 
 dropout_1727 (Dropout)      (None, 320)               0         
                                                                 
 dense_2575 (Dense)          (None, 384)               123264    
                                                                 
 dropout_1728 (Dropout)      (None, 384)               0         
                                                                 
 dense_2576 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 384474 (1.47 MB)
Trainable params: 384474 (1.47 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 848:
  Value: 0.8681
  num_layers: 3
  units_0: 448
  units_1: 416
  units_2: 480
  activation_0: tanh
  activation_1: relu
  activation_2: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0001447391783927415

Model: "sequential_848"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_848 (Flatten)       (None, 784)               0         
                                                                 
 dense_2577 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1729 (Dropout)      (None, 448)               0         
                                                                 
 dense_2578 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1730 (Dropout)      (None, 416)               0         
                                                                 
 dense_2579 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_160 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1731 (Dropout)      (None, 480)               0         
                                                                 
 dense_2580 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 753050 (2.87 MB)
Trainable params: 752090 (2.87 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 849:
  Value: 0.9024
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00014557129273845562

Model: "sequential_849"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_849 (Flatten)       (None, 784)               0         
                                                                 
 dense_2581 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1732 (Dropout)      (None, 512)               0         
                                                                 
 dense_2582 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1733 (Dropout)      (None, 416)               0         
                                                                 
 dense_2583 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 850:
  Value: 0.7947
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0001654971558778998

Model: "sequential_850"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_850 (Flatten)       (None, 784)               0         
                                                                 
 dense_2584 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1734 (Dropout)      (None, 480)               0         
                                                                 
 dense_2585 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1735 (Dropout)      (None, 448)               0         
                                                                 
 dense_2586 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 851:
  Value: 0.8587
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00011608579885048263

Model: "sequential_851"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_851 (Flatten)       (None, 784)               0         
                                                                 
 dense_2587 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1736 (Dropout)      (None, 448)               0         
                                                                 
 dense_2588 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1737 (Dropout)      (None, 416)               0         
                                                                 
 dense_2589 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 852:
  Value: 0.8648
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00015430035467457295

Model: "sequential_852"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_852 (Flatten)       (None, 784)               0         
                                                                 
 dense_2590 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1738 (Dropout)      (None, 480)               0         
                                                                 
 dense_2591 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1739 (Dropout)      (None, 384)               0         
                                                                 
 dense_2592 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 853:
  Value: 0.8688
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003983642906967876

Model: "sequential_853"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_853 (Flatten)       (None, 784)               0         
                                                                 
 dense_2593 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1740 (Dropout)      (None, 512)               0         
                                                                 
 dense_2594 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1741 (Dropout)      (None, 448)               0         
                                                                 
 dense_2595 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 854:
  Value: 0.7502
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00026008584969036897

Model: "sequential_854"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_854 (Flatten)       (None, 784)               0         
                                                                 
 dense_2596 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1742 (Dropout)      (None, 448)               0         
                                                                 
 dense_2597 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1743 (Dropout)      (None, 416)               0         
                                                                 
 dense_2598 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 855:
  Value: 0.7848
  num_layers: 2
  units_0: 64
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00010184249461445885

Model: "sequential_855"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_855 (Flatten)       (None, 784)               0         
                                                                 
 dense_2599 (Dense)          (None, 64)                50240     
                                                                 
 batch_normalization_161 (B  (None, 64)                256       
 atchNormalization)                                              
                                                                 
 dropout_1744 (Dropout)      (None, 64)                0         
                                                                 
 dense_2600 (Dense)          (None, 448)               29120     
                                                                 
 dropout_1745 (Dropout)      (None, 448)               0         
                                                                 
 dense_2601 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 91290 (356.60 KB)
Trainable params: 91162 (356.10 KB)
Non-trainable params: 128 (512.00 Byte)
_________________________________________________________________



Trial 856:
  Value: 0.8291
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.00022020734209056748

Model: "sequential_856"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_856 (Flatten)       (None, 784)               0         
                                                                 
 dense_2602 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1746 (Dropout)      (None, 480)               0         
                                                                 
 dense_2603 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1747 (Dropout)      (None, 384)               0         
                                                                 
 dense_2604 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 857:
  Value: 0.8678
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00033580969017882827

Model: "sequential_857"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_857 (Flatten)       (None, 784)               0         
                                                                 
 dense_2605 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1748 (Dropout)      (None, 448)               0         
                                                                 
 dense_2606 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1749 (Dropout)      (None, 416)               0         
                                                                 
 dense_2607 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 858:
  Value: 0.9047
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001075756243184713

Model: "sequential_858"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_858 (Flatten)       (None, 784)               0         
                                                                 
 dense_2608 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1750 (Dropout)      (None, 512)               0         
                                                                 
 dense_2609 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1751 (Dropout)      (None, 448)               0         
                                                                 
 dense_2610 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 859:
  Value: 0.8653
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001107547069097117

Model: "sequential_859"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_859 (Flatten)       (None, 784)               0         
                                                                 
 dense_2611 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1752 (Dropout)      (None, 416)               0         
                                                                 
 dense_2612 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1753 (Dropout)      (None, 416)               0         
                                                                 
 dense_2613 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 860:
  Value: 0.9086
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00029657186753235225

Model: "sequential_860"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_860 (Flatten)       (None, 784)               0         
                                                                 
 dense_2614 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1754 (Dropout)      (None, 480)               0         
                                                                 
 dense_2615 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1755 (Dropout)      (None, 448)               0         
                                                                 
 dense_2616 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 861:
  Value: 0.1223
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0004726128193089467

Model: "sequential_861"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_861 (Flatten)       (None, 784)               0         
                                                                 
 dense_2617 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1756 (Dropout)      (None, 480)               0         
                                                                 
 dense_2618 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1757 (Dropout)      (None, 384)               0         
                                                                 
 dense_2619 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 862:
  Value: 0.8916
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006059068348425623

Model: "sequential_862"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_862 (Flatten)       (None, 784)               0         
                                                                 
 dense_2620 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1758 (Dropout)      (None, 448)               0         
                                                                 
 dense_2621 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1759 (Dropout)      (None, 416)               0         
                                                                 
 dense_2622 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 863:
  Value: 0.8975
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001248024645733325

Model: "sequential_863"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_863 (Flatten)       (None, 784)               0         
                                                                 
 dense_2623 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1760 (Dropout)      (None, 512)               0         
                                                                 
 dense_2624 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1761 (Dropout)      (None, 448)               0         
                                                                 
 dense_2625 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 864:
  Value: 0.9078
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017926965149372314

Model: "sequential_864"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_864 (Flatten)       (None, 784)               0         
                                                                 
 dense_2626 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1762 (Dropout)      (None, 512)               0         
                                                                 
 dense_2627 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1763 (Dropout)      (None, 416)               0         
                                                                 
 dense_2628 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 865:
  Value: 0.8631
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002029672671838438

Model: "sequential_865"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_865 (Flatten)       (None, 784)               0         
                                                                 
 dense_2629 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1764 (Dropout)      (None, 416)               0         
                                                                 
 dense_2630 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1765 (Dropout)      (None, 448)               0         
                                                                 
 dense_2631 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 866:
  Value: 0.8874
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003158046254603116

Model: "sequential_866"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_866 (Flatten)       (None, 784)               0         
                                                                 
 dense_2632 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1766 (Dropout)      (None, 480)               0         
                                                                 
 dense_2633 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1767 (Dropout)      (None, 384)               0         
                                                                 
 dense_2634 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 867:
  Value: 0.3634
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.00018416037933707244

Model: "sequential_867"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_867 (Flatten)       (None, 784)               0         
                                                                 
 dense_2635 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1768 (Dropout)      (None, 448)               0         
                                                                 
 dense_2636 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1769 (Dropout)      (None, 448)               0         
                                                                 
 dense_2637 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 868:
  Value: 0.8668
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00013375253267492997

Model: "sequential_868"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_868 (Flatten)       (None, 784)               0         
                                                                 
 dense_2638 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1770 (Dropout)      (None, 480)               0         
                                                                 
 dense_2639 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1771 (Dropout)      (None, 416)               0         
                                                                 
 dense_2640 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 869:
  Value: 0.7761
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: tanh
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001229261481382662

Model: "sequential_869"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_869 (Flatten)       (None, 784)               0         
                                                                 
 dense_2641 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1772 (Dropout)      (None, 448)               0         
                                                                 
 dense_2642 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1773 (Dropout)      (None, 384)               0         
                                                                 
 dense_2643 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 870:
  Value: 0.9074
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005305519233484492

Model: "sequential_870"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_870 (Flatten)       (None, 784)               0         
                                                                 
 dense_2644 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1774 (Dropout)      (None, 512)               0         
                                                                 
 dense_2645 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1775 (Dropout)      (None, 448)               0         
                                                                 
 dense_2646 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 871:
  Value: 0.8582
  num_layers: 2
  units_0: 480
  units_1: 224
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0010498373051176135

Model: "sequential_871"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_871 (Flatten)       (None, 784)               0         
                                                                 
 dense_2647 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1776 (Dropout)      (None, 480)               0         
                                                                 
 dense_2648 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1777 (Dropout)      (None, 224)               0         
                                                                 
 dense_2649 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 490394 (1.87 MB)
Trainable params: 490394 (1.87 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 872:
  Value: 0.0393
  num_layers: 2
  units_0: 480
  units_1: 160
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.00021412336223653508

Model: "sequential_872"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_872 (Flatten)       (None, 784)               0         
                                                                 
 dense_2650 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1778 (Dropout)      (None, 480)               0         
                                                                 
 dense_2651 (Dense)          (None, 160)               76960     
                                                                 
 dropout_1779 (Dropout)      (None, 160)               0         
                                                                 
 dense_2652 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 457946 (1.75 MB)
Trainable params: 457946 (1.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 873:
  Value: 0.9084
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001417909199558479

Model: "sequential_873"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_873 (Flatten)       (None, 784)               0         
                                                                 
 dense_2653 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1780 (Dropout)      (None, 448)               0         
                                                                 
 dense_2654 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1781 (Dropout)      (None, 416)               0         
                                                                 
 dense_2655 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 874:
  Value: 0.9104
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004912811533933403

Model: "sequential_874"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_874 (Flatten)       (None, 784)               0         
                                                                 
 dense_2656 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1782 (Dropout)      (None, 512)               0         
                                                                 
 dense_2657 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1783 (Dropout)      (None, 416)               0         
                                                                 
 dense_2658 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 875:
  Value: 0.8638
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003675897697922139

Model: "sequential_875"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_875 (Flatten)       (None, 784)               0         
                                                                 
 dense_2659 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_162 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1784 (Dropout)      (None, 512)               0         
                                                                 
 dense_2660 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1785 (Dropout)      (None, 416)               0         
                                                                 
 dense_2661 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 628218 (2.40 MB)
Trainable params: 627194 (2.39 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 876:
  Value: 0.6620
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.00048816039096020325

Model: "sequential_876"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_876 (Flatten)       (None, 784)               0         
                                                                 
 dense_2662 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1786 (Dropout)      (None, 512)               0         
                                                                 
 dense_2663 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1787 (Dropout)      (None, 384)               0         
                                                                 
 dense_2664 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 877:
  Value: 0.8675
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00036488049688319685

Model: "sequential_877"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_877 (Flatten)       (None, 784)               0         
                                                                 
 dense_2665 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1788 (Dropout)      (None, 512)               0         
                                                                 
 dense_2666 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1789 (Dropout)      (None, 416)               0         
                                                                 
 dense_2667 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 878:
  Value: 0.8691
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004352151286529394

Model: "sequential_878"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_878 (Flatten)       (None, 784)               0         
                                                                 
 dense_2668 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1790 (Dropout)      (None, 512)               0         
                                                                 
 dense_2669 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1791 (Dropout)      (None, 416)               0         
                                                                 
 dense_2670 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 879:
  Value: 0.8982
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012718461623870733

Model: "sequential_879"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_879 (Flatten)       (None, 784)               0         
                                                                 
 dense_2671 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1792 (Dropout)      (None, 512)               0         
                                                                 
 dense_2672 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1793 (Dropout)      (None, 416)               0         
                                                                 
 dense_2673 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 880:
  Value: 0.8880
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002806635352827044

Model: "sequential_880"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_880 (Flatten)       (None, 784)               0         
                                                                 
 dense_2674 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1794 (Dropout)      (None, 512)               0         
                                                                 
 dense_2675 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1795 (Dropout)      (None, 384)               0         
                                                                 
 dense_2676 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 881:
  Value: 0.9038
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004695004400279635

Model: "sequential_881"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_881 (Flatten)       (None, 784)               0         
                                                                 
 dense_2677 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1796 (Dropout)      (None, 512)               0         
                                                                 
 dense_2678 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1797 (Dropout)      (None, 416)               0         
                                                                 
 dense_2679 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 882:
  Value: 0.9041
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005269105545236143

Model: "sequential_882"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_882 (Flatten)       (None, 784)               0         
                                                                 
 dense_2680 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1798 (Dropout)      (None, 512)               0         
                                                                 
 dense_2681 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1799 (Dropout)      (None, 416)               0         
                                                                 
 dense_2682 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 883:
  Value: 0.8985
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004065817878379038

Model: "sequential_883"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_883 (Flatten)       (None, 784)               0         
                                                                 
 dense_2683 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1800 (Dropout)      (None, 512)               0         
                                                                 
 dense_2684 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1801 (Dropout)      (None, 416)               0         
                                                                 
 dense_2685 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 884:
  Value: 0.9083
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006565911625951458

Model: "sequential_884"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_884 (Flatten)       (None, 784)               0         
                                                                 
 dense_2686 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1802 (Dropout)      (None, 512)               0         
                                                                 
 dense_2687 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1803 (Dropout)      (None, 384)               0         
                                                                 
 dense_2688 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 885:
  Value: 0.8258
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.001126501693516588

Model: "sequential_885"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_885 (Flatten)       (None, 784)               0         
                                                                 
 dense_2689 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1804 (Dropout)      (None, 512)               0         
                                                                 
 dense_2690 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1805 (Dropout)      (None, 416)               0         
                                                                 
 dense_2691 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 886:
  Value: 0.9070
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006045867179281925

Model: "sequential_886"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_886 (Flatten)       (None, 784)               0         
                                                                 
 dense_2692 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1806 (Dropout)      (None, 512)               0         
                                                                 
 dense_2693 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1807 (Dropout)      (None, 384)               0         
                                                                 
 dense_2694 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 887:
  Value: 0.9092
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00032708070284312923

Model: "sequential_887"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_887 (Flatten)       (None, 784)               0         
                                                                 
 dense_2695 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1808 (Dropout)      (None, 512)               0         
                                                                 
 dense_2696 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1809 (Dropout)      (None, 416)               0         
                                                                 
 dense_2697 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 888:
  Value: 0.1518
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.008629405864948843

Model: "sequential_888"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_888 (Flatten)       (None, 784)               0         
                                                                 
 dense_2698 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1810 (Dropout)      (None, 480)               0         
                                                                 
 dense_2699 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1811 (Dropout)      (None, 416)               0         
                                                                 
 dense_2700 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 889:
  Value: 0.9010
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0005011710437727558

Model: "sequential_889"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_889 (Flatten)       (None, 784)               0         
                                                                 
 dense_2701 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1812 (Dropout)      (None, 480)               0         
                                                                 
 dense_2702 (Dense)          (None, 384)               184704    
                                                                 
 batch_normalization_163 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1813 (Dropout)      (None, 384)               0         
                                                                 
 dense_2703 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 573050 (2.19 MB)
Trainable params: 572282 (2.18 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 890:
  Value: 0.8879
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005814785359567647

Model: "sequential_890"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_890 (Flatten)       (None, 784)               0         
                                                                 
 dense_2704 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1814 (Dropout)      (None, 512)               0         
                                                                 
 dense_2705 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1815 (Dropout)      (None, 384)               0         
                                                                 
 dense_2706 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 891:
  Value: 0.8631
  num_layers: 2
  units_0: 352
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004394822335216978

Model: "sequential_891"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_891 (Flatten)       (None, 784)               0         
                                                                 
 dense_2707 (Dense)          (None, 352)               276320    
                                                                 
 dropout_1816 (Dropout)      (None, 352)               0         
                                                                 
 dense_2708 (Dense)          (None, 416)               146848    
                                                                 
 dropout_1817 (Dropout)      (None, 416)               0         
                                                                 
 dense_2709 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 434010 (1.66 MB)
Trainable params: 434010 (1.66 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 892:
  Value: 0.8559
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00039543851875520125

Model: "sequential_892"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_892 (Flatten)       (None, 784)               0         
                                                                 
 dense_2710 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1818 (Dropout)      (None, 480)               0         
                                                                 
 dense_2711 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1819 (Dropout)      (None, 416)               0         
                                                                 
 dense_2712 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 893:
  Value: 0.8097
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00014285317471006027

Model: "sequential_893"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_893 (Flatten)       (None, 784)               0         
                                                                 
 dense_2713 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1820 (Dropout)      (None, 512)               0         
                                                                 
 dense_2714 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1821 (Dropout)      (None, 416)               0         
                                                                 
 dense_2715 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 894:
  Value: 0.8568
  num_layers: 2
  units_0: 480
  units_1: 256
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002468693595183146

Model: "sequential_894"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_894 (Flatten)       (None, 784)               0         
                                                                 
 dense_2716 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_164 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1822 (Dropout)      (None, 480)               0         
                                                                 
 dense_2717 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1823 (Dropout)      (None, 256)               0         
                                                                 
 dense_2718 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 508538 (1.94 MB)
Trainable params: 507578 (1.94 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 895:
  Value: 0.9080
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0009990169633495158

Model: "sequential_895"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_895 (Flatten)       (None, 784)               0         
                                                                 
 dense_2719 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1824 (Dropout)      (None, 512)               0         
                                                                 
 dense_2720 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1825 (Dropout)      (None, 512)               0         
                                                                 
 dense_2721 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 896:
  Value: 0.3108
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.00031423063138744177

Model: "sequential_896"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_896 (Flatten)       (None, 784)               0         
                                                                 
 dense_2722 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1826 (Dropout)      (None, 480)               0         
                                                                 
 dense_2723 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1827 (Dropout)      (None, 416)               0         
                                                                 
 dense_2724 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 897:
  Value: 0.9077
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002163486634873425

Model: "sequential_897"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_897 (Flatten)       (None, 784)               0         
                                                                 
 dense_2725 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1828 (Dropout)      (None, 512)               0         
                                                                 
 dense_2726 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1829 (Dropout)      (None, 384)               0         
                                                                 
 dense_2727 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 898:
  Value: 0.7447
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001095079245158272

Model: "sequential_898"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_898 (Flatten)       (None, 784)               0         
                                                                 
 dense_2728 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1830 (Dropout)      (None, 480)               0         
                                                                 
 dense_2729 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1831 (Dropout)      (None, 448)               0         
                                                                 
 dense_2730 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 899:
  Value: 0.0392
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0012991552719098954

Model: "sequential_899"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_899 (Flatten)       (None, 784)               0         
                                                                 
 dense_2731 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1832 (Dropout)      (None, 480)               0         
                                                                 
 dense_2732 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1833 (Dropout)      (None, 384)               0         
                                                                 
 dense_2733 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 900:
  Value: 0.9030
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00016571053752679216

Model: "sequential_900"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_900 (Flatten)       (None, 784)               0         
                                                                 
 dense_2734 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1834 (Dropout)      (None, 512)               0         
                                                                 
 dense_2735 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1835 (Dropout)      (None, 416)               0         
                                                                 
 dense_2736 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 901:
  Value: 0.9067
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00035300704545215974

Model: "sequential_901"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_901 (Flatten)       (None, 784)               0         
                                                                 
 dense_2737 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1836 (Dropout)      (None, 480)               0         
                                                                 
 dense_2738 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1837 (Dropout)      (None, 448)               0         
                                                                 
 dense_2739 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 902:
  Value: 0.6528
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 224
  units_3: 480
  activation_0: relu
  activation_1: relu
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0029019736900420356

Model: "sequential_902"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_902 (Flatten)       (None, 784)               0         
                                                                 
 dense_2740 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1838 (Dropout)      (None, 512)               0         
                                                                 
 dense_2741 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1839 (Dropout)      (None, 448)               0         
                                                                 
 dense_2742 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1840 (Dropout)      (None, 224)               0         
                                                                 
 dense_2743 (Dense)          (None, 480)               108000    
                                                                 
 batch_normalization_165 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1841 (Dropout)      (None, 480)               0         
                                                                 
 dense_2744 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 854746 (3.26 MB)
Trainable params: 853786 (3.26 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 903:
  Value: 0.8955
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00027069241713959105

Model: "sequential_903"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_903 (Flatten)       (None, 784)               0         
                                                                 
 dense_2745 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1842 (Dropout)      (None, 512)               0         
                                                                 
 dense_2746 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1843 (Dropout)      (None, 416)               0         
                                                                 
 dense_2747 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 904:
  Value: 0.7918
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.000891857675209578

Model: "sequential_904"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_904 (Flatten)       (None, 784)               0         
                                                                 
 dense_2748 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1844 (Dropout)      (None, 480)               0         
                                                                 
 dense_2749 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1845 (Dropout)      (None, 480)               0         
                                                                 
 dense_2750 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 905:
  Value: 0.8669
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001493889969880721

Model: "sequential_905"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_905 (Flatten)       (None, 784)               0         
                                                                 
 dense_2751 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1846 (Dropout)      (None, 480)               0         
                                                                 
 dense_2752 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1847 (Dropout)      (None, 384)               0         
                                                                 
 dense_2753 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 906:
  Value: 0.8679
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00012806676858897776

Model: "sequential_906"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_906 (Flatten)       (None, 784)               0         
                                                                 
 dense_2754 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1848 (Dropout)      (None, 480)               0         
                                                                 
 dense_2755 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1849 (Dropout)      (None, 416)               0         
                                                                 
 dense_2756 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 907:
  Value: 0.9053
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006970495229509818

Model: "sequential_907"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_907 (Flatten)       (None, 784)               0         
                                                                 
 dense_2757 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1850 (Dropout)      (None, 512)               0         
                                                                 
 dense_2758 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1851 (Dropout)      (None, 448)               0         
                                                                 
 dense_2759 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 908:
  Value: 0.9082
  num_layers: 3
  units_0: 512
  units_1: 512
  units_2: 160
  activation_0: relu
  activation_1: relu
  activation_2: sigmoid
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.2
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: False
  optimizer: adam
  learning_rate: 0.000553162015703344

Model: "sequential_908"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_908 (Flatten)       (None, 784)               0         
                                                                 
 dense_2760 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1852 (Dropout)      (None, 512)               0         
                                                                 
 dense_2761 (Dense)          (None, 512)               262656    
                                                                 
 batch_normalization_166 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1853 (Dropout)      (None, 512)               0         
                                                                 
 dense_2762 (Dense)          (None, 160)               82080     
                                                                 
 dropout_1854 (Dropout)      (None, 160)               0         
                                                                 
 dense_2763 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 752890 (2.87 MB)
Trainable params: 751866 (2.87 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 909:
  Value: 0.9086
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009240399352270405

Model: "sequential_909"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_909 (Flatten)       (None, 784)               0         
                                                                 
 dense_2764 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1855 (Dropout)      (None, 480)               0         
                                                                 
 dense_2765 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1856 (Dropout)      (None, 480)               0         
                                                                 
 dense_2766 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 910:
  Value: 0.8668
  num_layers: 2
  units_0: 384
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017469256029833973

Model: "sequential_910"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_910 (Flatten)       (None, 784)               0         
                                                                 
 dense_2767 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1857 (Dropout)      (None, 384)               0         
                                                                 
 dense_2768 (Dense)          (None, 384)               147840    
                                                                 
 dropout_1858 (Dropout)      (None, 384)               0         
                                                                 
 dense_2769 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 459290 (1.75 MB)
Trainable params: 459290 (1.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 911:
  Value: 0.9093
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0025830348795846253

Model: "sequential_911"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_911 (Flatten)       (None, 784)               0         
                                                                 
 dense_2770 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1859 (Dropout)      (None, 480)               0         
                                                                 
 dense_2771 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1860 (Dropout)      (None, 416)               0         
                                                                 
 dense_2772 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 912:
  Value: 0.8677
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.000290035303873973

Model: "sequential_912"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_912 (Flatten)       (None, 784)               0         
                                                                 
 dense_2773 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_167 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1861 (Dropout)      (None, 512)               0         
                                                                 
 dense_2774 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1862 (Dropout)      (None, 448)               0         
                                                                 
 dense_2775 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 645466 (2.46 MB)
Trainable params: 644442 (2.46 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 913:
  Value: 0.8683
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0031982030793229125

Model: "sequential_913"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_913 (Flatten)       (None, 784)               0         
                                                                 
 dense_2776 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1863 (Dropout)      (None, 480)               0         
                                                                 
 dense_2777 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1864 (Dropout)      (None, 416)               0         
                                                                 
 dense_2778 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 914:
  Value: 0.8598
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.008092204153636763

Model: "sequential_914"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_914 (Flatten)       (None, 784)               0         
                                                                 
 dense_2779 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1865 (Dropout)      (None, 512)               0         
                                                                 
 dense_2780 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1866 (Dropout)      (None, 448)               0         
                                                                 
 dense_2781 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 915:
  Value: 0.0375
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.00019450779369708593

Model: "sequential_915"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_915 (Flatten)       (None, 784)               0         
                                                                 
 dense_2782 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1867 (Dropout)      (None, 480)               0         
                                                                 
 dense_2783 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1868 (Dropout)      (None, 384)               0         
                                                                 
 dense_2784 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 916:
  Value: 0.9101
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007826583020097092

Model: "sequential_916"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_916 (Flatten)       (None, 784)               0         
                                                                 
 dense_2785 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1869 (Dropout)      (None, 512)               0         
                                                                 
 dense_2786 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1870 (Dropout)      (None, 448)               0         
                                                                 
 dense_2787 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 917:
  Value: 0.8392
  num_layers: 2
  units_0: 480
  units_1: 96
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004405787830188868

Model: "sequential_917"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_917 (Flatten)       (None, 784)               0         
                                                                 
 dense_2788 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1871 (Dropout)      (None, 480)               0         
                                                                 
 dense_2789 (Dense)          (None, 96)                46176     
                                                                 
 dropout_1872 (Dropout)      (None, 96)                0         
                                                                 
 dense_2790 (Dense)          (None, 26)                2522      
                                                                 
=================================================================
Total params: 425498 (1.62 MB)
Trainable params: 425498 (1.62 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 918:
  Value: 0.9081
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0011383538334944902

Model: "sequential_918"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_918 (Flatten)       (None, 784)               0         
                                                                 
 dense_2791 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1873 (Dropout)      (None, 448)               0         
                                                                 
 dense_2792 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1874 (Dropout)      (None, 480)               0         
                                                                 
 dense_2793 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 919:
  Value: 0.8691
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004952771733811128

Model: "sequential_919"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_919 (Flatten)       (None, 784)               0         
                                                                 
 dense_2794 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1875 (Dropout)      (None, 480)               0         
                                                                 
 dense_2795 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1876 (Dropout)      (None, 416)               0         
                                                                 
 dense_2796 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 920:
  Value: 0.9084
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003759627639271308

Model: "sequential_920"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_920 (Flatten)       (None, 784)               0         
                                                                 
 dense_2797 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1877 (Dropout)      (None, 512)               0         
                                                                 
 dense_2798 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1878 (Dropout)      (None, 416)               0         
                                                                 
 dense_2799 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 921:
  Value: 0.8578
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001374447111434514

Model: "sequential_921"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_921 (Flatten)       (None, 784)               0         
                                                                 
 dense_2800 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1879 (Dropout)      (None, 448)               0         
                                                                 
 dense_2801 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1880 (Dropout)      (None, 384)               0         
                                                                 
 dense_2802 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 922:
  Value: 0.9019
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016134195762424852

Model: "sequential_922"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_922 (Flatten)       (None, 784)               0         
                                                                 
 dense_2803 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1881 (Dropout)      (None, 480)               0         
                                                                 
 dense_2804 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1882 (Dropout)      (None, 448)               0         
                                                                 
 dense_2805 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 923:
  Value: 0.2744
  num_layers: 2
  units_0: 512
  units_1: 320
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0009335138796888426

Model: "sequential_923"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_923 (Flatten)       (None, 784)               0         
                                                                 
 dense_2806 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1883 (Dropout)      (None, 512)               0         
                                                                 
 dense_2807 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1884 (Dropout)      (None, 320)               0         
                                                                 
 dense_2808 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 574426 (2.19 MB)
Trainable params: 574426 (2.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 924:
  Value: 0.8805
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00010613688784651824

Model: "sequential_924"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_924 (Flatten)       (None, 784)               0         
                                                                 
 dense_2809 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1885 (Dropout)      (None, 480)               0         
                                                                 
 dense_2810 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1886 (Dropout)      (None, 416)               0         
                                                                 
 dense_2811 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 925:
  Value: 0.9099
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006226009372545077

Model: "sequential_925"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_925 (Flatten)       (None, 784)               0         
                                                                 
 dense_2812 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1887 (Dropout)      (None, 448)               0         
                                                                 
 dense_2813 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1888 (Dropout)      (None, 480)               0         
                                                                 
 dense_2814 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 926:
  Value: 0.8281
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0012186643787208738

Model: "sequential_926"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_926 (Flatten)       (None, 784)               0         
                                                                 
 dense_2815 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1889 (Dropout)      (None, 512)               0         
                                                                 
 dense_2816 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 927:
  Value: 0.0387
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0010290112273453082

Model: "sequential_927"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_927 (Flatten)       (None, 784)               0         
                                                                 
 dense_2817 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1890 (Dropout)      (None, 416)               0         
                                                                 
 dense_2818 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1891 (Dropout)      (None, 448)               0         
                                                                 
 dense_2819 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 928:
  Value: 0.8963
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0002273790487591964

Model: "sequential_928"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_928 (Flatten)       (None, 784)               0         
                                                                 
 dense_2820 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1892 (Dropout)      (None, 480)               0         
                                                                 
 dense_2821 (Dense)          (None, 384)               184704    
                                                                 
 batch_normalization_168 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1893 (Dropout)      (None, 384)               0         
                                                                 
 dense_2822 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 573050 (2.19 MB)
Trainable params: 572282 (2.18 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 929:
  Value: 0.8635
  num_layers: 2
  units_0: 448
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003439991218310667

Model: "sequential_929"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_929 (Flatten)       (None, 784)               0         
                                                                 
 dense_2823 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1894 (Dropout)      (None, 448)               0         
                                                                 
 dense_2824 (Dense)          (None, 288)               129312    
                                                                 
 dropout_1895 (Dropout)      (None, 288)               0         
                                                                 
 dense_2825 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 488506 (1.86 MB)
Trainable params: 488506 (1.86 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 930:
  Value: 0.8668
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001502629116884445

Model: "sequential_930"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_930 (Flatten)       (None, 784)               0         
                                                                 
 dense_2826 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1896 (Dropout)      (None, 480)               0         
                                                                 
 dense_2827 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1897 (Dropout)      (None, 416)               0         
                                                                 
 dense_2828 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 931:
  Value: 0.8686
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00010201474660248066

Model: "sequential_931"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_931 (Flatten)       (None, 784)               0         
                                                                 
 dense_2829 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1898 (Dropout)      (None, 512)               0         
                                                                 
 dense_2830 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1899 (Dropout)      (None, 448)               0         
                                                                 
 dense_2831 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 932:
  Value: 0.8199
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.00025840927394126125

Model: "sequential_932"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_932 (Flatten)       (None, 784)               0         
                                                                 
 dense_2832 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_169 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1900 (Dropout)      (None, 512)               0         
                                                                 
 dense_2833 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1901 (Dropout)      (None, 416)               0         
                                                                 
 dense_2834 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 628218 (2.40 MB)
Trainable params: 627194 (2.39 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 933:
  Value: 0.8873
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008424517823888366

Model: "sequential_933"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_933 (Flatten)       (None, 784)               0         
                                                                 
 dense_2835 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1902 (Dropout)      (None, 448)               0         
                                                                 
 dense_2836 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1903 (Dropout)      (None, 480)               0         
                                                                 
 dense_2837 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 934:
  Value: 0.8507
  num_layers: 2
  units_0: 256
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007274818422635706

Model: "sequential_934"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_934 (Flatten)       (None, 784)               0         
                                                                 
 dense_2838 (Dense)          (None, 256)               200960    
                                                                 
 dropout_1904 (Dropout)      (None, 256)               0         
                                                                 
 dense_2839 (Dense)          (None, 448)               115136    
                                                                 
 dropout_1905 (Dropout)      (None, 448)               0         
                                                                 
 dense_2840 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 327770 (1.25 MB)
Trainable params: 327770 (1.25 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 935:
  Value: 0.8695
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00029437633576904576

Model: "sequential_935"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_935 (Flatten)       (None, 784)               0         
                                                                 
 dense_2841 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1906 (Dropout)      (None, 480)               0         
                                                                 
 dense_2842 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1907 (Dropout)      (None, 384)               0         
                                                                 
 dense_2843 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 936:
  Value: 0.8557
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006727899488302435

Model: "sequential_936"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_936 (Flatten)       (None, 784)               0         
                                                                 
 dense_2844 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1908 (Dropout)      (None, 480)               0         
                                                                 
 dense_2845 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1909 (Dropout)      (None, 416)               0         
                                                                 
 dense_2846 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 937:
  Value: 0.8077
  num_layers: 2
  units_0: 416
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00040044664555548016

Model: "sequential_937"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_937 (Flatten)       (None, 784)               0         
                                                                 
 dense_2847 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1910 (Dropout)      (None, 416)               0         
                                                                 
 dense_2848 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1911 (Dropout)      (None, 448)               0         
                                                                 
 dense_2849 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 525050 (2.00 MB)
Trainable params: 525050 (2.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 938:
  Value: 0.9062
  num_layers: 2
  units_0: 512
  units_1: 512
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014405083504036912

Model: "sequential_938"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_938 (Flatten)       (None, 784)               0         
                                                                 
 dense_2850 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1912 (Dropout)      (None, 512)               0         
                                                                 
 dense_2851 (Dense)          (None, 512)               262656    
                                                                 
 dropout_1913 (Dropout)      (None, 512)               0         
                                                                 
 dense_2852 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 677914 (2.59 MB)
Trainable params: 677914 (2.59 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 939:
  Value: 0.8126
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.0007462666066992345

Model: "sequential_939"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_939 (Flatten)       (None, 784)               0         
                                                                 
 dense_2853 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1914 (Dropout)      (None, 448)               0         
                                                                 
 dense_2854 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1915 (Dropout)      (None, 384)               0         
                                                                 
 dense_2855 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 940:
  Value: 0.9073
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00274619577709679

Model: "sequential_940"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_940 (Flatten)       (None, 784)               0         
                                                                 
 dense_2856 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1916 (Dropout)      (None, 480)               0         
                                                                 
 dense_2857 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1917 (Dropout)      (None, 416)               0         
                                                                 
 dense_2858 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 941:
  Value: 0.8788
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005566714492457448

Model: "sequential_941"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_941 (Flatten)       (None, 784)               0         
                                                                 
 dense_2859 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1918 (Dropout)      (None, 448)               0         
                                                                 
 dense_2860 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1919 (Dropout)      (None, 448)               0         
                                                                 
 dense_2861 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 942:
  Value: 0.8688
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006701796586100434

Model: "sequential_942"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_942 (Flatten)       (None, 784)               0         
                                                                 
 dense_2862 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1920 (Dropout)      (None, 512)               0         
                                                                 
 dense_2863 (Dense)          (None, 352)               180576    
                                                                 
 dropout_1921 (Dropout)      (None, 352)               0         
                                                                 
 dense_2864 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 943:
  Value: 0.7501
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001760090733401845

Model: "sequential_943"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_943 (Flatten)       (None, 784)               0         
                                                                 
 dense_2865 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1922 (Dropout)      (None, 512)               0         
                                                                 
 dense_2866 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1923 (Dropout)      (None, 480)               0         
                                                                 
 dense_2867 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 944:
  Value: 0.1574
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0031583112312637573

Model: "sequential_944"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_944 (Flatten)       (None, 784)               0         
                                                                 
 dense_2868 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1924 (Dropout)      (None, 480)               0         
                                                                 
 dense_2869 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1925 (Dropout)      (None, 416)               0         
                                                                 
 dense_2870 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 945:
  Value: 0.8971
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00031792739349158385

Model: "sequential_945"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_945 (Flatten)       (None, 784)               0         
                                                                 
 dense_2871 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1926 (Dropout)      (None, 480)               0         
                                                                 
 dense_2872 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1927 (Dropout)      (None, 480)               0         
                                                                 
 dense_2873 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 946:
  Value: 0.8982
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00018665280886421876

Model: "sequential_946"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_946 (Flatten)       (None, 784)               0         
                                                                 
 dense_2874 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1928 (Dropout)      (None, 448)               0         
                                                                 
 dense_2875 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1929 (Dropout)      (None, 448)               0         
                                                                 
 dense_2876 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 947:
  Value: 0.8877
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0023417615430643118

Model: "sequential_947"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_947 (Flatten)       (None, 784)               0         
                                                                 
 dense_2877 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1930 (Dropout)      (None, 480)               0         
                                                                 
 dense_2878 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1931 (Dropout)      (None, 416)               0         
                                                                 
 dense_2879 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 948:
  Value: 0.8916
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.00025257054142637734

Model: "sequential_948"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_948 (Flatten)       (None, 784)               0         
                                                                 
 dense_2880 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1932 (Dropout)      (None, 512)               0         
                                                                 
 dense_2881 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_170 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1933 (Dropout)      (None, 448)               0         
                                                                 
 dense_2882 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 645210 (2.46 MB)
Trainable params: 644314 (2.46 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 949:
  Value: 0.9061
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00021714987239761216

Model: "sequential_949"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_949 (Flatten)       (None, 784)               0         
                                                                 
 dense_2883 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1934 (Dropout)      (None, 480)               0         
                                                                 
 dense_2884 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1935 (Dropout)      (None, 416)               0         
                                                                 
 dense_2885 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 950:
  Value: 0.8544
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004695986787143134

Model: "sequential_950"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_950 (Flatten)       (None, 784)               0         
                                                                 
 dense_2886 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_171 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1936 (Dropout)      (None, 448)               0         
                                                                 
 dense_2887 (Dense)          (None, 384)               172416    
                                                                 
 dropout_1937 (Dropout)      (None, 384)               0         
                                                                 
 dense_2888 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 535898 (2.04 MB)
Trainable params: 535002 (2.04 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 951:
  Value: 0.9078
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012982115587922382

Model: "sequential_951"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_951 (Flatten)       (None, 784)               0         
                                                                 
 dense_2889 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1938 (Dropout)      (None, 512)               0         
                                                                 
 dense_2890 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1939 (Dropout)      (None, 448)               0         
                                                                 
 dense_2891 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 952:
  Value: 0.3296
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0045726862377823895

Model: "sequential_952"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_952 (Flatten)       (None, 784)               0         
                                                                 
 dense_2892 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1940 (Dropout)      (None, 416)               0         
                                                                 
 dense_2893 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1941 (Dropout)      (None, 416)               0         
                                                                 
 dense_2894 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 953:
  Value: 0.8645
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00817469244697277

Model: "sequential_953"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_953 (Flatten)       (None, 784)               0         
                                                                 
 dense_2895 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1942 (Dropout)      (None, 480)               0         
                                                                 
 dense_2896 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1943 (Dropout)      (None, 320)               0         
                                                                 
 dense_2897 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 954:
  Value: 0.8663
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0016464787200182278

Model: "sequential_954"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_954 (Flatten)       (None, 784)               0         
                                                                 
 dense_2898 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1944 (Dropout)      (None, 448)               0         
                                                                 
 dense_2899 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1945 (Dropout)      (None, 448)               0         
                                                                 
 dense_2900 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 955:
  Value: 0.8157
  num_layers: 2
  units_0: 96
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003583598913325843

Model: "sequential_955"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_955 (Flatten)       (None, 784)               0         
                                                                 
 dense_2901 (Dense)          (None, 96)                75360     
                                                                 
 dropout_1946 (Dropout)      (None, 96)                0         
                                                                 
 dense_2902 (Dense)          (None, 480)               46560     
                                                                 
 dropout_1947 (Dropout)      (None, 480)               0         
                                                                 
 dense_2903 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 134426 (525.10 KB)
Trainable params: 134426 (525.10 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 956:
  Value: 0.0385
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0025744548605856716

Model: "sequential_956"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_956 (Flatten)       (None, 784)               0         
                                                                 
 dense_2904 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1948 (Dropout)      (None, 512)               0         
                                                                 
 dense_2905 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1949 (Dropout)      (None, 384)               0         
                                                                 
 dense_2906 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 957:
  Value: 0.8672
  num_layers: 2
  units_0: 480
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0019640737021368966

Model: "sequential_957"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_957 (Flatten)       (None, 784)               0         
                                                                 
 dense_2907 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1950 (Dropout)      (None, 480)               0         
                                                                 
 dense_2908 (Dense)          (None, 352)               169312    
                                                                 
 dropout_1951 (Dropout)      (None, 352)               0         
                                                                 
 dense_2909 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 555290 (2.12 MB)
Trainable params: 555290 (2.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 958:
  Value: 0.8660
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009994347625887853

Model: "sequential_958"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_958 (Flatten)       (None, 784)               0         
                                                                 
 dense_2910 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1952 (Dropout)      (None, 448)               0         
                                                                 
 dense_2911 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1953 (Dropout)      (None, 416)               0         
                                                                 
 dense_2912 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 959:
  Value: 0.7011
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: tanh
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0034982396885265073

Model: "sequential_959"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_959 (Flatten)       (None, 784)               0         
                                                                 
 dense_2913 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1954 (Dropout)      (None, 512)               0         
                                                                 
 dense_2914 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1955 (Dropout)      (None, 448)               0         
                                                                 
 dense_2915 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 960:
  Value: 0.8689
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00042693862194821247

Model: "sequential_960"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_960 (Flatten)       (None, 784)               0         
                                                                 
 dense_2916 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1956 (Dropout)      (None, 480)               0         
                                                                 
 dense_2917 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1957 (Dropout)      (None, 416)               0         
                                                                 
 dense_2918 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 961:
  Value: 0.8687
  num_layers: 2
  units_0: 480
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00013250099740498038

Model: "sequential_961"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_961 (Flatten)       (None, 784)               0         
                                                                 
 dense_2919 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1958 (Dropout)      (None, 480)               0         
                                                                 
 dense_2920 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1959 (Dropout)      (None, 384)               0         
                                                                 
 dense_2921 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 571514 (2.18 MB)
Trainable params: 571514 (2.18 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 962:
  Value: 0.9012
  num_layers: 2
  units_0: 512
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.001118052453145247

Model: "sequential_962"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_962 (Flatten)       (None, 784)               0         
                                                                 
 dense_2922 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1960 (Dropout)      (None, 512)               0         
                                                                 
 dense_2923 (Dense)          (None, 480)               246240    
                                                                 
 dropout_1961 (Dropout)      (None, 480)               0         
                                                                 
 dense_2924 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 660666 (2.52 MB)
Trainable params: 660666 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 963:
  Value: 0.8688
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00038883466466365014

Model: "sequential_963"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_963 (Flatten)       (None, 784)               0         
                                                                 
 dense_2925 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1962 (Dropout)      (None, 448)               0         
                                                                 
 dense_2926 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1963 (Dropout)      (None, 416)               0         
                                                                 
 dense_2927 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 964:
  Value: 0.8682
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005135964751952757

Model: "sequential_964"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_964 (Flatten)       (None, 784)               0         
                                                                 
 dense_2928 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1964 (Dropout)      (None, 512)               0         
                                                                 
 dense_2929 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1965 (Dropout)      (None, 448)               0         
                                                                 
 dense_2930 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 965:
  Value: 0.7485
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0015197804961369975

Model: "sequential_965"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_965 (Flatten)       (None, 784)               0         
                                                                 
 dense_2931 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1966 (Dropout)      (None, 448)               0         
                                                                 
 dense_2932 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1967 (Dropout)      (None, 448)               0         
                                                                 
 dense_2933 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 966:
  Value: 0.9086
  num_layers: 3
  units_0: 480
  units_1: 512
  units_2: 416
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.00014881244078522032

Model: "sequential_966"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_966 (Flatten)       (None, 784)               0         
                                                                 
 dense_2934 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1968 (Dropout)      (None, 480)               0         
                                                                 
 dense_2935 (Dense)          (None, 512)               246272    
                                                                 
 dropout_1969 (Dropout)      (None, 512)               0         
                                                                 
 dense_2936 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_172 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1970 (Dropout)      (None, 416)               0         
                                                                 
 dense_2937 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 848986 (3.24 MB)
Trainable params: 848154 (3.24 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 967:
  Value: 0.8272
  num_layers: 2
  units_0: 160
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: True
  optimizer: rmsprop
  learning_rate: 0.00024423575664093663

Model: "sequential_967"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_967 (Flatten)       (None, 784)               0         
                                                                 
 dense_2938 (Dense)          (None, 160)               125600    
                                                                 
 dropout_1971 (Dropout)      (None, 160)               0         
                                                                 
 dense_2939 (Dense)          (None, 384)               61824     
                                                                 
 batch_normalization_173 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1972 (Dropout)      (None, 384)               0         
                                                                 
 dense_2940 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 198970 (777.23 KB)
Trainable params: 198202 (774.23 KB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 968:
  Value: 0.9088
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0008445229886655456

Model: "sequential_968"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_968 (Flatten)       (None, 784)               0         
                                                                 
 dense_2941 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1973 (Dropout)      (None, 480)               0         
                                                                 
 dense_2942 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1974 (Dropout)      (None, 480)               0         
                                                                 
 dense_2943 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 969:
  Value: 0.9102
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00031900226989646356

Model: "sequential_969"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_969 (Flatten)       (None, 784)               0         
                                                                 
 dense_2944 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1975 (Dropout)      (None, 512)               0         
                                                                 
 dense_2945 (Dense)          (None, 352)               180576    
                                                                 
 dropout_1976 (Dropout)      (None, 352)               0         
                                                                 
 dense_2946 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 970:
  Value: 0.2045
  num_layers: 2
  units_0: 416
  units_1: 416
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.001029012795121738

Model: "sequential_970"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_970 (Flatten)       (None, 784)               0         
                                                                 
 dense_2947 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1977 (Dropout)      (None, 416)               0         
                                                                 
 dense_2948 (Dense)          (None, 416)               173472    
                                                                 
 dropout_1978 (Dropout)      (None, 416)               0         
                                                                 
 dense_2949 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 510874 (1.95 MB)
Trainable params: 510874 (1.95 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 971:
  Value: 0.8025
  num_layers: 2
  units_0: 448
  units_1: 32
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017103675463735419

Model: "sequential_971"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_971 (Flatten)       (None, 784)               0         
                                                                 
 dense_2950 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_174 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1979 (Dropout)      (None, 448)               0         
                                                                 
 dense_2951 (Dense)          (None, 32)                14368     
                                                                 
 dropout_1980 (Dropout)      (None, 32)                0         
                                                                 
 dense_2952 (Dense)          (None, 26)                858       
                                                                 
=================================================================
Total params: 368698 (1.41 MB)
Trainable params: 367802 (1.40 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 972:
  Value: 0.8284
  num_layers: 1
  units_0: 480
  activation_0: relu
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.007655744541359301

Model: "sequential_972"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_972 (Flatten)       (None, 784)               0         
                                                                 
 dense_2953 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1981 (Dropout)      (None, 480)               0         
                                                                 
 dense_2954 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 973:
  Value: 0.8582
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.5
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00020304619094279656

Model: "sequential_973"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_973 (Flatten)       (None, 784)               0         
                                                                 
 dense_2955 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1982 (Dropout)      (None, 512)               0         
                                                                 
 dense_2956 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1983 (Dropout)      (None, 416)               0         
                                                                 
 dense_2957 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 974:
  Value: 0.8875
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0065598950395008414

Model: "sequential_974"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_974 (Flatten)       (None, 784)               0         
                                                                 
 dense_2958 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1984 (Dropout)      (None, 480)               0         
                                                                 
 dense_2959 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1985 (Dropout)      (None, 448)               0         
                                                                 
 dense_2960 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 975:
  Value: 0.9101
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0007480686815744091

Model: "sequential_975"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_975 (Flatten)       (None, 784)               0         
                                                                 
 dense_2961 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1986 (Dropout)      (None, 512)               0         
                                                                 
 dense_2962 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1987 (Dropout)      (None, 448)               0         
                                                                 
 dense_2963 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 976:
  Value: 0.8458
  num_layers: 2
  units_0: 224
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005655638529753895

Model: "sequential_976"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_976 (Flatten)       (None, 784)               0         
                                                                 
 dense_2964 (Dense)          (None, 224)               175840    
                                                                 
 dropout_1988 (Dropout)      (None, 224)               0         
                                                                 
 dense_2965 (Dense)          (None, 384)               86400     
                                                                 
 dropout_1989 (Dropout)      (None, 384)               0         
                                                                 
 dense_2966 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 272250 (1.04 MB)
Trainable params: 272250 (1.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 977:
  Value: 0.9090
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013516264247893483

Model: "sequential_977"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_977 (Flatten)       (None, 784)               0         
                                                                 
 dense_2967 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1990 (Dropout)      (None, 448)               0         
                                                                 
 dense_2968 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1991 (Dropout)      (None, 480)               0         
                                                                 
 dense_2969 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 978:
  Value: 0.3597
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0009405350742117983

Model: "sequential_978"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_978 (Flatten)       (None, 784)               0         
                                                                 
 dense_2970 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1992 (Dropout)      (None, 480)               0         
                                                                 
 dense_2971 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1993 (Dropout)      (None, 416)               0         
                                                                 
 dense_2972 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 979:
  Value: 0.8356
  num_layers: 2
  units_0: 192
  units_1: 448
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00027425326421585467

Model: "sequential_979"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_979 (Flatten)       (None, 784)               0         
                                                                 
 dense_2973 (Dense)          (None, 192)               150720    
                                                                 
 dropout_1994 (Dropout)      (None, 192)               0         
                                                                 
 dense_2974 (Dense)          (None, 448)               86464     
                                                                 
 dropout_1995 (Dropout)      (None, 448)               0         
                                                                 
 dense_2975 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 248858 (972.10 KB)
Trainable params: 248858 (972.10 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 980:
  Value: 0.8872
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0028844628741742017

Model: "sequential_980"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_980 (Flatten)       (None, 784)               0         
                                                                 
 dense_2976 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1996 (Dropout)      (None, 480)               0         
                                                                 
 dense_2977 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1997 (Dropout)      (None, 416)               0         
                                                                 
 dense_2978 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 587738 (2.24 MB)
Trainable params: 587738 (2.24 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 981:
  Value: 0.8101
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0006490974048196254

Model: "sequential_981"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_981 (Flatten)       (None, 784)               0         
                                                                 
 dense_2979 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1998 (Dropout)      (None, 512)               0         
                                                                 
 dense_2980 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1999 (Dropout)      (None, 384)               0         
                                                                 
 dense_2981 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 982:
  Value: 0.8684
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0012077624388973978

Model: "sequential_982"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_982 (Flatten)       (None, 784)               0         
                                                                 
 dense_2982 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2000 (Dropout)      (None, 448)               0         
                                                                 
 dense_2983 (Dense)          (None, 480)               215520    
                                                                 
 dropout_2001 (Dropout)      (None, 480)               0         
                                                                 
 dense_2984 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 579706 (2.21 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 983:
  Value: 0.8792
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: relu
  activation_1: relu
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009009871904378741

Model: "sequential_983"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_983 (Flatten)       (None, 784)               0         
                                                                 
 dense_2985 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2002 (Dropout)      (None, 512)               0         
                                                                 
 dense_2986 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2003 (Dropout)      (None, 352)               0         
                                                                 
 dense_2987 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 591674 (2.26 MB)
Trainable params: 591674 (2.26 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 984:
  Value: 0.0387
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0017685931371405578

Model: "sequential_984"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_984 (Flatten)       (None, 784)               0         
                                                                 
 dense_2988 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2004 (Dropout)      (None, 448)               0         
                                                                 
 dense_2989 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2005 (Dropout)      (None, 448)               0         
                                                                 
 dense_2990 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 985:
  Value: 0.7491
  num_layers: 2
  units_0: 480
  units_1: 416
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.005386174889685477

Model: "sequential_985"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_985 (Flatten)       (None, 784)               0         
                                                                 
 dense_2991 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2006 (Dropout)      (None, 480)               0         
                                                                 
 dense_2992 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_175 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_2007 (Dropout)      (None, 416)               0         
                                                                 
 dense_2993 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 589402 (2.25 MB)
Trainable params: 588570 (2.25 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 986:
  Value: 0.9075
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.002154658916060079

Model: "sequential_986"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_986 (Flatten)       (None, 784)               0         
                                                                 
 dense_2994 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2008 (Dropout)      (None, 480)               0         
                                                                 
 dense_2995 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2009 (Dropout)      (None, 448)               0         
                                                                 
 dense_2996 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 987:
  Value: 0.7840
  num_layers: 2
  units_0: 288
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.004166376587158793

Model: "sequential_987"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_987 (Flatten)       (None, 784)               0         
                                                                 
 dense_2997 (Dense)          (None, 288)               226080    
                                                                 
 dropout_2010 (Dropout)      (None, 288)               0         
                                                                 
 dense_2998 (Dense)          (None, 416)               120224    
                                                                 
 dropout_2011 (Dropout)      (None, 416)               0         
                                                                 
 dense_2999 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 357146 (1.36 MB)
Trainable params: 357146 (1.36 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 988:
  Value: 0.8646
  num_layers: 2
  units_0: 416
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002979007946256822

Model: "sequential_988"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_988 (Flatten)       (None, 784)               0         
                                                                 
 dense_3000 (Dense)          (None, 416)               326560    
                                                                 
 batch_normalization_176 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_2012 (Dropout)      (None, 416)               0         
                                                                 
 dense_3001 (Dense)          (None, 384)               160128    
                                                                 
 dropout_2013 (Dropout)      (None, 384)               0         
                                                                 
 dense_3002 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 498362 (1.90 MB)
Trainable params: 497530 (1.90 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 989:
  Value: 0.9020
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00012421409530151534

Model: "sequential_989"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_989 (Flatten)       (None, 784)               0         
                                                                 
 dense_3003 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2014 (Dropout)      (None, 448)               0         
                                                                 
 dense_3004 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2015 (Dropout)      (None, 448)               0         
                                                                 
 dense_3005 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 990:
  Value: 0.9032
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0003418353518910243

Model: "sequential_990"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_990 (Flatten)       (None, 784)               0         
                                                                 
 dense_3006 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2016 (Dropout)      (None, 512)               0         
                                                                 
 dense_3007 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2017 (Dropout)      (None, 416)               0         
                                                                 
 dense_3008 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 991:
  Value: 0.8661
  num_layers: 2
  units_0: 448
  units_1: 384
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00042463535365268095

Model: "sequential_991"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_991 (Flatten)       (None, 784)               0         
                                                                 
 dense_3009 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2018 (Dropout)      (None, 448)               0         
                                                                 
 dense_3010 (Dense)          (None, 384)               172416    
                                                                 
 dropout_2019 (Dropout)      (None, 384)               0         
                                                                 
 dense_3011 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 534106 (2.04 MB)
Trainable params: 534106 (2.04 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 992:
  Value: 0.9009
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.007154794519769048

Model: "sequential_992"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_992 (Flatten)       (None, 784)               0         
                                                                 
 dense_3012 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2020 (Dropout)      (None, 480)               0         
                                                                 
 dense_3013 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2021 (Dropout)      (None, 448)               0         
                                                                 
 dense_3014 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 993:
  Value: 0.8649
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.004606852849530615

Model: "sequential_993"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_993 (Flatten)       (None, 784)               0         
                                                                 
 dense_3015 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2022 (Dropout)      (None, 512)               0         
                                                                 
 dense_3016 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2023 (Dropout)      (None, 416)               0         
                                                                 
 dense_3017 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 994:
  Value: 0.8190
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: rmsprop
  learning_rate: 0.002437085127845845

Model: "sequential_994"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_994 (Flatten)       (None, 784)               0         
                                                                 
 dense_3018 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2024 (Dropout)      (None, 480)               0         
                                                                 
 dense_3019 (Dense)          (None, 480)               230880    
                                                                 
 dropout_2025 (Dropout)      (None, 480)               0         
                                                                 
 dense_3020 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 995:
  Value: 0.8670
  num_layers: 2
  units_0: 512
  units_1: 288
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0037943691454245835

Model: "sequential_995"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_995 (Flatten)       (None, 784)               0         
                                                                 
 dense_3021 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2026 (Dropout)      (None, 512)               0         
                                                                 
 dense_3022 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2027 (Dropout)      (None, 288)               0         
                                                                 
 dense_3023 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 557178 (2.13 MB)
Trainable params: 557178 (2.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 996:
  Value: 0.8659
  num_layers: 2
  units_0: 480
  units_1: 320
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0014341107421215725

Model: "sequential_996"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_996 (Flatten)       (None, 784)               0         
                                                                 
 dense_3024 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2028 (Dropout)      (None, 480)               0         
                                                                 
 dense_3025 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2029 (Dropout)      (None, 320)               0         
                                                                 
 dense_3026 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 539066 (2.06 MB)
Trainable params: 539066 (2.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 997:
  Value: 0.8685
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: relu
  dropout_0: 0.2
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0005987279830146327

Model: "sequential_997"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_997 (Flatten)       (None, 784)               0         
                                                                 
 dense_3027 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2030 (Dropout)      (None, 448)               0         
                                                                 
 dense_3028 (Dense)          (None, 416)               186784    
                                                                 
 dropout_2031 (Dropout)      (None, 416)               0         
                                                                 
 dense_3029 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 998:
  Value: 0.9108
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0004906897420899561

Model: "sequential_998"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_998 (Flatten)       (None, 784)               0         
                                                                 
 dense_3030 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2032 (Dropout)      (None, 480)               0         
                                                                 
 dense_3031 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2033 (Dropout)      (None, 448)               0         
                                                                 
 dense_3032 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 999:
  Value: 0.9052
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002376874887966593

Model: "sequential_999"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_999 (Flatten)       (None, 784)               0         
                                                                 
 dense_3033 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2034 (Dropout)      (None, 480)               0         
                                                                 
 dense_3034 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2035 (Dropout)      (None, 448)               0         
                                                                 
 dense_3035 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 0:
  Value: 0.5785
  num_layers: 3
  units_0: 32
  units_1: 64
  units_2: 384
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.0
  dropout_2: 0.5
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: adagrad
  learning_rate: 0.0031221639239710536

Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 32)                25120     
                                                                 
 dropout (Dropout)           (None, 32)                0         
                                                                 
 dense_1 (Dense)             (None, 64)                2112      
                                                                 
 batch_normalization (Batch  (None, 64)                256       
 Normalization)                                                  
                                                                 
 dropout_1 (Dropout)         (None, 64)                0         
                                                                 
 dense_2 (Dense)             (None, 384)               24960     
                                                                 
 batch_normalization_1 (Bat  (None, 384)               1536      
 chNormalization)                                                
                                                                 
 dropout_2 (Dropout)         (None, 384)               0         
                                                                 
 dense_3 (Dense)             (None, 26)                10010     
                                                                 
=================================================================
Total params: 63994 (249.98 KB)
Trainable params: 63098 (246.48 KB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 0:
  Value: 0.7049
  num_layers: 1
  units_0: 480
  activation_0: sigmoid
  dropout_0: 0.30000000000000004
  batch_norm_0: True
  optimizer: sgd
  learning_rate: 0.0001640987934020905

Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 480)               376800    
                                                                 
 batch_normalization (Batch  (None, 480)               1920      
 Normalization)                                                  
                                                                 
 dropout (Dropout)           (None, 480)               0         
                                                                 
 dense_1 (Dense)             (None, 26)                12506     
                                                                 
=================================================================
Total params: 391226 (1.49 MB)
Trainable params: 390266 (1.49 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 1:
  Value: 0.7274
  num_layers: 1
  units_0: 288
  activation_0: tanh
  dropout_0: 0.0
  batch_norm_0: True
  optimizer: adagrad
  learning_rate: 0.004403730905561369

Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_1 (Flatten)         (None, 784)               0         
                                                                 
 dense_2 (Dense)             (None, 288)               226080    
                                                                 
 batch_normalization_1 (Bat  (None, 288)               1152      
 chNormalization)                                                
                                                                 
 dropout_1 (Dropout)         (None, 288)               0         
                                                                 
 dense_3 (Dense)             (None, 26)                7514      
                                                                 
=================================================================
Total params: 234746 (916.98 KB)
Trainable params: 234170 (914.73 KB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 2:
  Value: 0.9093
  num_layers: 4
  units_0: 320
  units_1: 256
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001711969972470454

Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_2 (Flatten)         (None, 784)               0         
                                                                 
 dense_4 (Dense)             (None, 320)               251200    
                                                                 
 dropout_2 (Dropout)         (None, 320)               0         
                                                                 
 dense_5 (Dense)             (None, 256)               82176     
                                                                 
 dropout_3 (Dropout)         (None, 256)               0         
                                                                 
 dense_6 (Dense)             (None, 288)               74016     
                                                                 
 batch_normalization_2 (Bat  (None, 288)               1152      
 chNormalization)                                                
                                                                 
 dropout_4 (Dropout)         (None, 288)               0         
                                                                 
 dense_7 (Dense)             (None, 512)               147968    
                                                                 
 batch_normalization_3 (Bat  (None, 512)               2048      
 chNormalization)                                                
                                                                 
 dropout_5 (Dropout)         (None, 512)               0         
                                                                 
 dense_8 (Dense)             (None, 26)                13338     
                                                                 
=================================================================
Total params: 571898 (2.18 MB)
Trainable params: 570298 (2.18 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 3:
  Value: 0.8840
  num_layers: 1
  units_0: 224
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: True
  optimizer: adam
  learning_rate: 0.0022184808437199378

Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_3 (Flatten)         (None, 784)               0         
                                                                 
 dense_9 (Dense)             (None, 224)               175840    
                                                                 
 batch_normalization_4 (Bat  (None, 224)               896       
 chNormalization)                                                
                                                                 
 dropout_6 (Dropout)         (None, 224)               0         
                                                                 
 dense_10 (Dense)            (None, 26)                5850      
                                                                 
=================================================================
Total params: 182586 (713.23 KB)
Trainable params: 182138 (711.48 KB)
Non-trainable params: 448 (1.75 KB)
_________________________________________________________________



Trial 4:
  Value: 0.8188
  num_layers: 3
  units_0: 480
  units_1: 416
  units_2: 160
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: True
  optimizer: adagrad
  learning_rate: 0.001358333913939465

Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_4 (Flatten)         (None, 784)               0         
                                                                 
 dense_11 (Dense)            (None, 480)               376800    
                                                                 
 batch_normalization_5 (Bat  (None, 480)               1920      
 chNormalization)                                                
                                                                 
 dropout_7 (Dropout)         (None, 480)               0         
                                                                 
 dense_12 (Dense)            (None, 416)               200096    
                                                                 
 batch_normalization_6 (Bat  (None, 416)               1664      
 chNormalization)                                                
                                                                 
 dropout_8 (Dropout)         (None, 416)               0         
                                                                 
 dense_13 (Dense)            (None, 160)               66720     
                                                                 
 batch_normalization_7 (Bat  (None, 160)               640       
 chNormalization)                                                
                                                                 
 dropout_9 (Dropout)         (None, 160)               0         
                                                                 
 dense_14 (Dense)            (None, 26)                4186      
                                                                 
=================================================================
Total params: 652026 (2.49 MB)
Trainable params: 649914 (2.48 MB)
Non-trainable params: 2112 (8.25 KB)
_________________________________________________________________



Trial 5:
  Value: 0.8893
  num_layers: 2
  units_0: 480
  units_1: 96
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.0
  batch_norm_0: True
  batch_norm_1: True
  optimizer: adamax
  learning_rate: 0.0006812095641607617

Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_5 (Flatten)         (None, 784)               0         
                                                                 
 dense_15 (Dense)            (None, 480)               376800    
                                                                 
 batch_normalization_8 (Bat  (None, 480)               1920      
 chNormalization)                                                
                                                                 
 dropout_10 (Dropout)        (None, 480)               0         
                                                                 
 dense_16 (Dense)            (None, 96)                46176     
                                                                 
 batch_normalization_9 (Bat  (None, 96)                384       
 chNormalization)                                                
                                                                 
 dropout_11 (Dropout)        (None, 96)                0         
                                                                 
 dense_17 (Dense)            (None, 26)                2522      
                                                                 
=================================================================
Total params: 427802 (1.63 MB)
Trainable params: 426650 (1.63 MB)
Non-trainable params: 1152 (4.50 KB)
_________________________________________________________________



Trial 6:
  Value: 0.7888
  num_layers: 3
  units_0: 64
  units_1: 352
  units_2: 64
  activation_0: sigmoid
  activation_1: tanh
  activation_2: sigmoid
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.5
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: rmsprop
  learning_rate: 0.0013175168050635318

Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_6 (Flatten)         (None, 784)               0         
                                                                 
 dense_18 (Dense)            (None, 64)                50240     
                                                                 
 dropout_12 (Dropout)        (None, 64)                0         
                                                                 
 dense_19 (Dense)            (None, 352)               22880     
                                                                 
 batch_normalization_10 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_13 (Dropout)        (None, 352)               0         
                                                                 
 dense_20 (Dense)            (None, 64)                22592     
                                                                 
 batch_normalization_11 (Ba  (None, 64)                256       
 tchNormalization)                                               
                                                                 
 dropout_14 (Dropout)        (None, 64)                0         
                                                                 
 dense_21 (Dense)            (None, 26)                1690      
                                                                 
=================================================================
Total params: 99066 (386.98 KB)
Trainable params: 98234 (383.73 KB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 7:
  Value: 0.6840
  num_layers: 1
  units_0: 32
  activation_0: sigmoid
  dropout_0: 0.5
  batch_norm_0: False
  optimizer: adamax
  learning_rate: 0.004988662502721844

Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_7 (Flatten)         (None, 784)               0         
                                                                 
 dense_22 (Dense)            (None, 32)                25120     
                                                                 
 dropout_15 (Dropout)        (None, 32)                0         
                                                                 
 dense_23 (Dense)            (None, 26)                858       
                                                                 
=================================================================
Total params: 25978 (101.48 KB)
Trainable params: 25978 (101.48 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 8:
  Value: 0.0381
  num_layers: 3
  units_0: 256
  units_1: 160
  units_2: 32
  activation_0: sigmoid
  activation_1: tanh
  activation_2: tanh
  dropout_0: 0.2
  dropout_1: 0.0
  dropout_2: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: False
  optimizer: ftrl
  learning_rate: 0.005546398646919532

Model: "sequential_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_8 (Flatten)         (None, 784)               0         
                                                                 
 dense_24 (Dense)            (None, 256)               200960    
                                                                 
 dropout_16 (Dropout)        (None, 256)               0         
                                                                 
 dense_25 (Dense)            (None, 160)               41120     
                                                                 
 batch_normalization_12 (Ba  (None, 160)               640       
 tchNormalization)                                               
                                                                 
 dropout_17 (Dropout)        (None, 160)               0         
                                                                 
 dense_26 (Dense)            (None, 32)                5152      
                                                                 
 dropout_18 (Dropout)        (None, 32)                0         
                                                                 
 dense_27 (Dense)            (None, 26)                858       
                                                                 
=================================================================
Total params: 248730 (971.60 KB)
Trainable params: 248410 (970.35 KB)
Non-trainable params: 320 (1.25 KB)
_________________________________________________________________



Trial 9:
  Value: 0.7179
  num_layers: 1
  units_0: 96
  activation_0: relu
  dropout_0: 0.5
  batch_norm_0: True
  optimizer: adagrad
  learning_rate: 0.0004641892309648648

Model: "sequential_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_9 (Flatten)         (None, 784)               0         
                                                                 
 dense_28 (Dense)            (None, 96)                75360     
                                                                 
 batch_normalization_13 (Ba  (None, 96)                384       
 tchNormalization)                                               
                                                                 
 dropout_19 (Dropout)        (None, 96)                0         
                                                                 
 dense_29 (Dense)            (None, 26)                2522      
                                                                 
=================================================================
Total params: 78266 (305.73 KB)
Trainable params: 78074 (304.98 KB)
Non-trainable params: 192 (768.00 Byte)
_________________________________________________________________



Trial 10:
  Value: 0.9108
  num_layers: 4
  units_0: 384
  units_1: 256
  units_2: 416
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001024373194326578

Model: "sequential_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_10 (Flatten)        (None, 784)               0         
                                                                 
 dense_30 (Dense)            (None, 384)               301440    
                                                                 
 dropout_20 (Dropout)        (None, 384)               0         
                                                                 
 dense_31 (Dense)            (None, 256)               98560     
                                                                 
 dropout_21 (Dropout)        (None, 256)               0         
                                                                 
 dense_32 (Dense)            (None, 416)               106912    
                                                                 
 batch_normalization_14 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_22 (Dropout)        (None, 416)               0         
                                                                 
 dense_33 (Dense)            (None, 512)               213504    
                                                                 
 batch_normalization_15 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_23 (Dropout)        (None, 512)               0         
                                                                 
 dense_34 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 737466 (2.81 MB)
Trainable params: 735610 (2.81 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 11:
  Value: 0.9148
  num_layers: 4
  units_0: 384
  units_1: 256
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010542557544083467

Model: "sequential_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_11 (Flatten)        (None, 784)               0         
                                                                 
 dense_35 (Dense)            (None, 384)               301440    
                                                                 
 dropout_24 (Dropout)        (None, 384)               0         
                                                                 
 dense_36 (Dense)            (None, 256)               98560     
                                                                 
 dropout_25 (Dropout)        (None, 256)               0         
                                                                 
 dense_37 (Dense)            (None, 384)               98688     
                                                                 
 batch_normalization_16 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_26 (Dropout)        (None, 384)               0         
                                                                 
 dense_38 (Dense)            (None, 512)               197120    
                                                                 
 batch_normalization_17 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_27 (Dropout)        (None, 512)               0         
                                                                 
 dense_39 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 712730 (2.72 MB)
Trainable params: 710938 (2.71 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 12:
  Value: 0.9114
  num_layers: 4
  units_0: 384
  units_1: 256
  units_2: 512
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010883911326583609

Model: "sequential_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_12 (Flatten)        (None, 784)               0         
                                                                 
 dense_40 (Dense)            (None, 384)               301440    
                                                                 
 dropout_28 (Dropout)        (None, 384)               0         
                                                                 
 dense_41 (Dense)            (None, 256)               98560     
                                                                 
 dropout_29 (Dropout)        (None, 256)               0         
                                                                 
 dense_42 (Dense)            (None, 512)               131584    
                                                                 
 batch_normalization_18 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_30 (Dropout)        (None, 512)               0         
                                                                 
 dense_43 (Dense)            (None, 512)               262656    
                                                                 
 batch_normalization_19 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_31 (Dropout)        (None, 512)               0         
                                                                 
 dense_44 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 811674 (3.10 MB)
Trainable params: 809626 (3.09 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 13:
  Value: 0.6205
  num_layers: 4
  units_0: 384
  units_1: 192
  units_2: 512
  units_3: 352
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0003248985788804618

Model: "sequential_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_13 (Flatten)        (None, 784)               0         
                                                                 
 dense_45 (Dense)            (None, 384)               301440    
                                                                 
 dropout_32 (Dropout)        (None, 384)               0         
                                                                 
 dense_46 (Dense)            (None, 192)               73920     
                                                                 
 dropout_33 (Dropout)        (None, 192)               0         
                                                                 
 dense_47 (Dense)            (None, 512)               98816     
                                                                 
 batch_normalization_20 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_34 (Dropout)        (None, 512)               0         
                                                                 
 dense_48 (Dense)            (None, 352)               180576    
                                                                 
 batch_normalization_21 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_35 (Dropout)        (None, 352)               0         
                                                                 
 dense_49 (Dense)            (None, 26)                9178      
                                                                 
=================================================================
Total params: 667386 (2.55 MB)
Trainable params: 665658 (2.54 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 14:
  Value: 0.9154
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 416
  units_3: 160
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001019590202312619

Model: "sequential_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_14 (Flatten)        (None, 784)               0         
                                                                 
 dense_50 (Dense)            (None, 384)               301440    
                                                                 
 dropout_36 (Dropout)        (None, 384)               0         
                                                                 
 dense_51 (Dense)            (None, 512)               197120    
                                                                 
 dropout_37 (Dropout)        (None, 512)               0         
                                                                 
 dense_52 (Dense)            (None, 416)               213408    
                                                                 
 dropout_38 (Dropout)        (None, 416)               0         
                                                                 
 dense_53 (Dense)            (None, 160)               66720     
                                                                 
 dropout_39 (Dropout)        (None, 160)               0         
                                                                 
 dense_54 (Dense)            (None, 26)                4186      
                                                                 
=================================================================
Total params: 782874 (2.99 MB)
Trainable params: 782874 (2.99 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 15:
  Value: 0.3255
  num_layers: 2
  units_0: 160
  units_1: 512
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.1
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: sgd
  learning_rate: 0.0002965572626940732

Model: "sequential_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_15 (Flatten)        (None, 784)               0         
                                                                 
 dense_55 (Dense)            (None, 160)               125600    
                                                                 
 dropout_40 (Dropout)        (None, 160)               0         
                                                                 
 dense_56 (Dense)            (None, 512)               82432     
                                                                 
 dropout_41 (Dropout)        (None, 512)               0         
                                                                 
 dense_57 (Dense)            (None, 26)                13338     
                                                                 
=================================================================
Total params: 221370 (864.73 KB)
Trainable params: 221370 (864.73 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 16:
  Value: 0.0393
  num_layers: 3
  units_0: 352
  units_1: 384
  units_2: 320
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  optimizer: ftrl
  learning_rate: 0.00022415029024407576

Model: "sequential_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_16 (Flatten)        (None, 784)               0         
                                                                 
 dense_58 (Dense)            (None, 352)               276320    
                                                                 
 dropout_42 (Dropout)        (None, 352)               0         
                                                                 
 dense_59 (Dense)            (None, 384)               135552    
                                                                 
 dropout_43 (Dropout)        (None, 384)               0         
                                                                 
 dense_60 (Dense)            (None, 320)               123200    
                                                                 
 dropout_44 (Dropout)        (None, 320)               0         
                                                                 
 dense_61 (Dense)            (None, 26)                8346      
                                                                 
=================================================================
Total params: 543418 (2.07 MB)
Trainable params: 543418 (2.07 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 17:
  Value: 0.5015
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 64
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  activation_3: relu
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.00010216760991898923

Model: "sequential_17"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_17 (Flatten)        (None, 784)               0         
                                                                 
 dense_62 (Dense)            (None, 448)               351680    
                                                                 
 dropout_45 (Dropout)        (None, 448)               0         
                                                                 
 dense_63 (Dense)            (None, 512)               229888    
                                                                 
 dropout_46 (Dropout)        (None, 512)               0         
                                                                 
 dense_64 (Dense)            (None, 384)               196992    
                                                                 
 dropout_47 (Dropout)        (None, 384)               0         
                                                                 
 dense_65 (Dense)            (None, 64)                24640     
                                                                 
 dropout_48 (Dropout)        (None, 64)                0         
                                                                 
 dense_66 (Dense)            (None, 26)                1690      
                                                                 
=================================================================
Total params: 804890 (3.07 MB)
Trainable params: 804890 (3.07 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 18:
  Value: 0.9049
  num_layers: 4
  units_0: 416
  units_1: 64
  units_2: 416
  units_3: 160
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.4
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004885857827431052

Model: "sequential_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_18 (Flatten)        (None, 784)               0         
                                                                 
 dense_67 (Dense)            (None, 416)               326560    
                                                                 
 dropout_49 (Dropout)        (None, 416)               0         
                                                                 
 dense_68 (Dense)            (None, 64)                26688     
                                                                 
 dropout_50 (Dropout)        (None, 64)                0         
                                                                 
 dense_69 (Dense)            (None, 416)               27040     
                                                                 
 dropout_51 (Dropout)        (None, 416)               0         
                                                                 
 dense_70 (Dense)            (None, 160)               66720     
                                                                 
 dropout_52 (Dropout)        (None, 160)               0         
                                                                 
 dense_71 (Dense)            (None, 26)                4186      
                                                                 
=================================================================
Total params: 451194 (1.72 MB)
Trainable params: 451194 (1.72 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 19:
  Value: 0.8506
  num_layers: 2
  units_0: 192
  units_1: 352
  activation_0: tanh
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00017604906255347163

Model: "sequential_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_19 (Flatten)        (None, 784)               0         
                                                                 
 dense_72 (Dense)            (None, 192)               150720    
                                                                 
 dropout_53 (Dropout)        (None, 192)               0         
                                                                 
 dense_73 (Dense)            (None, 352)               67936     
                                                                 
 dropout_54 (Dropout)        (None, 352)               0         
                                                                 
 dense_74 (Dense)            (None, 26)                9178      
                                                                 
=================================================================
Total params: 227834 (889.98 KB)
Trainable params: 227834 (889.98 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 20:
  Value: 0.9086
  num_layers: 3
  units_0: 320
  units_1: 448
  units_2: 192
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  optimizer: adam
  learning_rate: 0.0002773489547264875

Model: "sequential_20"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_20 (Flatten)        (None, 784)               0         
                                                                 
 dense_75 (Dense)            (None, 320)               251200    
                                                                 
 dropout_55 (Dropout)        (None, 320)               0         
                                                                 
 dense_76 (Dense)            (None, 448)               143808    
                                                                 
 dropout_56 (Dropout)        (None, 448)               0         
                                                                 
 dense_77 (Dense)            (None, 192)               86208     
                                                                 
 dropout_57 (Dropout)        (None, 192)               0         
                                                                 
 dense_78 (Dense)            (None, 26)                5018      
                                                                 
=================================================================
Total params: 486234 (1.85 MB)
Trainable params: 486234 (1.85 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 21:
  Value: 0.9120
  num_layers: 4
  units_0: 416
  units_1: 288
  units_2: 512
  units_3: 320
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010258616783767518

Model: "sequential_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_21 (Flatten)        (None, 784)               0         
                                                                 
 dense_79 (Dense)            (None, 416)               326560    
                                                                 
 dropout_58 (Dropout)        (None, 416)               0         
                                                                 
 dense_80 (Dense)            (None, 288)               120096    
                                                                 
 dropout_59 (Dropout)        (None, 288)               0         
                                                                 
 dense_81 (Dense)            (None, 512)               147968    
                                                                 
 batch_normalization_22 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_60 (Dropout)        (None, 512)               0         
                                                                 
 dense_82 (Dense)            (None, 320)               164160    
                                                                 
 batch_normalization_23 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_61 (Dropout)        (None, 320)               0         
                                                                 
 dense_83 (Dense)            (None, 26)                8346      
                                                                 
=================================================================
Total params: 770458 (2.94 MB)
Trainable params: 768794 (2.93 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 22:
  Value: 0.9110
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 448
  units_3: 256
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00014430882753276914

Model: "sequential_22"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_22 (Flatten)        (None, 784)               0         
                                                                 
 dense_84 (Dense)            (None, 512)               401920    
                                                                 
 dropout_62 (Dropout)        (None, 512)               0         
                                                                 
 dense_85 (Dense)            (None, 320)               164160    
                                                                 
 dropout_63 (Dropout)        (None, 320)               0         
                                                                 
 dense_86 (Dense)            (None, 448)               143808    
                                                                 
 batch_normalization_24 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_64 (Dropout)        (None, 448)               0         
                                                                 
 dense_87 (Dense)            (None, 256)               114944    
                                                                 
 dropout_65 (Dropout)        (None, 256)               0         
                                                                 
 dense_88 (Dense)            (None, 26)                6682      
                                                                 
=================================================================
Total params: 833306 (3.18 MB)
Trainable params: 832410 (3.18 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 23:
  Value: 0.9113
  num_layers: 4
  units_0: 416
  units_1: 160
  units_2: 480
  units_3: 352
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001384744907998443

Model: "sequential_23"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_23 (Flatten)        (None, 784)               0         
                                                                 
 dense_89 (Dense)            (None, 416)               326560    
                                                                 
 dropout_66 (Dropout)        (None, 416)               0         
                                                                 
 dense_90 (Dense)            (None, 160)               66720     
                                                                 
 dropout_67 (Dropout)        (None, 160)               0         
                                                                 
 dense_91 (Dense)            (None, 480)               77280     
                                                                 
 batch_normalization_25 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_68 (Dropout)        (None, 480)               0         
                                                                 
 dense_92 (Dense)            (None, 352)               169312    
                                                                 
 batch_normalization_26 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_69 (Dropout)        (None, 352)               0         
                                                                 
 dense_93 (Dense)            (None, 26)                9178      
                                                                 
=================================================================
Total params: 652378 (2.49 MB)
Trainable params: 650714 (2.48 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 24:
  Value: 0.7892
  num_layers: 3
  units_0: 320
  units_1: 192
  units_2: 352
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  optimizer: adam
  learning_rate: 0.00021270003747183138

Model: "sequential_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_24 (Flatten)        (None, 784)               0         
                                                                 
 dense_94 (Dense)            (None, 320)               251200    
                                                                 
 dropout_70 (Dropout)        (None, 320)               0         
                                                                 
 dense_95 (Dense)            (None, 192)               61632     
                                                                 
 dropout_71 (Dropout)        (None, 192)               0         
                                                                 
 dense_96 (Dense)            (None, 352)               67936     
                                                                 
 dropout_72 (Dropout)        (None, 352)               0         
                                                                 
 dense_97 (Dense)            (None, 26)                9178      
                                                                 
=================================================================
Total params: 389946 (1.49 MB)
Trainable params: 389946 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 25:
  Value: 0.0372
  num_layers: 4
  units_0: 416
  units_1: 448
  units_2: 448
  units_3: 224
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.00012417300979359193

Model: "sequential_25"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_25 (Flatten)        (None, 784)               0         
                                                                 
 dense_98 (Dense)            (None, 416)               326560    
                                                                 
 dropout_73 (Dropout)        (None, 416)               0         
                                                                 
 dense_99 (Dense)            (None, 448)               186816    
                                                                 
 dropout_74 (Dropout)        (None, 448)               0         
                                                                 
 dense_100 (Dense)           (None, 448)               201152    
                                                                 
 batch_normalization_27 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_75 (Dropout)        (None, 448)               0         
                                                                 
 dense_101 (Dense)           (None, 224)               100576    
                                                                 
 dropout_76 (Dropout)        (None, 224)               0         
                                                                 
 dense_102 (Dense)           (None, 26)                5850      
                                                                 
=================================================================
Total params: 822746 (3.14 MB)
Trainable params: 821850 (3.14 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 26:
  Value: 0.6095
  num_layers: 4
  units_0: 352
  units_1: 320
  units_2: 224
  units_3: 128
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: relu
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: True
  optimizer: adamax
  learning_rate: 0.000220671357065281

Model: "sequential_26"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_26 (Flatten)        (None, 784)               0         
                                                                 
 dense_103 (Dense)           (None, 352)               276320    
                                                                 
 dropout_77 (Dropout)        (None, 352)               0         
                                                                 
 dense_104 (Dense)           (None, 320)               112960    
                                                                 
 dropout_78 (Dropout)        (None, 320)               0         
                                                                 
 dense_105 (Dense)           (None, 224)               71904     
                                                                 
 dropout_79 (Dropout)        (None, 224)               0         
                                                                 
 dense_106 (Dense)           (None, 128)               28800     
                                                                 
 batch_normalization_28 (Ba  (None, 128)               512       
 tchNormalization)                                               
                                                                 
 dropout_80 (Dropout)        (None, 128)               0         
                                                                 
 dense_107 (Dense)           (None, 26)                3354      
                                                                 
=================================================================
Total params: 493850 (1.88 MB)
Trainable params: 493594 (1.88 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________



Trial 27:
  Value: 0.5725
  num_layers: 3
  units_0: 448
  units_1: 32
  units_2: 352
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: sgd
  learning_rate: 0.0001453664505035423

Model: "sequential_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_27 (Flatten)        (None, 784)               0         
                                                                 
 dense_108 (Dense)           (None, 448)               351680    
                                                                 
 dropout_81 (Dropout)        (None, 448)               0         
                                                                 
 dense_109 (Dense)           (None, 32)                14368     
                                                                 
 batch_normalization_29 (Ba  (None, 32)                128       
 tchNormalization)                                               
                                                                 
 dropout_82 (Dropout)        (None, 32)                0         
                                                                 
 dense_110 (Dense)           (None, 352)               11616     
                                                                 
 batch_normalization_30 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_83 (Dropout)        (None, 352)               0         
                                                                 
 dense_111 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 388378 (1.48 MB)
Trainable params: 387610 (1.48 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 28:
  Value: 0.6169
  num_layers: 4
  units_0: 288
  units_1: 224
  units_2: 448
  units_3: 384
  activation_0: sigmoid
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.1
  dropout_2: 0.30000000000000004
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: rmsprop
  learning_rate: 0.0003707271651524396

Model: "sequential_28"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_28 (Flatten)        (None, 784)               0         
                                                                 
 dense_112 (Dense)           (None, 288)               226080    
                                                                 
 dropout_84 (Dropout)        (None, 288)               0         
                                                                 
 dense_113 (Dense)           (None, 224)               64736     
                                                                 
 dropout_85 (Dropout)        (None, 224)               0         
                                                                 
 dense_114 (Dense)           (None, 448)               100800    
                                                                 
 batch_normalization_31 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_86 (Dropout)        (None, 448)               0         
                                                                 
 dense_115 (Dense)           (None, 384)               172416    
                                                                 
 batch_normalization_32 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_87 (Dropout)        (None, 384)               0         
                                                                 
 dense_116 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 577370 (2.20 MB)
Trainable params: 575706 (2.20 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 29:
  Value: 0.1362
  num_layers: 3
  units_0: 512
  units_1: 128
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: False
  optimizer: sgd
  learning_rate: 0.0001806397011428254

Model: "sequential_29"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_29 (Flatten)        (None, 784)               0         
                                                                 
 dense_117 (Dense)           (None, 512)               401920    
                                                                 
 batch_normalization_33 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_88 (Dropout)        (None, 512)               0         
                                                                 
 dense_118 (Dense)           (None, 128)               65664     
                                                                 
 dropout_89 (Dropout)        (None, 128)               0         
                                                                 
 dense_119 (Dense)           (None, 512)               66048     
                                                                 
 dropout_90 (Dropout)        (None, 512)               0         
                                                                 
 dense_120 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 549018 (2.09 MB)
Trainable params: 547994 (2.09 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 30:
  Value: 0.6907
  num_layers: 4
  units_0: 448
  units_1: 320
  units_2: 384
  units_3: 416
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: tanh
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00010175700522911054

Model: "sequential_30"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_30 (Flatten)        (None, 784)               0         
                                                                 
 dense_121 (Dense)           (None, 448)               351680    
                                                                 
 dropout_91 (Dropout)        (None, 448)               0         
                                                                 
 dense_122 (Dense)           (None, 320)               143680    
                                                                 
 dropout_92 (Dropout)        (None, 320)               0         
                                                                 
 dense_123 (Dense)           (None, 384)               123264    
                                                                 
 batch_normalization_34 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_93 (Dropout)        (None, 384)               0         
                                                                 
 dense_124 (Dense)           (None, 416)               160160    
                                                                 
 dropout_94 (Dropout)        (None, 416)               0         
                                                                 
 dense_125 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 791162 (3.02 MB)
Trainable params: 790394 (3.02 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 31:
  Value: 0.9116
  num_layers: 4
  units_0: 384
  units_1: 288
  units_2: 512
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012839295724933277

Model: "sequential_31"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_31 (Flatten)        (None, 784)               0         
                                                                 
 dense_126 (Dense)           (None, 384)               301440    
                                                                 
 dropout_95 (Dropout)        (None, 384)               0         
                                                                 
 dense_127 (Dense)           (None, 288)               110880    
                                                                 
 dropout_96 (Dropout)        (None, 288)               0         
                                                                 
 dense_128 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_35 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_97 (Dropout)        (None, 512)               0         
                                                                 
 dense_129 (Dense)           (None, 448)               229824    
                                                                 
 batch_normalization_36 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_98 (Dropout)        (None, 448)               0         
                                                                 
 dense_130 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 805626 (3.07 MB)
Trainable params: 803706 (3.07 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 32:
  Value: 0.8261
  num_layers: 4
  units_0: 352
  units_1: 288
  units_2: 480
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00014375954803430324

Model: "sequential_32"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_32 (Flatten)        (None, 784)               0         
                                                                 
 dense_131 (Dense)           (None, 352)               276320    
                                                                 
 dropout_99 (Dropout)        (None, 352)               0         
                                                                 
 dense_132 (Dense)           (None, 288)               101664    
                                                                 
 dropout_100 (Dropout)       (None, 288)               0         
                                                                 
 dense_133 (Dense)           (None, 480)               138720    
                                                                 
 batch_normalization_37 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_101 (Dropout)       (None, 480)               0         
                                                                 
 dense_134 (Dense)           (None, 448)               215488    
                                                                 
 batch_normalization_38 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_102 (Dropout)       (None, 448)               0         
                                                                 
 dense_135 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 747578 (2.85 MB)
Trainable params: 745722 (2.84 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 33:
  Value: 0.8009
  num_layers: 4
  units_0: 288
  units_1: 288
  units_2: 480
  units_3: 288
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00018142368988653625

Model: "sequential_33"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_33 (Flatten)        (None, 784)               0         
                                                                 
 dense_136 (Dense)           (None, 288)               226080    
                                                                 
 dropout_103 (Dropout)       (None, 288)               0         
                                                                 
 dense_137 (Dense)           (None, 288)               83232     
                                                                 
 dropout_104 (Dropout)       (None, 288)               0         
                                                                 
 dense_138 (Dense)           (None, 480)               138720    
                                                                 
 batch_normalization_39 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_105 (Dropout)       (None, 480)               0         
                                                                 
 dense_139 (Dense)           (None, 288)               138528    
                                                                 
 batch_normalization_40 (Ba  (None, 288)               1152      
 tchNormalization)                                               
                                                                 
 dropout_106 (Dropout)       (None, 288)               0         
                                                                 
 dense_140 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 597146 (2.28 MB)
Trainable params: 595610 (2.27 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 34:
  Value: 0.6151
  num_layers: 4
  units_0: 384
  units_1: 224
  units_2: 416
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012538455259597633

Model: "sequential_34"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_34 (Flatten)        (None, 784)               0         
                                                                 
 dense_141 (Dense)           (None, 384)               301440    
                                                                 
 batch_normalization_41 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_107 (Dropout)       (None, 384)               0         
                                                                 
 dense_142 (Dense)           (None, 224)               86240     
                                                                 
 dropout_108 (Dropout)       (None, 224)               0         
                                                                 
 dense_143 (Dense)           (None, 416)               93600     
                                                                 
 batch_normalization_42 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_109 (Dropout)       (None, 416)               0         
                                                                 
 dense_144 (Dense)           (None, 448)               186816    
                                                                 
 batch_normalization_43 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_110 (Dropout)       (None, 448)               0         
                                                                 
 dense_145 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 684762 (2.61 MB)
Trainable params: 682266 (2.60 MB)
Non-trainable params: 2496 (9.75 KB)
_________________________________________________________________



Trial 35:
  Value: 0.0591
  num_layers: 4
  units_0: 256
  units_1: 224
  units_2: 512
  units_3: 192
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adagrad
  learning_rate: 0.00021435045760960785

Model: "sequential_35"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_35 (Flatten)        (None, 784)               0         
                                                                 
 dense_146 (Dense)           (None, 256)               200960    
                                                                 
 dropout_111 (Dropout)       (None, 256)               0         
                                                                 
 dense_147 (Dense)           (None, 224)               57568     
                                                                 
 dropout_112 (Dropout)       (None, 224)               0         
                                                                 
 dense_148 (Dense)           (None, 512)               115200    
                                                                 
 batch_normalization_44 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_113 (Dropout)       (None, 512)               0         
                                                                 
 dense_149 (Dense)           (None, 192)               98496     
                                                                 
 batch_normalization_45 (Ba  (None, 192)               768       
 tchNormalization)                                               
                                                                 
 dropout_114 (Dropout)       (None, 192)               0         
                                                                 
 dense_150 (Dense)           (None, 26)                5018      
                                                                 
=================================================================
Total params: 480058 (1.83 MB)
Trainable params: 478650 (1.83 MB)
Non-trainable params: 1408 (5.50 KB)
_________________________________________________________________



Trial 36:
  Value: 0.6631
  num_layers: 3
  units_0: 448
  units_1: 384
  units_2: 288
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: False
  optimizer: adam
  learning_rate: 0.0001574443596163793

Model: "sequential_36"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_36 (Flatten)        (None, 784)               0         
                                                                 
 dense_151 (Dense)           (None, 448)               351680    
                                                                 
 batch_normalization_46 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_115 (Dropout)       (None, 448)               0         
                                                                 
 dense_152 (Dense)           (None, 384)               172416    
                                                                 
 dropout_116 (Dropout)       (None, 384)               0         
                                                                 
 dense_153 (Dense)           (None, 288)               110880    
                                                                 
 dropout_117 (Dropout)       (None, 288)               0         
                                                                 
 dense_154 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 644282 (2.46 MB)
Trainable params: 643386 (2.45 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 37:
  Value: 0.9090
  num_layers: 4
  units_0: 352
  units_1: 448
  units_2: 384
  units_3: 320
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00010062331200017742

Model: "sequential_37"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_37 (Flatten)        (None, 784)               0         
                                                                 
 dense_155 (Dense)           (None, 352)               276320    
                                                                 
 dropout_118 (Dropout)       (None, 352)               0         
                                                                 
 dense_156 (Dense)           (None, 448)               158144    
                                                                 
 batch_normalization_47 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_119 (Dropout)       (None, 448)               0         
                                                                 
 dense_157 (Dense)           (None, 384)               172416    
                                                                 
 batch_normalization_48 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_120 (Dropout)       (None, 384)               0         
                                                                 
 dense_158 (Dense)           (None, 320)               123200    
                                                                 
 dropout_121 (Dropout)       (None, 320)               0         
                                                                 
 dense_159 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 741754 (2.83 MB)
Trainable params: 740090 (2.82 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 38:
  Value: 0.6795
  num_layers: 2
  units_0: 480
  units_1: 288
  activation_0: tanh
  activation_1: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.0002546176749511382

Model: "sequential_38"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_38 (Flatten)        (None, 784)               0         
                                                                 
 dense_160 (Dense)           (None, 480)               376800    
                                                                 
 dropout_122 (Dropout)       (None, 480)               0         
                                                                 
 dense_161 (Dense)           (None, 288)               138528    
                                                                 
 dropout_123 (Dropout)       (None, 288)               0         
                                                                 
 dense_162 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 522842 (1.99 MB)
Trainable params: 522842 (1.99 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 39:
  Value: 0.3627
  num_layers: 4
  units_0: 416
  units_1: 384
  units_2: 256
  units_3: 64
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: relu
  dropout_0: 0.0
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adagrad
  learning_rate: 0.0001675732455362421

Model: "sequential_39"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_39 (Flatten)        (None, 784)               0         
                                                                 
 dense_163 (Dense)           (None, 416)               326560    
                                                                 
 batch_normalization_49 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_124 (Dropout)       (None, 416)               0         
                                                                 
 dense_164 (Dense)           (None, 384)               160128    
                                                                 
 batch_normalization_50 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_125 (Dropout)       (None, 384)               0         
                                                                 
 dense_165 (Dense)           (None, 256)               98560     
                                                                 
 batch_normalization_51 (Ba  (None, 256)               1024      
 tchNormalization)                                               
                                                                 
 dropout_126 (Dropout)       (None, 256)               0         
                                                                 
 dense_166 (Dense)           (None, 64)                16448     
                                                                 
 batch_normalization_52 (Ba  (None, 64)                256       
 tchNormalization)                                               
                                                                 
 dropout_127 (Dropout)       (None, 64)                0         
                                                                 
 dense_167 (Dense)           (None, 26)                1690      
                                                                 
=================================================================
Total params: 607866 (2.32 MB)
Trainable params: 605626 (2.31 MB)
Non-trainable params: 2240 (8.75 KB)
_________________________________________________________________



Trial 40:
  Value: 0.2459
  num_layers: 3
  units_0: 320
  units_1: 480
  units_2: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.1
  dropout_1: 0.5
  dropout_2: 0.2
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: rmsprop
  learning_rate: 0.0001285373200917349

Model: "sequential_40"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_40 (Flatten)        (None, 784)               0         
                                                                 
 dense_168 (Dense)           (None, 320)               251200    
                                                                 
 dropout_128 (Dropout)       (None, 320)               0         
                                                                 
 dense_169 (Dense)           (None, 480)               154080    
                                                                 
 batch_normalization_53 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_129 (Dropout)       (None, 480)               0         
                                                                 
 dense_170 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_54 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_130 (Dropout)       (None, 320)               0         
                                                                 
 dense_171 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 570746 (2.18 MB)
Trainable params: 569146 (2.17 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 41:
  Value: 0.9126
  num_layers: 4
  units_0: 384
  units_1: 256
  units_2: 512
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011471415510881329

Model: "sequential_41"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_41 (Flatten)        (None, 784)               0         
                                                                 
 dense_172 (Dense)           (None, 384)               301440    
                                                                 
 dropout_131 (Dropout)       (None, 384)               0         
                                                                 
 dense_173 (Dense)           (None, 256)               98560     
                                                                 
 dropout_132 (Dropout)       (None, 256)               0         
                                                                 
 dense_174 (Dense)           (None, 512)               131584    
                                                                 
 batch_normalization_55 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_133 (Dropout)       (None, 512)               0         
                                                                 
 dense_175 (Dense)           (None, 512)               262656    
                                                                 
 batch_normalization_56 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_134 (Dropout)       (None, 512)               0         
                                                                 
 dense_176 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 811674 (3.10 MB)
Trainable params: 809626 (3.09 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 42:
  Value: 0.8087
  num_layers: 4
  units_0: 384
  units_1: 256
  units_2: 480
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012306359496917836

Model: "sequential_42"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_42 (Flatten)        (None, 784)               0         
                                                                 
 dense_177 (Dense)           (None, 384)               301440    
                                                                 
 dropout_135 (Dropout)       (None, 384)               0         
                                                                 
 dense_178 (Dense)           (None, 256)               98560     
                                                                 
 dropout_136 (Dropout)       (None, 256)               0         
                                                                 
 dense_179 (Dense)           (None, 480)               123360    
                                                                 
 batch_normalization_57 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_137 (Dropout)       (None, 480)               0         
                                                                 
 dense_180 (Dense)           (None, 448)               215488    
                                                                 
 batch_normalization_58 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_138 (Dropout)       (None, 448)               0         
                                                                 
 dense_181 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 754234 (2.88 MB)
Trainable params: 752378 (2.87 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 43:
  Value: 0.9137
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 448
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00018222156637813633

Model: "sequential_43"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_43 (Flatten)        (None, 784)               0         
                                                                 
 dense_182 (Dense)           (None, 480)               376800    
                                                                 
 dropout_139 (Dropout)       (None, 480)               0         
                                                                 
 dense_183 (Dense)           (None, 352)               169312    
                                                                 
 dropout_140 (Dropout)       (None, 352)               0         
                                                                 
 dense_184 (Dense)           (None, 448)               158144    
                                                                 
 batch_normalization_59 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_141 (Dropout)       (None, 448)               0         
                                                                 
 dense_185 (Dense)           (None, 480)               215520    
                                                                 
 batch_normalization_60 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_142 (Dropout)       (None, 480)               0         
                                                                 
 dense_186 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 935994 (3.57 MB)
Trainable params: 934138 (3.56 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 44:
  Value: 0.9154
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 448
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00018590806311868718

Model: "sequential_44"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_44 (Flatten)        (None, 784)               0         
                                                                 
 dense_187 (Dense)           (None, 480)               376800    
                                                                 
 dropout_143 (Dropout)       (None, 480)               0         
                                                                 
 dense_188 (Dense)           (None, 352)               169312    
                                                                 
 dropout_144 (Dropout)       (None, 352)               0         
                                                                 
 dense_189 (Dense)           (None, 448)               158144    
                                                                 
 batch_normalization_61 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_145 (Dropout)       (None, 448)               0         
                                                                 
 dense_190 (Dense)           (None, 512)               229888    
                                                                 
 batch_normalization_62 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_146 (Dropout)       (None, 512)               0         
                                                                 
 dense_191 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 951322 (3.63 MB)
Trainable params: 949402 (3.62 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 45:
  Value: 0.7036
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001770805822548124

Model: "sequential_45"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_45 (Flatten)        (None, 784)               0         
                                                                 
 dense_192 (Dense)           (None, 480)               376800    
                                                                 
 dropout_147 (Dropout)       (None, 480)               0         
                                                                 
 dense_193 (Dense)           (None, 416)               200096    
                                                                 
 dropout_148 (Dropout)       (None, 416)               0         
                                                                 
 dense_194 (Dense)           (None, 448)               186816    
                                                                 
 batch_normalization_63 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_149 (Dropout)       (None, 448)               0         
                                                                 
 dense_195 (Dense)           (None, 512)               229888    
                                                                 
 dropout_150 (Dropout)       (None, 512)               0         
                                                                 
 dense_196 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 1008730 (3.85 MB)
Trainable params: 1007834 (3.84 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 46:
  Value: 0.0389
  num_layers: 3
  units_0: 512
  units_1: 352
  units_2: 128
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: ftrl
  learning_rate: 0.0003674321809622191

Model: "sequential_46"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_46 (Flatten)        (None, 784)               0         
                                                                 
 dense_197 (Dense)           (None, 512)               401920    
                                                                 
 dropout_151 (Dropout)       (None, 512)               0         
                                                                 
 dense_198 (Dense)           (None, 352)               180576    
                                                                 
 dropout_152 (Dropout)       (None, 352)               0         
                                                                 
 dense_199 (Dense)           (None, 128)               45184     
                                                                 
 batch_normalization_64 (Ba  (None, 128)               512       
 tchNormalization)                                               
                                                                 
 dropout_153 (Dropout)       (None, 128)               0         
                                                                 
 dense_200 (Dense)           (None, 26)                3354      
                                                                 
=================================================================
Total params: 631546 (2.41 MB)
Trainable params: 631290 (2.41 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________



Trial 47:
  Value: 0.5929
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.5
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: False
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00025286976694745815

Model: "sequential_47"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_47 (Flatten)        (None, 784)               0         
                                                                 
 dense_201 (Dense)           (None, 480)               376800    
                                                                 
 batch_normalization_65 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_154 (Dropout)       (None, 480)               0         
                                                                 
 dense_202 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_66 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_155 (Dropout)       (None, 352)               0         
                                                                 
 dense_203 (Dense)           (None, 416)               146848    
                                                                 
 dropout_156 (Dropout)       (None, 416)               0         
                                                                 
 dense_204 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_67 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_157 (Dropout)       (None, 480)               0         
                                                                 
 dense_205 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 910874 (3.47 MB)
Trainable params: 908250 (3.46 MB)
Non-trainable params: 2624 (10.25 KB)
_________________________________________________________________



Trial 48:
  Value: 0.6397
  num_layers: 1
  units_0: 448
  activation_0: sigmoid
  dropout_0: 0.0
  batch_norm_0: False
  optimizer: adamax
  learning_rate: 0.0007456569825125228

Model: "sequential_48"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_48 (Flatten)        (None, 784)               0         
                                                                 
 dense_206 (Dense)           (None, 448)               351680    
                                                                 
 dropout_158 (Dropout)       (None, 448)               0         
                                                                 
 dense_207 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 363354 (1.39 MB)
Trainable params: 363354 (1.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 49:
  Value: 0.6064
  num_layers: 4
  units_0: 512
  units_1: 192
  units_2: 416
  units_3: 480
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: sgd
  learning_rate: 0.002384264841638874

Model: "sequential_49"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_49 (Flatten)        (None, 784)               0         
                                                                 
 dense_208 (Dense)           (None, 512)               401920    
                                                                 
 dropout_159 (Dropout)       (None, 512)               0         
                                                                 
 dense_209 (Dense)           (None, 192)               98496     
                                                                 
 dropout_160 (Dropout)       (None, 192)               0         
                                                                 
 dense_210 (Dense)           (None, 416)               80288     
                                                                 
 batch_normalization_68 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_161 (Dropout)       (None, 416)               0         
                                                                 
 dense_211 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_69 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_162 (Dropout)       (None, 480)               0         
                                                                 
 dense_212 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 796954 (3.04 MB)
Trainable params: 795162 (3.03 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 50:
  Value: 0.7294
  num_layers: 4
  units_0: 128
  units_1: 480
  units_2: 352
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.30000000000000004
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00020229720544701519

Model: "sequential_50"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_50 (Flatten)        (None, 784)               0         
                                                                 
 dense_213 (Dense)           (None, 128)               100480    
                                                                 
 dropout_163 (Dropout)       (None, 128)               0         
                                                                 
 dense_214 (Dense)           (None, 480)               61920     
                                                                 
 dropout_164 (Dropout)       (None, 480)               0         
                                                                 
 dense_215 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_70 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_165 (Dropout)       (None, 352)               0         
                                                                 
 dense_216 (Dense)           (None, 480)               169440    
                                                                 
 batch_normalization_71 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_166 (Dropout)       (None, 480)               0         
                                                                 
 dense_217 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 516986 (1.97 MB)
Trainable params: 515322 (1.97 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 51:
  Value: 0.9110
  num_layers: 4
  units_0: 416
  units_1: 256
  units_2: 480
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011085645359661335

Model: "sequential_51"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_51 (Flatten)        (None, 784)               0         
                                                                 
 dense_218 (Dense)           (None, 416)               326560    
                                                                 
 dropout_167 (Dropout)       (None, 416)               0         
                                                                 
 dense_219 (Dense)           (None, 256)               106752    
                                                                 
 dropout_168 (Dropout)       (None, 256)               0         
                                                                 
 dense_220 (Dense)           (None, 480)               123360    
                                                                 
 batch_normalization_72 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_169 (Dropout)       (None, 480)               0         
                                                                 
 dense_221 (Dense)           (None, 512)               246272    
                                                                 
 batch_normalization_73 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_170 (Dropout)       (None, 512)               0         
                                                                 
 dense_222 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 820250 (3.13 MB)
Trainable params: 818266 (3.12 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 52:
  Value: 0.9122
  num_layers: 4
  units_0: 448
  units_1: 320
  units_2: 448
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00015326595978911193

Model: "sequential_52"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_52 (Flatten)        (None, 784)               0         
                                                                 
 dense_223 (Dense)           (None, 448)               351680    
                                                                 
 dropout_171 (Dropout)       (None, 448)               0         
                                                                 
 dense_224 (Dense)           (None, 320)               143680    
                                                                 
 dropout_172 (Dropout)       (None, 320)               0         
                                                                 
 dense_225 (Dense)           (None, 448)               143808    
                                                                 
 batch_normalization_74 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_173 (Dropout)       (None, 448)               0         
                                                                 
 dense_226 (Dense)           (None, 416)               186784    
                                                                 
 batch_normalization_75 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_174 (Dropout)       (None, 416)               0         
                                                                 
 dense_227 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 840250 (3.21 MB)
Trainable params: 838522 (3.20 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 53:
  Value: 0.9120
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 448
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00016163049114879005

Model: "sequential_53"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_53 (Flatten)        (None, 784)               0         
                                                                 
 dense_228 (Dense)           (None, 480)               376800    
                                                                 
 dropout_175 (Dropout)       (None, 480)               0         
                                                                 
 dense_229 (Dense)           (None, 320)               153920    
                                                                 
 dropout_176 (Dropout)       (None, 320)               0         
                                                                 
 dense_230 (Dense)           (None, 448)               143808    
                                                                 
 batch_normalization_76 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_177 (Dropout)       (None, 448)               0         
                                                                 
 dense_231 (Dense)           (None, 480)               215520    
                                                                 
 batch_normalization_77 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_178 (Dropout)       (None, 480)               0         
                                                                 
 dense_232 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 906266 (3.46 MB)
Trainable params: 904410 (3.45 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 54:
  Value: 0.8100
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 384
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00015218830637699134

Model: "sequential_54"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_54 (Flatten)        (None, 784)               0         
                                                                 
 dense_233 (Dense)           (None, 448)               351680    
                                                                 
 dropout_179 (Dropout)       (None, 448)               0         
                                                                 
 dense_234 (Dense)           (None, 416)               186784    
                                                                 
 dropout_180 (Dropout)       (None, 416)               0         
                                                                 
 dense_235 (Dense)           (None, 384)               160128    
                                                                 
 dropout_181 (Dropout)       (None, 384)               0         
                                                                 
 dense_236 (Dense)           (None, 416)               160160    
                                                                 
 batch_normalization_78 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_182 (Dropout)       (None, 416)               0         
                                                                 
 dense_237 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 871258 (3.32 MB)
Trainable params: 870426 (3.32 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 55:
  Value: 0.1064
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 416
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adagrad
  learning_rate: 0.0002552423505621673

Model: "sequential_55"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_55 (Flatten)        (None, 784)               0         
                                                                 
 dense_238 (Dense)           (None, 480)               376800    
                                                                 
 dropout_183 (Dropout)       (None, 480)               0         
                                                                 
 dense_239 (Dense)           (None, 384)               184704    
                                                                 
 dropout_184 (Dropout)       (None, 384)               0         
                                                                 
 dense_240 (Dense)           (None, 416)               160160    
                                                                 
 batch_normalization_79 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_185 (Dropout)       (None, 416)               0         
                                                                 
 dense_241 (Dense)           (None, 512)               213504    
                                                                 
 batch_normalization_80 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_186 (Dropout)       (None, 512)               0         
                                                                 
 dense_242 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 952218 (3.63 MB)
Trainable params: 950362 (3.63 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 56:
  Value: 0.6380
  num_layers: 4
  units_0: 448
  units_1: 352
  units_2: 448
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012017409578777366

Model: "sequential_56"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_56 (Flatten)        (None, 784)               0         
                                                                 
 dense_243 (Dense)           (None, 448)               351680    
                                                                 
 dropout_187 (Dropout)       (None, 448)               0         
                                                                 
 dense_244 (Dense)           (None, 352)               158048    
                                                                 
 dropout_188 (Dropout)       (None, 352)               0         
                                                                 
 dense_245 (Dense)           (None, 448)               158144    
                                                                 
 batch_normalization_81 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_189 (Dropout)       (None, 448)               0         
                                                                 
 dense_246 (Dense)           (None, 512)               229888    
                                                                 
 batch_normalization_82 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_190 (Dropout)       (None, 512)               0         
                                                                 
 dense_247 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 914938 (3.49 MB)
Trainable params: 913018 (3.48 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 57:
  Value: 0.7828
  num_layers: 3
  units_0: 416
  units_1: 256
  units_2: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  optimizer: adam
  learning_rate: 0.0001861354156822869

Model: "sequential_57"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_57 (Flatten)        (None, 784)               0         
                                                                 
 dense_248 (Dense)           (None, 416)               326560    
                                                                 
 dropout_191 (Dropout)       (None, 416)               0         
                                                                 
 dense_249 (Dense)           (None, 256)               106752    
                                                                 
 dropout_192 (Dropout)       (None, 256)               0         
                                                                 
 dense_250 (Dense)           (None, 480)               123360    
                                                                 
 dropout_193 (Dropout)       (None, 480)               0         
                                                                 
 dense_251 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 569178 (2.17 MB)
Trainable params: 569178 (2.17 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 58:
  Value: 0.0385
  num_layers: 2
  units_0: 512
  units_1: 224
  activation_0: tanh
  activation_1: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.00014420642496832387

Model: "sequential_58"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_58 (Flatten)        (None, 784)               0         
                                                                 
 dense_252 (Dense)           (None, 512)               401920    
                                                                 
 dropout_194 (Dropout)       (None, 512)               0         
                                                                 
 dense_253 (Dense)           (None, 224)               114912    
                                                                 
 dropout_195 (Dropout)       (None, 224)               0         
                                                                 
 dense_254 (Dense)           (None, 26)                5850      
                                                                 
=================================================================
Total params: 522682 (1.99 MB)
Trainable params: 522682 (1.99 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 59:
  Value: 0.8285
  num_layers: 4
  units_0: 320
  units_1: 320
  units_2: 320
  units_3: 416
  activation_0: tanh
  activation_1: relu
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.5
  dropout_2: 0.4
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.00011915733822309635

Model: "sequential_59"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_59 (Flatten)        (None, 784)               0         
                                                                 
 dense_255 (Dense)           (None, 320)               251200    
                                                                 
 dropout_196 (Dropout)       (None, 320)               0         
                                                                 
 dense_256 (Dense)           (None, 320)               102720    
                                                                 
 dropout_197 (Dropout)       (None, 320)               0         
                                                                 
 dense_257 (Dense)           (None, 320)               102720    
                                                                 
 batch_normalization_83 (Ba  (None, 320)               1280      
 tchNormalization)                                               
                                                                 
 dropout_198 (Dropout)       (None, 320)               0         
                                                                 
 dense_258 (Dense)           (None, 416)               133536    
                                                                 
 dropout_199 (Dropout)       (None, 416)               0         
                                                                 
 dense_259 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 602298 (2.30 MB)
Trainable params: 601658 (2.30 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 60:
  Value: 0.6620
  num_layers: 4
  units_0: 352
  units_1: 160
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0002085362826218791

Model: "sequential_60"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_60 (Flatten)        (None, 784)               0         
                                                                 
 dense_260 (Dense)           (None, 352)               276320    
                                                                 
 dropout_200 (Dropout)       (None, 352)               0         
                                                                 
 dense_261 (Dense)           (None, 160)               56480     
                                                                 
 dropout_201 (Dropout)       (None, 160)               0         
                                                                 
 dense_262 (Dense)           (None, 416)               66976     
                                                                 
 batch_normalization_84 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_202 (Dropout)       (None, 416)               0         
                                                                 
 dense_263 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_85 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_203 (Dropout)       (None, 480)               0         
                                                                 
 dense_264 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 616026 (2.35 MB)
Trainable params: 614234 (2.34 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 61:
  Value: 0.8174
  num_layers: 4
  units_0: 416
  units_1: 288
  units_2: 512
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010260426065122194

Model: "sequential_61"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_61 (Flatten)        (None, 784)               0         
                                                                 
 dense_265 (Dense)           (None, 416)               326560    
                                                                 
 dropout_204 (Dropout)       (None, 416)               0         
                                                                 
 dense_266 (Dense)           (None, 288)               120096    
                                                                 
 dropout_205 (Dropout)       (None, 288)               0         
                                                                 
 dense_267 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_86 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_206 (Dropout)       (None, 512)               0         
                                                                 
 dense_268 (Dense)           (None, 512)               262656    
                                                                 
 batch_normalization_87 (Ba  (None, 512)               2048      
 tchNormalization)                                               
                                                                 
 dropout_207 (Dropout)       (None, 512)               0         
                                                                 
 dense_269 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 874714 (3.34 MB)
Trainable params: 872666 (3.33 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 62:
  Value: 0.8106
  num_layers: 4
  units_0: 384
  units_1: 320
  units_2: 480
  units_3: 128
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010012231128887307

Model: "sequential_62"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_62 (Flatten)        (None, 784)               0         
                                                                 
 dense_270 (Dense)           (None, 384)               301440    
                                                                 
 dropout_208 (Dropout)       (None, 384)               0         
                                                                 
 dense_271 (Dense)           (None, 320)               123200    
                                                                 
 dropout_209 (Dropout)       (None, 320)               0         
                                                                 
 dense_272 (Dense)           (None, 480)               154080    
                                                                 
 batch_normalization_88 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_210 (Dropout)       (None, 480)               0         
                                                                 
 dense_273 (Dense)           (None, 128)               61568     
                                                                 
 batch_normalization_89 (Ba  (None, 128)               512       
 tchNormalization)                                               
                                                                 
 dropout_211 (Dropout)       (None, 128)               0         
                                                                 
 dense_274 (Dense)           (None, 26)                3354      
                                                                 
=================================================================
Total params: 646074 (2.46 MB)
Trainable params: 644858 (2.46 MB)
Non-trainable params: 1216 (4.75 KB)
_________________________________________________________________



Trial 63:
  Value: 0.9155
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 448
  units_3: 352
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00013869574009237344

Model: "sequential_63"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_63 (Flatten)        (None, 784)               0         
                                                                 
 dense_275 (Dense)           (None, 448)               351680    
                                                                 
 dropout_212 (Dropout)       (None, 448)               0         
                                                                 
 dense_276 (Dense)           (None, 416)               186784    
                                                                 
 dropout_213 (Dropout)       (None, 416)               0         
                                                                 
 dense_277 (Dense)           (None, 448)               186816    
                                                                 
 batch_normalization_90 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_214 (Dropout)       (None, 448)               0         
                                                                 
 dense_278 (Dense)           (None, 352)               158048    
                                                                 
 batch_normalization_91 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_215 (Dropout)       (None, 352)               0         
                                                                 
 dense_279 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 895706 (3.42 MB)
Trainable params: 894106 (3.41 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 64:
  Value: 0.8184
  num_layers: 4
  units_0: 224
  units_1: 416
  units_2: 448
  units_3: 384
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00014000659210591324

Model: "sequential_64"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_64 (Flatten)        (None, 784)               0         
                                                                 
 dense_280 (Dense)           (None, 224)               175840    
                                                                 
 dropout_216 (Dropout)       (None, 224)               0         
                                                                 
 dense_281 (Dense)           (None, 416)               93600     
                                                                 
 dropout_217 (Dropout)       (None, 416)               0         
                                                                 
 dense_282 (Dense)           (None, 448)               186816    
                                                                 
 batch_normalization_92 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_218 (Dropout)       (None, 448)               0         
                                                                 
 dense_283 (Dense)           (None, 384)               172416    
                                                                 
 batch_normalization_93 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_219 (Dropout)       (None, 384)               0         
                                                                 
 dense_284 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 642010 (2.45 MB)
Trainable params: 640346 (2.44 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 65:
  Value: 0.7694
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 32
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00016351323690163278

Model: "sequential_65"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_65 (Flatten)        (None, 784)               0         
                                                                 
 dense_285 (Dense)           (None, 448)               351680    
                                                                 
 dropout_220 (Dropout)       (None, 448)               0         
                                                                 
 dense_286 (Dense)           (None, 512)               229888    
                                                                 
 dropout_221 (Dropout)       (None, 512)               0         
                                                                 
 dense_287 (Dense)           (None, 384)               196992    
                                                                 
 dropout_222 (Dropout)       (None, 384)               0         
                                                                 
 dense_288 (Dense)           (None, 32)                12320     
                                                                 
 dropout_223 (Dropout)       (None, 32)                0         
                                                                 
 dense_289 (Dense)           (None, 26)                858       
                                                                 
=================================================================
Total params: 791738 (3.02 MB)
Trainable params: 791738 (3.02 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 66:
  Value: 0.5315
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 352
  units_3: 384
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011675336256450328

Model: "sequential_66"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_66 (Flatten)        (None, 784)               0         
                                                                 
 dense_290 (Dense)           (None, 480)               376800    
                                                                 
 dropout_224 (Dropout)       (None, 480)               0         
                                                                 
 dense_291 (Dense)           (None, 480)               230880    
                                                                 
 dropout_225 (Dropout)       (None, 480)               0         
                                                                 
 dense_292 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_94 (Ba  (None, 352)               1408      
 tchNormalization)                                               
                                                                 
 dropout_226 (Dropout)       (None, 352)               0         
                                                                 
 dense_293 (Dense)           (None, 384)               135552    
                                                                 
 batch_normalization_95 (Ba  (None, 384)               1536      
 tchNormalization)                                               
                                                                 
 dropout_227 (Dropout)       (None, 384)               0         
                                                                 
 dense_294 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 925498 (3.53 MB)
Trainable params: 924026 (3.52 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 67:
  Value: 0.2050
  num_layers: 4
  units_0: 32
  units_1: 352
  units_2: 448
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.2
  dropout_3: 0.5
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: sgd
  learning_rate: 0.00029555650848046557

Model: "sequential_67"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_67 (Flatten)        (None, 784)               0         
                                                                 
 dense_295 (Dense)           (None, 32)                25120     
                                                                 
 batch_normalization_96 (Ba  (None, 32)                128       
 tchNormalization)                                               
                                                                 
 dropout_228 (Dropout)       (None, 32)                0         
                                                                 
 dense_296 (Dense)           (None, 352)               11616     
                                                                 
 dropout_229 (Dropout)       (None, 352)               0         
                                                                 
 dense_297 (Dense)           (None, 448)               158144    
                                                                 
 batch_normalization_97 (Ba  (None, 448)               1792      
 tchNormalization)                                               
                                                                 
 dropout_230 (Dropout)       (None, 448)               0         
                                                                 
 dense_298 (Dense)           (None, 480)               215520    
                                                                 
 batch_normalization_98 (Ba  (None, 480)               1920      
 tchNormalization)                                               
                                                                 
 dropout_231 (Dropout)       (None, 480)               0         
                                                                 
 dense_299 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 426746 (1.63 MB)
Trainable params: 424826 (1.62 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 68:
  Value: 0.7360
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001895897776882855

Model: "sequential_68"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_68 (Flatten)        (None, 784)               0         
                                                                 
 dense_300 (Dense)           (None, 512)               401920    
                                                                 
 dropout_232 (Dropout)       (None, 512)               0         
                                                                 
 dense_301 (Dense)           (None, 416)               213408    
                                                                 
 batch_normalization_99 (Ba  (None, 416)               1664      
 tchNormalization)                                               
                                                                 
 dropout_233 (Dropout)       (None, 416)               0         
                                                                 
 dense_302 (Dense)           (None, 416)               173472    
                                                                 
 dropout_234 (Dropout)       (None, 416)               0         
                                                                 
 dense_303 (Dense)           (None, 352)               146784    
                                                                 
 dropout_235 (Dropout)       (None, 352)               0         
                                                                 
 dense_304 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 946426 (3.61 MB)
Trainable params: 945594 (3.61 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 69:
  Value: 0.7189
  num_layers: 3
  units_0: 448
  units_1: 384
  units_2: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adamax
  learning_rate: 0.0002328731562326846

Model: "sequential_69"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_69 (Flatten)        (None, 784)               0         
                                                                 
 dense_305 (Dense)           (None, 448)               351680    
                                                                 
 dropout_236 (Dropout)       (None, 448)               0         
                                                                 
 dense_306 (Dense)           (None, 384)               172416    
                                                                 
 dropout_237 (Dropout)       (None, 384)               0         
                                                                 
 dense_307 (Dense)           (None, 480)               184800    
                                                                 
 batch_normalization_100 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_238 (Dropout)       (None, 480)               0         
                                                                 
 dense_308 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 723322 (2.76 MB)
Trainable params: 722362 (2.76 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 70:
  Value: 0.5394
  num_layers: 4
  units_0: 416
  units_1: 352
  units_2: 64
  units_3: 256
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00013588550194869396

Model: "sequential_70"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_70 (Flatten)        (None, 784)               0         
                                                                 
 dense_309 (Dense)           (None, 416)               326560    
                                                                 
 dropout_239 (Dropout)       (None, 416)               0         
                                                                 
 dense_310 (Dense)           (None, 352)               146784    
                                                                 
 dropout_240 (Dropout)       (None, 352)               0         
                                                                 
 dense_311 (Dense)           (None, 64)                22592     
                                                                 
 batch_normalization_101 (B  (None, 64)                256       
 atchNormalization)                                              
                                                                 
 dropout_241 (Dropout)       (None, 64)                0         
                                                                 
 dense_312 (Dense)           (None, 256)               16640     
                                                                 
 batch_normalization_102 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_242 (Dropout)       (None, 256)               0         
                                                                 
 dense_313 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 520538 (1.99 MB)
Trainable params: 519898 (1.98 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 71:
  Value: 0.8222
  num_layers: 4
  units_0: 384
  units_1: 288
  units_2: 512
  units_3: 352
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011271891903978064

Model: "sequential_71"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_71 (Flatten)        (None, 784)               0         
                                                                 
 dense_314 (Dense)           (None, 384)               301440    
                                                                 
 dropout_243 (Dropout)       (None, 384)               0         
                                                                 
 dense_315 (Dense)           (None, 288)               110880    
                                                                 
 dropout_244 (Dropout)       (None, 288)               0         
                                                                 
 dense_316 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_103 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_245 (Dropout)       (None, 512)               0         
                                                                 
 dense_317 (Dense)           (None, 352)               180576    
                                                                 
 batch_normalization_104 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_246 (Dropout)       (None, 352)               0         
                                                                 
 dense_318 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 753498 (2.87 MB)
Trainable params: 751770 (2.87 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 72:
  Value: 0.8191
  num_layers: 4
  units_0: 416
  units_1: 320
  units_2: 512
  units_3: 320
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00015810475295116987

Model: "sequential_72"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_72 (Flatten)        (None, 784)               0         
                                                                 
 dense_319 (Dense)           (None, 416)               326560    
                                                                 
 dropout_247 (Dropout)       (None, 416)               0         
                                                                 
 dense_320 (Dense)           (None, 320)               133440    
                                                                 
 dropout_248 (Dropout)       (None, 320)               0         
                                                                 
 dense_321 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_105 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_249 (Dropout)       (None, 512)               0         
                                                                 
 dense_322 (Dense)           (None, 320)               164160    
                                                                 
 batch_normalization_106 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_250 (Dropout)       (None, 320)               0         
                                                                 
 dense_323 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 800186 (3.05 MB)
Trainable params: 798522 (3.05 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 73:
  Value: 0.8104
  num_layers: 4
  units_0: 384
  units_1: 256
  units_2: 448
  units_3: 288
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00013311382153095776

Model: "sequential_73"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_73 (Flatten)        (None, 784)               0         
                                                                 
 dense_324 (Dense)           (None, 384)               301440    
                                                                 
 dropout_251 (Dropout)       (None, 384)               0         
                                                                 
 dense_325 (Dense)           (None, 256)               98560     
                                                                 
 dropout_252 (Dropout)       (None, 256)               0         
                                                                 
 dense_326 (Dense)           (None, 448)               115136    
                                                                 
 batch_normalization_107 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_253 (Dropout)       (None, 448)               0         
                                                                 
 dense_327 (Dense)           (None, 288)               129312    
                                                                 
 batch_normalization_108 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_254 (Dropout)       (None, 288)               0         
                                                                 
 dense_328 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 654906 (2.50 MB)
Trainable params: 653434 (2.49 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 74:
  Value: 0.8199
  num_layers: 4
  units_0: 480
  units_1: 288
  units_2: 480
  units_3: 320
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.0
  dropout_1: 0.2
  dropout_2: 0.4
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011049759821840406

Model: "sequential_74"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_74 (Flatten)        (None, 784)               0         
                                                                 
 dense_329 (Dense)           (None, 480)               376800    
                                                                 
 dropout_255 (Dropout)       (None, 480)               0         
                                                                 
 dense_330 (Dense)           (None, 288)               138528    
                                                                 
 dropout_256 (Dropout)       (None, 288)               0         
                                                                 
 dense_331 (Dense)           (None, 480)               138720    
                                                                 
 batch_normalization_109 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_257 (Dropout)       (None, 480)               0         
                                                                 
 dense_332 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_110 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_258 (Dropout)       (None, 320)               0         
                                                                 
 dense_333 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 819514 (3.13 MB)
Trainable params: 817914 (3.12 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 75:
  Value: 0.7895
  num_layers: 4
  units_0: 352
  units_1: 192
  units_2: 448
  units_3: 448
  activation_0: tanh
  activation_1: tanh
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00013749864632513334

Model: "sequential_75"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_75 (Flatten)        (None, 784)               0         
                                                                 
 dense_334 (Dense)           (None, 352)               276320    
                                                                 
 dropout_259 (Dropout)       (None, 352)               0         
                                                                 
 dense_335 (Dense)           (None, 192)               67776     
                                                                 
 dropout_260 (Dropout)       (None, 192)               0         
                                                                 
 dense_336 (Dense)           (None, 448)               86464     
                                                                 
 batch_normalization_111 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_261 (Dropout)       (None, 448)               0         
                                                                 
 dense_337 (Dense)           (None, 448)               201152    
                                                                 
 batch_normalization_112 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_262 (Dropout)       (None, 448)               0         
                                                                 
 dense_338 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 646970 (2.47 MB)
Trainable params: 645178 (2.46 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 76:
  Value: 0.1128
  num_layers: 4
  units_0: 448
  units_1: 224
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.30000000000000004
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.00018330239543741717

Model: "sequential_76"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_76 (Flatten)        (None, 784)               0         
                                                                 
 dense_339 (Dense)           (None, 448)               351680    
                                                                 
 dropout_263 (Dropout)       (None, 448)               0         
                                                                 
 dense_340 (Dense)           (None, 224)               100576    
                                                                 
 dropout_264 (Dropout)       (None, 224)               0         
                                                                 
 dense_341 (Dense)           (None, 384)               86400     
                                                                 
 dropout_265 (Dropout)       (None, 384)               0         
                                                                 
 dense_342 (Dense)           (None, 512)               197120    
                                                                 
 dropout_266 (Dropout)       (None, 512)               0         
                                                                 
 dense_343 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 749114 (2.86 MB)
Trainable params: 749114 (2.86 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 77:
  Value: 0.6018
  num_layers: 4
  units_0: 416
  units_1: 448
  units_2: 512
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: rmsprop
  learning_rate: 0.00016008912208392045

Model: "sequential_77"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_77 (Flatten)        (None, 784)               0         
                                                                 
 dense_344 (Dense)           (None, 416)               326560    
                                                                 
 batch_normalization_113 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_267 (Dropout)       (None, 416)               0         
                                                                 
 dense_345 (Dense)           (None, 448)               186816    
                                                                 
 dropout_268 (Dropout)       (None, 448)               0         
                                                                 
 dense_346 (Dense)           (None, 512)               229888    
                                                                 
 batch_normalization_114 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_269 (Dropout)       (None, 512)               0         
                                                                 
 dense_347 (Dense)           (None, 416)               213408    
                                                                 
 batch_normalization_115 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_270 (Dropout)       (None, 416)               0         
                                                                 
 dense_348 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 972890 (3.71 MB)
Trainable params: 970202 (3.70 MB)
Non-trainable params: 2688 (10.50 KB)
_________________________________________________________________



Trial 78:
  Value: 0.0389
  num_layers: 3
  units_0: 480
  units_1: 512
  units_2: 416
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  optimizer: ftrl
  learning_rate: 0.00011754940381266108

Model: "sequential_78"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_78 (Flatten)        (None, 784)               0         
                                                                 
 dense_349 (Dense)           (None, 480)               376800    
                                                                 
 dropout_271 (Dropout)       (None, 480)               0         
                                                                 
 dense_350 (Dense)           (None, 512)               246272    
                                                                 
 batch_normalization_116 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_272 (Dropout)       (None, 512)               0         
                                                                 
 dense_351 (Dense)           (None, 416)               213408    
                                                                 
 batch_normalization_117 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_273 (Dropout)       (None, 416)               0         
                                                                 
 dense_352 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 851034 (3.25 MB)
Trainable params: 849178 (3.24 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 79:
  Value: 0.8134
  num_layers: 4
  units_0: 384
  units_1: 256
  units_2: 480
  units_3: 128
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00013035299579662016

Model: "sequential_79"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_79 (Flatten)        (None, 784)               0         
                                                                 
 dense_353 (Dense)           (None, 384)               301440    
                                                                 
 dropout_274 (Dropout)       (None, 384)               0         
                                                                 
 dense_354 (Dense)           (None, 256)               98560     
                                                                 
 dropout_275 (Dropout)       (None, 256)               0         
                                                                 
 dense_355 (Dense)           (None, 480)               123360    
                                                                 
 batch_normalization_118 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_276 (Dropout)       (None, 480)               0         
                                                                 
 dense_356 (Dense)           (None, 128)               61568     
                                                                 
 batch_normalization_119 (B  (None, 128)               512       
 atchNormalization)                                              
                                                                 
 dropout_277 (Dropout)       (None, 128)               0         
                                                                 
 dense_357 (Dense)           (None, 26)                3354      
                                                                 
=================================================================
Total params: 590714 (2.25 MB)
Trainable params: 589498 (2.25 MB)
Non-trainable params: 1216 (4.75 KB)
_________________________________________________________________



Trial 80:
  Value: 0.9120
  num_layers: 4
  units_0: 352
  units_1: 352
  units_2: 448
  units_3: 448
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00019512024780181763

Model: "sequential_80"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_80 (Flatten)        (None, 784)               0         
                                                                 
 dense_358 (Dense)           (None, 352)               276320    
                                                                 
 dropout_278 (Dropout)       (None, 352)               0         
                                                                 
 dense_359 (Dense)           (None, 352)               124256    
                                                                 
 dropout_279 (Dropout)       (None, 352)               0         
                                                                 
 dense_360 (Dense)           (None, 448)               158144    
                                                                 
 dropout_280 (Dropout)       (None, 448)               0         
                                                                 
 dense_361 (Dense)           (None, 448)               201152    
                                                                 
 dropout_281 (Dropout)       (None, 448)               0         
                                                                 
 dense_362 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 771546 (2.94 MB)
Trainable params: 771546 (2.94 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 81:
  Value: 0.9114
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 448
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00016277620170600303

Model: "sequential_81"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_81 (Flatten)        (None, 784)               0         
                                                                 
 dense_363 (Dense)           (None, 480)               376800    
                                                                 
 dropout_282 (Dropout)       (None, 480)               0         
                                                                 
 dense_364 (Dense)           (None, 320)               153920    
                                                                 
 dropout_283 (Dropout)       (None, 320)               0         
                                                                 
 dense_365 (Dense)           (None, 448)               143808    
                                                                 
 batch_normalization_120 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_284 (Dropout)       (None, 448)               0         
                                                                 
 dense_366 (Dense)           (None, 480)               215520    
                                                                 
 batch_normalization_121 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_285 (Dropout)       (None, 480)               0         
                                                                 
 dense_367 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 906266 (3.46 MB)
Trainable params: 904410 (3.45 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 82:
  Value: 0.9132
  num_layers: 4
  units_0: 448
  units_1: 320
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00015285025662520994

Model: "sequential_82"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_82 (Flatten)        (None, 784)               0         
                                                                 
 dense_368 (Dense)           (None, 448)               351680    
                                                                 
 dropout_286 (Dropout)       (None, 448)               0         
                                                                 
 dense_369 (Dense)           (None, 320)               143680    
                                                                 
 dropout_287 (Dropout)       (None, 320)               0         
                                                                 
 dense_370 (Dense)           (None, 416)               133536    
                                                                 
 batch_normalization_122 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_288 (Dropout)       (None, 416)               0         
                                                                 
 dense_371 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_123 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_289 (Dropout)       (None, 480)               0         
                                                                 
 dense_372 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 845146 (3.22 MB)
Trainable params: 843354 (3.22 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 83:
  Value: 0.9128
  num_layers: 4
  units_0: 448
  units_1: 288
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011459923553700742

Model: "sequential_83"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_83 (Flatten)        (None, 784)               0         
                                                                 
 dense_373 (Dense)           (None, 448)               351680    
                                                                 
 dropout_290 (Dropout)       (None, 448)               0         
                                                                 
 dense_374 (Dense)           (None, 288)               129312    
                                                                 
 dropout_291 (Dropout)       (None, 288)               0         
                                                                 
 dense_375 (Dense)           (None, 384)               110976    
                                                                 
 batch_normalization_124 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_292 (Dropout)       (None, 384)               0         
                                                                 
 dense_376 (Dense)           (None, 512)               197120    
                                                                 
 batch_normalization_125 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_293 (Dropout)       (None, 512)               0         
                                                                 
 dense_377 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 806010 (3.07 MB)
Trainable params: 804218 (3.07 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 84:
  Value: 0.8171
  num_layers: 4
  units_0: 448
  units_1: 288
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00022906887532019135

Model: "sequential_84"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_84 (Flatten)        (None, 784)               0         
                                                                 
 dense_378 (Dense)           (None, 448)               351680    
                                                                 
 dropout_294 (Dropout)       (None, 448)               0         
                                                                 
 dense_379 (Dense)           (None, 288)               129312    
                                                                 
 dropout_295 (Dropout)       (None, 288)               0         
                                                                 
 dense_380 (Dense)           (None, 384)               110976    
                                                                 
 batch_normalization_126 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_296 (Dropout)       (None, 384)               0         
                                                                 
 dense_381 (Dense)           (None, 512)               197120    
                                                                 
 batch_normalization_127 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_297 (Dropout)       (None, 512)               0         
                                                                 
 dense_382 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 806010 (3.07 MB)
Trainable params: 804218 (3.07 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 85:
  Value: 0.9148
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001492721479595524

Model: "sequential_85"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_85 (Flatten)        (None, 784)               0         
                                                                 
 dense_383 (Dense)           (None, 512)               401920    
                                                                 
 dropout_298 (Dropout)       (None, 512)               0         
                                                                 
 dense_384 (Dense)           (None, 320)               164160    
                                                                 
 dropout_299 (Dropout)       (None, 320)               0         
                                                                 
 dense_385 (Dense)           (None, 416)               133536    
                                                                 
 batch_normalization_128 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_300 (Dropout)       (None, 416)               0         
                                                                 
 dense_386 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_129 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_301 (Dropout)       (None, 480)               0         
                                                                 
 dense_387 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 915866 (3.49 MB)
Trainable params: 914074 (3.49 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 86:
  Value: 0.9155
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 352
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011234746619928657

Model: "sequential_86"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_86 (Flatten)        (None, 784)               0         
                                                                 
 dense_388 (Dense)           (None, 512)               401920    
                                                                 
 dropout_302 (Dropout)       (None, 512)               0         
                                                                 
 dense_389 (Dense)           (None, 384)               196992    
                                                                 
 dropout_303 (Dropout)       (None, 384)               0         
                                                                 
 dense_390 (Dense)           (None, 352)               135520    
                                                                 
 batch_normalization_130 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_304 (Dropout)       (None, 352)               0         
                                                                 
 dense_391 (Dense)           (None, 480)               169440    
                                                                 
 batch_normalization_131 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_305 (Dropout)       (None, 480)               0         
                                                                 
 dense_392 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 919706 (3.51 MB)
Trainable params: 918042 (3.50 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 87:
  Value: 0.2816
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 352
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: sgd
  learning_rate: 0.00014151229362344587

Model: "sequential_87"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_87 (Flatten)        (None, 784)               0         
                                                                 
 dense_393 (Dense)           (None, 512)               401920    
                                                                 
 dropout_306 (Dropout)       (None, 512)               0         
                                                                 
 dense_394 (Dense)           (None, 384)               196992    
                                                                 
 dropout_307 (Dropout)       (None, 384)               0         
                                                                 
 dense_395 (Dense)           (None, 352)               135520    
                                                                 
 batch_normalization_132 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_308 (Dropout)       (None, 352)               0         
                                                                 
 dense_396 (Dense)           (None, 480)               169440    
                                                                 
 batch_normalization_133 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_309 (Dropout)       (None, 480)               0         
                                                                 
 dense_397 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 919706 (3.51 MB)
Trainable params: 918042 (3.50 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 88:
  Value: 0.8379
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 384
  units_3: 192
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012781834071226762

Model: "sequential_88"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_88 (Flatten)        (None, 784)               0         
                                                                 
 dense_398 (Dense)           (None, 512)               401920    
                                                                 
 dropout_310 (Dropout)       (None, 512)               0         
                                                                 
 dense_399 (Dense)           (None, 384)               196992    
                                                                 
 dropout_311 (Dropout)       (None, 384)               0         
                                                                 
 dense_400 (Dense)           (None, 384)               147840    
                                                                 
 batch_normalization_134 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_312 (Dropout)       (None, 384)               0         
                                                                 
 dense_401 (Dense)           (None, 192)               73920     
                                                                 
 batch_normalization_135 (B  (None, 192)               768       
 atchNormalization)                                              
                                                                 
 dropout_313 (Dropout)       (None, 192)               0         
                                                                 
 dense_402 (Dense)           (None, 26)                5018      
                                                                 
=================================================================
Total params: 827994 (3.16 MB)
Trainable params: 826842 (3.15 MB)
Non-trainable params: 1152 (4.50 KB)
_________________________________________________________________



Trial 89:
  Value: 0.6912
  num_layers: 2
  units_0: 512
  units_1: 352
  activation_0: tanh
  activation_1: tanh
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adamax
  learning_rate: 0.00017308862420481824

Model: "sequential_89"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_89 (Flatten)        (None, 784)               0         
                                                                 
 dense_403 (Dense)           (None, 512)               401920    
                                                                 
 batch_normalization_136 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_314 (Dropout)       (None, 512)               0         
                                                                 
 dense_404 (Dense)           (None, 352)               180576    
                                                                 
 dropout_315 (Dropout)       (None, 352)               0         
                                                                 
 dense_405 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 593722 (2.26 MB)
Trainable params: 592698 (2.26 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 90:
  Value: 0.9090
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 416
  units_3: 448
  activation_0: tanh
  activation_1: relu
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010966625810937307

Model: "sequential_90"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_90 (Flatten)        (None, 784)               0         
                                                                 
 dense_406 (Dense)           (None, 480)               376800    
                                                                 
 dropout_316 (Dropout)       (None, 480)               0         
                                                                 
 dense_407 (Dense)           (None, 448)               215488    
                                                                 
 batch_normalization_137 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_317 (Dropout)       (None, 448)               0         
                                                                 
 dense_408 (Dense)           (None, 416)               186784    
                                                                 
 batch_normalization_138 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_318 (Dropout)       (None, 416)               0         
                                                                 
 dense_409 (Dense)           (None, 448)               186816    
                                                                 
 batch_normalization_139 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_319 (Dropout)       (None, 448)               0         
                                                                 
 dense_410 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 982810 (3.75 MB)
Trainable params: 980186 (3.74 MB)
Non-trainable params: 2624 (10.25 KB)
_________________________________________________________________



Trial 91:
  Value: 0.9109
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011947610370931425

Model: "sequential_91"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_91 (Flatten)        (None, 784)               0         
                                                                 
 dense_411 (Dense)           (None, 480)               376800    
                                                                 
 dropout_320 (Dropout)       (None, 480)               0         
                                                                 
 dense_412 (Dense)           (None, 320)               153920    
                                                                 
 dropout_321 (Dropout)       (None, 320)               0         
                                                                 
 dense_413 (Dense)           (None, 320)               102720    
                                                                 
 batch_normalization_140 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_322 (Dropout)       (None, 320)               0         
                                                                 
 dense_414 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_141 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_323 (Dropout)       (None, 512)               0         
                                                                 
 dense_415 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 814458 (3.11 MB)
Trainable params: 812794 (3.10 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 92:
  Value: 0.9146
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010815377840310069

Model: "sequential_92"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_92 (Flatten)        (None, 784)               0         
                                                                 
 dense_416 (Dense)           (None, 512)               401920    
                                                                 
 dropout_324 (Dropout)       (None, 512)               0         
                                                                 
 dense_417 (Dense)           (None, 352)               180576    
                                                                 
 dropout_325 (Dropout)       (None, 352)               0         
                                                                 
 dense_418 (Dense)           (None, 416)               146848    
                                                                 
 batch_normalization_142 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_326 (Dropout)       (None, 416)               0         
                                                                 
 dense_419 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_143 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_327 (Dropout)       (None, 480)               0         
                                                                 
 dense_420 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 945594 (3.61 MB)
Trainable params: 943802 (3.60 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 93:
  Value: 0.9114
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010186448506413252

Model: "sequential_93"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_93 (Flatten)        (None, 784)               0         
                                                                 
 dense_421 (Dense)           (None, 512)               401920    
                                                                 
 dropout_328 (Dropout)       (None, 512)               0         
                                                                 
 dense_422 (Dense)           (None, 352)               180576    
                                                                 
 dropout_329 (Dropout)       (None, 352)               0         
                                                                 
 dense_423 (Dense)           (None, 416)               146848    
                                                                 
 batch_normalization_144 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_330 (Dropout)       (None, 416)               0         
                                                                 
 dense_424 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_145 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_331 (Dropout)       (None, 480)               0         
                                                                 
 dense_425 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 945594 (3.61 MB)
Trainable params: 943802 (3.60 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 94:
  Value: 0.8228
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 352
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00014807662706082899

Model: "sequential_94"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_94 (Flatten)        (None, 784)               0         
                                                                 
 dense_426 (Dense)           (None, 512)               401920    
                                                                 
 dropout_332 (Dropout)       (None, 512)               0         
                                                                 
 dense_427 (Dense)           (None, 384)               196992    
                                                                 
 dropout_333 (Dropout)       (None, 384)               0         
                                                                 
 dense_428 (Dense)           (None, 352)               135520    
                                                                 
 batch_normalization_146 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_334 (Dropout)       (None, 352)               0         
                                                                 
 dense_429 (Dense)           (None, 480)               169440    
                                                                 
 batch_normalization_147 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_335 (Dropout)       (None, 480)               0         
                                                                 
 dense_430 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 919706 (3.51 MB)
Trainable params: 918042 (3.50 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 95:
  Value: 0.8208
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 384
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001270207676442937

Model: "sequential_95"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_95 (Flatten)        (None, 784)               0         
                                                                 
 dense_431 (Dense)           (None, 480)               376800    
                                                                 
 dropout_336 (Dropout)       (None, 480)               0         
                                                                 
 dense_432 (Dense)           (None, 416)               200096    
                                                                 
 dropout_337 (Dropout)       (None, 416)               0         
                                                                 
 dense_433 (Dense)           (None, 384)               160128    
                                                                 
 batch_normalization_148 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_338 (Dropout)       (None, 384)               0         
                                                                 
 dense_434 (Dense)           (None, 448)               172480    
                                                                 
 batch_normalization_149 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_339 (Dropout)       (None, 448)               0         
                                                                 
 dense_435 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 924506 (3.53 MB)
Trainable params: 922842 (3.52 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 96:
  Value: 0.9139
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 416
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001959652217576836

Model: "sequential_96"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_96 (Flatten)        (None, 784)               0         
                                                                 
 dense_436 (Dense)           (None, 512)               401920    
                                                                 
 dropout_340 (Dropout)       (None, 512)               0         
                                                                 
 dense_437 (Dense)           (None, 352)               180576    
                                                                 
 dropout_341 (Dropout)       (None, 352)               0         
                                                                 
 dense_438 (Dense)           (None, 416)               146848    
                                                                 
 batch_normalization_150 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_342 (Dropout)       (None, 416)               0         
                                                                 
 dense_439 (Dense)           (None, 512)               213504    
                                                                 
 dropout_343 (Dropout)       (None, 512)               0         
                                                                 
 dense_440 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 957850 (3.65 MB)
Trainable params: 957018 (3.65 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 97:
  Value: 0.0516
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 416
  units_3: 480
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.00020110124987839635

Model: "sequential_97"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_97 (Flatten)        (None, 784)               0         
                                                                 
 dense_441 (Dense)           (None, 512)               401920    
                                                                 
 dropout_344 (Dropout)       (None, 512)               0         
                                                                 
 dense_442 (Dense)           (None, 384)               196992    
                                                                 
 dropout_345 (Dropout)       (None, 384)               0         
                                                                 
 dense_443 (Dense)           (None, 416)               160160    
                                                                 
 dropout_346 (Dropout)       (None, 416)               0         
                                                                 
 dense_444 (Dense)           (None, 480)               200160    
                                                                 
 dropout_347 (Dropout)       (None, 480)               0         
                                                                 
 dense_445 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 971738 (3.71 MB)
Trainable params: 971738 (3.71 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 98:
  Value: 0.7652
  num_layers: 1
  units_0: 512
  activation_0: tanh
  dropout_0: 0.1
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.00018083022753651794

Model: "sequential_98"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_98 (Flatten)        (None, 784)               0         
                                                                 
 dense_446 (Dense)           (None, 512)               401920    
                                                                 
 dropout_348 (Dropout)       (None, 512)               0         
                                                                 
 dense_447 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 99:
  Value: 0.0375
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 416
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.00014825879299775084

Model: "sequential_99"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_99 (Flatten)        (None, 784)               0         
                                                                 
 dense_448 (Dense)           (None, 512)               401920    
                                                                 
 dropout_349 (Dropout)       (None, 512)               0         
                                                                 
 dense_449 (Dense)           (None, 352)               180576    
                                                                 
 dropout_350 (Dropout)       (None, 352)               0         
                                                                 
 dense_450 (Dense)           (None, 416)               146848    
                                                                 
 batch_normalization_151 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_351 (Dropout)       (None, 416)               0         
                                                                 
 dense_451 (Dense)           (None, 448)               186816    
                                                                 
 dropout_352 (Dropout)       (None, 448)               0         
                                                                 
 dense_452 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 929498 (3.55 MB)
Trainable params: 928666 (3.54 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 100:
  Value: 0.8155
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 352
  units_3: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.2
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.00017327125431571615

Model: "sequential_100"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_100 (Flatten)       (None, 784)               0         
                                                                 
 dense_453 (Dense)           (None, 480)               376800    
                                                                 
 dropout_353 (Dropout)       (None, 480)               0         
                                                                 
 dense_454 (Dense)           (None, 384)               184704    
                                                                 
 dropout_354 (Dropout)       (None, 384)               0         
                                                                 
 dense_455 (Dense)           (None, 352)               135520    
                                                                 
 batch_normalization_152 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_355 (Dropout)       (None, 352)               0         
                                                                 
 dense_456 (Dense)           (None, 512)               180736    
                                                                 
 dropout_356 (Dropout)       (None, 512)               0         
                                                                 
 dense_457 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 892506 (3.40 MB)
Trainable params: 891802 (3.40 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 101:
  Value: 0.9126
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00011300572588132864

Model: "sequential_101"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_101 (Flatten)       (None, 784)               0         
                                                                 
 dense_458 (Dense)           (None, 480)               376800    
                                                                 
 dropout_357 (Dropout)       (None, 480)               0         
                                                                 
 dense_459 (Dense)           (None, 352)               169312    
                                                                 
 dropout_358 (Dropout)       (None, 352)               0         
                                                                 
 dense_460 (Dense)           (None, 384)               135552    
                                                                 
 batch_normalization_153 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_359 (Dropout)       (None, 384)               0         
                                                                 
 dense_461 (Dense)           (None, 512)               197120    
                                                                 
 dropout_360 (Dropout)       (None, 512)               0         
                                                                 
 dense_462 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 893658 (3.41 MB)
Trainable params: 892890 (3.41 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 102:
  Value: 0.8438
  num_layers: 4
  units_0: 448
  units_1: 320
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010023374009773848

Model: "sequential_102"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_102 (Flatten)       (None, 784)               0         
                                                                 
 dense_463 (Dense)           (None, 448)               351680    
                                                                 
 dropout_361 (Dropout)       (None, 448)               0         
                                                                 
 dense_464 (Dense)           (None, 320)               143680    
                                                                 
 dropout_362 (Dropout)       (None, 320)               0         
                                                                 
 dense_465 (Dense)           (None, 416)               133536    
                                                                 
 batch_normalization_154 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_363 (Dropout)       (None, 416)               0         
                                                                 
 dense_466 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_155 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_364 (Dropout)       (None, 480)               0         
                                                                 
 dense_467 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 845146 (3.22 MB)
Trainable params: 843354 (3.22 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 103:
  Value: 0.6937
  num_layers: 4
  units_0: 64
  units_1: 320
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.30000000000000004
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00013161921525066628

Model: "sequential_103"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_103 (Flatten)       (None, 784)               0         
                                                                 
 dense_468 (Dense)           (None, 64)                50240     
                                                                 
 dropout_365 (Dropout)       (None, 64)                0         
                                                                 
 dense_469 (Dense)           (None, 320)               20800     
                                                                 
 dropout_366 (Dropout)       (None, 320)               0         
                                                                 
 dense_470 (Dense)           (None, 384)               123264    
                                                                 
 batch_normalization_156 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_367 (Dropout)       (None, 384)               0         
                                                                 
 dense_471 (Dense)           (None, 512)               197120    
                                                                 
 batch_normalization_157 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_368 (Dropout)       (None, 512)               0         
                                                                 
 dense_472 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 408346 (1.56 MB)
Trainable params: 406554 (1.55 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 104:
  Value: 0.9135
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 416
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00014989827129317115

Model: "sequential_104"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_104 (Flatten)       (None, 784)               0         
                                                                 
 dense_473 (Dense)           (None, 480)               376800    
                                                                 
 dropout_369 (Dropout)       (None, 480)               0         
                                                                 
 dense_474 (Dense)           (None, 352)               169312    
                                                                 
 dropout_370 (Dropout)       (None, 352)               0         
                                                                 
 dense_475 (Dense)           (None, 416)               146848    
                                                                 
 batch_normalization_158 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_371 (Dropout)       (None, 416)               0         
                                                                 
 dense_476 (Dense)           (None, 512)               213504    
                                                                 
 dropout_372 (Dropout)       (None, 512)               0         
                                                                 
 dense_477 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 921466 (3.52 MB)
Trainable params: 920634 (3.51 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 105:
  Value: 0.9136
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00020661515867905544

Model: "sequential_105"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_105 (Flatten)       (None, 784)               0         
                                                                 
 dense_478 (Dense)           (None, 480)               376800    
                                                                 
 dropout_373 (Dropout)       (None, 480)               0         
                                                                 
 dense_479 (Dense)           (None, 416)               200096    
                                                                 
 dropout_374 (Dropout)       (None, 416)               0         
                                                                 
 dense_480 (Dense)           (None, 416)               173472    
                                                                 
 batch_normalization_159 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_375 (Dropout)       (None, 416)               0         
                                                                 
 dense_481 (Dense)           (None, 480)               200160    
                                                                 
 dropout_376 (Dropout)       (None, 480)               0         
                                                                 
 dense_482 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 964698 (3.68 MB)
Trainable params: 963866 (3.68 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 106:
  Value: 0.9124
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 160
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00020849739816899455

Model: "sequential_106"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_106 (Flatten)       (None, 784)               0         
                                                                 
 dense_483 (Dense)           (None, 512)               401920    
                                                                 
 dropout_377 (Dropout)       (None, 512)               0         
                                                                 
 dense_484 (Dense)           (None, 416)               213408    
                                                                 
 dropout_378 (Dropout)       (None, 416)               0         
                                                                 
 dense_485 (Dense)           (None, 448)               186816    
                                                                 
 batch_normalization_160 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_379 (Dropout)       (None, 448)               0         
                                                                 
 dense_486 (Dense)           (None, 160)               71840     
                                                                 
 dropout_380 (Dropout)       (None, 160)               0         
                                                                 
 dense_487 (Dense)           (None, 26)                4186      
                                                                 
=================================================================
Total params: 879962 (3.36 MB)
Trainable params: 879066 (3.35 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 107:
  Value: 0.9098
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 416
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00024426560477080946

Model: "sequential_107"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_107 (Flatten)       (None, 784)               0         
                                                                 
 dense_488 (Dense)           (None, 480)               376800    
                                                                 
 dropout_381 (Dropout)       (None, 480)               0         
                                                                 
 dense_489 (Dense)           (None, 416)               200096    
                                                                 
 dropout_382 (Dropout)       (None, 416)               0         
                                                                 
 dense_490 (Dense)           (None, 416)               173472    
                                                                 
 dropout_383 (Dropout)       (None, 416)               0         
                                                                 
 dense_491 (Dense)           (None, 448)               186816    
                                                                 
 dropout_384 (Dropout)       (None, 448)               0         
                                                                 
 dense_492 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 948858 (3.62 MB)
Trainable params: 948858 (3.62 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 108:
  Value: 0.8140
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 224
  units_3: 96
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002758907731213916

Model: "sequential_108"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_108 (Flatten)       (None, 784)               0         
                                                                 
 dense_493 (Dense)           (None, 512)               401920    
                                                                 
 dropout_385 (Dropout)       (None, 512)               0         
                                                                 
 dense_494 (Dense)           (None, 384)               196992    
                                                                 
 dropout_386 (Dropout)       (None, 384)               0         
                                                                 
 dense_495 (Dense)           (None, 224)               86240     
                                                                 
 batch_normalization_161 (B  (None, 224)               896       
 atchNormalization)                                              
                                                                 
 dropout_387 (Dropout)       (None, 224)               0         
                                                                 
 dense_496 (Dense)           (None, 96)                21600     
                                                                 
 dropout_388 (Dropout)       (None, 96)                0         
                                                                 
 dense_497 (Dense)           (None, 26)                2522      
                                                                 
=================================================================
Total params: 710170 (2.71 MB)
Trainable params: 709722 (2.71 MB)
Non-trainable params: 448 (1.75 KB)
_________________________________________________________________



Trial 109:
  Value: 0.8091
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 416
  units_3: 224
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.5
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00022816597839226744

Model: "sequential_109"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_109 (Flatten)       (None, 784)               0         
                                                                 
 dense_498 (Dense)           (None, 480)               376800    
                                                                 
 batch_normalization_162 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_389 (Dropout)       (None, 480)               0         
                                                                 
 dense_499 (Dense)           (None, 384)               184704    
                                                                 
 dropout_390 (Dropout)       (None, 384)               0         
                                                                 
 dense_500 (Dense)           (None, 416)               160160    
                                                                 
 batch_normalization_163 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_391 (Dropout)       (None, 416)               0         
                                                                 
 dense_501 (Dense)           (None, 224)               93408     
                                                                 
 dropout_392 (Dropout)       (None, 224)               0         
                                                                 
 dense_502 (Dense)           (None, 26)                5850      
                                                                 
=================================================================
Total params: 824506 (3.15 MB)
Trainable params: 822714 (3.14 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 110:
  Value: 0.2276
  num_layers: 4
  units_0: 288
  units_1: 480
  units_2: 448
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.00019412704740748047

Model: "sequential_110"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_110 (Flatten)       (None, 784)               0         
                                                                 
 dense_503 (Dense)           (None, 288)               226080    
                                                                 
 dropout_393 (Dropout)       (None, 288)               0         
                                                                 
 dense_504 (Dense)           (None, 480)               138720    
                                                                 
 batch_normalization_164 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_394 (Dropout)       (None, 480)               0         
                                                                 
 dense_505 (Dense)           (None, 448)               215488    
                                                                 
 batch_normalization_165 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_395 (Dropout)       (None, 448)               0         
                                                                 
 dense_506 (Dense)           (None, 480)               215520    
                                                                 
 dropout_396 (Dropout)       (None, 480)               0         
                                                                 
 dense_507 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 812026 (3.10 MB)
Trainable params: 810170 (3.09 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 111:
  Value: 0.9139
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00015205030937436774

Model: "sequential_111"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_111 (Flatten)       (None, 784)               0         
                                                                 
 dense_508 (Dense)           (None, 480)               376800    
                                                                 
 dropout_397 (Dropout)       (None, 480)               0         
                                                                 
 dense_509 (Dense)           (None, 352)               169312    
                                                                 
 dropout_398 (Dropout)       (None, 352)               0         
                                                                 
 dense_510 (Dense)           (None, 416)               146848    
                                                                 
 batch_normalization_166 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_399 (Dropout)       (None, 416)               0         
                                                                 
 dense_511 (Dense)           (None, 480)               200160    
                                                                 
 dropout_400 (Dropout)       (None, 480)               0         
                                                                 
 dense_512 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 907290 (3.46 MB)
Trainable params: 906458 (3.46 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 112:
  Value: 0.9131
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 448
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00016854680858830064

Model: "sequential_112"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_112 (Flatten)       (None, 784)               0         
                                                                 
 dense_513 (Dense)           (None, 512)               401920    
                                                                 
 dropout_401 (Dropout)       (None, 512)               0         
                                                                 
 dense_514 (Dense)           (None, 352)               180576    
                                                                 
 dropout_402 (Dropout)       (None, 352)               0         
                                                                 
 dense_515 (Dense)           (None, 448)               158144    
                                                                 
 batch_normalization_167 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_403 (Dropout)       (None, 448)               0         
                                                                 
 dense_516 (Dense)           (None, 512)               229888    
                                                                 
 dropout_404 (Dropout)       (None, 512)               0         
                                                                 
 dense_517 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 985658 (3.76 MB)
Trainable params: 984762 (3.76 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 113:
  Value: 0.9139
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 384
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00013577536650960197

Model: "sequential_113"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_113 (Flatten)       (None, 784)               0         
                                                                 
 dense_518 (Dense)           (None, 480)               376800    
                                                                 
 dropout_405 (Dropout)       (None, 480)               0         
                                                                 
 dense_519 (Dense)           (None, 352)               169312    
                                                                 
 dropout_406 (Dropout)       (None, 352)               0         
                                                                 
 dense_520 (Dense)           (None, 384)               135552    
                                                                 
 batch_normalization_168 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_407 (Dropout)       (None, 384)               0         
                                                                 
 dense_521 (Dense)           (None, 480)               184800    
                                                                 
 dropout_408 (Dropout)       (None, 480)               0         
                                                                 
 dense_522 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 880506 (3.36 MB)
Trainable params: 879738 (3.36 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 114:
  Value: 0.9140
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 384
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00013471604111655184

Model: "sequential_114"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_114 (Flatten)       (None, 784)               0         
                                                                 
 dense_523 (Dense)           (None, 480)               376800    
                                                                 
 dropout_409 (Dropout)       (None, 480)               0         
                                                                 
 dense_524 (Dense)           (None, 352)               169312    
                                                                 
 dropout_410 (Dropout)       (None, 352)               0         
                                                                 
 dense_525 (Dense)           (None, 384)               135552    
                                                                 
 batch_normalization_169 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_411 (Dropout)       (None, 384)               0         
                                                                 
 dense_526 (Dense)           (None, 480)               184800    
                                                                 
 dropout_412 (Dropout)       (None, 480)               0         
                                                                 
 dense_527 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 880506 (3.36 MB)
Trainable params: 879738 (3.36 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 115:
  Value: 0.9101
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 352
  units_3: 480
  activation_0: tanh
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00013627921713077343

Model: "sequential_115"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_115 (Flatten)       (None, 784)               0         
                                                                 
 dense_528 (Dense)           (None, 512)               401920    
                                                                 
 dropout_413 (Dropout)       (None, 512)               0         
                                                                 
 dense_529 (Dense)           (None, 352)               180576    
                                                                 
 dropout_414 (Dropout)       (None, 352)               0         
                                                                 
 dense_530 (Dense)           (None, 352)               124256    
                                                                 
 batch_normalization_170 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_415 (Dropout)       (None, 352)               0         
                                                                 
 dense_531 (Dense)           (None, 480)               169440    
                                                                 
 dropout_416 (Dropout)       (None, 480)               0         
                                                                 
 dense_532 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 890106 (3.40 MB)
Trainable params: 889402 (3.39 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 116:
  Value: 0.7405
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 384
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.00012191232937576551

Model: "sequential_116"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_116 (Flatten)       (None, 784)               0         
                                                                 
 dense_533 (Dense)           (None, 480)               376800    
                                                                 
 dropout_417 (Dropout)       (None, 480)               0         
                                                                 
 dense_534 (Dense)           (None, 352)               169312    
                                                                 
 dropout_418 (Dropout)       (None, 352)               0         
                                                                 
 dense_535 (Dense)           (None, 384)               135552    
                                                                 
 batch_normalization_171 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_419 (Dropout)       (None, 384)               0         
                                                                 
 dense_536 (Dense)           (None, 448)               172480    
                                                                 
 dropout_420 (Dropout)       (None, 448)               0         
                                                                 
 dense_537 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 867354 (3.31 MB)
Trainable params: 866586 (3.31 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 117:
  Value: 0.9120
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 352
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00010688498970929842

Model: "sequential_117"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_117 (Flatten)       (None, 784)               0         
                                                                 
 dense_538 (Dense)           (None, 512)               401920    
                                                                 
 dropout_421 (Dropout)       (None, 512)               0         
                                                                 
 dense_539 (Dense)           (None, 384)               196992    
                                                                 
 dropout_422 (Dropout)       (None, 384)               0         
                                                                 
 dense_540 (Dense)           (None, 352)               135520    
                                                                 
 dropout_423 (Dropout)       (None, 352)               0         
                                                                 
 dense_541 (Dense)           (None, 416)               146848    
                                                                 
 dropout_424 (Dropout)       (None, 416)               0         
                                                                 
 dense_542 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 892122 (3.40 MB)
Trainable params: 892122 (3.40 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 118:
  Value: 0.6094
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 384
  units_3: 448
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001273751946126027

Model: "sequential_118"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_118 (Flatten)       (None, 784)               0         
                                                                 
 dense_543 (Dense)           (None, 480)               376800    
                                                                 
 dropout_425 (Dropout)       (None, 480)               0         
                                                                 
 dense_544 (Dense)           (None, 320)               153920    
                                                                 
 dropout_426 (Dropout)       (None, 320)               0         
                                                                 
 dense_545 (Dense)           (None, 384)               123264    
                                                                 
 batch_normalization_172 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_427 (Dropout)       (None, 384)               0         
                                                                 
 dense_546 (Dense)           (None, 448)               172480    
                                                                 
 dropout_428 (Dropout)       (None, 448)               0         
                                                                 
 dense_547 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 839674 (3.20 MB)
Trainable params: 838906 (3.20 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 119:
  Value: 0.9144
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00013976300107714363

Model: "sequential_119"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_119 (Flatten)       (None, 784)               0         
                                                                 
 dense_548 (Dense)           (None, 512)               401920    
                                                                 
 dropout_429 (Dropout)       (None, 512)               0         
                                                                 
 dense_549 (Dense)           (None, 352)               180576    
                                                                 
 dropout_430 (Dropout)       (None, 352)               0         
                                                                 
 dense_550 (Dense)           (None, 320)               112960    
                                                                 
 batch_normalization_173 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_431 (Dropout)       (None, 320)               0         
                                                                 
 dense_551 (Dense)           (None, 512)               164352    
                                                                 
 dropout_432 (Dropout)       (None, 512)               0         
                                                                 
 dense_552 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 874426 (3.34 MB)
Trainable params: 873786 (3.33 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 120:
  Value: 0.9123
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00014293878952102224

Model: "sequential_120"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_120 (Flatten)       (None, 784)               0         
                                                                 
 dense_553 (Dense)           (None, 512)               401920    
                                                                 
 dropout_433 (Dropout)       (None, 512)               0         
                                                                 
 dense_554 (Dense)           (None, 320)               164160    
                                                                 
 dropout_434 (Dropout)       (None, 320)               0         
                                                                 
 dense_555 (Dense)           (None, 320)               102720    
                                                                 
 batch_normalization_174 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_435 (Dropout)       (None, 320)               0         
                                                                 
 dense_556 (Dense)           (None, 512)               164352    
                                                                 
 dropout_436 (Dropout)       (None, 512)               0         
                                                                 
 dense_557 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 847770 (3.23 MB)
Trainable params: 847130 (3.23 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 121:
  Value: 0.9119
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 320
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00016432984975827005

Model: "sequential_121"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_121 (Flatten)       (None, 784)               0         
                                                                 
 dense_558 (Dense)           (None, 512)               401920    
                                                                 
 dropout_437 (Dropout)       (None, 512)               0         
                                                                 
 dense_559 (Dense)           (None, 352)               180576    
                                                                 
 dropout_438 (Dropout)       (None, 352)               0         
                                                                 
 dense_560 (Dense)           (None, 320)               112960    
                                                                 
 batch_normalization_175 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_439 (Dropout)       (None, 320)               0         
                                                                 
 dense_561 (Dense)           (None, 480)               154080    
                                                                 
 dropout_440 (Dropout)       (None, 480)               0         
                                                                 
 dense_562 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 863322 (3.29 MB)
Trainable params: 862682 (3.29 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 122:
  Value: 0.8895
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 384
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00011183474031386598

Model: "sequential_122"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_122 (Flatten)       (None, 784)               0         
                                                                 
 dense_563 (Dense)           (None, 480)               376800    
                                                                 
 dropout_441 (Dropout)       (None, 480)               0         
                                                                 
 dense_564 (Dense)           (None, 352)               169312    
                                                                 
 dropout_442 (Dropout)       (None, 352)               0         
                                                                 
 dense_565 (Dense)           (None, 384)               135552    
                                                                 
 batch_normalization_176 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_443 (Dropout)       (None, 384)               0         
                                                                 
 dense_566 (Dense)           (None, 512)               197120    
                                                                 
 dropout_444 (Dropout)       (None, 512)               0         
                                                                 
 dense_567 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 893658 (3.41 MB)
Trainable params: 892890 (3.41 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 123:
  Value: 0.8507
  num_layers: 4
  units_0: 448
  units_1: 384
  units_2: 352
  units_3: 384
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00013407693310499248

Model: "sequential_123"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_123 (Flatten)       (None, 784)               0         
                                                                 
 dense_568 (Dense)           (None, 448)               351680    
                                                                 
 dropout_445 (Dropout)       (None, 448)               0         
                                                                 
 dense_569 (Dense)           (None, 384)               172416    
                                                                 
 dropout_446 (Dropout)       (None, 384)               0         
                                                                 
 dense_570 (Dense)           (None, 352)               135520    
                                                                 
 batch_normalization_177 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_447 (Dropout)       (None, 352)               0         
                                                                 
 dense_571 (Dense)           (None, 384)               135552    
                                                                 
 dropout_448 (Dropout)       (None, 384)               0         
                                                                 
 dense_572 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 806586 (3.08 MB)
Trainable params: 805882 (3.07 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 124:
  Value: 0.9127
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 256
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00011964399072069252

Model: "sequential_124"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_124 (Flatten)       (None, 784)               0         
                                                                 
 dense_573 (Dense)           (None, 512)               401920    
                                                                 
 dropout_449 (Dropout)       (None, 512)               0         
                                                                 
 dense_574 (Dense)           (None, 352)               180576    
                                                                 
 dropout_450 (Dropout)       (None, 352)               0         
                                                                 
 dense_575 (Dense)           (None, 256)               90368     
                                                                 
 batch_normalization_178 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_451 (Dropout)       (None, 256)               0         
                                                                 
 dense_576 (Dense)           (None, 480)               123360    
                                                                 
 dropout_452 (Dropout)       (None, 480)               0         
                                                                 
 dense_577 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 809754 (3.09 MB)
Trainable params: 809242 (3.09 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________



Trial 125:
  Value: 0.9154
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 288
  units_3: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00017307501898506294

Model: "sequential_125"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_125 (Flatten)       (None, 784)               0         
                                                                 
 dense_578 (Dense)           (None, 480)               376800    
                                                                 
 dropout_453 (Dropout)       (None, 480)               0         
                                                                 
 dense_579 (Dense)           (None, 384)               184704    
                                                                 
 dropout_454 (Dropout)       (None, 384)               0         
                                                                 
 dense_580 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_179 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_455 (Dropout)       (None, 288)               0         
                                                                 
 dense_581 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_180 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_456 (Dropout)       (None, 512)               0         
                                                                 
 dense_582 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 836890 (3.19 MB)
Trainable params: 835290 (3.19 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 126:
  Value: 0.0421
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 288
  units_3: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.00015457032569936885

Model: "sequential_126"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_126 (Flatten)       (None, 784)               0         
                                                                 
 dense_583 (Dense)           (None, 512)               401920    
                                                                 
 dropout_457 (Dropout)       (None, 512)               0         
                                                                 
 dense_584 (Dense)           (None, 384)               196992    
                                                                 
 dropout_458 (Dropout)       (None, 384)               0         
                                                                 
 dense_585 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_181 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_459 (Dropout)       (None, 288)               0         
                                                                 
 dense_586 (Dense)           (None, 512)               147968    
                                                                 
 dropout_460 (Dropout)       (None, 512)               0         
                                                                 
 dense_587 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 872250 (3.33 MB)
Trainable params: 871674 (3.33 MB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 127:
  Value: 0.9108
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 288
  units_3: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001401706913311139

Model: "sequential_127"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_127 (Flatten)       (None, 784)               0         
                                                                 
 dense_588 (Dense)           (None, 480)               376800    
                                                                 
 dropout_461 (Dropout)       (None, 480)               0         
                                                                 
 dense_589 (Dense)           (None, 352)               169312    
                                                                 
 dropout_462 (Dropout)       (None, 352)               0         
                                                                 
 dense_590 (Dense)           (None, 288)               101664    
                                                                 
 batch_normalization_182 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_463 (Dropout)       (None, 288)               0         
                                                                 
 dense_591 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_183 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_464 (Dropout)       (None, 512)               0         
                                                                 
 dense_592 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 812282 (3.10 MB)
Trainable params: 810682 (3.09 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 128:
  Value: 0.4886
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 256
  units_3: 480
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: True
  optimizer: rmsprop
  learning_rate: 0.00010571510170144636

Model: "sequential_128"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_128 (Flatten)       (None, 784)               0         
                                                                 
 dense_593 (Dense)           (None, 480)               376800    
                                                                 
 dropout_465 (Dropout)       (None, 480)               0         
                                                                 
 dense_594 (Dense)           (None, 448)               215488    
                                                                 
 dropout_466 (Dropout)       (None, 448)               0         
                                                                 
 dense_595 (Dense)           (None, 256)               114944    
                                                                 
 dropout_467 (Dropout)       (None, 256)               0         
                                                                 
 dense_596 (Dense)           (None, 480)               123360    
                                                                 
 batch_normalization_184 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_468 (Dropout)       (None, 480)               0         
                                                                 
 dense_597 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 845018 (3.22 MB)
Trainable params: 844058 (3.22 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 129:
  Value: 0.0385
  num_layers: 4
  units_0: 448
  units_1: 320
  units_2: 320
  units_3: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.00017085955391278593

Model: "sequential_129"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_129 (Flatten)       (None, 784)               0         
                                                                 
 dense_598 (Dense)           (None, 448)               351680    
                                                                 
 batch_normalization_185 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_469 (Dropout)       (None, 448)               0         
                                                                 
 dense_599 (Dense)           (None, 320)               143680    
                                                                 
 dropout_470 (Dropout)       (None, 320)               0         
                                                                 
 dense_600 (Dense)           (None, 320)               102720    
                                                                 
 batch_normalization_186 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_471 (Dropout)       (None, 320)               0         
                                                                 
 dense_601 (Dense)           (None, 512)               164352    
                                                                 
 dropout_472 (Dropout)       (None, 512)               0         
                                                                 
 dense_602 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 778842 (2.97 MB)
Trainable params: 777306 (2.97 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 130:
  Value: 0.4186
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 288
  units_3: 480
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.5
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012254394892924242

Model: "sequential_130"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_130 (Flatten)       (None, 784)               0         
                                                                 
 dense_603 (Dense)           (None, 512)               401920    
                                                                 
 dropout_473 (Dropout)       (None, 512)               0         
                                                                 
 dense_604 (Dense)           (None, 384)               196992    
                                                                 
 batch_normalization_187 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_474 (Dropout)       (None, 384)               0         
                                                                 
 dense_605 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_188 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_475 (Dropout)       (None, 288)               0         
                                                                 
 dense_606 (Dense)           (None, 480)               138720    
                                                                 
 batch_normalization_189 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_476 (Dropout)       (None, 480)               0         
                                                                 
 dense_607 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 865626 (3.30 MB)
Trainable params: 863322 (3.29 MB)
Non-trainable params: 2304 (9.00 KB)
_________________________________________________________________



Trial 131:
  Value: 0.9135
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 448
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00018669651059657633

Model: "sequential_131"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_131 (Flatten)       (None, 784)               0         
                                                                 
 dense_608 (Dense)           (None, 480)               376800    
                                                                 
 dropout_477 (Dropout)       (None, 480)               0         
                                                                 
 dense_609 (Dense)           (None, 352)               169312    
                                                                 
 dropout_478 (Dropout)       (None, 352)               0         
                                                                 
 dense_610 (Dense)           (None, 448)               158144    
                                                                 
 batch_normalization_190 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_479 (Dropout)       (None, 448)               0         
                                                                 
 dense_611 (Dense)           (None, 512)               229888    
                                                                 
 batch_normalization_191 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_480 (Dropout)       (None, 512)               0         
                                                                 
 dense_612 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 951322 (3.63 MB)
Trainable params: 949402 (3.62 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 132:
  Value: 0.8073
  num_layers: 4
  units_0: 224
  units_1: 384
  units_2: 384
  units_3: 288
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00015765689950257217

Model: "sequential_132"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_132 (Flatten)       (None, 784)               0         
                                                                 
 dense_613 (Dense)           (None, 224)               175840    
                                                                 
 dropout_481 (Dropout)       (None, 224)               0         
                                                                 
 dense_614 (Dense)           (None, 384)               86400     
                                                                 
 dropout_482 (Dropout)       (None, 384)               0         
                                                                 
 dense_615 (Dense)           (None, 384)               147840    
                                                                 
 batch_normalization_192 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_483 (Dropout)       (None, 384)               0         
                                                                 
 dense_616 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_193 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_484 (Dropout)       (None, 288)               0         
                                                                 
 dense_617 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 531162 (2.03 MB)
Trainable params: 529818 (2.02 MB)
Non-trainable params: 1344 (5.25 KB)
_________________________________________________________________



Trial 133:
  Value: 0.8313
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00018535650279215266

Model: "sequential_133"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_133 (Flatten)       (None, 784)               0         
                                                                 
 dense_618 (Dense)           (None, 480)               376800    
                                                                 
 dropout_485 (Dropout)       (None, 480)               0         
                                                                 
 dense_619 (Dense)           (None, 352)               169312    
                                                                 
 dropout_486 (Dropout)       (None, 352)               0         
                                                                 
 dense_620 (Dense)           (None, 416)               146848    
                                                                 
 batch_normalization_194 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_487 (Dropout)       (None, 416)               0         
                                                                 
 dense_621 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_195 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_488 (Dropout)       (None, 480)               0         
                                                                 
 dense_622 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 909210 (3.47 MB)
Trainable params: 907418 (3.46 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 134:
  Value: 0.9179
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00014406304358752264

Model: "sequential_134"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_134 (Flatten)       (None, 784)               0         
                                                                 
 dense_623 (Dense)           (None, 512)               401920    
                                                                 
 dropout_489 (Dropout)       (None, 512)               0         
                                                                 
 dense_624 (Dense)           (None, 352)               180576    
                                                                 
 dropout_490 (Dropout)       (None, 352)               0         
                                                                 
 dense_625 (Dense)           (None, 320)               112960    
                                                                 
 batch_normalization_196 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_491 (Dropout)       (None, 320)               0         
                                                                 
 dense_626 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_197 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_492 (Dropout)       (None, 512)               0         
                                                                 
 dense_627 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 876474 (3.34 MB)
Trainable params: 874810 (3.34 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 135:
  Value: 0.5672
  num_layers: 4
  units_0: 256
  units_1: 64
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012769281802251745

Model: "sequential_135"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_135 (Flatten)       (None, 784)               0         
                                                                 
 dense_628 (Dense)           (None, 256)               200960    
                                                                 
 dropout_493 (Dropout)       (None, 256)               0         
                                                                 
 dense_629 (Dense)           (None, 64)                16448     
                                                                 
 dropout_494 (Dropout)       (None, 64)                0         
                                                                 
 dense_630 (Dense)           (None, 320)               20800     
                                                                 
 batch_normalization_198 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_495 (Dropout)       (None, 320)               0         
                                                                 
 dense_631 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_199 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_496 (Dropout)       (None, 512)               0         
                                                                 
 dense_632 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 419226 (1.60 MB)
Trainable params: 417562 (1.59 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 136:
  Value: 0.6702
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 352
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010991741415635653

Model: "sequential_136"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_136 (Flatten)       (None, 784)               0         
                                                                 
 dense_633 (Dense)           (None, 512)               401920    
                                                                 
 dropout_497 (Dropout)       (None, 512)               0         
                                                                 
 dense_634 (Dense)           (None, 320)               164160    
                                                                 
 dropout_498 (Dropout)       (None, 320)               0         
                                                                 
 dense_635 (Dense)           (None, 352)               112992    
                                                                 
 batch_normalization_200 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_499 (Dropout)       (None, 352)               0         
                                                                 
 dense_636 (Dense)           (None, 512)               180736    
                                                                 
 batch_normalization_201 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_500 (Dropout)       (None, 512)               0         
                                                                 
 dense_637 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 876602 (3.34 MB)
Trainable params: 874874 (3.34 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 137:
  Value: 0.9143
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 320
  units_3: 480
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001457279872952751

Model: "sequential_137"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_137 (Flatten)       (None, 784)               0         
                                                                 
 dense_638 (Dense)           (None, 512)               401920    
                                                                 
 dropout_501 (Dropout)       (None, 512)               0         
                                                                 
 dense_639 (Dense)           (None, 384)               196992    
                                                                 
 dropout_502 (Dropout)       (None, 384)               0         
                                                                 
 dense_640 (Dense)           (None, 320)               123200    
                                                                 
 batch_normalization_202 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_503 (Dropout)       (None, 320)               0         
                                                                 
 dense_641 (Dense)           (None, 480)               154080    
                                                                 
 batch_normalization_203 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_504 (Dropout)       (None, 480)               0         
                                                                 
 dense_642 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 891898 (3.40 MB)
Trainable params: 890298 (3.40 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 138:
  Value: 0.8013
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: tanh
  activation_1: tanh
  dropout_0: 0.1
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001447744130805901

Model: "sequential_138"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_138 (Flatten)       (None, 784)               0         
                                                                 
 dense_643 (Dense)           (None, 512)               401920    
                                                                 
 dropout_505 (Dropout)       (None, 512)               0         
                                                                 
 dense_644 (Dense)           (None, 384)               196992    
                                                                 
 dropout_506 (Dropout)       (None, 384)               0         
                                                                 
 dense_645 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 139:
  Value: 0.9019
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 288
  units_3: 512
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00021852129458399907

Model: "sequential_139"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_139 (Flatten)       (None, 784)               0         
                                                                 
 dense_646 (Dense)           (None, 512)               401920    
                                                                 
 dropout_507 (Dropout)       (None, 512)               0         
                                                                 
 dense_647 (Dense)           (None, 416)               213408    
                                                                 
 dropout_508 (Dropout)       (None, 416)               0         
                                                                 
 dense_648 (Dense)           (None, 288)               120096    
                                                                 
 batch_normalization_204 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_509 (Dropout)       (None, 288)               0         
                                                                 
 dense_649 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_205 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_510 (Dropout)       (None, 512)               0         
                                                                 
 dense_650 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 899930 (3.43 MB)
Trainable params: 898330 (3.43 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 140:
  Value: 0.6201
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: sgd
  learning_rate: 0.0001564317175080468

Model: "sequential_140"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_140 (Flatten)       (None, 784)               0         
                                                                 
 dense_651 (Dense)           (None, 512)               401920    
                                                                 
 dropout_511 (Dropout)       (None, 512)               0         
                                                                 
 dense_652 (Dense)           (None, 384)               196992    
                                                                 
 dropout_512 (Dropout)       (None, 384)               0         
                                                                 
 dense_653 (Dense)           (None, 320)               123200    
                                                                 
 batch_normalization_206 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_513 (Dropout)       (None, 320)               0         
                                                                 
 dense_654 (Dense)           (None, 448)               143808    
                                                                 
 batch_normalization_207 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_514 (Dropout)       (None, 448)               0         
                                                                 
 dense_655 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 880666 (3.36 MB)
Trainable params: 879130 (3.35 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 141:
  Value: 0.9131
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 352
  units_3: 480
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010003349272825823

Model: "sequential_141"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_141 (Flatten)       (None, 784)               0         
                                                                 
 dense_656 (Dense)           (None, 480)               376800    
                                                                 
 dropout_515 (Dropout)       (None, 480)               0         
                                                                 
 dense_657 (Dense)           (None, 352)               169312    
                                                                 
 dropout_516 (Dropout)       (None, 352)               0         
                                                                 
 dense_658 (Dense)           (None, 352)               124256    
                                                                 
 batch_normalization_208 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_517 (Dropout)       (None, 352)               0         
                                                                 
 dense_659 (Dense)           (None, 480)               169440    
                                                                 
 batch_normalization_209 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_518 (Dropout)       (None, 480)               0         
                                                                 
 dense_660 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 855642 (3.26 MB)
Trainable params: 853978 (3.26 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 142:
  Value: 0.9104
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 352
  units_3: 480
  activation_0: tanh
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00013618004049513368

Model: "sequential_142"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_142 (Flatten)       (None, 784)               0         
                                                                 
 dense_661 (Dense)           (None, 512)               401920    
                                                                 
 dropout_519 (Dropout)       (None, 512)               0         
                                                                 
 dense_662 (Dense)           (None, 352)               180576    
                                                                 
 dropout_520 (Dropout)       (None, 352)               0         
                                                                 
 dense_663 (Dense)           (None, 352)               124256    
                                                                 
 batch_normalization_210 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_521 (Dropout)       (None, 352)               0         
                                                                 
 dense_664 (Dense)           (None, 480)               169440    
                                                                 
 batch_normalization_211 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_522 (Dropout)       (None, 480)               0         
                                                                 
 dense_665 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 892026 (3.40 MB)
Trainable params: 890362 (3.40 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 143:
  Value: 0.9148
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012191070201704923

Model: "sequential_143"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_143 (Flatten)       (None, 784)               0         
                                                                 
 dense_666 (Dense)           (None, 512)               401920    
                                                                 
 dropout_523 (Dropout)       (None, 512)               0         
                                                                 
 dense_667 (Dense)           (None, 384)               196992    
                                                                 
 dropout_524 (Dropout)       (None, 384)               0         
                                                                 
 dense_668 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_212 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_525 (Dropout)       (None, 288)               0         
                                                                 
 dense_669 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_213 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_526 (Dropout)       (None, 512)               0         
                                                                 
 dense_670 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 874298 (3.34 MB)
Trainable params: 872698 (3.33 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 144:
  Value: 0.9139
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011840285049277872

Model: "sequential_144"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_144 (Flatten)       (None, 784)               0         
                                                                 
 dense_671 (Dense)           (None, 512)               401920    
                                                                 
 dropout_527 (Dropout)       (None, 512)               0         
                                                                 
 dense_672 (Dense)           (None, 384)               196992    
                                                                 
 dropout_528 (Dropout)       (None, 384)               0         
                                                                 
 dense_673 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_214 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_529 (Dropout)       (None, 288)               0         
                                                                 
 dense_674 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_215 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_530 (Dropout)       (None, 512)               0         
                                                                 
 dense_675 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 874298 (3.34 MB)
Trainable params: 872698 (3.33 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 145:
  Value: 0.9129
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 288
  units_3: 256
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001180165338411326

Model: "sequential_145"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_145 (Flatten)       (None, 784)               0         
                                                                 
 dense_676 (Dense)           (None, 512)               401920    
                                                                 
 dropout_531 (Dropout)       (None, 512)               0         
                                                                 
 dense_677 (Dense)           (None, 416)               213408    
                                                                 
 dropout_532 (Dropout)       (None, 416)               0         
                                                                 
 dense_678 (Dense)           (None, 288)               120096    
                                                                 
 dropout_533 (Dropout)       (None, 288)               0         
                                                                 
 dense_679 (Dense)           (None, 256)               73984     
                                                                 
 batch_normalization_216 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_534 (Dropout)       (None, 256)               0         
                                                                 
 dense_680 (Dense)           (None, 26)                6682      
                                                                 
=================================================================
Total params: 817114 (3.12 MB)
Trainable params: 816602 (3.12 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________



Trial 146:
  Value: 0.9135
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 256
  units_3: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011085578461091852

Model: "sequential_146"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_146 (Flatten)       (None, 784)               0         
                                                                 
 dense_681 (Dense)           (None, 512)               401920    
                                                                 
 dropout_535 (Dropout)       (None, 512)               0         
                                                                 
 dense_682 (Dense)           (None, 416)               213408    
                                                                 
 dropout_536 (Dropout)       (None, 416)               0         
                                                                 
 dense_683 (Dense)           (None, 256)               106752    
                                                                 
 batch_normalization_217 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_537 (Dropout)       (None, 256)               0         
                                                                 
 dense_684 (Dense)           (None, 512)               131584    
                                                                 
 batch_normalization_218 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_538 (Dropout)       (None, 512)               0         
                                                                 
 dense_685 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 870074 (3.32 MB)
Trainable params: 868538 (3.31 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 147:
  Value: 0.8008
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 320
  units_3: 512
  activation_0: sigmoid
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adamax
  learning_rate: 0.0001184664166412281

Model: "sequential_147"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_147 (Flatten)       (None, 784)               0         
                                                                 
 dense_686 (Dense)           (None, 512)               401920    
                                                                 
 dropout_539 (Dropout)       (None, 512)               0         
                                                                 
 dense_687 (Dense)           (None, 384)               196992    
                                                                 
 dropout_540 (Dropout)       (None, 384)               0         
                                                                 
 dense_688 (Dense)           (None, 320)               123200    
                                                                 
 batch_normalization_219 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_541 (Dropout)       (None, 320)               0         
                                                                 
 dense_689 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_220 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_542 (Dropout)       (None, 512)               0         
                                                                 
 dense_690 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 903130 (3.45 MB)
Trainable params: 901466 (3.44 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 148:
  Value: 0.9106
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.1
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012672240266377617

Model: "sequential_148"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_148 (Flatten)       (None, 784)               0         
                                                                 
 dense_691 (Dense)           (None, 512)               401920    
                                                                 
 dropout_543 (Dropout)       (None, 512)               0         
                                                                 
 dense_692 (Dense)           (None, 384)               196992    
                                                                 
 dropout_544 (Dropout)       (None, 384)               0         
                                                                 
 dense_693 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_221 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_545 (Dropout)       (None, 288)               0         
                                                                 
 dense_694 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_222 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_546 (Dropout)       (None, 512)               0         
                                                                 
 dense_695 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 874298 (3.34 MB)
Trainable params: 872698 (3.33 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 149:
  Value: 0.9021
  num_layers: 4
  units_0: 160
  units_1: 384
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001000618107535671

Model: "sequential_149"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_149 (Flatten)       (None, 784)               0         
                                                                 
 dense_696 (Dense)           (None, 160)               125600    
                                                                 
 dropout_547 (Dropout)       (None, 160)               0         
                                                                 
 dense_697 (Dense)           (None, 384)               61824     
                                                                 
 dropout_548 (Dropout)       (None, 384)               0         
                                                                 
 dense_698 (Dense)           (None, 320)               123200    
                                                                 
 batch_normalization_223 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_549 (Dropout)       (None, 320)               0         
                                                                 
 dense_699 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_224 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_550 (Dropout)       (None, 512)               0         
                                                                 
 dense_700 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 491642 (1.88 MB)
Trainable params: 489978 (1.87 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 150:
  Value: 0.9040
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 256
  units_3: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00017126265397570891

Model: "sequential_150"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_150 (Flatten)       (None, 784)               0         
                                                                 
 dense_701 (Dense)           (None, 512)               401920    
                                                                 
 dropout_551 (Dropout)       (None, 512)               0         
                                                                 
 dense_702 (Dense)           (None, 416)               213408    
                                                                 
 dropout_552 (Dropout)       (None, 416)               0         
                                                                 
 dense_703 (Dense)           (None, 256)               106752    
                                                                 
 batch_normalization_225 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_553 (Dropout)       (None, 256)               0         
                                                                 
 dense_704 (Dense)           (None, 512)               131584    
                                                                 
 batch_normalization_226 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_554 (Dropout)       (None, 512)               0         
                                                                 
 dense_705 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 870074 (3.32 MB)
Trainable params: 868538 (3.31 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 151:
  Value: 0.8505
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 288
  units_3: 480
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.0
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00014366850642418786

Model: "sequential_151"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_151 (Flatten)       (None, 784)               0         
                                                                 
 dense_706 (Dense)           (None, 480)               376800    
                                                                 
 dropout_555 (Dropout)       (None, 480)               0         
                                                                 
 dense_707 (Dense)           (None, 384)               184704    
                                                                 
 dropout_556 (Dropout)       (None, 384)               0         
                                                                 
 dense_708 (Dense)           (None, 288)               110880    
                                                                 
 batch_normalization_227 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_557 (Dropout)       (None, 288)               0         
                                                                 
 dense_709 (Dense)           (None, 480)               138720    
                                                                 
 batch_normalization_228 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_558 (Dropout)       (None, 480)               0         
                                                                 
 dense_710 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 826682 (3.15 MB)
Trainable params: 825146 (3.15 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 152:
  Value: 0.9119
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 320
  units_3: 480
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00014856504287033594

Model: "sequential_152"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_152 (Flatten)       (None, 784)               0         
                                                                 
 dense_711 (Dense)           (None, 512)               401920    
                                                                 
 dropout_559 (Dropout)       (None, 512)               0         
                                                                 
 dense_712 (Dense)           (None, 448)               229824    
                                                                 
 dropout_560 (Dropout)       (None, 448)               0         
                                                                 
 dense_713 (Dense)           (None, 320)               143680    
                                                                 
 batch_normalization_229 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_561 (Dropout)       (None, 320)               0         
                                                                 
 dense_714 (Dense)           (None, 480)               154080    
                                                                 
 batch_normalization_230 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_562 (Dropout)       (None, 480)               0         
                                                                 
 dense_715 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 945210 (3.61 MB)
Trainable params: 943610 (3.60 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 153:
  Value: 0.8654
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 288
  units_3: 32
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00012360742265071724

Model: "sequential_153"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_153 (Flatten)       (None, 784)               0         
                                                                 
 dense_716 (Dense)           (None, 480)               376800    
                                                                 
 dropout_563 (Dropout)       (None, 480)               0         
                                                                 
 dense_717 (Dense)           (None, 352)               169312    
                                                                 
 dropout_564 (Dropout)       (None, 352)               0         
                                                                 
 dense_718 (Dense)           (None, 288)               101664    
                                                                 
 batch_normalization_231 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_565 (Dropout)       (None, 288)               0         
                                                                 
 dense_719 (Dense)           (None, 32)                9248      
                                                                 
 batch_normalization_232 (B  (None, 32)                128       
 atchNormalization)                                              
                                                                 
 dropout_566 (Dropout)       (None, 32)                0         
                                                                 
 dense_720 (Dense)           (None, 26)                858       
                                                                 
=================================================================
Total params: 659162 (2.51 MB)
Trainable params: 658522 (2.51 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 154:
  Value: 0.9156
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001659392850835517

Model: "sequential_154"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_154 (Flatten)       (None, 784)               0         
                                                                 
 dense_721 (Dense)           (None, 512)               401920    
                                                                 
 dropout_567 (Dropout)       (None, 512)               0         
                                                                 
 dense_722 (Dense)           (None, 512)               262656    
                                                                 
 dropout_568 (Dropout)       (None, 512)               0         
                                                                 
 dense_723 (Dense)           (None, 320)               164160    
                                                                 
 batch_normalization_233 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_569 (Dropout)       (None, 320)               0         
                                                                 
 dense_724 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_234 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_570 (Dropout)       (None, 512)               0         
                                                                 
 dense_725 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 1009754 (3.85 MB)
Trainable params: 1008090 (3.85 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 155:
  Value: 0.8130
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 320
  units_3: 224
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.1
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00011218290238775743

Model: "sequential_155"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_155 (Flatten)       (None, 784)               0         
                                                                 
 dense_726 (Dense)           (None, 512)               401920    
                                                                 
 dropout_571 (Dropout)       (None, 512)               0         
                                                                 
 dense_727 (Dense)           (None, 512)               262656    
                                                                 
 dropout_572 (Dropout)       (None, 512)               0         
                                                                 
 dense_728 (Dense)           (None, 320)               164160    
                                                                 
 batch_normalization_235 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_573 (Dropout)       (None, 320)               0         
                                                                 
 dense_729 (Dense)           (None, 224)               71904     
                                                                 
 batch_normalization_236 (B  (None, 224)               896       
 atchNormalization)                                              
                                                                 
 dropout_574 (Dropout)       (None, 224)               0         
                                                                 
 dense_730 (Dense)           (None, 26)                5850      
                                                                 
=================================================================
Total params: 908666 (3.47 MB)
Trainable params: 907578 (3.46 MB)
Non-trainable params: 1088 (4.25 KB)
_________________________________________________________________



Trial 156:
  Value: 0.7849
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 320
  units_3: 512
  activation_0: tanh
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00016799226186301242

Model: "sequential_156"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_156 (Flatten)       (None, 784)               0         
                                                                 
 dense_731 (Dense)           (None, 512)               401920    
                                                                 
 batch_normalization_237 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_575 (Dropout)       (None, 512)               0         
                                                                 
 dense_732 (Dense)           (None, 512)               262656    
                                                                 
 dropout_576 (Dropout)       (None, 512)               0         
                                                                 
 dense_733 (Dense)           (None, 320)               164160    
                                                                 
 batch_normalization_238 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_577 (Dropout)       (None, 320)               0         
                                                                 
 dense_734 (Dense)           (None, 512)               164352    
                                                                 
 batch_normalization_239 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_578 (Dropout)       (None, 512)               0         
                                                                 
 dense_735 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 1011802 (3.86 MB)
Trainable params: 1009114 (3.85 MB)
Non-trainable params: 2688 (10.50 KB)
_________________________________________________________________



Trial 157:
  Value: 0.3126
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.2
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: False
  batch_norm_3: True
  optimizer: adagrad
  learning_rate: 0.00013251968483095786

Model: "sequential_157"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_157 (Flatten)       (None, 784)               0         
                                                                 
 dense_736 (Dense)           (None, 512)               401920    
                                                                 
 dropout_579 (Dropout)       (None, 512)               0         
                                                                 
 dense_737 (Dense)           (None, 480)               246240    
                                                                 
 batch_normalization_240 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_580 (Dropout)       (None, 480)               0         
                                                                 
 dense_738 (Dense)           (None, 288)               138528    
                                                                 
 dropout_581 (Dropout)       (None, 288)               0         
                                                                 
 dense_739 (Dense)           (None, 512)               147968    
                                                                 
 batch_normalization_241 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_582 (Dropout)       (None, 512)               0         
                                                                 
 dense_740 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 951962 (3.63 MB)
Trainable params: 949978 (3.62 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 158:
  Value: 0.8382
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 320
  units_3: 160
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001996113725848367

Model: "sequential_158"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_158 (Flatten)       (None, 784)               0         
                                                                 
 dense_741 (Dense)           (None, 512)               401920    
                                                                 
 dropout_583 (Dropout)       (None, 512)               0         
                                                                 
 dense_742 (Dense)           (None, 512)               262656    
                                                                 
 dropout_584 (Dropout)       (None, 512)               0         
                                                                 
 dense_743 (Dense)           (None, 320)               164160    
                                                                 
 batch_normalization_242 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_585 (Dropout)       (None, 320)               0         
                                                                 
 dense_744 (Dense)           (None, 160)               51360     
                                                                 
 batch_normalization_243 (B  (None, 160)               640       
 atchNormalization)                                              
                                                                 
 dropout_586 (Dropout)       (None, 160)               0         
                                                                 
 dense_745 (Dense)           (None, 26)                4186      
                                                                 
=================================================================
Total params: 886202 (3.38 MB)
Trainable params: 885242 (3.38 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 159:
  Value: 0.8227
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 256
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: rmsprop
  learning_rate: 0.0001089224277833467

Model: "sequential_159"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_159 (Flatten)       (None, 784)               0         
                                                                 
 dense_746 (Dense)           (None, 480)               376800    
                                                                 
 dropout_587 (Dropout)       (None, 480)               0         
                                                                 
 dense_747 (Dense)           (None, 480)               230880    
                                                                 
 dropout_588 (Dropout)       (None, 480)               0         
                                                                 
 dense_748 (Dense)           (None, 256)               123136    
                                                                 
 batch_normalization_244 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_589 (Dropout)       (None, 256)               0         
                                                                 
 dense_749 (Dense)           (None, 512)               131584    
                                                                 
 batch_normalization_245 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_590 (Dropout)       (None, 512)               0         
                                                                 
 dense_750 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 878810 (3.35 MB)
Trainable params: 877274 (3.35 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 160:
  Value: 0.8270
  num_layers: 4
  units_0: 512
  units_1: 256
  units_2: 352
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0005144566366522169

Model: "sequential_160"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_160 (Flatten)       (None, 784)               0         
                                                                 
 dense_751 (Dense)           (None, 512)               401920    
                                                                 
 dropout_591 (Dropout)       (None, 512)               0         
                                                                 
 dense_752 (Dense)           (None, 256)               131328    
                                                                 
 dropout_592 (Dropout)       (None, 256)               0         
                                                                 
 dense_753 (Dense)           (None, 352)               90464     
                                                                 
 batch_normalization_246 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_593 (Dropout)       (None, 352)               0         
                                                                 
 dense_754 (Dense)           (None, 512)               180736    
                                                                 
 batch_normalization_247 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_594 (Dropout)       (None, 512)               0         
                                                                 
 dense_755 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 821242 (3.13 MB)
Trainable params: 819514 (3.13 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 161:
  Value: 0.8279
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 224
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00015132267204113283

Model: "sequential_161"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_161 (Flatten)       (None, 784)               0         
                                                                 
 dense_756 (Dense)           (None, 480)               376800    
                                                                 
 dropout_595 (Dropout)       (None, 480)               0         
                                                                 
 dense_757 (Dense)           (None, 352)               169312    
                                                                 
 dropout_596 (Dropout)       (None, 352)               0         
                                                                 
 dense_758 (Dense)           (None, 224)               79072     
                                                                 
 batch_normalization_248 (B  (None, 224)               896       
 atchNormalization)                                              
                                                                 
 dropout_597 (Dropout)       (None, 224)               0         
                                                                 
 dense_759 (Dense)           (None, 480)               108000    
                                                                 
 batch_normalization_249 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_598 (Dropout)       (None, 480)               0         
                                                                 
 dense_760 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 748506 (2.86 MB)
Trainable params: 747098 (2.85 MB)
Non-trainable params: 1408 (5.50 KB)
_________________________________________________________________



Trial 162:
  Value: 0.8355
  num_layers: 4
  units_0: 448
  units_1: 320
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00016236778481989062

Model: "sequential_162"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_162 (Flatten)       (None, 784)               0         
                                                                 
 dense_761 (Dense)           (None, 448)               351680    
                                                                 
 dropout_599 (Dropout)       (None, 448)               0         
                                                                 
 dense_762 (Dense)           (None, 320)               143680    
                                                                 
 dropout_600 (Dropout)       (None, 320)               0         
                                                                 
 dense_763 (Dense)           (None, 416)               133536    
                                                                 
 batch_normalization_250 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_601 (Dropout)       (None, 416)               0         
                                                                 
 dense_764 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_251 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_602 (Dropout)       (None, 480)               0         
                                                                 
 dense_765 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 845146 (3.22 MB)
Trainable params: 843354 (3.22 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 163:
  Value: 0.8313
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 416
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00017736307990164716

Model: "sequential_163"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_163 (Flatten)       (None, 784)               0         
                                                                 
 dense_766 (Dense)           (None, 480)               376800    
                                                                 
 dropout_603 (Dropout)       (None, 480)               0         
                                                                 
 dense_767 (Dense)           (None, 384)               184704    
                                                                 
 dropout_604 (Dropout)       (None, 384)               0         
                                                                 
 dense_768 (Dense)           (None, 416)               160160    
                                                                 
 batch_normalization_252 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_605 (Dropout)       (None, 416)               0         
                                                                 
 dense_769 (Dense)           (None, 480)               200160    
                                                                 
 batch_normalization_253 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_606 (Dropout)       (None, 480)               0         
                                                                 
 dense_770 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 937914 (3.58 MB)
Trainable params: 936122 (3.57 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 164:
  Value: 0.9151
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 448
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001343836491108293

Model: "sequential_164"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_164 (Flatten)       (None, 784)               0         
                                                                 
 dense_771 (Dense)           (None, 512)               401920    
                                                                 
 dropout_607 (Dropout)       (None, 512)               0         
                                                                 
 dense_772 (Dense)           (None, 512)               262656    
                                                                 
 dropout_608 (Dropout)       (None, 512)               0         
                                                                 
 dense_773 (Dense)           (None, 448)               229824    
                                                                 
 batch_normalization_254 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_609 (Dropout)       (None, 448)               0         
                                                                 
 dense_774 (Dense)           (None, 512)               229888    
                                                                 
 dropout_610 (Dropout)       (None, 512)               0         
                                                                 
 dense_775 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 1139418 (4.35 MB)
Trainable params: 1138522 (4.34 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 165:
  Value: 0.0364
  num_layers: 4
  units_0: 320
  units_1: 512
  units_2: 448
  units_3: 192
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: ftrl
  learning_rate: 0.0001312740407792691

Model: "sequential_165"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_165 (Flatten)       (None, 784)               0         
                                                                 
 dense_776 (Dense)           (None, 320)               251200    
                                                                 
 dropout_611 (Dropout)       (None, 320)               0         
                                                                 
 dense_777 (Dense)           (None, 512)               164352    
                                                                 
 dropout_612 (Dropout)       (None, 512)               0         
                                                                 
 dense_778 (Dense)           (None, 448)               229824    
                                                                 
 batch_normalization_255 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_613 (Dropout)       (None, 448)               0         
                                                                 
 dense_779 (Dense)           (None, 192)               86208     
                                                                 
 batch_normalization_256 (B  (None, 192)               768       
 atchNormalization)                                              
                                                                 
 dropout_614 (Dropout)       (None, 192)               0         
                                                                 
 dense_780 (Dense)           (None, 26)                5018      
                                                                 
=================================================================
Total params: 739162 (2.82 MB)
Trainable params: 737882 (2.81 MB)
Non-trainable params: 1280 (5.00 KB)
_________________________________________________________________



Trial 166:
  Value: 0.5854
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 480
  units_3: 512
  activation_0: relu
  activation_1: relu
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00012144392196264201

Model: "sequential_166"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_166 (Flatten)       (None, 784)               0         
                                                                 
 dense_781 (Dense)           (None, 512)               401920    
                                                                 
 dropout_615 (Dropout)       (None, 512)               0         
                                                                 
 dense_782 (Dense)           (None, 512)               262656    
                                                                 
 dropout_616 (Dropout)       (None, 512)               0         
                                                                 
 dense_783 (Dense)           (None, 480)               246240    
                                                                 
 batch_normalization_257 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_617 (Dropout)       (None, 480)               0         
                                                                 
 dense_784 (Dense)           (None, 512)               246272    
                                                                 
 dropout_618 (Dropout)       (None, 512)               0         
                                                                 
 dense_785 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 1172346 (4.47 MB)
Trainable params: 1171386 (4.47 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 167:
  Value: 0.8281
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 128
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0001428579982423378

Model: "sequential_167"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_167 (Flatten)       (None, 784)               0         
                                                                 
 dense_786 (Dense)           (None, 512)               401920    
                                                                 
 dropout_619 (Dropout)       (None, 512)               0         
                                                                 
 dense_787 (Dense)           (None, 480)               246240    
                                                                 
 dropout_620 (Dropout)       (None, 480)               0         
                                                                 
 dense_788 (Dense)           (None, 128)               61568     
                                                                 
 batch_normalization_258 (B  (None, 128)               512       
 atchNormalization)                                              
                                                                 
 dropout_621 (Dropout)       (None, 128)               0         
                                                                 
 dense_789 (Dense)           (None, 512)               66048     
                                                                 
 batch_normalization_259 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_622 (Dropout)       (None, 512)               0         
                                                                 
 dense_790 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 791674 (3.02 MB)
Trainable params: 790394 (3.02 MB)
Non-trainable params: 1280 (5.00 KB)
_________________________________________________________________



Trial 168:
  Value: 0.8533
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 448
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.00010879155402957776

Model: "sequential_168"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_168 (Flatten)       (None, 784)               0         
                                                                 
 dense_791 (Dense)           (None, 512)               401920    
                                                                 
 dropout_623 (Dropout)       (None, 512)               0         
                                                                 
 dense_792 (Dense)           (None, 512)               262656    
                                                                 
 dropout_624 (Dropout)       (None, 512)               0         
                                                                 
 dense_793 (Dense)           (None, 448)               229824    
                                                                 
 batch_normalization_260 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_625 (Dropout)       (None, 448)               0         
                                                                 
 dense_794 (Dense)           (None, 512)               229888    
                                                                 
 batch_normalization_261 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_626 (Dropout)       (None, 512)               0         
                                                                 
 dense_795 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 1141466 (4.35 MB)
Trainable params: 1139546 (4.35 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 169:
  Value: 0.9142
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010957631703546768

Model: "sequential_169"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_169 (Flatten)       (None, 784)               0         
                                                                 
 dense_796 (Dense)           (None, 512)               401920    
                                                                 
 dropout_627 (Dropout)       (None, 512)               0         
                                                                 
 dense_797 (Dense)           (None, 512)               262656    
                                                                 
 dropout_628 (Dropout)       (None, 512)               0         
                                                                 
 dense_798 (Dense)           (None, 288)               147744    
                                                                 
 batch_normalization_262 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_629 (Dropout)       (None, 288)               0         
                                                                 
 dense_799 (Dense)           (None, 512)               147968    
                                                                 
 dropout_630 (Dropout)       (None, 512)               0         
                                                                 
 dense_800 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 974778 (3.72 MB)
Trainable params: 974202 (3.72 MB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 170:
  Value: 0.8226
  num_layers: 4
  units_0: 480
  units_1: 512
  units_2: 320
  units_3: 96
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012791213333139633

Model: "sequential_170"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_170 (Flatten)       (None, 784)               0         
                                                                 
 dense_801 (Dense)           (None, 480)               376800    
                                                                 
 dropout_631 (Dropout)       (None, 480)               0         
                                                                 
 dense_802 (Dense)           (None, 512)               246272    
                                                                 
 dropout_632 (Dropout)       (None, 512)               0         
                                                                 
 dense_803 (Dense)           (None, 320)               164160    
                                                                 
 dropout_633 (Dropout)       (None, 320)               0         
                                                                 
 dense_804 (Dense)           (None, 96)                30816     
                                                                 
 dropout_634 (Dropout)       (None, 96)                0         
                                                                 
 dense_805 (Dense)           (None, 26)                2522      
                                                                 
=================================================================
Total params: 820570 (3.13 MB)
Trainable params: 820570 (3.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 171:
  Value: 0.9135
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00013136077049075135

Model: "sequential_171"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_171 (Flatten)       (None, 784)               0         
                                                                 
 dense_806 (Dense)           (None, 512)               401920    
                                                                 
 dropout_635 (Dropout)       (None, 512)               0         
                                                                 
 dense_807 (Dense)           (None, 480)               246240    
                                                                 
 dropout_636 (Dropout)       (None, 480)               0         
                                                                 
 dense_808 (Dense)           (None, 288)               138528    
                                                                 
 batch_normalization_263 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_637 (Dropout)       (None, 288)               0         
                                                                 
 dense_809 (Dense)           (None, 512)               147968    
                                                                 
 dropout_638 (Dropout)       (None, 512)               0         
                                                                 
 dense_810 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 949146 (3.62 MB)
Trainable params: 948570 (3.62 MB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 172:
  Value: 0.9122
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00011840353658342953

Model: "sequential_172"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_172 (Flatten)       (None, 784)               0         
                                                                 
 dense_811 (Dense)           (None, 512)               401920    
                                                                 
 dropout_639 (Dropout)       (None, 512)               0         
                                                                 
 dense_812 (Dense)           (None, 512)               262656    
                                                                 
 dropout_640 (Dropout)       (None, 512)               0         
                                                                 
 dense_813 (Dense)           (None, 288)               147744    
                                                                 
 batch_normalization_264 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_641 (Dropout)       (None, 288)               0         
                                                                 
 dense_814 (Dense)           (None, 512)               147968    
                                                                 
 dropout_642 (Dropout)       (None, 512)               0         
                                                                 
 dense_815 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 974778 (3.72 MB)
Trainable params: 974202 (3.72 MB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 173:
  Value: 0.8537
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 288
  units_3: 512
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010061273845891213

Model: "sequential_173"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_173 (Flatten)       (None, 784)               0         
                                                                 
 dense_816 (Dense)           (None, 512)               401920    
                                                                 
 dropout_643 (Dropout)       (None, 512)               0         
                                                                 
 dense_817 (Dense)           (None, 512)               262656    
                                                                 
 dropout_644 (Dropout)       (None, 512)               0         
                                                                 
 dense_818 (Dense)           (None, 288)               147744    
                                                                 
 batch_normalization_265 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_645 (Dropout)       (None, 288)               0         
                                                                 
 dense_819 (Dense)           (None, 512)               147968    
                                                                 
 dropout_646 (Dropout)       (None, 512)               0         
                                                                 
 dense_820 (Dense)           (None, 26)                13338     
                                                                 
=================================================================
Total params: 974778 (3.72 MB)
Trainable params: 974202 (3.72 MB)
Non-trainable params: 576 (2.25 KB)
_________________________________________________________________



Trial 174:
  Value: 0.9154
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 320
  units_3: 480
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00018597065471969603

Model: "sequential_174"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_174 (Flatten)       (None, 784)               0         
                                                                 
 dense_821 (Dense)           (None, 512)               401920    
                                                                 
 dropout_647 (Dropout)       (None, 512)               0         
                                                                 
 dense_822 (Dense)           (None, 480)               246240    
                                                                 
 dropout_648 (Dropout)       (None, 480)               0         
                                                                 
 dense_823 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_266 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_649 (Dropout)       (None, 320)               0         
                                                                 
 dense_824 (Dense)           (None, 480)               154080    
                                                                 
 dropout_650 (Dropout)       (None, 480)               0         
                                                                 
 dense_825 (Dense)           (None, 26)                12506     
                                                                 
=================================================================
Total params: 969946 (3.70 MB)
Trainable params: 969306 (3.70 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 175:
  Value: 0.9153
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00019905987604473206

Model: "sequential_175"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_175 (Flatten)       (None, 784)               0         
                                                                 
 dense_826 (Dense)           (None, 512)               401920    
                                                                 
 dropout_651 (Dropout)       (None, 512)               0         
                                                                 
 dense_827 (Dense)           (None, 480)               246240    
                                                                 
 dropout_652 (Dropout)       (None, 480)               0         
                                                                 
 dense_828 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_267 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_653 (Dropout)       (None, 320)               0         
                                                                 
 dense_829 (Dense)           (None, 448)               143808    
                                                                 
 dropout_654 (Dropout)       (None, 448)               0         
                                                                 
 dense_830 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 958842 (3.66 MB)
Trainable params: 958202 (3.66 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 176:
  Value: 0.9147
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002250299924439866

Model: "sequential_176"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_176 (Flatten)       (None, 784)               0         
                                                                 
 dense_831 (Dense)           (None, 480)               376800    
                                                                 
 dropout_655 (Dropout)       (None, 480)               0         
                                                                 
 dense_832 (Dense)           (None, 480)               230880    
                                                                 
 dropout_656 (Dropout)       (None, 480)               0         
                                                                 
 dense_833 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_268 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_657 (Dropout)       (None, 320)               0         
                                                                 
 dense_834 (Dense)           (None, 448)               143808    
                                                                 
 dropout_658 (Dropout)       (None, 448)               0         
                                                                 
 dense_835 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 918362 (3.50 MB)
Trainable params: 917722 (3.50 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 177:
  Value: 0.9145
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002626503985376967

Model: "sequential_177"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_177 (Flatten)       (None, 784)               0         
                                                                 
 dense_836 (Dense)           (None, 512)               401920    
                                                                 
 dropout_659 (Dropout)       (None, 512)               0         
                                                                 
 dense_837 (Dense)           (None, 480)               246240    
                                                                 
 dropout_660 (Dropout)       (None, 480)               0         
                                                                 
 dense_838 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_269 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_661 (Dropout)       (None, 320)               0         
                                                                 
 dense_839 (Dense)           (None, 448)               143808    
                                                                 
 dropout_662 (Dropout)       (None, 448)               0         
                                                                 
 dense_840 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 958842 (3.66 MB)
Trainable params: 958202 (3.66 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 178:
  Value: 0.1491
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 320
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0002303863849216486

Model: "sequential_178"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_178 (Flatten)       (None, 784)               0         
                                                                 
 dense_841 (Dense)           (None, 512)               401920    
                                                                 
 dropout_663 (Dropout)       (None, 512)               0         
                                                                 
 dense_842 (Dense)           (None, 480)               246240    
                                                                 
 dropout_664 (Dropout)       (None, 480)               0         
                                                                 
 dense_843 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_270 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_665 (Dropout)       (None, 320)               0         
                                                                 
 dense_844 (Dense)           (None, 416)               133536    
                                                                 
 dropout_666 (Dropout)       (None, 416)               0         
                                                                 
 dense_845 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 947738 (3.62 MB)
Trainable params: 947098 (3.61 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 179:
  Value: 0.4899
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 320
  units_3: 448
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00020656311986069157

Model: "sequential_179"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_179 (Flatten)       (None, 784)               0         
                                                                 
 dense_846 (Dense)           (None, 480)               376800    
                                                                 
 dropout_667 (Dropout)       (None, 480)               0         
                                                                 
 dense_847 (Dense)           (None, 480)               230880    
                                                                 
 dropout_668 (Dropout)       (None, 480)               0         
                                                                 
 dense_848 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_271 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_669 (Dropout)       (None, 320)               0         
                                                                 
 dense_849 (Dense)           (None, 448)               143808    
                                                                 
 dropout_670 (Dropout)       (None, 448)               0         
                                                                 
 dense_850 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 918362 (3.50 MB)
Trainable params: 917722 (3.50 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 180:
  Value: 0.5896
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001872021696315329

Model: "sequential_180"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_180 (Flatten)       (None, 784)               0         
                                                                 
 dense_851 (Dense)           (None, 480)               376800    
                                                                 
 batch_normalization_272 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_671 (Dropout)       (None, 480)               0         
                                                                 
 dense_852 (Dense)           (None, 448)               215488    
                                                                 
 dropout_672 (Dropout)       (None, 448)               0         
                                                                 
 dense_853 (Dense)           (None, 320)               143680    
                                                                 
 batch_normalization_273 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_673 (Dropout)       (None, 320)               0         
                                                                 
 dense_854 (Dense)           (None, 448)               143808    
                                                                 
 dropout_674 (Dropout)       (None, 448)               0         
                                                                 
 dense_855 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 894650 (3.41 MB)
Trainable params: 893050 (3.41 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 181:
  Value: 0.9163
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00024474463582640056

Model: "sequential_181"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_181 (Flatten)       (None, 784)               0         
                                                                 
 dense_856 (Dense)           (None, 512)               401920    
                                                                 
 dropout_675 (Dropout)       (None, 512)               0         
                                                                 
 dense_857 (Dense)           (None, 480)               246240    
                                                                 
 dropout_676 (Dropout)       (None, 480)               0         
                                                                 
 dense_858 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_274 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_677 (Dropout)       (None, 320)               0         
                                                                 
 dense_859 (Dense)           (None, 448)               143808    
                                                                 
 dropout_678 (Dropout)       (None, 448)               0         
                                                                 
 dense_860 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 958842 (3.66 MB)
Trainable params: 958202 (3.66 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 182:
  Value: 0.9147
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002554100349091148

Model: "sequential_182"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_182 (Flatten)       (None, 784)               0         
                                                                 
 dense_861 (Dense)           (None, 512)               401920    
                                                                 
 dropout_679 (Dropout)       (None, 512)               0         
                                                                 
 dense_862 (Dense)           (None, 480)               246240    
                                                                 
 dropout_680 (Dropout)       (None, 480)               0         
                                                                 
 dense_863 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_275 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_681 (Dropout)       (None, 320)               0         
                                                                 
 dense_864 (Dense)           (None, 448)               143808    
                                                                 
 dropout_682 (Dropout)       (None, 448)               0         
                                                                 
 dense_865 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 958842 (3.66 MB)
Trainable params: 958202 (3.66 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 183:
  Value: 0.9135
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00028071258195393336

Model: "sequential_183"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_183 (Flatten)       (None, 784)               0         
                                                                 
 dense_866 (Dense)           (None, 512)               401920    
                                                                 
 dropout_683 (Dropout)       (None, 512)               0         
                                                                 
 dense_867 (Dense)           (None, 480)               246240    
                                                                 
 dropout_684 (Dropout)       (None, 480)               0         
                                                                 
 dense_868 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_276 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_685 (Dropout)       (None, 352)               0         
                                                                 
 dense_869 (Dense)           (None, 416)               146848    
                                                                 
 dropout_686 (Dropout)       (None, 416)               0         
                                                                 
 dense_870 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 976570 (3.73 MB)
Trainable params: 975866 (3.72 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 184:
  Value: 0.9158
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00025610133814388735

Model: "sequential_184"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_184 (Flatten)       (None, 784)               0         
                                                                 
 dense_871 (Dense)           (None, 512)               401920    
                                                                 
 dropout_687 (Dropout)       (None, 512)               0         
                                                                 
 dense_872 (Dense)           (None, 480)               246240    
                                                                 
 dropout_688 (Dropout)       (None, 480)               0         
                                                                 
 dense_873 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_277 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_689 (Dropout)       (None, 352)               0         
                                                                 
 dense_874 (Dense)           (None, 448)               158144    
                                                                 
 dropout_690 (Dropout)       (None, 448)               0         
                                                                 
 dense_875 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 988698 (3.77 MB)
Trainable params: 987994 (3.77 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 185:
  Value: 0.9146
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00025642133131860314

Model: "sequential_185"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_185 (Flatten)       (None, 784)               0         
                                                                 
 dense_876 (Dense)           (None, 512)               401920    
                                                                 
 dropout_691 (Dropout)       (None, 512)               0         
                                                                 
 dense_877 (Dense)           (None, 480)               246240    
                                                                 
 dropout_692 (Dropout)       (None, 480)               0         
                                                                 
 dense_878 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_278 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_693 (Dropout)       (None, 352)               0         
                                                                 
 dense_879 (Dense)           (None, 448)               158144    
                                                                 
 dropout_694 (Dropout)       (None, 448)               0         
                                                                 
 dense_880 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 988698 (3.77 MB)
Trainable params: 987994 (3.77 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 186:
  Value: 0.5940
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 416
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0002442291666329722

Model: "sequential_186"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_186 (Flatten)       (None, 784)               0         
                                                                 
 dense_881 (Dense)           (None, 512)               401920    
                                                                 
 dropout_695 (Dropout)       (None, 512)               0         
                                                                 
 dense_882 (Dense)           (None, 480)               246240    
                                                                 
 batch_normalization_279 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_696 (Dropout)       (None, 480)               0         
                                                                 
 dense_883 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_280 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_697 (Dropout)       (None, 352)               0         
                                                                 
 dense_884 (Dense)           (None, 416)               146848    
                                                                 
 dropout_698 (Dropout)       (None, 416)               0         
                                                                 
 dense_885 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 978490 (3.73 MB)
Trainable params: 976826 (3.73 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 187:
  Value: 0.9104
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 352
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00033373743724931837

Model: "sequential_187"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_187 (Flatten)       (None, 784)               0         
                                                                 
 dense_886 (Dense)           (None, 480)               376800    
                                                                 
 dropout_699 (Dropout)       (None, 480)               0         
                                                                 
 dense_887 (Dense)           (None, 448)               215488    
                                                                 
 dropout_700 (Dropout)       (None, 448)               0         
                                                                 
 dense_888 (Dense)           (None, 352)               158048    
                                                                 
 batch_normalization_281 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_701 (Dropout)       (None, 352)               0         
                                                                 
 dense_889 (Dense)           (None, 448)               158144    
                                                                 
 dropout_702 (Dropout)       (None, 448)               0         
                                                                 
 dense_890 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 921562 (3.52 MB)
Trainable params: 920858 (3.51 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 188:
  Value: 0.9133
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002500336190844559

Model: "sequential_188"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_188 (Flatten)       (None, 784)               0         
                                                                 
 dense_891 (Dense)           (None, 512)               401920    
                                                                 
 dropout_703 (Dropout)       (None, 512)               0         
                                                                 
 dense_892 (Dense)           (None, 480)               246240    
                                                                 
 dropout_704 (Dropout)       (None, 480)               0         
                                                                 
 dense_893 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_282 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_705 (Dropout)       (None, 352)               0         
                                                                 
 dense_894 (Dense)           (None, 448)               158144    
                                                                 
 dropout_706 (Dropout)       (None, 448)               0         
                                                                 
 dense_895 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 988698 (3.77 MB)
Trainable params: 987994 (3.77 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 189:
  Value: 0.8336
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 320
  units_3: 384
  activation_0: tanh
  activation_1: sigmoid
  activation_2: tanh
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00024670012097061263

Model: "sequential_189"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_189 (Flatten)       (None, 784)               0         
                                                                 
 dense_896 (Dense)           (None, 480)               376800    
                                                                 
 dropout_707 (Dropout)       (None, 480)               0         
                                                                 
 dense_897 (Dense)           (None, 480)               230880    
                                                                 
 dropout_708 (Dropout)       (None, 480)               0         
                                                                 
 dense_898 (Dense)           (None, 320)               153920    
                                                                 
 dropout_709 (Dropout)       (None, 320)               0         
                                                                 
 dense_899 (Dense)           (None, 384)               123264    
                                                                 
 dropout_710 (Dropout)       (None, 384)               0         
                                                                 
 dense_900 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 894874 (3.41 MB)
Trainable params: 894874 (3.41 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 190:
  Value: 0.7628
  num_layers: 1
  units_0: 320
  activation_0: tanh
  dropout_0: 0.0
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.00022242968338730799

Model: "sequential_190"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_190 (Flatten)       (None, 784)               0         
                                                                 
 dense_901 (Dense)           (None, 320)               251200    
                                                                 
 dropout_711 (Dropout)       (None, 320)               0         
                                                                 
 dense_902 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 259546 (1013.85 KB)
Trainable params: 259546 (1013.85 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 191:
  Value: 0.9156
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000302676266428998

Model: "sequential_191"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_191 (Flatten)       (None, 784)               0         
                                                                 
 dense_903 (Dense)           (None, 512)               401920    
                                                                 
 dropout_712 (Dropout)       (None, 512)               0         
                                                                 
 dense_904 (Dense)           (None, 480)               246240    
                                                                 
 dropout_713 (Dropout)       (None, 480)               0         
                                                                 
 dense_905 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_283 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_714 (Dropout)       (None, 352)               0         
                                                                 
 dense_906 (Dense)           (None, 448)               158144    
                                                                 
 dropout_715 (Dropout)       (None, 448)               0         
                                                                 
 dense_907 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 988698 (3.77 MB)
Trainable params: 987994 (3.77 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 192:
  Value: 0.9157
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 352
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00027455845857187665

Model: "sequential_192"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_192 (Flatten)       (None, 784)               0         
                                                                 
 dense_908 (Dense)           (None, 512)               401920    
                                                                 
 dropout_716 (Dropout)       (None, 512)               0         
                                                                 
 dense_909 (Dense)           (None, 448)               229824    
                                                                 
 dropout_717 (Dropout)       (None, 448)               0         
                                                                 
 dense_910 (Dense)           (None, 352)               158048    
                                                                 
 batch_normalization_284 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_718 (Dropout)       (None, 352)               0         
                                                                 
 dense_911 (Dense)           (None, 416)               146848    
                                                                 
 dropout_719 (Dropout)       (None, 416)               0         
                                                                 
 dense_912 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 948890 (3.62 MB)
Trainable params: 948186 (3.62 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 193:
  Value: 0.9026
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 352
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003078383463905711

Model: "sequential_193"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_193 (Flatten)       (None, 784)               0         
                                                                 
 dense_913 (Dense)           (None, 512)               401920    
                                                                 
 dropout_720 (Dropout)       (None, 512)               0         
                                                                 
 dense_914 (Dense)           (None, 448)               229824    
                                                                 
 dropout_721 (Dropout)       (None, 448)               0         
                                                                 
 dense_915 (Dense)           (None, 352)               158048    
                                                                 
 batch_normalization_285 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_722 (Dropout)       (None, 352)               0         
                                                                 
 dense_916 (Dense)           (None, 416)               146848    
                                                                 
 dropout_723 (Dropout)       (None, 416)               0         
                                                                 
 dense_917 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 948890 (3.62 MB)
Trainable params: 948186 (3.62 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 194:
  Value: 0.8598
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 352
  units_3: 352
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002894496107203136

Model: "sequential_194"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_194 (Flatten)       (None, 784)               0         
                                                                 
 dense_918 (Dense)           (None, 512)               401920    
                                                                 
 dropout_724 (Dropout)       (None, 512)               0         
                                                                 
 dense_919 (Dense)           (None, 448)               229824    
                                                                 
 dropout_725 (Dropout)       (None, 448)               0         
                                                                 
 dense_920 (Dense)           (None, 352)               158048    
                                                                 
 batch_normalization_286 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_726 (Dropout)       (None, 352)               0         
                                                                 
 dense_921 (Dense)           (None, 352)               124256    
                                                                 
 dropout_727 (Dropout)       (None, 352)               0         
                                                                 
 dense_922 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 924634 (3.53 MB)
Trainable params: 923930 (3.52 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 195:
  Value: 0.8308
  num_layers: 4
  units_0: 352
  units_1: 480
  units_2: 320
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00021948145762291634

Model: "sequential_195"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_195 (Flatten)       (None, 784)               0         
                                                                 
 dense_923 (Dense)           (None, 352)               276320    
                                                                 
 dropout_728 (Dropout)       (None, 352)               0         
                                                                 
 dense_924 (Dense)           (None, 480)               169440    
                                                                 
 dropout_729 (Dropout)       (None, 480)               0         
                                                                 
 dense_925 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_287 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_730 (Dropout)       (None, 320)               0         
                                                                 
 dense_926 (Dense)           (None, 448)               143808    
                                                                 
 dropout_731 (Dropout)       (None, 448)               0         
                                                                 
 dense_927 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 756442 (2.89 MB)
Trainable params: 755802 (2.88 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 196:
  Value: 0.9140
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 384
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00020501890882160302

Model: "sequential_196"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_196 (Flatten)       (None, 784)               0         
                                                                 
 dense_928 (Dense)           (None, 512)               401920    
                                                                 
 dropout_732 (Dropout)       (None, 512)               0         
                                                                 
 dense_929 (Dense)           (None, 448)               229824    
                                                                 
 dropout_733 (Dropout)       (None, 448)               0         
                                                                 
 dense_930 (Dense)           (None, 384)               172416    
                                                                 
 batch_normalization_288 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_734 (Dropout)       (None, 384)               0         
                                                                 
 dense_931 (Dense)           (None, 448)               172480    
                                                                 
 dropout_735 (Dropout)       (None, 448)               0         
                                                                 
 dense_932 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 989850 (3.78 MB)
Trainable params: 989082 (3.77 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 197:
  Value: 0.8409
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.30000000000000004
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000268369666860462

Model: "sequential_197"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_197 (Flatten)       (None, 784)               0         
                                                                 
 dense_933 (Dense)           (None, 512)               401920    
                                                                 
 dropout_736 (Dropout)       (None, 512)               0         
                                                                 
 dense_934 (Dense)           (None, 480)               246240    
                                                                 
 dropout_737 (Dropout)       (None, 480)               0         
                                                                 
 dense_935 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_289 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_738 (Dropout)       (None, 352)               0         
                                                                 
 dense_936 (Dense)           (None, 416)               146848    
                                                                 
 dropout_739 (Dropout)       (None, 416)               0         
                                                                 
 dense_937 (Dense)           (None, 26)                10842     
                                                                 
=================================================================
Total params: 976570 (3.73 MB)
Trainable params: 975866 (3.72 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 198:
  Value: 0.0424
  num_layers: 4
  units_0: 480
  units_1: 512
  units_2: 32
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.30000000000000004
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.000304458111943983

Model: "sequential_198"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_198 (Flatten)       (None, 784)               0         
                                                                 
 dense_938 (Dense)           (None, 480)               376800    
                                                                 
 dropout_740 (Dropout)       (None, 480)               0         
                                                                 
 dense_939 (Dense)           (None, 512)               246272    
                                                                 
 dropout_741 (Dropout)       (None, 512)               0         
                                                                 
 dense_940 (Dense)           (None, 32)                16416     
                                                                 
 batch_normalization_290 (B  (None, 32)                128       
 atchNormalization)                                              
                                                                 
 dropout_742 (Dropout)       (None, 32)                0         
                                                                 
 dense_941 (Dense)           (None, 448)               14784     
                                                                 
 dropout_743 (Dropout)       (None, 448)               0         
                                                                 
 dense_942 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 666074 (2.54 MB)
Trainable params: 666010 (2.54 MB)
Non-trainable params: 64 (256.00 Byte)
_________________________________________________________________



Trial 199:
  Value: 0.5930
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00022265705993314226

Model: "sequential_199"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_199 (Flatten)       (None, 784)               0         
                                                                 
 dense_943 (Dense)           (None, 512)               401920    
                                                                 
 dropout_744 (Dropout)       (None, 512)               0         
                                                                 
 dense_944 (Dense)           (None, 448)               229824    
                                                                 
 dropout_745 (Dropout)       (None, 448)               0         
                                                                 
 dense_945 (Dense)           (None, 480)               215520    
                                                                 
 batch_normalization_291 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_746 (Dropout)       (None, 480)               0         
                                                                 
 dense_946 (Dense)           (None, 448)               215488    
                                                                 
 dropout_747 (Dropout)       (None, 448)               0         
                                                                 
 dense_947 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 1076346 (4.11 MB)
Trainable params: 1075386 (4.10 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 200:
  Value: 0.8016
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 320
  units_3: 384
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.00034094134250433483

Model: "sequential_200"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_200 (Flatten)       (None, 784)               0         
                                                                 
 dense_948 (Dense)           (None, 480)               376800    
                                                                 
 dropout_748 (Dropout)       (None, 480)               0         
                                                                 
 dense_949 (Dense)           (None, 480)               230880    
                                                                 
 dropout_749 (Dropout)       (None, 480)               0         
                                                                 
 dense_950 (Dense)           (None, 320)               153920    
                                                                 
 batch_normalization_292 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_750 (Dropout)       (None, 320)               0         
                                                                 
 dense_951 (Dense)           (None, 384)               123264    
                                                                 
 dropout_751 (Dropout)       (None, 384)               0         
                                                                 
 dense_952 (Dense)           (None, 26)                10010     
                                                                 
=================================================================
Total params: 896154 (3.42 MB)
Trainable params: 895514 (3.42 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 201:
  Value: 0.9149
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 448
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002471334709426214

Model: "sequential_201"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_201 (Flatten)       (None, 784)               0         
                                                                 
 dense_953 (Dense)           (None, 512)               401920    
                                                                 
 dropout_752 (Dropout)       (None, 512)               0         
                                                                 
 dense_954 (Dense)           (None, 480)               246240    
                                                                 
 dropout_753 (Dropout)       (None, 480)               0         
                                                                 
 dense_955 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_293 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_754 (Dropout)       (None, 352)               0         
                                                                 
 dense_956 (Dense)           (None, 448)               158144    
                                                                 
 dropout_755 (Dropout)       (None, 448)               0         
                                                                 
 dense_957 (Dense)           (None, 26)                11674     
                                                                 
=================================================================
Total params: 988698 (3.77 MB)
Trainable params: 987994 (3.77 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 202:
  Value: 0.9159
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 320
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00027271230804795806

Model: "sequential_202"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_202 (Flatten)       (None, 784)               0         
                                                                 
 dense_958 (Dense)           (None, 512)               401920    
                                                                 
 dropout_756 (Dropout)       (None, 512)               0         
                                                                 
 dense_959 (Dense)           (None, 480)               246240    
                                                                 
 dropout_757 (Dropout)       (None, 480)               0         
                                                                 
 dense_960 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_294 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_758 (Dropout)       (None, 352)               0         
                                                                 
 dense_961 (Dense)           (None, 320)               112960    
                                                                 
 dropout_759 (Dropout)       (None, 320)               0         
                                                                 
 dense_962 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 940186 (3.59 MB)
Trainable params: 939482 (3.58 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 203:
  Value: 0.9156
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 288
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002710554998479151

Model: "sequential_203"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_203 (Flatten)       (None, 784)               0         
                                                                 
 dense_963 (Dense)           (None, 512)               401920    
                                                                 
 dropout_760 (Dropout)       (None, 512)               0         
                                                                 
 dense_964 (Dense)           (None, 480)               246240    
                                                                 
 dropout_761 (Dropout)       (None, 480)               0         
                                                                 
 dense_965 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_295 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_762 (Dropout)       (None, 352)               0         
                                                                 
 dense_966 (Dense)           (None, 288)               101664    
                                                                 
 dropout_763 (Dropout)       (None, 288)               0         
                                                                 
 dense_967 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 928058 (3.54 MB)
Trainable params: 927354 (3.54 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 204:
  Value: 0.8445
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 352
  units_3: 288
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00028926707312004605

Model: "sequential_204"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_204 (Flatten)       (None, 784)               0         
                                                                 
 dense_968 (Dense)           (None, 512)               401920    
                                                                 
 dropout_764 (Dropout)       (None, 512)               0         
                                                                 
 dense_969 (Dense)           (None, 448)               229824    
                                                                 
 dropout_765 (Dropout)       (None, 448)               0         
                                                                 
 dense_970 (Dense)           (None, 352)               158048    
                                                                 
 batch_normalization_296 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_766 (Dropout)       (None, 352)               0         
                                                                 
 dense_971 (Dense)           (None, 288)               101664    
                                                                 
 dropout_767 (Dropout)       (None, 288)               0         
                                                                 
 dense_972 (Dense)           (None, 26)                7514      
                                                                 
=================================================================
Total params: 900378 (3.43 MB)
Trainable params: 899674 (3.43 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 205:
  Value: 0.8531
  num_layers: 4
  units_0: 512
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.2
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00023787916210151768

Model: "sequential_205"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_205 (Flatten)       (None, 784)               0         
                                                                 
 dense_973 (Dense)           (None, 512)               401920    
                                                                 
 dropout_768 (Dropout)       (None, 512)               0         
                                                                 
 dense_974 (Dense)           (None, 512)               262656    
                                                                 
 dropout_769 (Dropout)       (None, 512)               0         
                                                                 
 dense_975 (Dense)           (None, 352)               180576    
                                                                 
 batch_normalization_297 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_770 (Dropout)       (None, 352)               0         
                                                                 
 dense_976 (Dense)           (None, 320)               112960    
                                                                 
 dropout_771 (Dropout)       (None, 320)               0         
                                                                 
 dense_977 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 967866 (3.69 MB)
Trainable params: 967162 (3.69 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 206:
  Value: 0.0381
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 352
  units_3: 352
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0003181759310410606

Model: "sequential_206"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_206 (Flatten)       (None, 784)               0         
                                                                 
 dense_978 (Dense)           (None, 512)               401920    
                                                                 
 dropout_772 (Dropout)       (None, 512)               0         
                                                                 
 dense_979 (Dense)           (None, 480)               246240    
                                                                 
 dropout_773 (Dropout)       (None, 480)               0         
                                                                 
 dense_980 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_298 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_774 (Dropout)       (None, 352)               0         
                                                                 
 dense_981 (Dense)           (None, 352)               124256    
                                                                 
 dropout_775 (Dropout)       (None, 352)               0         
                                                                 
 dense_982 (Dense)           (None, 26)                9178      
                                                                 
=================================================================
Total params: 952314 (3.63 MB)
Trainable params: 951610 (3.63 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 207:
  Value: 0.9159
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00019712255379393195

Model: "sequential_207"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_207 (Flatten)       (None, 784)               0         
                                                                 
 dense_983 (Dense)           (None, 448)               351680    
                                                                 
 dropout_776 (Dropout)       (None, 448)               0         
                                                                 
 dense_984 (Dense)           (None, 480)               215520    
                                                                 
 dropout_777 (Dropout)       (None, 480)               0         
                                                                 
 dense_985 (Dense)           (None, 352)               169312    
                                                                 
 batch_normalization_299 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_778 (Dropout)       (None, 352)               0         
                                                                 
 dense_986 (Dense)           (None, 320)               112960    
                                                                 
 dropout_779 (Dropout)       (None, 320)               0         
                                                                 
 dense_987 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 859226 (3.28 MB)
Trainable params: 858522 (3.28 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 208:
  Value: 0.9179
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002709011155866743

Model: "sequential_208"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_208 (Flatten)       (None, 784)               0         
                                                                 
 dense_988 (Dense)           (None, 416)               326560    
                                                                 
 dropout_780 (Dropout)       (None, 416)               0         
                                                                 
 dense_989 (Dense)           (None, 512)               213504    
                                                                 
 dropout_781 (Dropout)       (None, 512)               0         
                                                                 
 dense_990 (Dense)           (None, 352)               180576    
                                                                 
 batch_normalization_300 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_782 (Dropout)       (None, 352)               0         
                                                                 
 dense_991 (Dense)           (None, 320)               112960    
                                                                 
 dropout_783 (Dropout)       (None, 320)               0         
                                                                 
 dense_992 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 843354 (3.22 MB)
Trainable params: 842650 (3.21 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 209:
  Value: 0.8373
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 384
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00018500796128066715

Model: "sequential_209"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_209 (Flatten)       (None, 784)               0         
                                                                 
 dense_993 (Dense)           (None, 384)               301440    
                                                                 
 dropout_784 (Dropout)       (None, 384)               0         
                                                                 
 dense_994 (Dense)           (None, 512)               197120    
                                                                 
 dropout_785 (Dropout)       (None, 512)               0         
                                                                 
 dense_995 (Dense)           (None, 384)               196992    
                                                                 
 dropout_786 (Dropout)       (None, 384)               0         
                                                                 
 dense_996 (Dense)           (None, 320)               123200    
                                                                 
 dropout_787 (Dropout)       (None, 320)               0         
                                                                 
 dense_997 (Dense)           (None, 26)                8346      
                                                                 
=================================================================
Total params: 827098 (3.16 MB)
Trainable params: 827098 (3.16 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 210:
  Value: 0.8043
  num_layers: 2
  units_0: 416
  units_1: 512
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.0
  dropout_1: 0.5
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0002746876032524243

Model: "sequential_210"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_210 (Flatten)       (None, 784)               0         
                                                                 
 dense_998 (Dense)           (None, 416)               326560    
                                                                 
 dropout_788 (Dropout)       (None, 416)               0         
                                                                 
 dense_999 (Dense)           (None, 512)               213504    
                                                                 
 dropout_789 (Dropout)       (None, 512)               0         
                                                                 
 dense_1000 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 553402 (2.11 MB)
Trainable params: 553402 (2.11 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 211:
  Value: 0.9168
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00028775400305938064

Model: "sequential_211"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_211 (Flatten)       (None, 784)               0         
                                                                 
 dense_1001 (Dense)          (None, 416)               326560    
                                                                 
 dropout_790 (Dropout)       (None, 416)               0         
                                                                 
 dense_1002 (Dense)          (None, 512)               213504    
                                                                 
 dropout_791 (Dropout)       (None, 512)               0         
                                                                 
 dense_1003 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_301 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_792 (Dropout)       (None, 352)               0         
                                                                 
 dense_1004 (Dense)          (None, 320)               112960    
                                                                 
 dropout_793 (Dropout)       (None, 320)               0         
                                                                 
 dense_1005 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 843354 (3.22 MB)
Trainable params: 842650 (3.21 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 212:
  Value: 0.9156
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00026846325834000014

Model: "sequential_212"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_212 (Flatten)       (None, 784)               0         
                                                                 
 dense_1006 (Dense)          (None, 416)               326560    
                                                                 
 dropout_794 (Dropout)       (None, 416)               0         
                                                                 
 dense_1007 (Dense)          (None, 512)               213504    
                                                                 
 dropout_795 (Dropout)       (None, 512)               0         
                                                                 
 dense_1008 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_302 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_796 (Dropout)       (None, 352)               0         
                                                                 
 dense_1009 (Dense)          (None, 352)               124256    
                                                                 
 dropout_797 (Dropout)       (None, 352)               0         
                                                                 
 dense_1010 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 855482 (3.26 MB)
Trainable params: 854778 (3.26 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 213:
  Value: 0.9179
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00030014206303726165

Model: "sequential_213"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_213 (Flatten)       (None, 784)               0         
                                                                 
 dense_1011 (Dense)          (None, 416)               326560    
                                                                 
 dropout_798 (Dropout)       (None, 416)               0         
                                                                 
 dense_1012 (Dense)          (None, 512)               213504    
                                                                 
 dropout_799 (Dropout)       (None, 512)               0         
                                                                 
 dense_1013 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_303 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_800 (Dropout)       (None, 352)               0         
                                                                 
 dense_1014 (Dense)          (None, 288)               101664    
                                                                 
 dropout_801 (Dropout)       (None, 288)               0         
                                                                 
 dense_1015 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 214:
  Value: 0.9159
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002960884960929777

Model: "sequential_214"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_214 (Flatten)       (None, 784)               0         
                                                                 
 dense_1016 (Dense)          (None, 416)               326560    
                                                                 
 dropout_802 (Dropout)       (None, 416)               0         
                                                                 
 dense_1017 (Dense)          (None, 512)               213504    
                                                                 
 dropout_803 (Dropout)       (None, 512)               0         
                                                                 
 dense_1018 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_304 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_804 (Dropout)       (None, 352)               0         
                                                                 
 dense_1019 (Dense)          (None, 320)               112960    
                                                                 
 dropout_805 (Dropout)       (None, 320)               0         
                                                                 
 dense_1020 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 843354 (3.22 MB)
Trainable params: 842650 (3.21 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 215:
  Value: 0.9183
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00035584416707895626

Model: "sequential_215"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_215 (Flatten)       (None, 784)               0         
                                                                 
 dense_1021 (Dense)          (None, 416)               326560    
                                                                 
 dropout_806 (Dropout)       (None, 416)               0         
                                                                 
 dense_1022 (Dense)          (None, 512)               213504    
                                                                 
 dropout_807 (Dropout)       (None, 512)               0         
                                                                 
 dense_1023 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_305 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_808 (Dropout)       (None, 352)               0         
                                                                 
 dense_1024 (Dense)          (None, 288)               101664    
                                                                 
 dropout_809 (Dropout)       (None, 288)               0         
                                                                 
 dense_1025 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 216:
  Value: 0.9181
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003445590919675488

Model: "sequential_216"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_216 (Flatten)       (None, 784)               0         
                                                                 
 dense_1026 (Dense)          (None, 416)               326560    
                                                                 
 dropout_810 (Dropout)       (None, 416)               0         
                                                                 
 dense_1027 (Dense)          (None, 512)               213504    
                                                                 
 dropout_811 (Dropout)       (None, 512)               0         
                                                                 
 dense_1028 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_306 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_812 (Dropout)       (None, 352)               0         
                                                                 
 dense_1029 (Dense)          (None, 288)               101664    
                                                                 
 dropout_813 (Dropout)       (None, 288)               0         
                                                                 
 dense_1030 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 217:
  Value: 0.9144
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003390895825641983

Model: "sequential_217"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_217 (Flatten)       (None, 784)               0         
                                                                 
 dense_1031 (Dense)          (None, 416)               326560    
                                                                 
 dropout_814 (Dropout)       (None, 416)               0         
                                                                 
 dense_1032 (Dense)          (None, 512)               213504    
                                                                 
 dropout_815 (Dropout)       (None, 512)               0         
                                                                 
 dense_1033 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_307 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_816 (Dropout)       (None, 352)               0         
                                                                 
 dense_1034 (Dense)          (None, 288)               101664    
                                                                 
 dropout_817 (Dropout)       (None, 288)               0         
                                                                 
 dense_1035 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 218:
  Value: 0.9136
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003594407530833542

Model: "sequential_218"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_218 (Flatten)       (None, 784)               0         
                                                                 
 dense_1036 (Dense)          (None, 416)               326560    
                                                                 
 dropout_818 (Dropout)       (None, 416)               0         
                                                                 
 dense_1037 (Dense)          (None, 512)               213504    
                                                                 
 dropout_819 (Dropout)       (None, 512)               0         
                                                                 
 dense_1038 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_308 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_820 (Dropout)       (None, 352)               0         
                                                                 
 dense_1039 (Dense)          (None, 320)               112960    
                                                                 
 dropout_821 (Dropout)       (None, 320)               0         
                                                                 
 dense_1040 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 843354 (3.22 MB)
Trainable params: 842650 (3.21 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 219:
  Value: 0.9144
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002980735646576882

Model: "sequential_219"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_219 (Flatten)       (None, 784)               0         
                                                                 
 dense_1041 (Dense)          (None, 416)               326560    
                                                                 
 dropout_822 (Dropout)       (None, 416)               0         
                                                                 
 dense_1042 (Dense)          (None, 512)               213504    
                                                                 
 dropout_823 (Dropout)       (None, 512)               0         
                                                                 
 dense_1043 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_309 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_824 (Dropout)       (None, 352)               0         
                                                                 
 dense_1044 (Dense)          (None, 288)               101664    
                                                                 
 dropout_825 (Dropout)       (None, 288)               0         
                                                                 
 dense_1045 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 220:
  Value: 0.7658
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.4
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00038130841341086155

Model: "sequential_220"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_220 (Flatten)       (None, 784)               0         
                                                                 
 dense_1046 (Dense)          (None, 416)               326560    
                                                                 
 batch_normalization_310 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_826 (Dropout)       (None, 416)               0         
                                                                 
 dense_1047 (Dense)          (None, 512)               213504    
                                                                 
 dropout_827 (Dropout)       (None, 512)               0         
                                                                 
 dense_1048 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_311 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_828 (Dropout)       (None, 352)               0         
                                                                 
 dense_1049 (Dense)          (None, 320)               112960    
                                                                 
 dropout_829 (Dropout)       (None, 320)               0         
                                                                 
 dense_1050 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 845018 (3.22 MB)
Trainable params: 843482 (3.22 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 221:
  Value: 0.9177
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00027472292108289786

Model: "sequential_221"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_221 (Flatten)       (None, 784)               0         
                                                                 
 dense_1051 (Dense)          (None, 416)               326560    
                                                                 
 dropout_830 (Dropout)       (None, 416)               0         
                                                                 
 dense_1052 (Dense)          (None, 512)               213504    
                                                                 
 dropout_831 (Dropout)       (None, 512)               0         
                                                                 
 dense_1053 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_312 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_832 (Dropout)       (None, 352)               0         
                                                                 
 dense_1054 (Dense)          (None, 288)               101664    
                                                                 
 dropout_833 (Dropout)       (None, 288)               0         
                                                                 
 dense_1055 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 222:
  Value: 0.9165
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003130751117569095

Model: "sequential_222"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_222 (Flatten)       (None, 784)               0         
                                                                 
 dense_1056 (Dense)          (None, 416)               326560    
                                                                 
 dropout_834 (Dropout)       (None, 416)               0         
                                                                 
 dense_1057 (Dense)          (None, 512)               213504    
                                                                 
 dropout_835 (Dropout)       (None, 512)               0         
                                                                 
 dense_1058 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_313 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_836 (Dropout)       (None, 352)               0         
                                                                 
 dense_1059 (Dense)          (None, 288)               101664    
                                                                 
 dropout_837 (Dropout)       (None, 288)               0         
                                                                 
 dense_1060 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 223:
  Value: 0.9149
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003180547269253759

Model: "sequential_223"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_223 (Flatten)       (None, 784)               0         
                                                                 
 dense_1061 (Dense)          (None, 416)               326560    
                                                                 
 dropout_838 (Dropout)       (None, 416)               0         
                                                                 
 dense_1062 (Dense)          (None, 512)               213504    
                                                                 
 dropout_839 (Dropout)       (None, 512)               0         
                                                                 
 dense_1063 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_314 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_840 (Dropout)       (None, 352)               0         
                                                                 
 dense_1064 (Dense)          (None, 256)               90368     
                                                                 
 dropout_841 (Dropout)       (None, 256)               0         
                                                                 
 dense_1065 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 819098 (3.12 MB)
Trainable params: 818394 (3.12 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 224:
  Value: 0.9133
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002703240867298691

Model: "sequential_224"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_224 (Flatten)       (None, 784)               0         
                                                                 
 dense_1066 (Dense)          (None, 416)               326560    
                                                                 
 dropout_842 (Dropout)       (None, 416)               0         
                                                                 
 dense_1067 (Dense)          (None, 512)               213504    
                                                                 
 dropout_843 (Dropout)       (None, 512)               0         
                                                                 
 dense_1068 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_315 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_844 (Dropout)       (None, 352)               0         
                                                                 
 dense_1069 (Dense)          (None, 288)               101664    
                                                                 
 dropout_845 (Dropout)       (None, 288)               0         
                                                                 
 dense_1070 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 225:
  Value: 0.9047
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.4
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00029846669733781314

Model: "sequential_225"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_225 (Flatten)       (None, 784)               0         
                                                                 
 dense_1071 (Dense)          (None, 416)               326560    
                                                                 
 dropout_846 (Dropout)       (None, 416)               0         
                                                                 
 dense_1072 (Dense)          (None, 512)               213504    
                                                                 
 dropout_847 (Dropout)       (None, 512)               0         
                                                                 
 dense_1073 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_316 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_848 (Dropout)       (None, 352)               0         
                                                                 
 dense_1074 (Dense)          (None, 320)               112960    
                                                                 
 dropout_849 (Dropout)       (None, 320)               0         
                                                                 
 dense_1075 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 843354 (3.22 MB)
Trainable params: 842650 (3.21 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 226:
  Value: 0.9134
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00028499941536840544

Model: "sequential_226"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_226 (Flatten)       (None, 784)               0         
                                                                 
 dense_1076 (Dense)          (None, 416)               326560    
                                                                 
 dropout_850 (Dropout)       (None, 416)               0         
                                                                 
 dense_1077 (Dense)          (None, 512)               213504    
                                                                 
 dropout_851 (Dropout)       (None, 512)               0         
                                                                 
 dense_1078 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_317 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_852 (Dropout)       (None, 352)               0         
                                                                 
 dense_1079 (Dense)          (None, 288)               101664    
                                                                 
 dropout_853 (Dropout)       (None, 288)               0         
                                                                 
 dense_1080 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 227:
  Value: 0.2723
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 384
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00027083019484396394

Model: "sequential_227"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_227 (Flatten)       (None, 784)               0         
                                                                 
 dense_1081 (Dense)          (None, 384)               301440    
                                                                 
 dropout_854 (Dropout)       (None, 384)               0         
                                                                 
 dense_1082 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_318 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_855 (Dropout)       (None, 512)               0         
                                                                 
 dense_1083 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_319 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_856 (Dropout)       (None, 384)               0         
                                                                 
 dense_1084 (Dense)          (None, 288)               110880    
                                                                 
 dropout_857 (Dropout)       (None, 288)               0         
                                                                 
 dense_1085 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 817530 (3.12 MB)
Trainable params: 815738 (3.11 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 228:
  Value: 0.4013
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.0
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0003843822924541107

Model: "sequential_228"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_228 (Flatten)       (None, 784)               0         
                                                                 
 dense_1086 (Dense)          (None, 384)               301440    
                                                                 
 dropout_858 (Dropout)       (None, 384)               0         
                                                                 
 dense_1087 (Dense)          (None, 512)               197120    
                                                                 
 dropout_859 (Dropout)       (None, 512)               0         
                                                                 
 dense_1088 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_320 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_860 (Dropout)       (None, 352)               0         
                                                                 
 dense_1089 (Dense)          (None, 320)               112960    
                                                                 
 dropout_861 (Dropout)       (None, 320)               0         
                                                                 
 dense_1090 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 801850 (3.06 MB)
Trainable params: 801146 (3.06 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 229:
  Value: 0.9125
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003229547478520838

Model: "sequential_229"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_229 (Flatten)       (None, 784)               0         
                                                                 
 dense_1091 (Dense)          (None, 416)               326560    
                                                                 
 dropout_862 (Dropout)       (None, 416)               0         
                                                                 
 dense_1092 (Dense)          (None, 512)               213504    
                                                                 
 dropout_863 (Dropout)       (None, 512)               0         
                                                                 
 dense_1093 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_321 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_864 (Dropout)       (None, 352)               0         
                                                                 
 dense_1094 (Dense)          (None, 352)               124256    
                                                                 
 dropout_865 (Dropout)       (None, 352)               0         
                                                                 
 dense_1095 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 855482 (3.26 MB)
Trainable params: 854778 (3.26 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 230:
  Value: 0.9163
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003540327741461947

Model: "sequential_230"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_230 (Flatten)       (None, 784)               0         
                                                                 
 dense_1096 (Dense)          (None, 448)               351680    
                                                                 
 dropout_866 (Dropout)       (None, 448)               0         
                                                                 
 dense_1097 (Dense)          (None, 512)               229888    
                                                                 
 dropout_867 (Dropout)       (None, 512)               0         
                                                                 
 dense_1098 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_322 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_868 (Dropout)       (None, 384)               0         
                                                                 
 dense_1099 (Dense)          (None, 320)               123200    
                                                                 
 dropout_869 (Dropout)       (None, 320)               0         
                                                                 
 dense_1100 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 911642 (3.48 MB)
Trainable params: 910874 (3.47 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 231:
  Value: 0.9151
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003608706843686913

Model: "sequential_231"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_231 (Flatten)       (None, 784)               0         
                                                                 
 dense_1101 (Dense)          (None, 448)               351680    
                                                                 
 dropout_870 (Dropout)       (None, 448)               0         
                                                                 
 dense_1102 (Dense)          (None, 512)               229888    
                                                                 
 dropout_871 (Dropout)       (None, 512)               0         
                                                                 
 dense_1103 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_323 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_872 (Dropout)       (None, 384)               0         
                                                                 
 dense_1104 (Dense)          (None, 320)               123200    
                                                                 
 dropout_873 (Dropout)       (None, 320)               0         
                                                                 
 dense_1105 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 911642 (3.48 MB)
Trainable params: 910874 (3.47 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 232:
  Value: 0.9169
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 352
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000311030176015119

Model: "sequential_232"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_232 (Flatten)       (None, 784)               0         
                                                                 
 dense_1106 (Dense)          (None, 448)               351680    
                                                                 
 dropout_874 (Dropout)       (None, 448)               0         
                                                                 
 dense_1107 (Dense)          (None, 512)               229888    
                                                                 
 dropout_875 (Dropout)       (None, 512)               0         
                                                                 
 dense_1108 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_324 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_876 (Dropout)       (None, 352)               0         
                                                                 
 dense_1109 (Dense)          (None, 256)               90368     
                                                                 
 dropout_877 (Dropout)       (None, 256)               0         
                                                                 
 dense_1110 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 860602 (3.28 MB)
Trainable params: 859898 (3.28 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 233:
  Value: 0.9139
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003253920251103438

Model: "sequential_233"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_233 (Flatten)       (None, 784)               0         
                                                                 
 dense_1111 (Dense)          (None, 416)               326560    
                                                                 
 dropout_878 (Dropout)       (None, 416)               0         
                                                                 
 dense_1112 (Dense)          (None, 512)               213504    
                                                                 
 dropout_879 (Dropout)       (None, 512)               0         
                                                                 
 dense_1113 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_325 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_880 (Dropout)       (None, 352)               0         
                                                                 
 dense_1114 (Dense)          (None, 288)               101664    
                                                                 
 dropout_881 (Dropout)       (None, 288)               0         
                                                                 
 dense_1115 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 831226 (3.17 MB)
Trainable params: 830522 (3.17 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 234:
  Value: 0.4025
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 352
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.0
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002944842784543836

Model: "sequential_234"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_234 (Flatten)       (None, 784)               0         
                                                                 
 dense_1116 (Dense)          (None, 448)               351680    
                                                                 
 dropout_882 (Dropout)       (None, 448)               0         
                                                                 
 dense_1117 (Dense)          (None, 512)               229888    
                                                                 
 dropout_883 (Dropout)       (None, 512)               0         
                                                                 
 dense_1118 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_326 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_884 (Dropout)       (None, 352)               0         
                                                                 
 dense_1119 (Dense)          (None, 320)               112960    
                                                                 
 dropout_885 (Dropout)       (None, 320)               0         
                                                                 
 dense_1120 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 884858 (3.38 MB)
Trainable params: 884154 (3.37 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 235:
  Value: 0.9169
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.0
  dropout_1: 0.5
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00027221874738487454

Model: "sequential_235"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_235 (Flatten)       (None, 784)               0         
                                                                 
 dense_1121 (Dense)          (None, 448)               351680    
                                                                 
 dropout_886 (Dropout)       (None, 448)               0         
                                                                 
 dense_1122 (Dense)          (None, 512)               229888    
                                                                 
 dropout_887 (Dropout)       (None, 512)               0         
                                                                 
 dense_1123 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_327 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_888 (Dropout)       (None, 384)               0         
                                                                 
 dense_1124 (Dense)          (None, 256)               98560     
                                                                 
 dropout_889 (Dropout)       (None, 256)               0         
                                                                 
 dense_1125 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 236:
  Value: 0.9163
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004138866853005796

Model: "sequential_236"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_236 (Flatten)       (None, 784)               0         
                                                                 
 dense_1126 (Dense)          (None, 448)               351680    
                                                                 
 dropout_890 (Dropout)       (None, 448)               0         
                                                                 
 dense_1127 (Dense)          (None, 512)               229888    
                                                                 
 dropout_891 (Dropout)       (None, 512)               0         
                                                                 
 dense_1128 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_328 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_892 (Dropout)       (None, 384)               0         
                                                                 
 dense_1129 (Dense)          (None, 256)               98560     
                                                                 
 dropout_893 (Dropout)       (None, 256)               0         
                                                                 
 dense_1130 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 237:
  Value: 0.9186
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004220635480679449

Model: "sequential_237"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_237 (Flatten)       (None, 784)               0         
                                                                 
 dense_1131 (Dense)          (None, 448)               351680    
                                                                 
 dropout_894 (Dropout)       (None, 448)               0         
                                                                 
 dense_1132 (Dense)          (None, 512)               229888    
                                                                 
 dropout_895 (Dropout)       (None, 512)               0         
                                                                 
 dense_1133 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_329 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_896 (Dropout)       (None, 384)               0         
                                                                 
 dense_1134 (Dense)          (None, 256)               98560     
                                                                 
 dropout_897 (Dropout)       (None, 256)               0         
                                                                 
 dense_1135 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 238:
  Value: 0.7885
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.00041009821742393114

Model: "sequential_238"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_238 (Flatten)       (None, 784)               0         
                                                                 
 dense_1136 (Dense)          (None, 448)               351680    
                                                                 
 dropout_898 (Dropout)       (None, 448)               0         
                                                                 
 dense_1137 (Dense)          (None, 512)               229888    
                                                                 
 dropout_899 (Dropout)       (None, 512)               0         
                                                                 
 dense_1138 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_330 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_900 (Dropout)       (None, 384)               0         
                                                                 
 dense_1139 (Dense)          (None, 256)               98560     
                                                                 
 dropout_901 (Dropout)       (None, 256)               0         
                                                                 
 dense_1140 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 239:
  Value: 0.8916
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00041868143287029875

Model: "sequential_239"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_239 (Flatten)       (None, 784)               0         
                                                                 
 dense_1141 (Dense)          (None, 448)               351680    
                                                                 
 dropout_902 (Dropout)       (None, 448)               0         
                                                                 
 dense_1142 (Dense)          (None, 512)               229888    
                                                                 
 dropout_903 (Dropout)       (None, 512)               0         
                                                                 
 dense_1143 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_331 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_904 (Dropout)       (None, 384)               0         
                                                                 
 dense_1144 (Dense)          (None, 256)               98560     
                                                                 
 dropout_905 (Dropout)       (None, 256)               0         
                                                                 
 dense_1145 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 240:
  Value: 0.8301
  num_layers: 3
  units_0: 448
  units_1: 512
  units_2: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  dropout_0: 0.5
  dropout_1: 0.5
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0003467940656983664

Model: "sequential_240"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_240 (Flatten)       (None, 784)               0         
                                                                 
 dense_1146 (Dense)          (None, 448)               351680    
                                                                 
 dropout_906 (Dropout)       (None, 448)               0         
                                                                 
 dense_1147 (Dense)          (None, 512)               229888    
                                                                 
 dropout_907 (Dropout)       (None, 512)               0         
                                                                 
 dense_1148 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_332 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_908 (Dropout)       (None, 384)               0         
                                                                 
 dense_1149 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 790106 (3.01 MB)
Trainable params: 789338 (3.01 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 241:
  Value: 0.9026
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 352
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003237550986552028

Model: "sequential_241"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_241 (Flatten)       (None, 784)               0         
                                                                 
 dense_1150 (Dense)          (None, 416)               326560    
                                                                 
 dropout_909 (Dropout)       (None, 416)               0         
                                                                 
 dense_1151 (Dense)          (None, 512)               213504    
                                                                 
 dropout_910 (Dropout)       (None, 512)               0         
                                                                 
 dense_1152 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_333 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_911 (Dropout)       (None, 352)               0         
                                                                 
 dense_1153 (Dense)          (None, 256)               90368     
                                                                 
 dropout_912 (Dropout)       (None, 256)               0         
                                                                 
 dense_1154 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 819098 (3.12 MB)
Trainable params: 818394 (3.12 MB)
Non-trainable params: 704 (2.75 KB)
_________________________________________________________________



Trial 242:
  Value: 0.9163
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.30000000000000004
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00027455310372399155

Model: "sequential_242"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_242 (Flatten)       (None, 784)               0         
                                                                 
 dense_1155 (Dense)          (None, 448)               351680    
                                                                 
 dropout_913 (Dropout)       (None, 448)               0         
                                                                 
 dense_1156 (Dense)          (None, 512)               229888    
                                                                 
 dropout_914 (Dropout)       (None, 512)               0         
                                                                 
 dense_1157 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_334 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_915 (Dropout)       (None, 384)               0         
                                                                 
 dense_1158 (Dense)          (None, 256)               98560     
                                                                 
 dropout_916 (Dropout)       (None, 256)               0         
                                                                 
 dense_1159 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 243:
  Value: 0.8983
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002739498508714313

Model: "sequential_243"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_243 (Flatten)       (None, 784)               0         
                                                                 
 dense_1160 (Dense)          (None, 448)               351680    
                                                                 
 dropout_917 (Dropout)       (None, 448)               0         
                                                                 
 dense_1161 (Dense)          (None, 512)               229888    
                                                                 
 dropout_918 (Dropout)       (None, 512)               0         
                                                                 
 dense_1162 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_335 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_919 (Dropout)       (None, 384)               0         
                                                                 
 dense_1163 (Dense)          (None, 256)               98560     
                                                                 
 dropout_920 (Dropout)       (None, 256)               0         
                                                                 
 dense_1164 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 244:
  Value: 0.9158
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003055013374069242

Model: "sequential_244"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_244 (Flatten)       (None, 784)               0         
                                                                 
 dense_1165 (Dense)          (None, 448)               351680    
                                                                 
 dropout_921 (Dropout)       (None, 448)               0         
                                                                 
 dense_1166 (Dense)          (None, 512)               229888    
                                                                 
 dropout_922 (Dropout)       (None, 512)               0         
                                                                 
 dense_1167 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_336 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_923 (Dropout)       (None, 384)               0         
                                                                 
 dense_1168 (Dense)          (None, 256)               98560     
                                                                 
 dropout_924 (Dropout)       (None, 256)               0         
                                                                 
 dense_1169 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 245:
  Value: 0.9037
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.5
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002970151913290164

Model: "sequential_245"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_245 (Flatten)       (None, 784)               0         
                                                                 
 dense_1170 (Dense)          (None, 448)               351680    
                                                                 
 dropout_925 (Dropout)       (None, 448)               0         
                                                                 
 dense_1171 (Dense)          (None, 512)               229888    
                                                                 
 dropout_926 (Dropout)       (None, 512)               0         
                                                                 
 dense_1172 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_337 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_927 (Dropout)       (None, 384)               0         
                                                                 
 dense_1173 (Dense)          (None, 224)               86240     
                                                                 
 dropout_928 (Dropout)       (None, 224)               0         
                                                                 
 dense_1174 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 872186 (3.33 MB)
Trainable params: 871418 (3.32 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 246:
  Value: 0.9135
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.30000000000000004
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003508305077848893

Model: "sequential_246"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_246 (Flatten)       (None, 784)               0         
                                                                 
 dense_1175 (Dense)          (None, 416)               326560    
                                                                 
 dropout_929 (Dropout)       (None, 416)               0         
                                                                 
 dense_1176 (Dense)          (None, 512)               213504    
                                                                 
 dropout_930 (Dropout)       (None, 512)               0         
                                                                 
 dense_1177 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_338 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_931 (Dropout)       (None, 384)               0         
                                                                 
 dense_1178 (Dense)          (None, 256)               98560     
                                                                 
 dropout_932 (Dropout)       (None, 256)               0         
                                                                 
 dense_1179 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 843834 (3.22 MB)
Trainable params: 843066 (3.22 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 247:
  Value: 0.9164
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00031274293815807967

Model: "sequential_247"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_247 (Flatten)       (None, 784)               0         
                                                                 
 dense_1180 (Dense)          (None, 448)               351680    
                                                                 
 dropout_933 (Dropout)       (None, 448)               0         
                                                                 
 dense_1181 (Dense)          (None, 512)               229888    
                                                                 
 dropout_934 (Dropout)       (None, 512)               0         
                                                                 
 dense_1182 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_339 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_935 (Dropout)       (None, 384)               0         
                                                                 
 dense_1183 (Dense)          (None, 256)               98560     
                                                                 
 dropout_936 (Dropout)       (None, 256)               0         
                                                                 
 dense_1184 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 248:
  Value: 0.9177
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003279551676251753

Model: "sequential_248"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_248 (Flatten)       (None, 784)               0         
                                                                 
 dense_1185 (Dense)          (None, 448)               351680    
                                                                 
 dropout_937 (Dropout)       (None, 448)               0         
                                                                 
 dense_1186 (Dense)          (None, 512)               229888    
                                                                 
 dropout_938 (Dropout)       (None, 512)               0         
                                                                 
 dense_1187 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_340 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_939 (Dropout)       (None, 384)               0         
                                                                 
 dense_1188 (Dense)          (None, 288)               110880    
                                                                 
 dropout_940 (Dropout)       (None, 288)               0         
                                                                 
 dense_1189 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 898490 (3.43 MB)
Trainable params: 897722 (3.42 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 249:
  Value: 0.9192
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00031475418970080567

Model: "sequential_249"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_249 (Flatten)       (None, 784)               0         
                                                                 
 dense_1190 (Dense)          (None, 448)               351680    
                                                                 
 dropout_941 (Dropout)       (None, 448)               0         
                                                                 
 dense_1191 (Dense)          (None, 512)               229888    
                                                                 
 dropout_942 (Dropout)       (None, 512)               0         
                                                                 
 dense_1192 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_341 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_943 (Dropout)       (None, 384)               0         
                                                                 
 dense_1193 (Dense)          (None, 256)               98560     
                                                                 
 dropout_944 (Dropout)       (None, 256)               0         
                                                                 
 dense_1194 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 250:
  Value: 0.9158
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.30000000000000004
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00032688661008378744

Model: "sequential_250"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_250 (Flatten)       (None, 784)               0         
                                                                 
 dense_1195 (Dense)          (None, 448)               351680    
                                                                 
 dropout_945 (Dropout)       (None, 448)               0         
                                                                 
 dense_1196 (Dense)          (None, 512)               229888    
                                                                 
 dropout_946 (Dropout)       (None, 512)               0         
                                                                 
 dense_1197 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_342 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_947 (Dropout)       (None, 384)               0         
                                                                 
 dense_1198 (Dense)          (None, 224)               86240     
                                                                 
 dropout_948 (Dropout)       (None, 224)               0         
                                                                 
 dense_1199 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 872186 (3.33 MB)
Trainable params: 871418 (3.32 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 251:
  Value: 0.9171
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003263813851915648

Model: "sequential_251"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_251 (Flatten)       (None, 784)               0         
                                                                 
 dense_1200 (Dense)          (None, 448)               351680    
                                                                 
 dropout_949 (Dropout)       (None, 448)               0         
                                                                 
 dense_1201 (Dense)          (None, 512)               229888    
                                                                 
 dropout_950 (Dropout)       (None, 512)               0         
                                                                 
 dense_1202 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_343 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_951 (Dropout)       (None, 384)               0         
                                                                 
 dense_1203 (Dense)          (None, 256)               98560     
                                                                 
 dropout_952 (Dropout)       (None, 256)               0         
                                                                 
 dense_1204 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 252:
  Value: 0.1100
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.00037941427239457875

Model: "sequential_252"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_252 (Flatten)       (None, 784)               0         
                                                                 
 dense_1205 (Dense)          (None, 448)               351680    
                                                                 
 dropout_953 (Dropout)       (None, 448)               0         
                                                                 
 dense_1206 (Dense)          (None, 512)               229888    
                                                                 
 dropout_954 (Dropout)       (None, 512)               0         
                                                                 
 dense_1207 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_344 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_955 (Dropout)       (None, 384)               0         
                                                                 
 dense_1208 (Dense)          (None, 224)               86240     
                                                                 
 dropout_956 (Dropout)       (None, 224)               0         
                                                                 
 dense_1209 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 872186 (3.33 MB)
Trainable params: 871418 (3.32 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 253:
  Value: 0.6686
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003259830410823436

Model: "sequential_253"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_253 (Flatten)       (None, 784)               0         
                                                                 
 dense_1210 (Dense)          (None, 448)               351680    
                                                                 
 dropout_957 (Dropout)       (None, 448)               0         
                                                                 
 dense_1211 (Dense)          (None, 512)               229888    
                                                                 
 dropout_958 (Dropout)       (None, 512)               0         
                                                                 
 dense_1212 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_345 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_959 (Dropout)       (None, 384)               0         
                                                                 
 dense_1213 (Dense)          (None, 256)               98560     
                                                                 
 dropout_960 (Dropout)       (None, 256)               0         
                                                                 
 dense_1214 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 254:
  Value: 0.9166
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003451682225519892

Model: "sequential_254"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_254 (Flatten)       (None, 784)               0         
                                                                 
 dense_1215 (Dense)          (None, 448)               351680    
                                                                 
 dropout_961 (Dropout)       (None, 448)               0         
                                                                 
 dense_1216 (Dense)          (None, 512)               229888    
                                                                 
 dropout_962 (Dropout)       (None, 512)               0         
                                                                 
 dense_1217 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_346 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_963 (Dropout)       (None, 384)               0         
                                                                 
 dense_1218 (Dense)          (None, 256)               98560     
                                                                 
 dropout_964 (Dropout)       (None, 256)               0         
                                                                 
 dense_1219 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 255:
  Value: 0.8239
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0004246625934217426

Model: "sequential_255"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_255 (Flatten)       (None, 784)               0         
                                                                 
 dense_1220 (Dense)          (None, 448)               351680    
                                                                 
 dropout_965 (Dropout)       (None, 448)               0         
                                                                 
 dense_1221 (Dense)          (None, 512)               229888    
                                                                 
 dropout_966 (Dropout)       (None, 512)               0         
                                                                 
 dense_1222 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_347 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_967 (Dropout)       (None, 384)               0         
                                                                 
 dense_1223 (Dense)          (None, 256)               98560     
                                                                 
 dropout_968 (Dropout)       (None, 256)               0         
                                                                 
 dense_1224 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 256:
  Value: 0.9166
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00036880812318321

Model: "sequential_256"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_256 (Flatten)       (None, 784)               0         
                                                                 
 dense_1225 (Dense)          (None, 448)               351680    
                                                                 
 dropout_969 (Dropout)       (None, 448)               0         
                                                                 
 dense_1226 (Dense)          (None, 512)               229888    
                                                                 
 dropout_970 (Dropout)       (None, 512)               0         
                                                                 
 dense_1227 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_348 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_971 (Dropout)       (None, 384)               0         
                                                                 
 dense_1228 (Dense)          (None, 256)               98560     
                                                                 
 dropout_972 (Dropout)       (None, 256)               0         
                                                                 
 dense_1229 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 257:
  Value: 0.9188
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00036462206108522823

Model: "sequential_257"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_257 (Flatten)       (None, 784)               0         
                                                                 
 dense_1230 (Dense)          (None, 448)               351680    
                                                                 
 dropout_973 (Dropout)       (None, 448)               0         
                                                                 
 dense_1231 (Dense)          (None, 512)               229888    
                                                                 
 dropout_974 (Dropout)       (None, 512)               0         
                                                                 
 dense_1232 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_349 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_975 (Dropout)       (None, 384)               0         
                                                                 
 dense_1233 (Dense)          (None, 256)               98560     
                                                                 
 dropout_976 (Dropout)       (None, 256)               0         
                                                                 
 dense_1234 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 258:
  Value: 0.0373
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0003651519413361951

Model: "sequential_258"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_258 (Flatten)       (None, 784)               0         
                                                                 
 dense_1235 (Dense)          (None, 448)               351680    
                                                                 
 dropout_977 (Dropout)       (None, 448)               0         
                                                                 
 dense_1236 (Dense)          (None, 512)               229888    
                                                                 
 dropout_978 (Dropout)       (None, 512)               0         
                                                                 
 dense_1237 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_350 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_979 (Dropout)       (None, 384)               0         
                                                                 
 dense_1238 (Dense)          (None, 256)               98560     
                                                                 
 dropout_980 (Dropout)       (None, 256)               0         
                                                                 
 dense_1239 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 259:
  Value: 0.6883
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003951488873460313

Model: "sequential_259"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_259 (Flatten)       (None, 784)               0         
                                                                 
 dense_1240 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_351 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_981 (Dropout)       (None, 448)               0         
                                                                 
 dense_1241 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_352 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_982 (Dropout)       (None, 512)               0         
                                                                 
 dense_1242 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_353 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_983 (Dropout)       (None, 384)               0         
                                                                 
 dense_1243 (Dense)          (None, 288)               110880    
                                                                 
 dropout_984 (Dropout)       (None, 288)               0         
                                                                 
 dense_1244 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 902330 (3.44 MB)
Trainable params: 899642 (3.43 MB)
Non-trainable params: 2688 (10.50 KB)
_________________________________________________________________



Trial 260:
  Value: 0.9102
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004507729669518662

Model: "sequential_260"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_260 (Flatten)       (None, 784)               0         
                                                                 
 dense_1245 (Dense)          (None, 448)               351680    
                                                                 
 dropout_985 (Dropout)       (None, 448)               0         
                                                                 
 dense_1246 (Dense)          (None, 512)               229888    
                                                                 
 dropout_986 (Dropout)       (None, 512)               0         
                                                                 
 dense_1247 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_354 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_987 (Dropout)       (None, 384)               0         
                                                                 
 dense_1248 (Dense)          (None, 256)               98560     
                                                                 
 dropout_988 (Dropout)       (None, 256)               0         
                                                                 
 dense_1249 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 261:
  Value: 0.9158
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003682931178464079

Model: "sequential_261"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_261 (Flatten)       (None, 784)               0         
                                                                 
 dense_1250 (Dense)          (None, 448)               351680    
                                                                 
 dropout_989 (Dropout)       (None, 448)               0         
                                                                 
 dense_1251 (Dense)          (None, 512)               229888    
                                                                 
 dropout_990 (Dropout)       (None, 512)               0         
                                                                 
 dense_1252 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_355 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_991 (Dropout)       (None, 384)               0         
                                                                 
 dense_1253 (Dense)          (None, 288)               110880    
                                                                 
 dropout_992 (Dropout)       (None, 288)               0         
                                                                 
 dense_1254 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 898490 (3.43 MB)
Trainable params: 897722 (3.42 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 262:
  Value: 0.9112
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00034680389951457195

Model: "sequential_262"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_262 (Flatten)       (None, 784)               0         
                                                                 
 dense_1255 (Dense)          (None, 416)               326560    
                                                                 
 dropout_993 (Dropout)       (None, 416)               0         
                                                                 
 dense_1256 (Dense)          (None, 512)               213504    
                                                                 
 dropout_994 (Dropout)       (None, 512)               0         
                                                                 
 dense_1257 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_356 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_995 (Dropout)       (None, 384)               0         
                                                                 
 dense_1258 (Dense)          (None, 256)               98560     
                                                                 
 dropout_996 (Dropout)       (None, 256)               0         
                                                                 
 dense_1259 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 843834 (3.22 MB)
Trainable params: 843066 (3.22 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 263:
  Value: 0.9181
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: tanh
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003462260176922785

Model: "sequential_263"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_263 (Flatten)       (None, 784)               0         
                                                                 
 dense_1260 (Dense)          (None, 448)               351680    
                                                                 
 dropout_997 (Dropout)       (None, 448)               0         
                                                                 
 dense_1261 (Dense)          (None, 512)               229888    
                                                                 
 dropout_998 (Dropout)       (None, 512)               0         
                                                                 
 dense_1262 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_357 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_999 (Dropout)       (None, 384)               0         
                                                                 
 dense_1263 (Dense)          (None, 256)               98560     
                                                                 
 dropout_1000 (Dropout)      (None, 256)               0         
                                                                 
 dense_1264 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 264:
  Value: 0.9184
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00039808542118353646

Model: "sequential_264"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_264 (Flatten)       (None, 784)               0         
                                                                 
 dense_1265 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1001 (Dropout)      (None, 448)               0         
                                                                 
 dense_1266 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1002 (Dropout)      (None, 512)               0         
                                                                 
 dense_1267 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_358 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1003 (Dropout)      (None, 384)               0         
                                                                 
 dense_1268 (Dense)          (None, 256)               98560     
                                                                 
 dropout_1004 (Dropout)      (None, 256)               0         
                                                                 
 dense_1269 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 265:
  Value: 0.9176
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00040259377080318124

Model: "sequential_265"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_265 (Flatten)       (None, 784)               0         
                                                                 
 dense_1270 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1005 (Dropout)      (None, 448)               0         
                                                                 
 dense_1271 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1006 (Dropout)      (None, 512)               0         
                                                                 
 dense_1272 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_359 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1007 (Dropout)      (None, 384)               0         
                                                                 
 dense_1273 (Dense)          (None, 256)               98560     
                                                                 
 dropout_1008 (Dropout)      (None, 256)               0         
                                                                 
 dense_1274 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 266:
  Value: 0.9164
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00046774306990070736

Model: "sequential_266"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_266 (Flatten)       (None, 784)               0         
                                                                 
 dense_1275 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1009 (Dropout)      (None, 448)               0         
                                                                 
 dense_1276 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1010 (Dropout)      (None, 512)               0         
                                                                 
 dense_1277 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_360 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1011 (Dropout)      (None, 384)               0         
                                                                 
 dense_1278 (Dense)          (None, 256)               98560     
                                                                 
 dropout_1012 (Dropout)      (None, 256)               0         
                                                                 
 dense_1279 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 267:
  Value: 0.9181
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00044561632912983517

Model: "sequential_267"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_267 (Flatten)       (None, 784)               0         
                                                                 
 dense_1280 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1013 (Dropout)      (None, 448)               0         
                                                                 
 dense_1281 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1014 (Dropout)      (None, 512)               0         
                                                                 
 dense_1282 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_361 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1015 (Dropout)      (None, 384)               0         
                                                                 
 dense_1283 (Dense)          (None, 256)               98560     
                                                                 
 dropout_1016 (Dropout)      (None, 256)               0         
                                                                 
 dense_1284 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 268:
  Value: 0.8407
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00045472235041129906

Model: "sequential_268"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_268 (Flatten)       (None, 784)               0         
                                                                 
 dense_1285 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1017 (Dropout)      (None, 448)               0         
                                                                 
 dense_1286 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1018 (Dropout)      (None, 512)               0         
                                                                 
 dense_1287 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_362 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1019 (Dropout)      (None, 384)               0         
                                                                 
 dense_1288 (Dense)          (None, 224)               86240     
                                                                 
 dropout_1020 (Dropout)      (None, 224)               0         
                                                                 
 dense_1289 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 872186 (3.33 MB)
Trainable params: 871418 (3.32 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 269:
  Value: 0.9027
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.5
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005110083017796934

Model: "sequential_269"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_269 (Flatten)       (None, 784)               0         
                                                                 
 dense_1290 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1021 (Dropout)      (None, 448)               0         
                                                                 
 dense_1291 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1022 (Dropout)      (None, 512)               0         
                                                                 
 dense_1292 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_363 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1023 (Dropout)      (None, 384)               0         
                                                                 
 dense_1293 (Dense)          (None, 256)               98560     
                                                                 
 dropout_1024 (Dropout)      (None, 256)               0         
                                                                 
 dense_1294 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 885338 (3.38 MB)
Trainable params: 884570 (3.37 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 270:
  Value: 0.0645
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 384
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.000398169113271358

Model: "sequential_270"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_270 (Flatten)       (None, 784)               0         
                                                                 
 dense_1295 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1025 (Dropout)      (None, 416)               0         
                                                                 
 dense_1296 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1026 (Dropout)      (None, 512)               0         
                                                                 
 dense_1297 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_364 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1027 (Dropout)      (None, 384)               0         
                                                                 
 dense_1298 (Dense)          (None, 256)               98560     
                                                                 
 dropout_1028 (Dropout)      (None, 256)               0         
                                                                 
 dense_1299 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 843834 (3.22 MB)
Trainable params: 843066 (3.22 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 271:
  Value: 0.9157
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00047393470748370955

Model: "sequential_271"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_271 (Flatten)       (None, 784)               0         
                                                                 
 dense_1300 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1029 (Dropout)      (None, 448)               0         
                                                                 
 dense_1301 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1030 (Dropout)      (None, 512)               0         
                                                                 
 dense_1302 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_365 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1031 (Dropout)      (None, 384)               0         
                                                                 
 dense_1303 (Dense)          (None, 224)               86240     
                                                                 
 dropout_1032 (Dropout)      (None, 224)               0         
                                                                 
 dense_1304 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 872186 (3.33 MB)
Trainable params: 871418 (3.32 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 272:
  Value: 0.8342
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 384
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000377638184596649

Model: "sequential_272"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_272 (Flatten)       (None, 784)               0         
                                                                 
 dense_1305 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1033 (Dropout)      (None, 448)               0         
                                                                 
 dense_1306 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1034 (Dropout)      (None, 512)               0         
                                                                 
 dense_1307 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_366 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1035 (Dropout)      (None, 384)               0         
                                                                 
 dense_1308 (Dense)          (None, 288)               110880    
                                                                 
 dropout_1036 (Dropout)      (None, 288)               0         
                                                                 
 dense_1309 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 898490 (3.43 MB)
Trainable params: 897722 (3.42 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 273:
  Value: 0.9169
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004340930993218383

Model: "sequential_273"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_273 (Flatten)       (None, 784)               0         
                                                                 
 dense_1310 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1037 (Dropout)      (None, 448)               0         
                                                                 
 dense_1311 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1038 (Dropout)      (None, 512)               0         
                                                                 
 dense_1312 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_367 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1039 (Dropout)      (None, 416)               0         
                                                                 
 dense_1313 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1040 (Dropout)      (None, 288)               0         
                                                                 
 dense_1314 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 924250 (3.53 MB)
Trainable params: 923418 (3.52 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 274:
  Value: 0.7783
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.00044172431415046806

Model: "sequential_274"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_274 (Flatten)       (None, 784)               0         
                                                                 
 dense_1315 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1041 (Dropout)      (None, 416)               0         
                                                                 
 dense_1316 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1042 (Dropout)      (None, 512)               0         
                                                                 
 dense_1317 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_368 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1043 (Dropout)      (None, 416)               0         
                                                                 
 dense_1318 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1044 (Dropout)      (None, 288)               0         
                                                                 
 dense_1319 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 882746 (3.37 MB)
Trainable params: 881914 (3.36 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 275:
  Value: 0.9181
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000406892473097795

Model: "sequential_275"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_275 (Flatten)       (None, 784)               0         
                                                                 
 dense_1320 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1045 (Dropout)      (None, 448)               0         
                                                                 
 dense_1321 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1046 (Dropout)      (None, 512)               0         
                                                                 
 dense_1322 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_369 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1047 (Dropout)      (None, 416)               0         
                                                                 
 dense_1323 (Dense)          (None, 256)               106752    
                                                                 
 dropout_1048 (Dropout)      (None, 256)               0         
                                                                 
 dense_1324 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 910074 (3.47 MB)
Trainable params: 909242 (3.47 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 276:
  Value: 0.9187
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004657386470180948

Model: "sequential_276"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_276 (Flatten)       (None, 784)               0         
                                                                 
 dense_1325 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1049 (Dropout)      (None, 448)               0         
                                                                 
 dense_1326 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1050 (Dropout)      (None, 512)               0         
                                                                 
 dense_1327 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_370 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1051 (Dropout)      (None, 416)               0         
                                                                 
 dense_1328 (Dense)          (None, 256)               106752    
                                                                 
 dropout_1052 (Dropout)      (None, 256)               0         
                                                                 
 dense_1329 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 910074 (3.47 MB)
Trainable params: 909242 (3.47 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 277:
  Value: 0.8295
  num_layers: 4
  units_0: 448
  units_1: 128
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004051693205848545

Model: "sequential_277"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_277 (Flatten)       (None, 784)               0         
                                                                 
 dense_1330 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_371 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1053 (Dropout)      (None, 448)               0         
                                                                 
 dense_1331 (Dense)          (None, 128)               57472     
                                                                 
 dropout_1054 (Dropout)      (None, 128)               0         
                                                                 
 dense_1332 (Dense)          (None, 416)               53664     
                                                                 
 batch_normalization_372 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1055 (Dropout)      (None, 416)               0         
                                                                 
 dense_1333 (Dense)          (None, 256)               106752    
                                                                 
 dropout_1056 (Dropout)      (None, 256)               0         
                                                                 
 dense_1334 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 579706 (2.21 MB)
Trainable params: 577978 (2.20 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 278:
  Value: 0.9205
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005604287858016266

Model: "sequential_278"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_278 (Flatten)       (None, 784)               0         
                                                                 
 dense_1335 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1057 (Dropout)      (None, 384)               0         
                                                                 
 dense_1336 (Dense)          (None, 512)               197120    
                                                                 
 dropout_1058 (Dropout)      (None, 512)               0         
                                                                 
 dense_1337 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_373 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1059 (Dropout)      (None, 416)               0         
                                                                 
 dense_1338 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1060 (Dropout)      (None, 288)               0         
                                                                 
 dense_1339 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 841242 (3.21 MB)
Trainable params: 840410 (3.21 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 279:
  Value: 0.3472
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00041894883734016643

Model: "sequential_279"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_279 (Flatten)       (None, 784)               0         
                                                                 
 dense_1340 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1061 (Dropout)      (None, 384)               0         
                                                                 
 dense_1341 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_374 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1062 (Dropout)      (None, 512)               0         
                                                                 
 dense_1342 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_375 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1063 (Dropout)      (None, 416)               0         
                                                                 
 dense_1343 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1064 (Dropout)      (None, 288)               0         
                                                                 
 dense_1344 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 843290 (3.22 MB)
Trainable params: 841434 (3.21 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 280:
  Value: 0.9187
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005267503226229723

Model: "sequential_280"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_280 (Flatten)       (None, 784)               0         
                                                                 
 dense_1345 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1065 (Dropout)      (None, 416)               0         
                                                                 
 dense_1346 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1066 (Dropout)      (None, 512)               0         
                                                                 
 dense_1347 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_376 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1067 (Dropout)      (None, 416)               0         
                                                                 
 dense_1348 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1068 (Dropout)      (None, 288)               0         
                                                                 
 dense_1349 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 882746 (3.37 MB)
Trainable params: 881914 (3.36 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 281:
  Value: 0.9171
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000490887169734926

Model: "sequential_281"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_281 (Flatten)       (None, 784)               0         
                                                                 
 dense_1350 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1069 (Dropout)      (None, 416)               0         
                                                                 
 dense_1351 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1070 (Dropout)      (None, 512)               0         
                                                                 
 dense_1352 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_377 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1071 (Dropout)      (None, 416)               0         
                                                                 
 dense_1353 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1072 (Dropout)      (None, 288)               0         
                                                                 
 dense_1354 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 882746 (3.37 MB)
Trainable params: 881914 (3.36 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 282:
  Value: 0.0507
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0005411023444640999

Model: "sequential_282"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_282 (Flatten)       (None, 784)               0         
                                                                 
 dense_1355 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1073 (Dropout)      (None, 416)               0         
                                                                 
 dense_1356 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1074 (Dropout)      (None, 512)               0         
                                                                 
 dense_1357 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_378 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1075 (Dropout)      (None, 416)               0         
                                                                 
 dense_1358 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1076 (Dropout)      (None, 288)               0         
                                                                 
 dense_1359 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 882746 (3.37 MB)
Trainable params: 881914 (3.36 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 283:
  Value: 0.7921
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0005039653873440027

Model: "sequential_283"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_283 (Flatten)       (None, 784)               0         
                                                                 
 dense_1360 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1077 (Dropout)      (None, 416)               0         
                                                                 
 dense_1361 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1078 (Dropout)      (None, 512)               0         
                                                                 
 dense_1362 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_379 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1079 (Dropout)      (None, 416)               0         
                                                                 
 dense_1363 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1080 (Dropout)      (None, 288)               0         
                                                                 
 dense_1364 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 882746 (3.37 MB)
Trainable params: 881914 (3.36 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 284:
  Value: 0.9147
  num_layers: 3
  units_0: 416
  units_1: 512
  units_2: 416
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0005415950571607514

Model: "sequential_284"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_284 (Flatten)       (None, 784)               0         
                                                                 
 dense_1365 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1081 (Dropout)      (None, 416)               0         
                                                                 
 dense_1366 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1082 (Dropout)      (None, 512)               0         
                                                                 
 dense_1367 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_380 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1083 (Dropout)      (None, 416)               0         
                                                                 
 dense_1368 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 765978 (2.92 MB)
Trainable params: 765146 (2.92 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 285:
  Value: 0.8953
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006078324013265098

Model: "sequential_285"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_285 (Flatten)       (None, 784)               0         
                                                                 
 dense_1369 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1084 (Dropout)      (None, 384)               0         
                                                                 
 dense_1370 (Dense)          (None, 512)               197120    
                                                                 
 dropout_1085 (Dropout)      (None, 512)               0         
                                                                 
 dense_1371 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_381 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1086 (Dropout)      (None, 416)               0         
                                                                 
 dense_1372 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1087 (Dropout)      (None, 288)               0         
                                                                 
 dense_1373 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 841242 (3.21 MB)
Trainable params: 840410 (3.21 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 286:
  Value: 0.0373
  num_layers: 2
  units_0: 416
  units_1: 512
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  batch_norm_0: False
  batch_norm_1: False
  optimizer: ftrl
  learning_rate: 0.0004683816084470045

Model: "sequential_286"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_286 (Flatten)       (None, 784)               0         
                                                                 
 dense_1374 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1088 (Dropout)      (None, 416)               0         
                                                                 
 dense_1375 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1089 (Dropout)      (None, 512)               0         
                                                                 
 dense_1376 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 553402 (2.11 MB)
Trainable params: 553402 (2.11 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 287:
  Value: 0.8945
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004346569218956044

Model: "sequential_287"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_287 (Flatten)       (None, 784)               0         
                                                                 
 dense_1377 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1090 (Dropout)      (None, 416)               0         
                                                                 
 dense_1378 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1091 (Dropout)      (None, 512)               0         
                                                                 
 dense_1379 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_382 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1092 (Dropout)      (None, 416)               0         
                                                                 
 dense_1380 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1093 (Dropout)      (None, 224)               0         
                                                                 
 dense_1381 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 854394 (3.26 MB)
Trainable params: 853562 (3.26 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 288:
  Value: 0.9147
  num_layers: 4
  units_0: 384
  units_1: 512
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004862119901374609

Model: "sequential_288"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_288 (Flatten)       (None, 784)               0         
                                                                 
 dense_1382 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1094 (Dropout)      (None, 384)               0         
                                                                 
 dense_1383 (Dense)          (None, 512)               197120    
                                                                 
 dropout_1095 (Dropout)      (None, 512)               0         
                                                                 
 dense_1384 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_383 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1096 (Dropout)      (None, 416)               0         
                                                                 
 dense_1385 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1097 (Dropout)      (None, 288)               0         
                                                                 
 dense_1386 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 841242 (3.21 MB)
Trainable params: 840410 (3.21 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 289:
  Value: 0.8142
  num_layers: 1
  units_0: 416
  activation_0: relu
  dropout_0: 0.4
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0003913313295369841

Model: "sequential_289"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_289 (Flatten)       (None, 784)               0         
                                                                 
 dense_1387 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1098 (Dropout)      (None, 416)               0         
                                                                 
 dense_1388 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 337402 (1.29 MB)
Trainable params: 337402 (1.29 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 290:
  Value: 0.9013
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004368647490426335

Model: "sequential_290"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_290 (Flatten)       (None, 784)               0         
                                                                 
 dense_1389 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1099 (Dropout)      (None, 448)               0         
                                                                 
 dense_1390 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1100 (Dropout)      (None, 512)               0         
                                                                 
 dense_1391 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_384 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1101 (Dropout)      (None, 416)               0         
                                                                 
 dense_1392 (Dense)          (None, 256)               106752    
                                                                 
 dropout_1102 (Dropout)      (None, 256)               0         
                                                                 
 dense_1393 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 910074 (3.47 MB)
Trainable params: 909242 (3.47 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 291:
  Value: 0.8987
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005518827567809314

Model: "sequential_291"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_291 (Flatten)       (None, 784)               0         
                                                                 
 dense_1394 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1103 (Dropout)      (None, 448)               0         
                                                                 
 dense_1395 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1104 (Dropout)      (None, 480)               0         
                                                                 
 dense_1396 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_385 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1105 (Dropout)      (None, 416)               0         
                                                                 
 dense_1397 (Dense)          (None, 288)               120096    
                                                                 
 dropout_1106 (Dropout)      (None, 288)               0         
                                                                 
 dense_1398 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 896570 (3.42 MB)
Trainable params: 895738 (3.42 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 292:
  Value: 0.9016
  num_layers: 4
  units_0: 416
  units_1: 512
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.30000000000000004
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004013749760621905

Model: "sequential_292"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_292 (Flatten)       (None, 784)               0         
                                                                 
 dense_1399 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1107 (Dropout)      (None, 416)               0         
                                                                 
 dense_1400 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1108 (Dropout)      (None, 512)               0         
                                                                 
 dense_1401 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_386 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1109 (Dropout)      (None, 416)               0         
                                                                 
 dense_1402 (Dense)          (None, 256)               106752    
                                                                 
 dropout_1110 (Dropout)      (None, 256)               0         
                                                                 
 dense_1403 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 868570 (3.31 MB)
Trainable params: 867738 (3.31 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 293:
  Value: 0.8524
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00046538440978086533

Model: "sequential_293"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_293 (Flatten)       (None, 784)               0         
                                                                 
 dense_1404 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1111 (Dropout)      (None, 448)               0         
                                                                 
 dense_1405 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1112 (Dropout)      (None, 512)               0         
                                                                 
 dense_1406 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_387 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1113 (Dropout)      (None, 416)               0         
                                                                 
 dense_1407 (Dense)          (None, 256)               106752    
                                                                 
 dropout_1114 (Dropout)      (None, 256)               0         
                                                                 
 dense_1408 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 910074 (3.47 MB)
Trainable params: 909242 (3.47 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 294:
  Value: 0.9177
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006065623661660782

Model: "sequential_294"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_294 (Flatten)       (None, 784)               0         
                                                                 
 dense_1409 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1115 (Dropout)      (None, 448)               0         
                                                                 
 dense_1410 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1116 (Dropout)      (None, 512)               0         
                                                                 
 dense_1411 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_388 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1117 (Dropout)      (None, 416)               0         
                                                                 
 dense_1412 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1118 (Dropout)      (None, 224)               0         
                                                                 
 dense_1413 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 895898 (3.42 MB)
Trainable params: 895066 (3.41 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 295:
  Value: 0.9174
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00062521029561809

Model: "sequential_295"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_295 (Flatten)       (None, 784)               0         
                                                                 
 dense_1414 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1119 (Dropout)      (None, 448)               0         
                                                                 
 dense_1415 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1120 (Dropout)      (None, 480)               0         
                                                                 
 dense_1416 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_389 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1121 (Dropout)      (None, 416)               0         
                                                                 
 dense_1417 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1122 (Dropout)      (None, 224)               0         
                                                                 
 dense_1418 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 868218 (3.31 MB)
Trainable params: 867386 (3.31 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 296:
  Value: 0.9214
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006462816815865512

Model: "sequential_296"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_296 (Flatten)       (None, 784)               0         
                                                                 
 dense_1419 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1123 (Dropout)      (None, 448)               0         
                                                                 
 dense_1420 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1124 (Dropout)      (None, 480)               0         
                                                                 
 dense_1421 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_390 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1125 (Dropout)      (None, 416)               0         
                                                                 
 dense_1422 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1126 (Dropout)      (None, 224)               0         
                                                                 
 dense_1423 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 868218 (3.31 MB)
Trainable params: 867386 (3.31 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 297:
  Value: 0.2538
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0006098436238258419

Model: "sequential_297"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_297 (Flatten)       (None, 784)               0         
                                                                 
 dense_1424 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_391 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1127 (Dropout)      (None, 448)               0         
                                                                 
 dense_1425 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1128 (Dropout)      (None, 480)               0         
                                                                 
 dense_1426 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_392 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1129 (Dropout)      (None, 416)               0         
                                                                 
 dense_1427 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1130 (Dropout)      (None, 224)               0         
                                                                 
 dense_1428 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 870010 (3.32 MB)
Trainable params: 868282 (3.31 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 298:
  Value: 0.9152
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006885838054603358

Model: "sequential_298"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_298 (Flatten)       (None, 784)               0         
                                                                 
 dense_1429 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1131 (Dropout)      (None, 448)               0         
                                                                 
 dense_1430 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1132 (Dropout)      (None, 480)               0         
                                                                 
 dense_1431 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_393 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1133 (Dropout)      (None, 416)               0         
                                                                 
 dense_1432 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1134 (Dropout)      (None, 224)               0         
                                                                 
 dense_1433 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 868218 (3.31 MB)
Trainable params: 867386 (3.31 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 299:
  Value: 0.8310
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006250266191769046

Model: "sequential_299"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_299 (Flatten)       (None, 784)               0         
                                                                 
 dense_1434 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1135 (Dropout)      (None, 448)               0         
                                                                 
 dense_1435 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1136 (Dropout)      (None, 480)               0         
                                                                 
 dense_1436 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_394 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1137 (Dropout)      (None, 416)               0         
                                                                 
 dense_1437 (Dense)          (None, 192)               80064     
                                                                 
 dropout_1138 (Dropout)      (None, 192)               0         
                                                                 
 dense_1438 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 854042 (3.26 MB)
Trainable params: 853210 (3.25 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 300:
  Value: 0.9187
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005740501582907798

Model: "sequential_300"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_300 (Flatten)       (None, 784)               0         
                                                                 
 dense_1439 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1139 (Dropout)      (None, 448)               0         
                                                                 
 dense_1440 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1140 (Dropout)      (None, 480)               0         
                                                                 
 dense_1441 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_395 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1141 (Dropout)      (None, 416)               0         
                                                                 
 dense_1442 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1142 (Dropout)      (None, 224)               0         
                                                                 
 dense_1443 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 868218 (3.31 MB)
Trainable params: 867386 (3.31 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 301:
  Value: 0.5303
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0005275794674656172

Model: "sequential_301"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_301 (Flatten)       (None, 784)               0         
                                                                 
 dense_1444 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1143 (Dropout)      (None, 416)               0         
                                                                 
 dense_1445 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_396 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1144 (Dropout)      (None, 480)               0         
                                                                 
 dense_1446 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_397 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1145 (Dropout)      (None, 416)               0         
                                                                 
 dense_1447 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1146 (Dropout)      (None, 224)               0         
                                                                 
 dense_1448 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 829658 (3.16 MB)
Trainable params: 827866 (3.16 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 302:
  Value: 0.9188
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005718992332226961

Model: "sequential_302"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_302 (Flatten)       (None, 784)               0         
                                                                 
 dense_1449 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1147 (Dropout)      (None, 448)               0         
                                                                 
 dense_1450 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1148 (Dropout)      (None, 480)               0         
                                                                 
 dense_1451 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_398 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1149 (Dropout)      (None, 448)               0         
                                                                 
 dense_1452 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1150 (Dropout)      (None, 192)               0         
                                                                 
 dense_1453 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 875706 (3.34 MB)
Trainable params: 874810 (3.34 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 303:
  Value: 0.9177
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005721735915058282

Model: "sequential_303"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_303 (Flatten)       (None, 784)               0         
                                                                 
 dense_1454 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1151 (Dropout)      (None, 448)               0         
                                                                 
 dense_1455 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1152 (Dropout)      (None, 480)               0         
                                                                 
 dense_1456 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_399 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1153 (Dropout)      (None, 416)               0         
                                                                 
 dense_1457 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1154 (Dropout)      (None, 224)               0         
                                                                 
 dense_1458 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 868218 (3.31 MB)
Trainable params: 867386 (3.31 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 304:
  Value: 0.9180
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005908368036270308

Model: "sequential_304"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_304 (Flatten)       (None, 784)               0         
                                                                 
 dense_1459 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1155 (Dropout)      (None, 448)               0         
                                                                 
 dense_1460 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1156 (Dropout)      (None, 480)               0         
                                                                 
 dense_1461 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_400 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1157 (Dropout)      (None, 448)               0         
                                                                 
 dense_1462 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1158 (Dropout)      (None, 224)               0         
                                                                 
 dense_1463 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 890906 (3.40 MB)
Trainable params: 890010 (3.40 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 305:
  Value: 0.9174
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005576769704882555

Model: "sequential_305"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_305 (Flatten)       (None, 784)               0         
                                                                 
 dense_1464 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1159 (Dropout)      (None, 448)               0         
                                                                 
 dense_1465 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1160 (Dropout)      (None, 480)               0         
                                                                 
 dense_1466 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_401 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1161 (Dropout)      (None, 448)               0         
                                                                 
 dense_1467 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1162 (Dropout)      (None, 192)               0         
                                                                 
 dense_1468 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 875706 (3.34 MB)
Trainable params: 874810 (3.34 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 306:
  Value: 0.9185
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005999754540280953

Model: "sequential_306"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_306 (Flatten)       (None, 784)               0         
                                                                 
 dense_1469 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1163 (Dropout)      (None, 448)               0         
                                                                 
 dense_1470 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1164 (Dropout)      (None, 480)               0         
                                                                 
 dense_1471 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_402 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1165 (Dropout)      (None, 448)               0         
                                                                 
 dense_1472 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1166 (Dropout)      (None, 192)               0         
                                                                 
 dense_1473 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 875706 (3.34 MB)
Trainable params: 874810 (3.34 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 307:
  Value: 0.9112
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000571134864463215

Model: "sequential_307"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_307 (Flatten)       (None, 784)               0         
                                                                 
 dense_1474 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1167 (Dropout)      (None, 448)               0         
                                                                 
 dense_1475 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1168 (Dropout)      (None, 480)               0         
                                                                 
 dense_1476 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_403 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1169 (Dropout)      (None, 448)               0         
                                                                 
 dense_1477 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1170 (Dropout)      (None, 192)               0         
                                                                 
 dense_1478 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 875706 (3.34 MB)
Trainable params: 874810 (3.34 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 308:
  Value: 0.9184
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007299894293729102

Model: "sequential_308"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_308 (Flatten)       (None, 784)               0         
                                                                 
 dense_1479 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1171 (Dropout)      (None, 448)               0         
                                                                 
 dense_1480 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1172 (Dropout)      (None, 480)               0         
                                                                 
 dense_1481 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_404 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1173 (Dropout)      (None, 448)               0         
                                                                 
 dense_1482 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1174 (Dropout)      (None, 224)               0         
                                                                 
 dense_1483 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 890906 (3.40 MB)
Trainable params: 890010 (3.40 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 309:
  Value: 0.7736
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 160
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000684319767524801

Model: "sequential_309"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_309 (Flatten)       (None, 784)               0         
                                                                 
 dense_1484 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1175 (Dropout)      (None, 448)               0         
                                                                 
 dense_1485 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1176 (Dropout)      (None, 480)               0         
                                                                 
 dense_1486 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_405 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1177 (Dropout)      (None, 448)               0         
                                                                 
 dense_1487 (Dense)          (None, 160)               71840     
                                                                 
 dropout_1178 (Dropout)      (None, 160)               0         
                                                                 
 dense_1488 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 860506 (3.28 MB)
Trainable params: 859610 (3.28 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 310:
  Value: 0.9181
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007724287345289214

Model: "sequential_310"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_310 (Flatten)       (None, 784)               0         
                                                                 
 dense_1489 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1179 (Dropout)      (None, 416)               0         
                                                                 
 dense_1490 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1180 (Dropout)      (None, 480)               0         
                                                                 
 dense_1491 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_406 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1181 (Dropout)      (None, 448)               0         
                                                                 
 dense_1492 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1182 (Dropout)      (None, 192)               0         
                                                                 
 dense_1493 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 835226 (3.19 MB)
Trainable params: 834330 (3.18 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 311:
  Value: 0.8696
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00077697911728413

Model: "sequential_311"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_311 (Flatten)       (None, 784)               0         
                                                                 
 dense_1494 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1183 (Dropout)      (None, 416)               0         
                                                                 
 dense_1495 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1184 (Dropout)      (None, 480)               0         
                                                                 
 dense_1496 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_407 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1185 (Dropout)      (None, 448)               0         
                                                                 
 dense_1497 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1186 (Dropout)      (None, 192)               0         
                                                                 
 dense_1498 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 835226 (3.19 MB)
Trainable params: 834330 (3.18 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 312:
  Value: 0.0385
  num_layers: 4
  units_0: 384
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.4
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0006374005383997998

Model: "sequential_312"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_312 (Flatten)       (None, 784)               0         
                                                                 
 dense_1499 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1187 (Dropout)      (None, 384)               0         
                                                                 
 dense_1500 (Dense)          (None, 480)               184800    
                                                                 
 dropout_1188 (Dropout)      (None, 480)               0         
                                                                 
 dense_1501 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_408 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1189 (Dropout)      (None, 448)               0         
                                                                 
 dense_1502 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1190 (Dropout)      (None, 192)               0         
                                                                 
 dense_1503 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 794746 (3.03 MB)
Trainable params: 793850 (3.03 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 313:
  Value: 0.8153
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0007451410828221121

Model: "sequential_313"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_313 (Flatten)       (None, 784)               0         
                                                                 
 dense_1504 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1191 (Dropout)      (None, 416)               0         
                                                                 
 dense_1505 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1192 (Dropout)      (None, 480)               0         
                                                                 
 dense_1506 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_409 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1193 (Dropout)      (None, 480)               0         
                                                                 
 dense_1507 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1194 (Dropout)      (None, 224)               0         
                                                                 
 dense_1508 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 873114 (3.33 MB)
Trainable params: 872154 (3.33 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 314:
  Value: 0.9190
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006888569030237056

Model: "sequential_314"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_314 (Flatten)       (None, 784)               0         
                                                                 
 dense_1509 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1195 (Dropout)      (None, 416)               0         
                                                                 
 dense_1510 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1196 (Dropout)      (None, 480)               0         
                                                                 
 dense_1511 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_410 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1197 (Dropout)      (None, 448)               0         
                                                                 
 dense_1512 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1198 (Dropout)      (None, 192)               0         
                                                                 
 dense_1513 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 835226 (3.19 MB)
Trainable params: 834330 (3.18 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 315:
  Value: 0.8104
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 160
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000689051277571723

Model: "sequential_315"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_315 (Flatten)       (None, 784)               0         
                                                                 
 dense_1514 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1199 (Dropout)      (None, 416)               0         
                                                                 
 dense_1515 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1200 (Dropout)      (None, 480)               0         
                                                                 
 dense_1516 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1201 (Dropout)      (None, 448)               0         
                                                                 
 dense_1517 (Dense)          (None, 160)               71840     
                                                                 
 dropout_1202 (Dropout)      (None, 160)               0         
                                                                 
 dense_1518 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 818234 (3.12 MB)
Trainable params: 818234 (3.12 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 316:
  Value: 0.0377
  num_layers: 4
  units_0: 384
  units_1: 448
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0005048843008429112

Model: "sequential_316"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_316 (Flatten)       (None, 784)               0         
                                                                 
 dense_1519 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1203 (Dropout)      (None, 384)               0         
                                                                 
 dense_1520 (Dense)          (None, 448)               172480    
                                                                 
 dropout_1204 (Dropout)      (None, 448)               0         
                                                                 
 dense_1521 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_411 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1205 (Dropout)      (None, 448)               0         
                                                                 
 dense_1522 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1206 (Dropout)      (None, 192)               0         
                                                                 
 dense_1523 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 768090 (2.93 MB)
Trainable params: 767194 (2.93 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 317:
  Value: 0.7134
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 480
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.0
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007765055694364214

Model: "sequential_317"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_317 (Flatten)       (None, 784)               0         
                                                                 
 dense_1524 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1207 (Dropout)      (None, 416)               0         
                                                                 
 dense_1525 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1208 (Dropout)      (None, 480)               0         
                                                                 
 dense_1526 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_412 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1209 (Dropout)      (None, 480)               0         
                                                                 
 dense_1527 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1210 (Dropout)      (None, 192)               0         
                                                                 
 dense_1528 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 856890 (3.27 MB)
Trainable params: 855930 (3.27 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 318:
  Value: 0.8483
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007239989199505443

Model: "sequential_318"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_318 (Flatten)       (None, 784)               0         
                                                                 
 dense_1529 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1211 (Dropout)      (None, 416)               0         
                                                                 
 dense_1530 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1212 (Dropout)      (None, 480)               0         
                                                                 
 dense_1531 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_413 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1213 (Dropout)      (None, 448)               0         
                                                                 
 dense_1532 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1214 (Dropout)      (None, 192)               0         
                                                                 
 dense_1533 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 835226 (3.19 MB)
Trainable params: 834330 (3.18 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 319:
  Value: 0.8212
  num_layers: 4
  units_0: 384
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006694492192569122

Model: "sequential_319"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_319 (Flatten)       (None, 784)               0         
                                                                 
 dense_1534 (Dense)          (None, 384)               301440    
                                                                 
 batch_normalization_414 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1215 (Dropout)      (None, 384)               0         
                                                                 
 dense_1535 (Dense)          (None, 480)               184800    
                                                                 
 dropout_1216 (Dropout)      (None, 480)               0         
                                                                 
 dense_1536 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_415 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1217 (Dropout)      (None, 448)               0         
                                                                 
 dense_1537 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1218 (Dropout)      (None, 192)               0         
                                                                 
 dense_1538 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 796282 (3.04 MB)
Trainable params: 794618 (3.03 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 320:
  Value: 0.4613
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005781418537026221

Model: "sequential_320"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_320 (Flatten)       (None, 784)               0         
                                                                 
 dense_1539 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1219 (Dropout)      (None, 416)               0         
                                                                 
 dense_1540 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_416 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1220 (Dropout)      (None, 480)               0         
                                                                 
 dense_1541 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_417 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1221 (Dropout)      (None, 448)               0         
                                                                 
 dense_1542 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1222 (Dropout)      (None, 224)               0         
                                                                 
 dense_1543 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 852346 (3.25 MB)
Trainable params: 850490 (3.24 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 321:
  Value: 0.8796
  num_layers: 4
  units_0: 416
  units_1: 448
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006611630478109812

Model: "sequential_321"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_321 (Flatten)       (None, 784)               0         
                                                                 
 dense_1544 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1223 (Dropout)      (None, 416)               0         
                                                                 
 dense_1545 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1224 (Dropout)      (None, 448)               0         
                                                                 
 dense_1546 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_418 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1225 (Dropout)      (None, 448)               0         
                                                                 
 dense_1547 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1226 (Dropout)      (None, 192)               0         
                                                                 
 dense_1548 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 807546 (3.08 MB)
Trainable params: 806650 (3.08 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 322:
  Value: 0.8284
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 480
  units_3: 160
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008227608345143094

Model: "sequential_322"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_322 (Flatten)       (None, 784)               0         
                                                                 
 dense_1549 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1227 (Dropout)      (None, 448)               0         
                                                                 
 dense_1550 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1228 (Dropout)      (None, 480)               0         
                                                                 
 dense_1551 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_419 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1229 (Dropout)      (None, 480)               0         
                                                                 
 dense_1552 (Dense)          (None, 160)               76960     
                                                                 
 dropout_1230 (Dropout)      (None, 160)               0         
                                                                 
 dense_1553 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 881146 (3.36 MB)
Trainable params: 880186 (3.36 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 323:
  Value: 0.9197
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008252415674990609

Model: "sequential_323"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_323 (Flatten)       (None, 784)               0         
                                                                 
 dense_1554 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1231 (Dropout)      (None, 416)               0         
                                                                 
 dense_1555 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1232 (Dropout)      (None, 480)               0         
                                                                 
 dense_1556 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_420 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1233 (Dropout)      (None, 448)               0         
                                                                 
 dense_1557 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1234 (Dropout)      (None, 224)               0         
                                                                 
 dense_1558 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 850426 (3.24 MB)
Trainable params: 849530 (3.24 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 324:
  Value: 0.8862
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005865866278486905

Model: "sequential_324"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_324 (Flatten)       (None, 784)               0         
                                                                 
 dense_1559 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1235 (Dropout)      (None, 416)               0         
                                                                 
 dense_1560 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1236 (Dropout)      (None, 480)               0         
                                                                 
 dense_1561 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_421 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1237 (Dropout)      (None, 448)               0         
                                                                 
 dense_1562 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1238 (Dropout)      (None, 224)               0         
                                                                 
 dense_1563 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 850426 (3.24 MB)
Trainable params: 849530 (3.24 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 325:
  Value: 0.7911
  num_layers: 4
  units_0: 384
  units_1: 32
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008580069072960998

Model: "sequential_325"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_325 (Flatten)       (None, 784)               0         
                                                                 
 dense_1564 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1239 (Dropout)      (None, 384)               0         
                                                                 
 dense_1565 (Dense)          (None, 32)                12320     
                                                                 
 dropout_1240 (Dropout)      (None, 32)                0         
                                                                 
 dense_1566 (Dense)          (None, 448)               14784     
                                                                 
 batch_normalization_422 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1241 (Dropout)      (None, 448)               0         
                                                                 
 dense_1567 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1242 (Dropout)      (None, 224)               0         
                                                                 
 dense_1568 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 436762 (1.67 MB)
Trainable params: 435866 (1.66 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 326:
  Value: 0.0742
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0005301758489396799

Model: "sequential_326"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_326 (Flatten)       (None, 784)               0         
                                                                 
 dense_1569 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1243 (Dropout)      (None, 416)               0         
                                                                 
 dense_1570 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1244 (Dropout)      (None, 480)               0         
                                                                 
 dense_1571 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_423 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1245 (Dropout)      (None, 448)               0         
                                                                 
 dense_1572 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1246 (Dropout)      (None, 192)               0         
                                                                 
 dense_1573 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 835226 (3.19 MB)
Trainable params: 834330 (3.18 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 327:
  Value: 0.7732
  num_layers: 4
  units_0: 96
  units_1: 448
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006969545044789918

Model: "sequential_327"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_327 (Flatten)       (None, 784)               0         
                                                                 
 dense_1574 (Dense)          (None, 96)                75360     
                                                                 
 dropout_1247 (Dropout)      (None, 96)                0         
                                                                 
 dense_1575 (Dense)          (None, 448)               43456     
                                                                 
 dropout_1248 (Dropout)      (None, 448)               0         
                                                                 
 dense_1576 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_424 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1249 (Dropout)      (None, 448)               0         
                                                                 
 dense_1577 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1250 (Dropout)      (None, 224)               0         
                                                                 
 dense_1578 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 428186 (1.63 MB)
Trainable params: 427290 (1.63 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 328:
  Value: 0.9179
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 448
  units_3: 160
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008770540147924388

Model: "sequential_328"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_328 (Flatten)       (None, 784)               0         
                                                                 
 dense_1579 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1251 (Dropout)      (None, 416)               0         
                                                                 
 dense_1580 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1252 (Dropout)      (None, 480)               0         
                                                                 
 dense_1581 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_425 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1253 (Dropout)      (None, 448)               0         
                                                                 
 dense_1582 (Dense)          (None, 160)               71840     
                                                                 
 dropout_1254 (Dropout)      (None, 160)               0         
                                                                 
 dense_1583 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 820026 (3.13 MB)
Trainable params: 819130 (3.12 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 329:
  Value: 0.7643
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 480
  units_3: 128
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008465848529214992

Model: "sequential_329"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_329 (Flatten)       (None, 784)               0         
                                                                 
 dense_1584 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1255 (Dropout)      (None, 416)               0         
                                                                 
 dense_1585 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1256 (Dropout)      (None, 480)               0         
                                                                 
 dense_1586 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_426 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1257 (Dropout)      (None, 480)               0         
                                                                 
 dense_1587 (Dense)          (None, 128)               61568     
                                                                 
 dropout_1258 (Dropout)      (None, 128)               0         
                                                                 
 dense_1588 (Dense)          (None, 26)                3354      
                                                                 
=================================================================
Total params: 824442 (3.14 MB)
Trainable params: 823482 (3.14 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 330:
  Value: 0.9124
  num_layers: 4
  units_0: 416
  units_1: 448
  units_2: 448
  units_3: 160
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.1
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007843196638970924

Model: "sequential_330"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_330 (Flatten)       (None, 784)               0         
                                                                 
 dense_1589 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1259 (Dropout)      (None, 416)               0         
                                                                 
 dense_1590 (Dense)          (None, 448)               186816    
                                                                 
 dropout_1260 (Dropout)      (None, 448)               0         
                                                                 
 dense_1591 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_427 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1261 (Dropout)      (None, 448)               0         
                                                                 
 dense_1592 (Dense)          (None, 160)               71840     
                                                                 
 dropout_1262 (Dropout)      (None, 160)               0         
                                                                 
 dense_1593 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 792346 (3.02 MB)
Trainable params: 791450 (3.02 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 331:
  Value: 0.7987
  num_layers: 3
  units_0: 416
  units_1: 480
  units_2: 448
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.2
  dropout_1: 0.1
  dropout_2: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adamax
  learning_rate: 0.0007314172274072012

Model: "sequential_331"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_331 (Flatten)       (None, 784)               0         
                                                                 
 dense_1594 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1263 (Dropout)      (None, 416)               0         
                                                                 
 dense_1595 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1264 (Dropout)      (None, 480)               0         
                                                                 
 dense_1596 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_428 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1265 (Dropout)      (None, 448)               0         
                                                                 
 dense_1597 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 755674 (2.88 MB)
Trainable params: 754778 (2.88 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 332:
  Value: 0.9170
  num_layers: 4
  units_0: 384
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006302403668733567

Model: "sequential_332"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_332 (Flatten)       (None, 784)               0         
                                                                 
 dense_1598 (Dense)          (None, 384)               301440    
                                                                 
 dropout_1266 (Dropout)      (None, 384)               0         
                                                                 
 dense_1599 (Dense)          (None, 480)               184800    
                                                                 
 dropout_1267 (Dropout)      (None, 480)               0         
                                                                 
 dense_1600 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_429 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1268 (Dropout)      (None, 448)               0         
                                                                 
 dense_1601 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1269 (Dropout)      (None, 224)               0         
                                                                 
 dense_1602 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 809946 (3.09 MB)
Trainable params: 809050 (3.09 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 333:
  Value: 0.8171
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 480
  units_3: 160
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009100668278763272

Model: "sequential_333"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_333 (Flatten)       (None, 784)               0         
                                                                 
 dense_1603 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1270 (Dropout)      (None, 448)               0         
                                                                 
 dense_1604 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1271 (Dropout)      (None, 480)               0         
                                                                 
 dense_1605 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1272 (Dropout)      (None, 480)               0         
                                                                 
 dense_1606 (Dense)          (None, 160)               76960     
                                                                 
 dropout_1273 (Dropout)      (None, 160)               0         
                                                                 
 dense_1607 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 879226 (3.35 MB)
Trainable params: 879226 (3.35 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 334:
  Value: 0.8506
  num_layers: 4
  units_0: 352
  units_1: 480
  units_2: 448
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.2
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004981903801243747

Model: "sequential_334"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_334 (Flatten)       (None, 784)               0         
                                                                 
 dense_1608 (Dense)          (None, 352)               276320    
                                                                 
 dropout_1274 (Dropout)      (None, 352)               0         
                                                                 
 dense_1609 (Dense)          (None, 480)               169440    
                                                                 
 dropout_1275 (Dropout)      (None, 480)               0         
                                                                 
 dense_1610 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_430 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1276 (Dropout)      (None, 448)               0         
                                                                 
 dense_1611 (Dense)          (None, 192)               86208     
                                                                 
 dropout_1277 (Dropout)      (None, 192)               0         
                                                                 
 dense_1612 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 754266 (2.88 MB)
Trainable params: 753370 (2.87 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 335:
  Value: 0.8958
  num_layers: 4
  units_0: 416
  units_1: 480
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009072275554527139

Model: "sequential_335"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_335 (Flatten)       (None, 784)               0         
                                                                 
 dense_1613 (Dense)          (None, 416)               326560    
                                                                 
 dropout_1278 (Dropout)      (None, 416)               0         
                                                                 
 dense_1614 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1279 (Dropout)      (None, 480)               0         
                                                                 
 dense_1615 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_431 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1280 (Dropout)      (None, 480)               0         
                                                                 
 dense_1616 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1281 (Dropout)      (None, 224)               0         
                                                                 
 dense_1617 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 873114 (3.33 MB)
Trainable params: 872154 (3.33 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 336:
  Value: 0.9195
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 448
  units_3: 128
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006709936509117102

Model: "sequential_336"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_336 (Flatten)       (None, 784)               0         
                                                                 
 dense_1618 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1282 (Dropout)      (None, 448)               0         
                                                                 
 dense_1619 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1283 (Dropout)      (None, 448)               0         
                                                                 
 dense_1620 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_432 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1284 (Dropout)      (None, 448)               0         
                                                                 
 dense_1621 (Dense)          (None, 128)               57472     
                                                                 
 dropout_1285 (Dropout)      (None, 128)               0         
                                                                 
 dense_1622 (Dense)          (None, 26)                3354      
                                                                 
=================================================================
Total params: 816602 (3.12 MB)
Trainable params: 815706 (3.11 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 337:
  Value: 0.9154
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 192
  units_3: 128
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006409877344390977

Model: "sequential_337"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_337 (Flatten)       (None, 784)               0         
                                                                 
 dense_1623 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1286 (Dropout)      (None, 448)               0         
                                                                 
 dense_1624 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1287 (Dropout)      (None, 448)               0         
                                                                 
 dense_1625 (Dense)          (None, 192)               86208     
                                                                 
 batch_normalization_433 (B  (None, 192)               768       
 atchNormalization)                                              
                                                                 
 dropout_1288 (Dropout)      (None, 192)               0         
                                                                 
 dense_1626 (Dense)          (None, 128)               24704     
                                                                 
 dropout_1289 (Dropout)      (None, 128)               0         
                                                                 
 dense_1627 (Dense)          (None, 26)                3354      
                                                                 
=================================================================
Total params: 667866 (2.55 MB)
Trainable params: 667482 (2.55 MB)
Non-trainable params: 384 (1.50 KB)
_________________________________________________________________



Trial 338:
  Value: 0.8110
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005748614449318937

Model: "sequential_338"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_338 (Flatten)       (None, 784)               0         
                                                                 
 dense_1628 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_434 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1290 (Dropout)      (None, 448)               0         
                                                                 
 dense_1629 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1291 (Dropout)      (None, 480)               0         
                                                                 
 dense_1630 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_435 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1292 (Dropout)      (None, 448)               0         
                                                                 
 dense_1631 (Dense)          (None, 256)               114944    
                                                                 
 dropout_1293 (Dropout)      (None, 256)               0         
                                                                 
 dense_1632 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 907898 (3.46 MB)
Trainable params: 906106 (3.46 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 339:
  Value: 0.8535
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 480
  units_3: 64
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000707751009458057

Model: "sequential_339"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_339 (Flatten)       (None, 784)               0         
                                                                 
 dense_1633 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1294 (Dropout)      (None, 448)               0         
                                                                 
 dense_1634 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1295 (Dropout)      (None, 448)               0         
                                                                 
 dense_1635 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_436 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1296 (Dropout)      (None, 480)               0         
                                                                 
 dense_1636 (Dense)          (None, 64)                30784     
                                                                 
 dropout_1297 (Dropout)      (None, 64)                0         
                                                                 
 dense_1637 (Dense)          (None, 26)                1690      
                                                                 
=================================================================
Total params: 802746 (3.06 MB)
Trainable params: 801786 (3.06 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 340:
  Value: 0.0395
  num_layers: 4
  units_0: 192
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0005463994150705068

Model: "sequential_340"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_340 (Flatten)       (None, 784)               0         
                                                                 
 dense_1638 (Dense)          (None, 192)               150720    
                                                                 
 dropout_1298 (Dropout)      (None, 192)               0         
                                                                 
 dense_1639 (Dense)          (None, 480)               92640     
                                                                 
 dropout_1299 (Dropout)      (None, 480)               0         
                                                                 
 dense_1640 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_437 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1300 (Dropout)      (None, 448)               0         
                                                                 
 dense_1641 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1301 (Dropout)      (None, 224)               0         
                                                                 
 dense_1642 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 567066 (2.16 MB)
Trainable params: 566170 (2.16 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 341:
  Value: 0.6358
  num_layers: 2
  units_0: 448
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.4
  dropout_1: 0.0
  batch_norm_0: False
  batch_norm_1: True
  optimizer: adam
  learning_rate: 0.0006453434221115973

Model: "sequential_341"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_341 (Flatten)       (None, 784)               0         
                                                                 
 dense_1643 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1302 (Dropout)      (None, 448)               0         
                                                                 
 dense_1644 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_438 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1303 (Dropout)      (None, 480)               0         
                                                                 
 dense_1645 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 581626 (2.22 MB)
Trainable params: 580666 (2.22 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 342:
  Value: 0.9171
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 96
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007454578406994612

Model: "sequential_342"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_342 (Flatten)       (None, 784)               0         
                                                                 
 dense_1646 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1304 (Dropout)      (None, 448)               0         
                                                                 
 dense_1647 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1305 (Dropout)      (None, 512)               0         
                                                                 
 dense_1648 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_439 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1306 (Dropout)      (None, 416)               0         
                                                                 
 dense_1649 (Dense)          (None, 96)                40032     
                                                                 
 dropout_1307 (Dropout)      (None, 96)                0         
                                                                 
 dense_1650 (Dense)          (None, 26)                2522      
                                                                 
=================================================================
Total params: 839194 (3.20 MB)
Trainable params: 838362 (3.20 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 343:
  Value: 0.0373
  num_layers: 4
  units_0: 448
  units_1: 512
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0004691222924534543

Model: "sequential_343"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_343 (Flatten)       (None, 784)               0         
                                                                 
 dense_1651 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1308 (Dropout)      (None, 448)               0         
                                                                 
 dense_1652 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1309 (Dropout)      (None, 512)               0         
                                                                 
 dense_1653 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_440 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1310 (Dropout)      (None, 416)               0         
                                                                 
 dense_1654 (Dense)          (None, 256)               106752    
                                                                 
 dropout_1311 (Dropout)      (None, 256)               0         
                                                                 
 dense_1655 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 910074 (3.47 MB)
Trainable params: 909242 (3.47 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 344:
  Value: 0.8078
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0005805204002870165

Model: "sequential_344"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_344 (Flatten)       (None, 784)               0         
                                                                 
 dense_1656 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1312 (Dropout)      (None, 448)               0         
                                                                 
 dense_1657 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1313 (Dropout)      (None, 448)               0         
                                                                 
 dense_1658 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_441 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1314 (Dropout)      (None, 448)               0         
                                                                 
 dense_1659 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1315 (Dropout)      (None, 224)               0         
                                                                 
 dense_1660 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 862202 (3.29 MB)
Trainable params: 861306 (3.29 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 345:
  Value: 0.9230
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005357248955414288

Model: "sequential_345"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_345 (Flatten)       (None, 784)               0         
                                                                 
 dense_1661 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1316 (Dropout)      (None, 480)               0         
                                                                 
 dense_1662 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1317 (Dropout)      (None, 480)               0         
                                                                 
 dense_1663 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_442 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1318 (Dropout)      (None, 448)               0         
                                                                 
 dense_1664 (Dense)          (None, 256)               114944    
                                                                 
 dropout_1319 (Dropout)      (None, 256)               0         
                                                                 
 dense_1665 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 946586 (3.61 MB)
Trainable params: 945690 (3.61 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 346:
  Value: 0.8050
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005204739396572214

Model: "sequential_346"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_346 (Flatten)       (None, 784)               0         
                                                                 
 dense_1666 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1320 (Dropout)      (None, 480)               0         
                                                                 
 dense_1667 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1321 (Dropout)      (None, 480)               0         
                                                                 
 dense_1668 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_443 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1322 (Dropout)      (None, 448)               0         
                                                                 
 dense_1669 (Dense)          (None, 256)               114944    
                                                                 
 dropout_1323 (Dropout)      (None, 256)               0         
                                                                 
 dense_1670 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 946586 (3.61 MB)
Trainable params: 945690 (3.61 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 347:
  Value: 0.8486
  num_layers: 4
  units_0: 288
  units_1: 480
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00048242661349330975

Model: "sequential_347"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_347 (Flatten)       (None, 784)               0         
                                                                 
 dense_1671 (Dense)          (None, 288)               226080    
                                                                 
 dropout_1324 (Dropout)      (None, 288)               0         
                                                                 
 dense_1672 (Dense)          (None, 480)               138720    
                                                                 
 dropout_1325 (Dropout)      (None, 480)               0         
                                                                 
 dense_1673 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_444 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1326 (Dropout)      (None, 448)               0         
                                                                 
 dense_1674 (Dense)          (None, 256)               114944    
                                                                 
 dropout_1327 (Dropout)      (None, 256)               0         
                                                                 
 dense_1675 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 703706 (2.68 MB)
Trainable params: 702810 (2.68 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 348:
  Value: 0.9192
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005993092334081453

Model: "sequential_348"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_348 (Flatten)       (None, 784)               0         
                                                                 
 dense_1676 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1328 (Dropout)      (None, 480)               0         
                                                                 
 dense_1677 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1329 (Dropout)      (None, 480)               0         
                                                                 
 dense_1678 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_445 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1330 (Dropout)      (None, 448)               0         
                                                                 
 dense_1679 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1331 (Dropout)      (None, 224)               0         
                                                                 
 dense_1680 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 931386 (3.55 MB)
Trainable params: 930490 (3.55 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 349:
  Value: 0.8512
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 64
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006178813428742319

Model: "sequential_349"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_349 (Flatten)       (None, 784)               0         
                                                                 
 dense_1681 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1332 (Dropout)      (None, 480)               0         
                                                                 
 dense_1682 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1333 (Dropout)      (None, 480)               0         
                                                                 
 dense_1683 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_446 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1334 (Dropout)      (None, 448)               0         
                                                                 
 dense_1684 (Dense)          (None, 64)                28736     
                                                                 
 dropout_1335 (Dropout)      (None, 64)                0         
                                                                 
 dense_1685 (Dense)          (None, 26)                1690      
                                                                 
=================================================================
Total params: 855386 (3.26 MB)
Trainable params: 854490 (3.26 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 350:
  Value: 0.7781
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 224
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.1
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006853323676950645

Model: "sequential_350"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_350 (Flatten)       (None, 784)               0         
                                                                 
 dense_1686 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1336 (Dropout)      (None, 480)               0         
                                                                 
 dense_1687 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1337 (Dropout)      (None, 448)               0         
                                                                 
 dense_1688 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_447 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1338 (Dropout)      (None, 480)               0         
                                                                 
 dense_1689 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1339 (Dropout)      (None, 224)               0         
                                                                 
 dense_1690 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 923322 (3.52 MB)
Trainable params: 922362 (3.52 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 351:
  Value: 0.9184
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005246642485685837

Model: "sequential_351"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_351 (Flatten)       (None, 784)               0         
                                                                 
 dense_1691 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1340 (Dropout)      (None, 480)               0         
                                                                 
 dense_1692 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1341 (Dropout)      (None, 480)               0         
                                                                 
 dense_1693 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_448 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1342 (Dropout)      (None, 448)               0         
                                                                 
 dense_1694 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1343 (Dropout)      (None, 224)               0         
                                                                 
 dense_1695 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 931386 (3.55 MB)
Trainable params: 930490 (3.55 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 352:
  Value: 0.9122
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005335411165842648

Model: "sequential_352"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_352 (Flatten)       (None, 784)               0         
                                                                 
 dense_1696 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1344 (Dropout)      (None, 480)               0         
                                                                 
 dense_1697 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1345 (Dropout)      (None, 480)               0         
                                                                 
 dense_1698 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_449 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1346 (Dropout)      (None, 448)               0         
                                                                 
 dense_1699 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1347 (Dropout)      (None, 224)               0         
                                                                 
 dense_1700 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 931386 (3.55 MB)
Trainable params: 930490 (3.55 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 353:
  Value: 0.9178
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000598603695261062

Model: "sequential_353"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_353 (Flatten)       (None, 784)               0         
                                                                 
 dense_1701 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1348 (Dropout)      (None, 480)               0         
                                                                 
 dense_1702 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1349 (Dropout)      (None, 480)               0         
                                                                 
 dense_1703 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_450 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1350 (Dropout)      (None, 448)               0         
                                                                 
 dense_1704 (Dense)          (None, 224)               100576    
                                                                 
 dropout_1351 (Dropout)      (None, 224)               0         
                                                                 
 dense_1705 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 931386 (3.55 MB)
Trainable params: 930490 (3.55 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 354:
  Value: 0.8206
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 416
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005527047944895746

Model: "sequential_354"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_354 (Flatten)       (None, 784)               0         
                                                                 
 dense_1706 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1352 (Dropout)      (None, 480)               0         
                                                                 
 dense_1707 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1353 (Dropout)      (None, 480)               0         
                                                                 
 dense_1708 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1354 (Dropout)      (None, 416)               0         
                                                                 
 dense_1709 (Dense)          (None, 224)               93408     
                                                                 
 dropout_1355 (Dropout)      (None, 224)               0         
                                                                 
 dense_1710 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 907034 (3.46 MB)
Trainable params: 907034 (3.46 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 355:
  Value: 0.0559
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0006552439760610327

Model: "sequential_355"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_355 (Flatten)       (None, 784)               0         
                                                                 
 dense_1711 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1356 (Dropout)      (None, 480)               0         
                                                                 
 dense_1712 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1357 (Dropout)      (None, 448)               0         
                                                                 
 dense_1713 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_451 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1358 (Dropout)      (None, 448)               0         
                                                                 
 dense_1714 (Dense)          (None, 256)               114944    
                                                                 
 dropout_1359 (Dropout)      (None, 256)               0         
                                                                 
 dense_1715 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 916858 (3.50 MB)
Trainable params: 915962 (3.49 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 356:
  Value: 0.9200
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004535030324670337

Model: "sequential_356"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_356 (Flatten)       (None, 784)               0         
                                                                 
 dense_1716 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1360 (Dropout)      (None, 480)               0         
                                                                 
 dense_1717 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1361 (Dropout)      (None, 480)               0         
                                                                 
 dense_1718 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_452 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1362 (Dropout)      (None, 480)               0         
                                                                 
 dense_1719 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1363 (Dropout)      (None, 192)               0         
                                                                 
 dense_1720 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 937850 (3.58 MB)
Trainable params: 936890 (3.57 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 357:
  Value: 0.9203
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00046494332659425186

Model: "sequential_357"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_357 (Flatten)       (None, 784)               0         
                                                                 
 dense_1721 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1364 (Dropout)      (None, 480)               0         
                                                                 
 dense_1722 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1365 (Dropout)      (None, 480)               0         
                                                                 
 dense_1723 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_453 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1366 (Dropout)      (None, 512)               0         
                                                                 
 dense_1724 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1367 (Dropout)      (None, 192)               0         
                                                                 
 dense_1725 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 959514 (3.66 MB)
Trainable params: 958490 (3.66 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 358:
  Value: 0.8530
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.4
  dropout_3: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004540867377607485

Model: "sequential_358"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_358 (Flatten)       (None, 784)               0         
                                                                 
 dense_1726 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_454 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1368 (Dropout)      (None, 480)               0         
                                                                 
 dense_1727 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1369 (Dropout)      (None, 480)               0         
                                                                 
 dense_1728 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_455 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1370 (Dropout)      (None, 480)               0         
                                                                 
 dense_1729 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1371 (Dropout)      (None, 192)               0         
                                                                 
 dense_1730 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 939770 (3.58 MB)
Trainable params: 937850 (3.58 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 359:
  Value: 0.9205
  num_layers: 4
  units_0: 480
  units_1: 192
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000493639389567805

Model: "sequential_359"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_359 (Flatten)       (None, 784)               0         
                                                                 
 dense_1731 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1372 (Dropout)      (None, 480)               0         
                                                                 
 dense_1732 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1373 (Dropout)      (None, 192)               0         
                                                                 
 dense_1733 (Dense)          (None, 512)               98816     
                                                                 
 batch_normalization_456 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1374 (Dropout)      (None, 512)               0         
                                                                 
 dense_1734 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1375 (Dropout)      (None, 192)               0         
                                                                 
 dense_1735 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 673530 (2.57 MB)
Trainable params: 672506 (2.57 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 360:
  Value: 0.7400
  num_layers: 4
  units_0: 480
  units_1: 128
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0005003916910500634

Model: "sequential_360"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_360 (Flatten)       (None, 784)               0         
                                                                 
 dense_1736 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1376 (Dropout)      (None, 480)               0         
                                                                 
 dense_1737 (Dense)          (None, 128)               61568     
                                                                 
 dropout_1377 (Dropout)      (None, 128)               0         
                                                                 
 dense_1738 (Dense)          (None, 512)               66048     
                                                                 
 batch_normalization_457 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1378 (Dropout)      (None, 512)               0         
                                                                 
 dense_1739 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1379 (Dropout)      (None, 192)               0         
                                                                 
 dense_1740 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 609978 (2.33 MB)
Trainable params: 608954 (2.32 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 361:
  Value: 0.6838
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00044190344886437454

Model: "sequential_361"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_361 (Flatten)       (None, 784)               0         
                                                                 
 dense_1741 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1380 (Dropout)      (None, 480)               0         
                                                                 
 dense_1742 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_458 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1381 (Dropout)      (None, 448)               0         
                                                                 
 dense_1743 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_459 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1382 (Dropout)      (None, 512)               0         
                                                                 
 dense_1744 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1383 (Dropout)      (None, 192)               0         
                                                                 
 dense_1745 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 929530 (3.55 MB)
Trainable params: 927610 (3.54 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 362:
  Value: 0.8532
  num_layers: 4
  units_0: 480
  units_1: 160
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005002236879669776

Model: "sequential_362"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_362 (Flatten)       (None, 784)               0         
                                                                 
 dense_1746 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1384 (Dropout)      (None, 480)               0         
                                                                 
 dense_1747 (Dense)          (None, 160)               76960     
                                                                 
 dropout_1385 (Dropout)      (None, 160)               0         
                                                                 
 dense_1748 (Dense)          (None, 512)               82432     
                                                                 
 batch_normalization_460 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1386 (Dropout)      (None, 512)               0         
                                                                 
 dense_1749 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1387 (Dropout)      (None, 192)               0         
                                                                 
 dense_1750 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 641754 (2.45 MB)
Trainable params: 640730 (2.44 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 363:
  Value: 0.8201
  num_layers: 4
  units_0: 256
  units_1: 160
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000452284551211892

Model: "sequential_363"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_363 (Flatten)       (None, 784)               0         
                                                                 
 dense_1751 (Dense)          (None, 256)               200960    
                                                                 
 dropout_1388 (Dropout)      (None, 256)               0         
                                                                 
 dense_1752 (Dense)          (None, 160)               41120     
                                                                 
 dropout_1389 (Dropout)      (None, 160)               0         
                                                                 
 dense_1753 (Dense)          (None, 512)               82432     
                                                                 
 batch_normalization_461 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1390 (Dropout)      (None, 512)               0         
                                                                 
 dense_1754 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1391 (Dropout)      (None, 192)               0         
                                                                 
 dense_1755 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 430074 (1.64 MB)
Trainable params: 429050 (1.64 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 364:
  Value: 0.8565
  num_layers: 4
  units_0: 480
  units_1: 192
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005402786357237013

Model: "sequential_364"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_364 (Flatten)       (None, 784)               0         
                                                                 
 dense_1756 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1392 (Dropout)      (None, 480)               0         
                                                                 
 dense_1757 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1393 (Dropout)      (None, 192)               0         
                                                                 
 dense_1758 (Dense)          (None, 512)               98816     
                                                                 
 batch_normalization_462 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1394 (Dropout)      (None, 512)               0         
                                                                 
 dense_1759 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1395 (Dropout)      (None, 192)               0         
                                                                 
 dense_1760 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 673530 (2.57 MB)
Trainable params: 672506 (2.57 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 365:
  Value: 0.8386
  num_layers: 4
  units_0: 480
  units_1: 96
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004885552437389929

Model: "sequential_365"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_365 (Flatten)       (None, 784)               0         
                                                                 
 dense_1761 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1396 (Dropout)      (None, 480)               0         
                                                                 
 dense_1762 (Dense)          (None, 96)                46176     
                                                                 
 dropout_1397 (Dropout)      (None, 96)                0         
                                                                 
 dense_1763 (Dense)          (None, 480)               46560     
                                                                 
 batch_normalization_463 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1398 (Dropout)      (None, 480)               0         
                                                                 
 dense_1764 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1399 (Dropout)      (None, 224)               0         
                                                                 
 dense_1765 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 585050 (2.23 MB)
Trainable params: 584090 (2.23 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 366:
  Value: 0.8539
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00042588004661191616

Model: "sequential_366"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_366 (Flatten)       (None, 784)               0         
                                                                 
 dense_1766 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1400 (Dropout)      (None, 480)               0         
                                                                 
 dense_1767 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1401 (Dropout)      (None, 480)               0         
                                                                 
 dense_1768 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_464 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1402 (Dropout)      (None, 512)               0         
                                                                 
 dense_1769 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1403 (Dropout)      (None, 192)               0         
                                                                 
 dense_1770 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 959514 (3.66 MB)
Trainable params: 958490 (3.66 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 367:
  Value: 0.9186
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005285207928989436

Model: "sequential_367"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_367 (Flatten)       (None, 784)               0         
                                                                 
 dense_1771 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1404 (Dropout)      (None, 480)               0         
                                                                 
 dense_1772 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1405 (Dropout)      (None, 480)               0         
                                                                 
 dense_1773 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_465 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1406 (Dropout)      (None, 480)               0         
                                                                 
 dense_1774 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1407 (Dropout)      (None, 256)               0         
                                                                 
 dense_1775 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 368:
  Value: 0.9186
  num_layers: 4
  units_0: 480
  units_1: 224
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005438557835367997

Model: "sequential_368"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_368 (Flatten)       (None, 784)               0         
                                                                 
 dense_1776 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1408 (Dropout)      (None, 480)               0         
                                                                 
 dense_1777 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1409 (Dropout)      (None, 224)               0         
                                                                 
 dense_1778 (Dense)          (None, 480)               108000    
                                                                 
 batch_normalization_466 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1410 (Dropout)      (None, 480)               0         
                                                                 
 dense_1779 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1411 (Dropout)      (None, 256)               0         
                                                                 
 dense_1780 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 724282 (2.76 MB)
Trainable params: 723322 (2.76 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 369:
  Value: 0.0445
  num_layers: 4
  units_0: 480
  units_1: 224
  units_2: 480
  units_3: 160
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0005661978958169778

Model: "sequential_369"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_369 (Flatten)       (None, 784)               0         
                                                                 
 dense_1781 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1412 (Dropout)      (None, 480)               0         
                                                                 
 dense_1782 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1413 (Dropout)      (None, 224)               0         
                                                                 
 dense_1783 (Dense)          (None, 480)               108000    
                                                                 
 batch_normalization_467 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1414 (Dropout)      (None, 480)               0         
                                                                 
 dense_1784 (Dense)          (None, 160)               76960     
                                                                 
 dropout_1415 (Dropout)      (None, 160)               0         
                                                                 
 dense_1785 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 675610 (2.58 MB)
Trainable params: 674650 (2.57 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 370:
  Value: 0.5906
  num_layers: 4
  units_0: 480
  units_1: 192
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005240826405932736

Model: "sequential_370"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_370 (Flatten)       (None, 784)               0         
                                                                 
 dense_1786 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1416 (Dropout)      (None, 480)               0         
                                                                 
 dense_1787 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1417 (Dropout)      (None, 192)               0         
                                                                 
 dense_1788 (Dense)          (None, 480)               92640     
                                                                 
 batch_normalization_468 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1418 (Dropout)      (None, 480)               0         
                                                                 
 dense_1789 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1419 (Dropout)      (None, 224)               0         
                                                                 
 dense_1790 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 677306 (2.58 MB)
Trainable params: 676346 (2.58 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 371:
  Value: 0.8271
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 96
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0006176754600556874

Model: "sequential_371"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_371 (Flatten)       (None, 784)               0         
                                                                 
 dense_1791 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1420 (Dropout)      (None, 480)               0         
                                                                 
 dense_1792 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1421 (Dropout)      (None, 448)               0         
                                                                 
 dense_1793 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_469 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1422 (Dropout)      (None, 480)               0         
                                                                 
 dense_1794 (Dense)          (None, 96)                46176     
                                                                 
 dropout_1423 (Dropout)      (None, 96)                0         
                                                                 
 dense_1795 (Dense)          (None, 26)                2522      
                                                                 
=================================================================
Total params: 858426 (3.27 MB)
Trainable params: 857466 (3.27 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 372:
  Value: 0.8795
  num_layers: 4
  units_0: 480
  units_1: 192
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004999128232091067

Model: "sequential_372"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_372 (Flatten)       (None, 784)               0         
                                                                 
 dense_1796 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1424 (Dropout)      (None, 480)               0         
                                                                 
 dense_1797 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1425 (Dropout)      (None, 192)               0         
                                                                 
 dense_1798 (Dense)          (None, 512)               98816     
                                                                 
 batch_normalization_470 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1426 (Dropout)      (None, 512)               0         
                                                                 
 dense_1799 (Dense)          (None, 224)               114912    
                                                                 
 dropout_1427 (Dropout)      (None, 224)               0         
                                                                 
 dense_1800 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 690778 (2.64 MB)
Trainable params: 689754 (2.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 373:
  Value: 0.8695
  num_layers: 4
  units_0: 480
  units_1: 224
  units_2: 512
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005646331386092438

Model: "sequential_373"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_373 (Flatten)       (None, 784)               0         
                                                                 
 dense_1801 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1428 (Dropout)      (None, 480)               0         
                                                                 
 dense_1802 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1429 (Dropout)      (None, 224)               0         
                                                                 
 dense_1803 (Dense)          (None, 512)               115200    
                                                                 
 batch_normalization_471 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1430 (Dropout)      (None, 512)               0         
                                                                 
 dense_1804 (Dense)          (None, 192)               98496     
                                                                 
 dropout_1431 (Dropout)      (None, 192)               0         
                                                                 
 dense_1805 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 705306 (2.69 MB)
Trainable params: 704282 (2.69 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 374:
  Value: 0.8519
  num_layers: 4
  units_0: 480
  units_1: 160
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006834241969486788

Model: "sequential_374"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_374 (Flatten)       (None, 784)               0         
                                                                 
 dense_1806 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1432 (Dropout)      (None, 480)               0         
                                                                 
 dense_1807 (Dense)          (None, 160)               76960     
                                                                 
 dropout_1433 (Dropout)      (None, 160)               0         
                                                                 
 dense_1808 (Dense)          (None, 480)               77280     
                                                                 
 dropout_1434 (Dropout)      (None, 480)               0         
                                                                 
 dense_1809 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1435 (Dropout)      (None, 256)               0         
                                                                 
 dense_1810 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 660858 (2.52 MB)
Trainable params: 660858 (2.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 375:
  Value: 0.0381
  num_layers: 4
  units_0: 480
  units_1: 224
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0005277524107955364

Model: "sequential_375"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_375 (Flatten)       (None, 784)               0         
                                                                 
 dense_1811 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1436 (Dropout)      (None, 480)               0         
                                                                 
 dense_1812 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1437 (Dropout)      (None, 224)               0         
                                                                 
 dense_1813 (Dense)          (None, 480)               108000    
                                                                 
 batch_normalization_472 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1438 (Dropout)      (None, 480)               0         
                                                                 
 dense_1814 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1439 (Dropout)      (None, 288)               0         
                                                                 
 dense_1815 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 740506 (2.82 MB)
Trainable params: 739546 (2.82 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 376:
  Value: 0.9185
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0030489367531857958

Model: "sequential_376"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_376 (Flatten)       (None, 784)               0         
                                                                 
 dense_1816 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1440 (Dropout)      (None, 480)               0         
                                                                 
 dense_1817 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1441 (Dropout)      (None, 480)               0         
                                                                 
 dense_1818 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_473 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1442 (Dropout)      (None, 512)               0         
                                                                 
 dense_1819 (Dense)          (None, 256)               131328    
                                                                 
 dropout_1443 (Dropout)      (None, 256)               0         
                                                                 
 dense_1820 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 994010 (3.79 MB)
Trainable params: 992986 (3.79 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 377:
  Value: 0.7716
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006203564644534784

Model: "sequential_377"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_377 (Flatten)       (None, 784)               0         
                                                                 
 dense_1821 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1444 (Dropout)      (None, 480)               0         
                                                                 
 dense_1822 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1445 (Dropout)      (None, 448)               0         
                                                                 
 dense_1823 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_474 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1446 (Dropout)      (None, 512)               0         
                                                                 
 dense_1824 (Dense)          (None, 256)               131328    
                                                                 
 dropout_1447 (Dropout)      (None, 256)               0         
                                                                 
 dense_1825 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 962234 (3.67 MB)
Trainable params: 961210 (3.67 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 378:
  Value: 0.9179
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013170207570121775

Model: "sequential_378"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_378 (Flatten)       (None, 784)               0         
                                                                 
 dense_1826 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1448 (Dropout)      (None, 480)               0         
                                                                 
 dense_1827 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1449 (Dropout)      (None, 480)               0         
                                                                 
 dense_1828 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_475 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1450 (Dropout)      (None, 512)               0         
                                                                 
 dense_1829 (Dense)          (None, 224)               114912    
                                                                 
 dropout_1451 (Dropout)      (None, 224)               0         
                                                                 
 dense_1830 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 976762 (3.73 MB)
Trainable params: 975738 (3.72 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 379:
  Value: 0.9196
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011219347515308163

Model: "sequential_379"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_379 (Flatten)       (None, 784)               0         
                                                                 
 dense_1831 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1452 (Dropout)      (None, 480)               0         
                                                                 
 dense_1832 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1453 (Dropout)      (None, 480)               0         
                                                                 
 dense_1833 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_476 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1454 (Dropout)      (None, 480)               0         
                                                                 
 dense_1834 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1455 (Dropout)      (None, 256)               0         
                                                                 
 dense_1835 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 380:
  Value: 0.8408
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.007880688111473603

Model: "sequential_380"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_380 (Flatten)       (None, 784)               0         
                                                                 
 dense_1836 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_477 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1456 (Dropout)      (None, 480)               0         
                                                                 
 dense_1837 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1457 (Dropout)      (None, 480)               0         
                                                                 
 dense_1838 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_478 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1458 (Dropout)      (None, 512)               0         
                                                                 
 dense_1839 (Dense)          (None, 256)               131328    
                                                                 
 dropout_1459 (Dropout)      (None, 256)               0         
                                                                 
 dense_1840 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 995930 (3.80 MB)
Trainable params: 993946 (3.79 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 381:
  Value: 0.8555
  num_layers: 4
  units_0: 480
  units_1: 224
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0024394112014471023

Model: "sequential_381"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_381 (Flatten)       (None, 784)               0         
                                                                 
 dense_1841 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1460 (Dropout)      (None, 480)               0         
                                                                 
 dense_1842 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1461 (Dropout)      (None, 224)               0         
                                                                 
 dense_1843 (Dense)          (None, 480)               108000    
                                                                 
 batch_normalization_479 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1462 (Dropout)      (None, 480)               0         
                                                                 
 dense_1844 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1463 (Dropout)      (None, 256)               0         
                                                                 
 dense_1845 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 724282 (2.76 MB)
Trainable params: 723322 (2.76 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 382:
  Value: 0.6105
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.0
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002754361545269299

Model: "sequential_382"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_382 (Flatten)       (None, 784)               0         
                                                                 
 dense_1846 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1464 (Dropout)      (None, 480)               0         
                                                                 
 dense_1847 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_480 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1465 (Dropout)      (None, 448)               0         
                                                                 
 dense_1848 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_481 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1466 (Dropout)      (None, 480)               0         
                                                                 
 dense_1849 (Dense)          (None, 224)               107744    
                                                                 
 dropout_1467 (Dropout)      (None, 224)               0         
                                                                 
 dense_1850 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 925114 (3.53 MB)
Trainable params: 923258 (3.52 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 383:
  Value: 0.9212
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015411272200613537

Model: "sequential_383"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_383 (Flatten)       (None, 784)               0         
                                                                 
 dense_1851 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1468 (Dropout)      (None, 480)               0         
                                                                 
 dense_1852 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1469 (Dropout)      (None, 480)               0         
                                                                 
 dense_1853 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_482 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1470 (Dropout)      (None, 480)               0         
                                                                 
 dense_1854 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1471 (Dropout)      (None, 256)               0         
                                                                 
 dense_1855 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 384:
  Value: 0.8526
  num_layers: 4
  units_0: 480
  units_1: 192
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010276890142470777

Model: "sequential_384"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_384 (Flatten)       (None, 784)               0         
                                                                 
 dense_1856 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1472 (Dropout)      (None, 480)               0         
                                                                 
 dense_1857 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1473 (Dropout)      (None, 192)               0         
                                                                 
 dense_1858 (Dense)          (None, 480)               92640     
                                                                 
 batch_normalization_483 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1474 (Dropout)      (None, 480)               0         
                                                                 
 dense_1859 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1475 (Dropout)      (None, 256)               0         
                                                                 
 dense_1860 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 693530 (2.65 MB)
Trainable params: 692570 (2.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 385:
  Value: 0.0753
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0019419729793439008

Model: "sequential_385"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_385 (Flatten)       (None, 784)               0         
                                                                 
 dense_1861 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1476 (Dropout)      (None, 480)               0         
                                                                 
 dense_1862 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1477 (Dropout)      (None, 480)               0         
                                                                 
 dense_1863 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_484 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1478 (Dropout)      (None, 512)               0         
                                                                 
 dense_1864 (Dense)          (None, 256)               131328    
                                                                 
 dropout_1479 (Dropout)      (None, 256)               0         
                                                                 
 dense_1865 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 994010 (3.79 MB)
Trainable params: 992986 (3.79 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 386:
  Value: 0.8742
  num_layers: 3
  units_0: 480
  units_1: 480
  units_2: 480
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0009659254236549658

Model: "sequential_386"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_386 (Flatten)       (None, 784)               0         
                                                                 
 dense_1866 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1480 (Dropout)      (None, 480)               0         
                                                                 
 dense_1867 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1481 (Dropout)      (None, 480)               0         
                                                                 
 dense_1868 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_485 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1482 (Dropout)      (None, 480)               0         
                                                                 
 dense_1869 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 852986 (3.25 MB)
Trainable params: 852026 (3.25 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 387:
  Value: 0.9200
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011594555318414747

Model: "sequential_387"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_387 (Flatten)       (None, 784)               0         
                                                                 
 dense_1870 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1483 (Dropout)      (None, 480)               0         
                                                                 
 dense_1871 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1484 (Dropout)      (None, 480)               0         
                                                                 
 dense_1872 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_486 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1485 (Dropout)      (None, 480)               0         
                                                                 
 dense_1873 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1486 (Dropout)      (None, 256)               0         
                                                                 
 dense_1874 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 388:
  Value: 0.9197
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001958214119443021

Model: "sequential_388"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_388 (Flatten)       (None, 784)               0         
                                                                 
 dense_1875 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1487 (Dropout)      (None, 480)               0         
                                                                 
 dense_1876 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1488 (Dropout)      (None, 448)               0         
                                                                 
 dense_1877 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_487 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1489 (Dropout)      (None, 480)               0         
                                                                 
 dense_1878 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1490 (Dropout)      (None, 256)               0         
                                                                 
 dense_1879 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 939546 (3.58 MB)
Trainable params: 938586 (3.58 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 389:
  Value: 0.9171
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011683952962348325

Model: "sequential_389"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_389 (Flatten)       (None, 784)               0         
                                                                 
 dense_1880 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1491 (Dropout)      (None, 480)               0         
                                                                 
 dense_1881 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1492 (Dropout)      (None, 448)               0         
                                                                 
 dense_1882 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_488 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1493 (Dropout)      (None, 480)               0         
                                                                 
 dense_1883 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1494 (Dropout)      (None, 256)               0         
                                                                 
 dense_1884 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 939546 (3.58 MB)
Trainable params: 938586 (3.58 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 390:
  Value: 0.7684
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0013938669108093434

Model: "sequential_390"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_390 (Flatten)       (None, 784)               0         
                                                                 
 dense_1885 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1495 (Dropout)      (None, 480)               0         
                                                                 
 dense_1886 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1496 (Dropout)      (None, 448)               0         
                                                                 
 dense_1887 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_489 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1497 (Dropout)      (None, 480)               0         
                                                                 
 dense_1888 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1498 (Dropout)      (None, 256)               0         
                                                                 
 dense_1889 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 939546 (3.58 MB)
Trainable params: 938586 (3.58 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 391:
  Value: 0.8572
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001697168229073024

Model: "sequential_391"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_391 (Flatten)       (None, 784)               0         
                                                                 
 dense_1890 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1499 (Dropout)      (None, 480)               0         
                                                                 
 dense_1891 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1500 (Dropout)      (None, 448)               0         
                                                                 
 dense_1892 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_490 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1501 (Dropout)      (None, 480)               0         
                                                                 
 dense_1893 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1502 (Dropout)      (None, 256)               0         
                                                                 
 dense_1894 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 939546 (3.58 MB)
Trainable params: 938586 (3.58 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 392:
  Value: 0.8582
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 160
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014864772362972259

Model: "sequential_392"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_392 (Flatten)       (None, 784)               0         
                                                                 
 dense_1895 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1503 (Dropout)      (None, 480)               0         
                                                                 
 dense_1896 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1504 (Dropout)      (None, 480)               0         
                                                                 
 dense_1897 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_491 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1505 (Dropout)      (None, 512)               0         
                                                                 
 dense_1898 (Dense)          (None, 160)               82080     
                                                                 
 dropout_1506 (Dropout)      (None, 160)               0         
                                                                 
 dense_1899 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 942266 (3.59 MB)
Trainable params: 941242 (3.59 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 393:
  Value: 0.9205
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0037020266663106466

Model: "sequential_393"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_393 (Flatten)       (None, 784)               0         
                                                                 
 dense_1900 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1507 (Dropout)      (None, 480)               0         
                                                                 
 dense_1901 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1508 (Dropout)      (None, 480)               0         
                                                                 
 dense_1902 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_492 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1509 (Dropout)      (None, 480)               0         
                                                                 
 dense_1903 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1510 (Dropout)      (None, 256)               0         
                                                                 
 dense_1904 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 394:
  Value: 0.7855
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004184189052726174

Model: "sequential_394"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_394 (Flatten)       (None, 784)               0         
                                                                 
 dense_1905 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1511 (Dropout)      (None, 480)               0         
                                                                 
 dense_1906 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1512 (Dropout)      (None, 448)               0         
                                                                 
 dense_1907 (Dense)          (None, 480)               215520    
                                                                 
 dropout_1513 (Dropout)      (None, 480)               0         
                                                                 
 dense_1908 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1514 (Dropout)      (None, 256)               0         
                                                                 
 dense_1909 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 937626 (3.58 MB)
Trainable params: 937626 (3.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 395:
  Value: 0.9182
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017125682777404043

Model: "sequential_395"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_395 (Flatten)       (None, 784)               0         
                                                                 
 dense_1910 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1515 (Dropout)      (None, 480)               0         
                                                                 
 dense_1911 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1516 (Dropout)      (None, 480)               0         
                                                                 
 dense_1912 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_493 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1517 (Dropout)      (None, 480)               0         
                                                                 
 dense_1913 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1518 (Dropout)      (None, 256)               0         
                                                                 
 dense_1914 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 396:
  Value: 0.8564
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 192
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001227086571098865

Model: "sequential_396"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_396 (Flatten)       (None, 784)               0         
                                                                 
 dense_1915 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1519 (Dropout)      (None, 480)               0         
                                                                 
 dense_1916 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1520 (Dropout)      (None, 480)               0         
                                                                 
 dense_1917 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_494 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1521 (Dropout)      (None, 480)               0         
                                                                 
 dense_1918 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1522 (Dropout)      (None, 192)               0         
                                                                 
 dense_1919 (Dense)          (None, 26)                5018      
                                                                 
=================================================================
Total params: 937850 (3.58 MB)
Trainable params: 936890 (3.57 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 397:
  Value: 0.9163
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011390164438220523

Model: "sequential_397"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_397 (Flatten)       (None, 784)               0         
                                                                 
 dense_1920 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1523 (Dropout)      (None, 480)               0         
                                                                 
 dense_1921 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1524 (Dropout)      (None, 480)               0         
                                                                 
 dense_1922 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_495 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1525 (Dropout)      (None, 480)               0         
                                                                 
 dense_1923 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1526 (Dropout)      (None, 256)               0         
                                                                 
 dense_1924 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 398:
  Value: 0.9194
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009771058949389283

Model: "sequential_398"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_398 (Flatten)       (None, 784)               0         
                                                                 
 dense_1925 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1527 (Dropout)      (None, 480)               0         
                                                                 
 dense_1926 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1528 (Dropout)      (None, 480)               0         
                                                                 
 dense_1927 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_496 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1529 (Dropout)      (None, 480)               0         
                                                                 
 dense_1928 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1530 (Dropout)      (None, 256)               0         
                                                                 
 dense_1929 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 399:
  Value: 0.0848
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: sigmoid
  activation_1: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  batch_norm_0: True
  batch_norm_1: False
  optimizer: adagrad
  learning_rate: 0.0009927158188264087

Model: "sequential_399"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_399 (Flatten)       (None, 784)               0         
                                                                 
 dense_1930 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_497 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1531 (Dropout)      (None, 480)               0         
                                                                 
 dense_1931 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1532 (Dropout)      (None, 448)               0         
                                                                 
 dense_1932 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 605882 (2.31 MB)
Trainable params: 604922 (2.31 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 400:
  Value: 0.8562
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011824160400233145

Model: "sequential_400"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_400 (Flatten)       (None, 784)               0         
                                                                 
 dense_1933 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1533 (Dropout)      (None, 480)               0         
                                                                 
 dense_1934 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1534 (Dropout)      (None, 480)               0         
                                                                 
 dense_1935 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_498 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1535 (Dropout)      (None, 480)               0         
                                                                 
 dense_1936 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1536 (Dropout)      (None, 256)               0         
                                                                 
 dense_1937 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 401:
  Value: 0.9131
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000998027071354341

Model: "sequential_401"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_401 (Flatten)       (None, 784)               0         
                                                                 
 dense_1938 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1537 (Dropout)      (None, 480)               0         
                                                                 
 dense_1939 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1538 (Dropout)      (None, 480)               0         
                                                                 
 dense_1940 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_499 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1539 (Dropout)      (None, 480)               0         
                                                                 
 dense_1941 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1540 (Dropout)      (None, 256)               0         
                                                                 
 dense_1942 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 402:
  Value: 0.8017
  num_layers: 1
  units_0: 480
  activation_0: relu
  dropout_0: 0.4
  batch_norm_0: False
  optimizer: rmsprop
  learning_rate: 0.0010814866845589959

Model: "sequential_402"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_402 (Flatten)       (None, 784)               0         
                                                                 
 dense_1943 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1541 (Dropout)      (None, 480)               0         
                                                                 
 dense_1944 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 403:
  Value: 0.0364
  num_layers: 4
  units_0: 480
  units_1: 256
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0008397563097553742

Model: "sequential_403"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_403 (Flatten)       (None, 784)               0         
                                                                 
 dense_1945 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1542 (Dropout)      (None, 480)               0         
                                                                 
 dense_1946 (Dense)          (None, 256)               123136    
                                                                 
 batch_normalization_500 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_1543 (Dropout)      (None, 256)               0         
                                                                 
 dense_1947 (Dense)          (None, 480)               123360    
                                                                 
 batch_normalization_501 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1544 (Dropout)      (None, 480)               0         
                                                                 
 dense_1948 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1545 (Dropout)      (None, 256)               0         
                                                                 
 dense_1949 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 756058 (2.88 MB)
Trainable params: 754586 (2.88 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 404:
  Value: 0.8711
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013037771105862794

Model: "sequential_404"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_404 (Flatten)       (None, 784)               0         
                                                                 
 dense_1950 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1546 (Dropout)      (None, 480)               0         
                                                                 
 dense_1951 (Dense)          (None, 480)               230880    
                                                                 
 dropout_1547 (Dropout)      (None, 480)               0         
                                                                 
 dense_1952 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_502 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1548 (Dropout)      (None, 480)               0         
                                                                 
 dense_1953 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1549 (Dropout)      (None, 288)               0         
                                                                 
 dense_1954 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986522 (3.76 MB)
Trainable params: 985562 (3.76 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 405:
  Value: 0.8579
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000925785763539464

Model: "sequential_405"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_405 (Flatten)       (None, 784)               0         
                                                                 
 dense_1955 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1550 (Dropout)      (None, 480)               0         
                                                                 
 dense_1956 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1551 (Dropout)      (None, 416)               0         
                                                                 
 dense_1957 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_503 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1552 (Dropout)      (None, 480)               0         
                                                                 
 dense_1958 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1553 (Dropout)      (None, 256)               0         
                                                                 
 dense_1959 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 908794 (3.47 MB)
Trainable params: 907834 (3.46 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 406:
  Value: 0.8559
  num_layers: 4
  units_0: 480
  units_1: 256
  units_2: 512
  units_3: 128
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001482936178639703

Model: "sequential_406"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_406 (Flatten)       (None, 784)               0         
                                                                 
 dense_1960 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1554 (Dropout)      (None, 480)               0         
                                                                 
 dense_1961 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1555 (Dropout)      (None, 256)               0         
                                                                 
 dense_1962 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_504 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1556 (Dropout)      (None, 512)               0         
                                                                 
 dense_1963 (Dense)          (None, 128)               65664     
                                                                 
 dropout_1557 (Dropout)      (None, 128)               0         
                                                                 
 dense_1964 (Dense)          (None, 26)                3354      
                                                                 
=================================================================
Total params: 702586 (2.68 MB)
Trainable params: 701562 (2.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 407:
  Value: 0.8580
  num_layers: 4
  units_0: 480
  units_1: 192
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011762292486153282

Model: "sequential_407"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_407 (Flatten)       (None, 784)               0         
                                                                 
 dense_1965 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1558 (Dropout)      (None, 480)               0         
                                                                 
 dense_1966 (Dense)          (None, 192)               92352     
                                                                 
 dropout_1559 (Dropout)      (None, 192)               0         
                                                                 
 dense_1967 (Dense)          (None, 480)               92640     
                                                                 
 batch_normalization_505 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1560 (Dropout)      (None, 480)               0         
                                                                 
 dense_1968 (Dense)          (None, 256)               123136    
                                                                 
 dropout_1561 (Dropout)      (None, 256)               0         
                                                                 
 dense_1969 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 693530 (2.65 MB)
Trainable params: 692570 (2.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 408:
  Value: 0.9201
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001074864562918185

Model: "sequential_408"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_408 (Flatten)       (None, 784)               0         
                                                                 
 dense_1970 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1562 (Dropout)      (None, 480)               0         
                                                                 
 dense_1971 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1563 (Dropout)      (None, 448)               0         
                                                                 
 dense_1972 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_506 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1564 (Dropout)      (None, 480)               0         
                                                                 
 dense_1973 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1565 (Dropout)      (None, 288)               0         
                                                                 
 dense_1974 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 409:
  Value: 0.8327
  num_layers: 4
  units_0: 224
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001094713277769057

Model: "sequential_409"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_409 (Flatten)       (None, 784)               0         
                                                                 
 dense_1975 (Dense)          (None, 224)               175840    
                                                                 
 dropout_1566 (Dropout)      (None, 224)               0         
                                                                 
 dense_1976 (Dense)          (None, 448)               100800    
                                                                 
 dropout_1567 (Dropout)      (None, 448)               0         
                                                                 
 dense_1977 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_507 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1568 (Dropout)      (None, 480)               0         
                                                                 
 dense_1978 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1569 (Dropout)      (None, 288)               0         
                                                                 
 dense_1979 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 640122 (2.44 MB)
Trainable params: 639162 (2.44 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 410:
  Value: 0.9221
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010440843008553671

Model: "sequential_410"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_410 (Flatten)       (None, 784)               0         
                                                                 
 dense_1980 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1570 (Dropout)      (None, 480)               0         
                                                                 
 dense_1981 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1571 (Dropout)      (None, 448)               0         
                                                                 
 dense_1982 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_508 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1572 (Dropout)      (None, 512)               0         
                                                                 
 dense_1983 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1573 (Dropout)      (None, 288)               0         
                                                                 
 dense_1984 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 411:
  Value: 0.9230
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010924115115932968

Model: "sequential_411"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_411 (Flatten)       (None, 784)               0         
                                                                 
 dense_1985 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1574 (Dropout)      (None, 448)               0         
                                                                 
 dense_1986 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1575 (Dropout)      (None, 448)               0         
                                                                 
 dense_1987 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_509 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1576 (Dropout)      (None, 512)               0         
                                                                 
 dense_1988 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1577 (Dropout)      (None, 288)               0         
                                                                 
 dense_1989 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 940026 (3.59 MB)
Trainable params: 939002 (3.58 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 412:
  Value: 0.8488
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 64
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001075912630330487

Model: "sequential_412"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_412 (Flatten)       (None, 784)               0         
                                                                 
 dense_1990 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1578 (Dropout)      (None, 448)               0         
                                                                 
 dense_1991 (Dense)          (None, 416)               186784    
                                                                 
 dropout_1579 (Dropout)      (None, 416)               0         
                                                                 
 dense_1992 (Dense)          (None, 64)                26688     
                                                                 
 batch_normalization_510 (B  (None, 64)                256       
 atchNormalization)                                              
                                                                 
 dropout_1580 (Dropout)      (None, 64)                0         
                                                                 
 dense_1993 (Dense)          (None, 288)               18720     
                                                                 
 dropout_1581 (Dropout)      (None, 288)               0         
                                                                 
 dense_1994 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 591642 (2.26 MB)
Trainable params: 591514 (2.26 MB)
Non-trainable params: 128 (512.00 Byte)
_________________________________________________________________



Trial 413:
  Value: 0.9178
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010406252303740292

Model: "sequential_413"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_413 (Flatten)       (None, 784)               0         
                                                                 
 dense_1995 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1582 (Dropout)      (None, 480)               0         
                                                                 
 dense_1996 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1583 (Dropout)      (None, 448)               0         
                                                                 
 dense_1997 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_511 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1584 (Dropout)      (None, 512)               0         
                                                                 
 dense_1998 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1585 (Dropout)      (None, 288)               0         
                                                                 
 dense_1999 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 414:
  Value: 0.9218
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011673831617356248

Model: "sequential_414"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_414 (Flatten)       (None, 784)               0         
                                                                 
 dense_2000 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1586 (Dropout)      (None, 480)               0         
                                                                 
 dense_2001 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1587 (Dropout)      (None, 416)               0         
                                                                 
 dense_2002 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_512 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1588 (Dropout)      (None, 512)               0         
                                                                 
 dense_2003 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1589 (Dropout)      (None, 288)               0         
                                                                 
 dense_2004 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 415:
  Value: 0.9184
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012603877349404973

Model: "sequential_415"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_415 (Flatten)       (None, 784)               0         
                                                                 
 dense_2005 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1590 (Dropout)      (None, 480)               0         
                                                                 
 dense_2006 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1591 (Dropout)      (None, 448)               0         
                                                                 
 dense_2007 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_513 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1592 (Dropout)      (None, 512)               0         
                                                                 
 dense_2008 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1593 (Dropout)      (None, 288)               0         
                                                                 
 dense_2009 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 416:
  Value: 0.0842
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0009528355955226183

Model: "sequential_416"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_416 (Flatten)       (None, 784)               0         
                                                                 
 dense_2010 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1594 (Dropout)      (None, 480)               0         
                                                                 
 dense_2011 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1595 (Dropout)      (None, 448)               0         
                                                                 
 dense_2012 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_514 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1596 (Dropout)      (None, 512)               0         
                                                                 
 dense_2013 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1597 (Dropout)      (None, 288)               0         
                                                                 
 dense_2014 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 417:
  Value: 0.8316
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011105063964935308

Model: "sequential_417"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_417 (Flatten)       (None, 784)               0         
                                                                 
 dense_2015 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1598 (Dropout)      (None, 480)               0         
                                                                 
 dense_2016 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1599 (Dropout)      (None, 416)               0         
                                                                 
 dense_2017 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1600 (Dropout)      (None, 512)               0         
                                                                 
 dense_2018 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1601 (Dropout)      (None, 288)               0         
                                                                 
 dense_2019 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 945658 (3.61 MB)
Trainable params: 945658 (3.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 418:
  Value: 0.8575
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012053960464328082

Model: "sequential_418"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_418 (Flatten)       (None, 784)               0         
                                                                 
 dense_2020 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1602 (Dropout)      (None, 480)               0         
                                                                 
 dense_2021 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1603 (Dropout)      (None, 416)               0         
                                                                 
 dense_2022 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_515 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1604 (Dropout)      (None, 512)               0         
                                                                 
 dense_2023 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1605 (Dropout)      (None, 288)               0         
                                                                 
 dense_2024 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 419:
  Value: 0.5081
  num_layers: 4
  units_0: 32
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009145463384618369

Model: "sequential_419"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_419 (Flatten)       (None, 784)               0         
                                                                 
 dense_2025 (Dense)          (None, 32)                25120     
                                                                 
 batch_normalization_516 (B  (None, 32)                128       
 atchNormalization)                                              
                                                                 
 dropout_1606 (Dropout)      (None, 32)                0         
                                                                 
 dense_2026 (Dense)          (None, 448)               14784     
                                                                 
 dropout_1607 (Dropout)      (None, 448)               0         
                                                                 
 dense_2027 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_517 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1608 (Dropout)      (None, 512)               0         
                                                                 
 dense_2028 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1609 (Dropout)      (None, 288)               0         
                                                                 
 dense_2029 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 427226 (1.63 MB)
Trainable params: 426138 (1.63 MB)
Non-trainable params: 1088 (4.25 KB)
_________________________________________________________________



Trial 420:
  Value: 0.7737
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.001415260746772454

Model: "sequential_420"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_420 (Flatten)       (None, 784)               0         
                                                                 
 dense_2030 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1610 (Dropout)      (None, 480)               0         
                                                                 
 dense_2031 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1611 (Dropout)      (None, 448)               0         
                                                                 
 dense_2032 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_518 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1612 (Dropout)      (None, 512)               0         
                                                                 
 dense_2033 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1613 (Dropout)      (None, 288)               0         
                                                                 
 dense_2034 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 421:
  Value: 0.8394
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: sigmoid
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010502412324513654

Model: "sequential_421"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_421 (Flatten)       (None, 784)               0         
                                                                 
 dense_2035 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1614 (Dropout)      (None, 480)               0         
                                                                 
 dense_2036 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1615 (Dropout)      (None, 448)               0         
                                                                 
 dense_2037 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_519 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1616 (Dropout)      (None, 512)               0         
                                                                 
 dense_2038 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1617 (Dropout)      (None, 288)               0         
                                                                 
 dense_2039 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 422:
  Value: 0.8797
  num_layers: 3
  units_0: 480
  units_1: 448
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0012760463153488409

Model: "sequential_422"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_422 (Flatten)       (None, 784)               0         
                                                                 
 dense_2040 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1618 (Dropout)      (None, 480)               0         
                                                                 
 dense_2041 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1619 (Dropout)      (None, 448)               0         
                                                                 
 dense_2042 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_520 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1620 (Dropout)      (None, 512)               0         
                                                                 
 dense_2043 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 837562 (3.20 MB)
Trainable params: 836538 (3.19 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 423:
  Value: 0.6394
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009789267552964991

Model: "sequential_423"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_423 (Flatten)       (None, 784)               0         
                                                                 
 dense_2044 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1621 (Dropout)      (None, 480)               0         
                                                                 
 dense_2045 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_521 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1622 (Dropout)      (None, 416)               0         
                                                                 
 dense_2046 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_522 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1623 (Dropout)      (None, 512)               0         
                                                                 
 dense_2047 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1624 (Dropout)      (None, 288)               0         
                                                                 
 dense_2048 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 949370 (3.62 MB)
Trainable params: 947514 (3.61 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 424:
  Value: 0.8710
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008310142500980661

Model: "sequential_424"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_424 (Flatten)       (None, 784)               0         
                                                                 
 dense_2049 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1625 (Dropout)      (None, 448)               0         
                                                                 
 dense_2050 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1626 (Dropout)      (None, 448)               0         
                                                                 
 dense_2051 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_523 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1627 (Dropout)      (None, 512)               0         
                                                                 
 dense_2052 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1628 (Dropout)      (None, 288)               0         
                                                                 
 dense_2053 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 940026 (3.59 MB)
Trainable params: 939002 (3.58 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 425:
  Value: 0.8518
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 160
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011034470407925493

Model: "sequential_425"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_425 (Flatten)       (None, 784)               0         
                                                                 
 dense_2054 (Dense)          (None, 448)               351680    
                                                                 
 dropout_1629 (Dropout)      (None, 448)               0         
                                                                 
 dense_2055 (Dense)          (None, 448)               201152    
                                                                 
 dropout_1630 (Dropout)      (None, 448)               0         
                                                                 
 dense_2056 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_524 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1631 (Dropout)      (None, 512)               0         
                                                                 
 dense_2057 (Dense)          (None, 160)               82080     
                                                                 
 dropout_1632 (Dropout)      (None, 160)               0         
                                                                 
 dense_2058 (Dense)          (None, 26)                4186      
                                                                 
=================================================================
Total params: 871034 (3.32 MB)
Trainable params: 870010 (3.32 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 426:
  Value: 0.8918
  num_layers: 4
  units_0: 288
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015858429958391267

Model: "sequential_426"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_426 (Flatten)       (None, 784)               0         
                                                                 
 dense_2059 (Dense)          (None, 288)               226080    
                                                                 
 dropout_1633 (Dropout)      (None, 288)               0         
                                                                 
 dense_2060 (Dense)          (None, 448)               129472    
                                                                 
 dropout_1634 (Dropout)      (None, 448)               0         
                                                                 
 dense_2061 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_525 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1635 (Dropout)      (None, 480)               0         
                                                                 
 dense_2062 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1636 (Dropout)      (None, 288)               0         
                                                                 
 dense_2063 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 719034 (2.74 MB)
Trainable params: 718074 (2.74 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 427:
  Value: 0.0372
  num_layers: 4
  units_0: 160
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0020347395115319286

Model: "sequential_427"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_427 (Flatten)       (None, 784)               0         
                                                                 
 dense_2064 (Dense)          (None, 160)               125600    
                                                                 
 dropout_1637 (Dropout)      (None, 160)               0         
                                                                 
 dense_2065 (Dense)          (None, 416)               66976     
                                                                 
 dropout_1638 (Dropout)      (None, 416)               0         
                                                                 
 dense_2066 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_526 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1639 (Dropout)      (None, 512)               0         
                                                                 
 dense_2067 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1640 (Dropout)      (None, 288)               0         
                                                                 
 dense_2068 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 563386 (2.15 MB)
Trainable params: 562362 (2.15 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 428:
  Value: 0.9198
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013691161594675816

Model: "sequential_428"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_428 (Flatten)       (None, 784)               0         
                                                                 
 dense_2069 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1641 (Dropout)      (None, 480)               0         
                                                                 
 dense_2070 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1642 (Dropout)      (None, 448)               0         
                                                                 
 dense_2071 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_527 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1643 (Dropout)      (None, 480)               0         
                                                                 
 dense_2072 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1644 (Dropout)      (None, 288)               0         
                                                                 
 dense_2073 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 429:
  Value: 0.9202
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012658060768897482

Model: "sequential_429"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_429 (Flatten)       (None, 784)               0         
                                                                 
 dense_2074 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1645 (Dropout)      (None, 480)               0         
                                                                 
 dense_2075 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1646 (Dropout)      (None, 448)               0         
                                                                 
 dense_2076 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_528 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1647 (Dropout)      (None, 480)               0         
                                                                 
 dense_2077 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1648 (Dropout)      (None, 288)               0         
                                                                 
 dense_2078 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 430:
  Value: 0.9211
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013376262860308075

Model: "sequential_430"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_430 (Flatten)       (None, 784)               0         
                                                                 
 dense_2079 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1649 (Dropout)      (None, 480)               0         
                                                                 
 dense_2080 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1650 (Dropout)      (None, 448)               0         
                                                                 
 dense_2081 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_529 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1651 (Dropout)      (None, 480)               0         
                                                                 
 dense_2082 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1652 (Dropout)      (None, 288)               0         
                                                                 
 dense_2083 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 431:
  Value: 0.8088
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0013392560269952934

Model: "sequential_431"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_431 (Flatten)       (None, 784)               0         
                                                                 
 dense_2084 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1653 (Dropout)      (None, 480)               0         
                                                                 
 dense_2085 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1654 (Dropout)      (None, 448)               0         
                                                                 
 dense_2086 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_530 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1655 (Dropout)      (None, 480)               0         
                                                                 
 dense_2087 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1656 (Dropout)      (None, 320)               0         
                                                                 
 dense_2088 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 971994 (3.71 MB)
Trainable params: 971034 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 432:
  Value: 0.9210
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001422254245990393

Model: "sequential_432"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_432 (Flatten)       (None, 784)               0         
                                                                 
 dense_2089 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1657 (Dropout)      (None, 480)               0         
                                                                 
 dense_2090 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1658 (Dropout)      (None, 416)               0         
                                                                 
 dense_2091 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_531 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1659 (Dropout)      (None, 480)               0         
                                                                 
 dense_2092 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1660 (Dropout)      (None, 288)               0         
                                                                 
 dense_2093 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 433:
  Value: 0.0417
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0014862228495479694

Model: "sequential_433"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_433 (Flatten)       (None, 784)               0         
                                                                 
 dense_2094 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1661 (Dropout)      (None, 480)               0         
                                                                 
 dense_2095 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1662 (Dropout)      (None, 416)               0         
                                                                 
 dense_2096 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_532 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1663 (Dropout)      (None, 480)               0         
                                                                 
 dense_2097 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1664 (Dropout)      (None, 320)               0         
                                                                 
 dense_2098 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 941242 (3.59 MB)
Trainable params: 940282 (3.59 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 434:
  Value: 0.9223
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013780230641711143

Model: "sequential_434"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_434 (Flatten)       (None, 784)               0         
                                                                 
 dense_2099 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1665 (Dropout)      (None, 480)               0         
                                                                 
 dense_2100 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1666 (Dropout)      (None, 416)               0         
                                                                 
 dense_2101 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_533 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1667 (Dropout)      (None, 480)               0         
                                                                 
 dense_2102 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1668 (Dropout)      (None, 288)               0         
                                                                 
 dense_2103 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 435:
  Value: 0.9209
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013052648619794837

Model: "sequential_435"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_435 (Flatten)       (None, 784)               0         
                                                                 
 dense_2104 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1669 (Dropout)      (None, 480)               0         
                                                                 
 dense_2105 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1670 (Dropout)      (None, 416)               0         
                                                                 
 dense_2106 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_534 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1671 (Dropout)      (None, 480)               0         
                                                                 
 dense_2107 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1672 (Dropout)      (None, 288)               0         
                                                                 
 dense_2108 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 436:
  Value: 0.9197
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001354306601173041

Model: "sequential_436"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_436 (Flatten)       (None, 784)               0         
                                                                 
 dense_2109 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1673 (Dropout)      (None, 480)               0         
                                                                 
 dense_2110 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1674 (Dropout)      (None, 416)               0         
                                                                 
 dense_2111 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_535 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1675 (Dropout)      (None, 480)               0         
                                                                 
 dense_2112 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1676 (Dropout)      (None, 288)               0         
                                                                 
 dense_2113 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 437:
  Value: 0.8214
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013205378021864471

Model: "sequential_437"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_437 (Flatten)       (None, 784)               0         
                                                                 
 dense_2114 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1677 (Dropout)      (None, 480)               0         
                                                                 
 dense_2115 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1678 (Dropout)      (None, 416)               0         
                                                                 
 dense_2116 (Dense)          (None, 480)               200160    
                                                                 
 dropout_1679 (Dropout)      (None, 480)               0         
                                                                 
 dense_2117 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1680 (Dropout)      (None, 288)               0         
                                                                 
 dense_2118 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 923098 (3.52 MB)
Trainable params: 923098 (3.52 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 438:
  Value: 0.9190
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013589327853353308

Model: "sequential_438"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_438 (Flatten)       (None, 784)               0         
                                                                 
 dense_2119 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1681 (Dropout)      (None, 480)               0         
                                                                 
 dense_2120 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1682 (Dropout)      (None, 416)               0         
                                                                 
 dense_2121 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_536 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1683 (Dropout)      (None, 480)               0         
                                                                 
 dense_2122 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1684 (Dropout)      (None, 288)               0         
                                                                 
 dense_2123 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 439:
  Value: 0.9197
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015435325001718504

Model: "sequential_439"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_439 (Flatten)       (None, 784)               0         
                                                                 
 dense_2124 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1685 (Dropout)      (None, 480)               0         
                                                                 
 dense_2125 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1686 (Dropout)      (None, 416)               0         
                                                                 
 dense_2126 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_537 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1687 (Dropout)      (None, 480)               0         
                                                                 
 dense_2127 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1688 (Dropout)      (None, 320)               0         
                                                                 
 dense_2128 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 941242 (3.59 MB)
Trainable params: 940282 (3.59 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 440:
  Value: 0.8449
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001543390522539379

Model: "sequential_440"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_440 (Flatten)       (None, 784)               0         
                                                                 
 dense_2129 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_538 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1689 (Dropout)      (None, 480)               0         
                                                                 
 dense_2130 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1690 (Dropout)      (None, 416)               0         
                                                                 
 dense_2131 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_539 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1691 (Dropout)      (None, 480)               0         
                                                                 
 dense_2132 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1692 (Dropout)      (None, 320)               0         
                                                                 
 dense_2133 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 943162 (3.60 MB)
Trainable params: 941242 (3.59 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 441:
  Value: 0.9164
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014237982664502494

Model: "sequential_441"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_441 (Flatten)       (None, 784)               0         
                                                                 
 dense_2134 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1693 (Dropout)      (None, 480)               0         
                                                                 
 dense_2135 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1694 (Dropout)      (None, 416)               0         
                                                                 
 dense_2136 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_540 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1695 (Dropout)      (None, 480)               0         
                                                                 
 dense_2137 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1696 (Dropout)      (None, 320)               0         
                                                                 
 dense_2138 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 941242 (3.59 MB)
Trainable params: 940282 (3.59 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 442:
  Value: 0.9189
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012249246340389347

Model: "sequential_442"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_442 (Flatten)       (None, 784)               0         
                                                                 
 dense_2139 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1697 (Dropout)      (None, 480)               0         
                                                                 
 dense_2140 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1698 (Dropout)      (None, 416)               0         
                                                                 
 dense_2141 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_541 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1699 (Dropout)      (None, 480)               0         
                                                                 
 dense_2142 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1700 (Dropout)      (None, 320)               0         
                                                                 
 dense_2143 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 941242 (3.59 MB)
Trainable params: 940282 (3.59 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 443:
  Value: 0.9191
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015901605607894025

Model: "sequential_443"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_443 (Flatten)       (None, 784)               0         
                                                                 
 dense_2144 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1701 (Dropout)      (None, 480)               0         
                                                                 
 dense_2145 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1702 (Dropout)      (None, 416)               0         
                                                                 
 dense_2146 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_542 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1703 (Dropout)      (None, 480)               0         
                                                                 
 dense_2147 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1704 (Dropout)      (None, 288)               0         
                                                                 
 dense_2148 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 444:
  Value: 0.0364
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.001233410931757583

Model: "sequential_444"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_444 (Flatten)       (None, 784)               0         
                                                                 
 dense_2149 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1705 (Dropout)      (None, 480)               0         
                                                                 
 dense_2150 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_543 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1706 (Dropout)      (None, 416)               0         
                                                                 
 dense_2151 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_544 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1707 (Dropout)      (None, 512)               0         
                                                                 
 dense_2152 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1708 (Dropout)      (None, 288)               0         
                                                                 
 dense_2153 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 949370 (3.62 MB)
Trainable params: 947514 (3.61 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 445:
  Value: 0.9124
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013876352067641047

Model: "sequential_445"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_445 (Flatten)       (None, 784)               0         
                                                                 
 dense_2154 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1709 (Dropout)      (None, 480)               0         
                                                                 
 dense_2155 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1710 (Dropout)      (None, 416)               0         
                                                                 
 dense_2156 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_545 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1711 (Dropout)      (None, 480)               0         
                                                                 
 dense_2157 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1712 (Dropout)      (None, 320)               0         
                                                                 
 dense_2158 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 941242 (3.59 MB)
Trainable params: 940282 (3.59 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 446:
  Value: 0.9185
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016053957652511744

Model: "sequential_446"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_446 (Flatten)       (None, 784)               0         
                                                                 
 dense_2159 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1713 (Dropout)      (None, 480)               0         
                                                                 
 dense_2160 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1714 (Dropout)      (None, 416)               0         
                                                                 
 dense_2161 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_546 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1715 (Dropout)      (None, 480)               0         
                                                                 
 dense_2162 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1716 (Dropout)      (None, 288)               0         
                                                                 
 dense_2163 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 447:
  Value: 0.9200
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014114121592654592

Model: "sequential_447"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_447 (Flatten)       (None, 784)               0         
                                                                 
 dense_2164 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1717 (Dropout)      (None, 480)               0         
                                                                 
 dense_2165 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1718 (Dropout)      (None, 416)               0         
                                                                 
 dense_2166 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_547 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1719 (Dropout)      (None, 512)               0         
                                                                 
 dense_2167 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1720 (Dropout)      (None, 288)               0         
                                                                 
 dense_2168 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 448:
  Value: 0.9107
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001430530737543

Model: "sequential_448"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_448 (Flatten)       (None, 784)               0         
                                                                 
 dense_2169 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1721 (Dropout)      (None, 480)               0         
                                                                 
 dense_2170 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1722 (Dropout)      (None, 416)               0         
                                                                 
 dense_2171 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_548 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1723 (Dropout)      (None, 512)               0         
                                                                 
 dense_2172 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1724 (Dropout)      (None, 288)               0         
                                                                 
 dense_2173 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 449:
  Value: 0.7721
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0017211370728328953

Model: "sequential_449"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_449 (Flatten)       (None, 784)               0         
                                                                 
 dense_2174 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1725 (Dropout)      (None, 480)               0         
                                                                 
 dense_2175 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1726 (Dropout)      (None, 416)               0         
                                                                 
 dense_2176 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_549 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1727 (Dropout)      (None, 512)               0         
                                                                 
 dense_2177 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1728 (Dropout)      (None, 288)               0         
                                                                 
 dense_2178 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 450:
  Value: 0.8589
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012841434265907644

Model: "sequential_450"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_450 (Flatten)       (None, 784)               0         
                                                                 
 dense_2179 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1729 (Dropout)      (None, 480)               0         
                                                                 
 dense_2180 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1730 (Dropout)      (None, 416)               0         
                                                                 
 dense_2181 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_550 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1731 (Dropout)      (None, 512)               0         
                                                                 
 dense_2182 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1732 (Dropout)      (None, 288)               0         
                                                                 
 dense_2183 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 451:
  Value: 0.9221
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001167058357317837

Model: "sequential_451"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_451 (Flatten)       (None, 784)               0         
                                                                 
 dense_2184 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1733 (Dropout)      (None, 480)               0         
                                                                 
 dense_2185 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1734 (Dropout)      (None, 416)               0         
                                                                 
 dense_2186 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_551 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1735 (Dropout)      (None, 512)               0         
                                                                 
 dense_2187 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1736 (Dropout)      (None, 320)               0         
                                                                 
 dense_2188 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 452:
  Value: 0.8847
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011944842854513852

Model: "sequential_452"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_452 (Flatten)       (None, 784)               0         
                                                                 
 dense_2189 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1737 (Dropout)      (None, 480)               0         
                                                                 
 dense_2190 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1738 (Dropout)      (None, 416)               0         
                                                                 
 dense_2191 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_552 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1739 (Dropout)      (None, 512)               0         
                                                                 
 dense_2192 (Dense)          (None, 352)               180576    
                                                                 
 dropout_1740 (Dropout)      (None, 352)               0         
                                                                 
 dense_2193 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 982202 (3.75 MB)
Trainable params: 981178 (3.74 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 453:
  Value: 0.8568
  num_layers: 3
  units_0: 480
  units_1: 416
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0013726455447021064

Model: "sequential_453"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_453 (Flatten)       (None, 784)               0         
                                                                 
 dense_2194 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1741 (Dropout)      (None, 480)               0         
                                                                 
 dense_2195 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1742 (Dropout)      (None, 416)               0         
                                                                 
 dense_2196 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_553 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1743 (Dropout)      (None, 512)               0         
                                                                 
 dense_2197 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 805786 (3.07 MB)
Trainable params: 804762 (3.07 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 454:
  Value: 0.8560
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 96
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015496977405005164

Model: "sequential_454"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_454 (Flatten)       (None, 784)               0         
                                                                 
 dense_2198 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1744 (Dropout)      (None, 480)               0         
                                                                 
 dense_2199 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1745 (Dropout)      (None, 416)               0         
                                                                 
 dense_2200 (Dense)          (None, 96)                40032     
                                                                 
 batch_normalization_554 (B  (None, 96)                384       
 atchNormalization)                                              
                                                                 
 dropout_1746 (Dropout)      (None, 96)                0         
                                                                 
 dense_2201 (Dense)          (None, 320)               31040     
                                                                 
 dropout_1747 (Dropout)      (None, 320)               0         
                                                                 
 dense_2202 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 656698 (2.51 MB)
Trainable params: 656506 (2.50 MB)
Non-trainable params: 192 (768.00 Byte)
_________________________________________________________________



Trial 455:
  Value: 0.9195
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001857456263532693

Model: "sequential_455"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_455 (Flatten)       (None, 784)               0         
                                                                 
 dense_2203 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1748 (Dropout)      (None, 480)               0         
                                                                 
 dense_2204 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1749 (Dropout)      (None, 416)               0         
                                                                 
 dense_2205 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_555 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1750 (Dropout)      (None, 512)               0         
                                                                 
 dense_2206 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1751 (Dropout)      (None, 320)               0         
                                                                 
 dense_2207 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 456:
  Value: 0.8243
  num_layers: 4
  units_0: 192
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00147252530553679

Model: "sequential_456"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_456 (Flatten)       (None, 784)               0         
                                                                 
 dense_2208 (Dense)          (None, 192)               150720    
                                                                 
 dropout_1752 (Dropout)      (None, 192)               0         
                                                                 
 dense_2209 (Dense)          (None, 416)               80288     
                                                                 
 dropout_1753 (Dropout)      (None, 416)               0         
                                                                 
 dense_2210 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_556 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1754 (Dropout)      (None, 512)               0         
                                                                 
 dense_2211 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1755 (Dropout)      (None, 320)               0         
                                                                 
 dense_2212 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 619066 (2.36 MB)
Trainable params: 618042 (2.36 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 457:
  Value: 0.0567
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0012897881413254585

Model: "sequential_457"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_457 (Flatten)       (None, 784)               0         
                                                                 
 dense_2213 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1756 (Dropout)      (None, 512)               0         
                                                                 
 dense_2214 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1757 (Dropout)      (None, 416)               0         
                                                                 
 dense_2215 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_557 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1758 (Dropout)      (None, 480)               0         
                                                                 
 dense_2216 (Dense)          (None, 320)               153920    
                                                                 
 dropout_1759 (Dropout)      (None, 320)               0         
                                                                 
 dense_2217 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 979674 (3.74 MB)
Trainable params: 978714 (3.73 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 458:
  Value: 0.8254
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011318813660815047

Model: "sequential_458"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_458 (Flatten)       (None, 784)               0         
                                                                 
 dense_2218 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1760 (Dropout)      (None, 480)               0         
                                                                 
 dense_2219 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1761 (Dropout)      (None, 448)               0         
                                                                 
 dense_2220 (Dense)          (None, 512)               229888    
                                                                 
 dropout_1762 (Dropout)      (None, 512)               0         
                                                                 
 dense_2221 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1763 (Dropout)      (None, 288)               0         
                                                                 
 dense_2222 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 977434 (3.73 MB)
Trainable params: 977434 (3.73 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 459:
  Value: 0.8589
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017998644869077942

Model: "sequential_459"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_459 (Flatten)       (None, 784)               0         
                                                                 
 dense_2223 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1764 (Dropout)      (None, 480)               0         
                                                                 
 dense_2224 (Dense)          (None, 384)               184704    
                                                                 
 dropout_1765 (Dropout)      (None, 384)               0         
                                                                 
 dense_2225 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_558 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1766 (Dropout)      (None, 512)               0         
                                                                 
 dense_2226 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1767 (Dropout)      (None, 288)               0         
                                                                 
 dense_2227 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 915930 (3.49 MB)
Trainable params: 914906 (3.49 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 460:
  Value: 0.8210
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.001624849731419104

Model: "sequential_460"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_460 (Flatten)       (None, 784)               0         
                                                                 
 dense_2228 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1768 (Dropout)      (None, 512)               0         
                                                                 
 dense_2229 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1769 (Dropout)      (None, 416)               0         
                                                                 
 dense_2230 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_559 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1770 (Dropout)      (None, 480)               0         
                                                                 
 dense_2231 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1771 (Dropout)      (None, 288)               0         
                                                                 
 dense_2232 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 461:
  Value: 0.8361
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014724778082314106

Model: "sequential_461"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_461 (Flatten)       (None, 784)               0         
                                                                 
 dense_2233 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_560 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1772 (Dropout)      (None, 480)               0         
                                                                 
 dense_2234 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1773 (Dropout)      (None, 448)               0         
                                                                 
 dense_2235 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_561 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1774 (Dropout)      (None, 512)               0         
                                                                 
 dense_2236 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1775 (Dropout)      (None, 320)               0         
                                                                 
 dense_2237 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 998650 (3.81 MB)
Trainable params: 996666 (3.80 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 462:
  Value: 0.8685
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001204243413306846

Model: "sequential_462"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_462 (Flatten)       (None, 784)               0         
                                                                 
 dense_2238 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1776 (Dropout)      (None, 480)               0         
                                                                 
 dense_2239 (Dense)          (None, 416)               200096    
                                                                 
 dropout_1777 (Dropout)      (None, 416)               0         
                                                                 
 dense_2240 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_562 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1778 (Dropout)      (None, 480)               0         
                                                                 
 dense_2241 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1779 (Dropout)      (None, 288)               0         
                                                                 
 dense_2242 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 463:
  Value: 0.9187
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013570082177595767

Model: "sequential_463"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_463 (Flatten)       (None, 784)               0         
                                                                 
 dense_2243 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1780 (Dropout)      (None, 480)               0         
                                                                 
 dense_2244 (Dense)          (None, 448)               215488    
                                                                 
 dropout_1781 (Dropout)      (None, 448)               0         
                                                                 
 dense_2245 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_563 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1782 (Dropout)      (None, 480)               0         
                                                                 
 dense_2246 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1783 (Dropout)      (None, 288)               0         
                                                                 
 dense_2247 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 464:
  Value: 0.5709
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017204301701565547

Model: "sequential_464"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_464 (Flatten)       (None, 784)               0         
                                                                 
 dense_2248 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1784 (Dropout)      (None, 480)               0         
                                                                 
 dense_2249 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_564 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_1785 (Dropout)      (None, 448)               0         
                                                                 
 dense_2250 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_565 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1786 (Dropout)      (None, 512)               0         
                                                                 
 dense_2251 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1787 (Dropout)      (None, 320)               0         
                                                                 
 dense_2252 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 998522 (3.81 MB)
Trainable params: 996602 (3.80 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 465:
  Value: 0.9194
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012497282303425947

Model: "sequential_465"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_465 (Flatten)       (None, 784)               0         
                                                                 
 dense_2253 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1788 (Dropout)      (None, 512)               0         
                                                                 
 dense_2254 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1789 (Dropout)      (None, 384)               0         
                                                                 
 dense_2255 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_566 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_1790 (Dropout)      (None, 480)               0         
                                                                 
 dense_2256 (Dense)          (None, 288)               138528    
                                                                 
 dropout_1791 (Dropout)      (None, 288)               0         
                                                                 
 dense_2257 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 931674 (3.55 MB)
Trainable params: 930714 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 466:
  Value: 0.0373
  num_layers: 1
  units_0: 480
  activation_0: sigmoid
  dropout_0: 0.4
  batch_norm_0: False
  optimizer: ftrl
  learning_rate: 0.0015054783594708058

Model: "sequential_466"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_466 (Flatten)       (None, 784)               0         
                                                                 
 dense_2258 (Dense)          (None, 480)               376800    
                                                                 
 dropout_1792 (Dropout)      (None, 480)               0         
                                                                 
 dense_2259 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 467:
  Value: 0.9203
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002072248244564177

Model: "sequential_467"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_467 (Flatten)       (None, 784)               0         
                                                                 
 dense_2260 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1793 (Dropout)      (None, 512)               0         
                                                                 
 dense_2261 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1794 (Dropout)      (None, 416)               0         
                                                                 
 dense_2262 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_567 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1795 (Dropout)      (None, 512)               0         
                                                                 
 dense_2263 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1796 (Dropout)      (None, 288)               0         
                                                                 
 dense_2264 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 468:
  Value: 0.9222
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0020684069286742864

Model: "sequential_468"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_468 (Flatten)       (None, 784)               0         
                                                                 
 dense_2265 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1797 (Dropout)      (None, 512)               0         
                                                                 
 dense_2266 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1798 (Dropout)      (None, 448)               0         
                                                                 
 dense_2267 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_568 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1799 (Dropout)      (None, 512)               0         
                                                                 
 dense_2268 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1800 (Dropout)      (None, 288)               0         
                                                                 
 dense_2269 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 469:
  Value: 0.9133
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019237955725371827

Model: "sequential_469"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_469 (Flatten)       (None, 784)               0         
                                                                 
 dense_2270 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1801 (Dropout)      (None, 512)               0         
                                                                 
 dense_2271 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1802 (Dropout)      (None, 448)               0         
                                                                 
 dense_2272 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_569 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1803 (Dropout)      (None, 512)               0         
                                                                 
 dense_2273 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1804 (Dropout)      (None, 288)               0         
                                                                 
 dense_2274 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 470:
  Value: 0.7595
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0024034750440212883

Model: "sequential_470"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_470 (Flatten)       (None, 784)               0         
                                                                 
 dense_2275 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1805 (Dropout)      (None, 512)               0         
                                                                 
 dense_2276 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1806 (Dropout)      (None, 448)               0         
                                                                 
 dense_2277 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_570 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1807 (Dropout)      (None, 512)               0         
                                                                 
 dense_2278 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1808 (Dropout)      (None, 288)               0         
                                                                 
 dense_2279 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 471:
  Value: 0.9110
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0021611748505252805

Model: "sequential_471"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_471 (Flatten)       (None, 784)               0         
                                                                 
 dense_2280 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1809 (Dropout)      (None, 512)               0         
                                                                 
 dense_2281 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1810 (Dropout)      (None, 448)               0         
                                                                 
 dense_2282 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_571 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1811 (Dropout)      (None, 512)               0         
                                                                 
 dense_2283 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1812 (Dropout)      (None, 288)               0         
                                                                 
 dense_2284 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 472:
  Value: 0.8719
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019467890773200314

Model: "sequential_472"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_472 (Flatten)       (None, 784)               0         
                                                                 
 dense_2285 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1813 (Dropout)      (None, 512)               0         
                                                                 
 dense_2286 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1814 (Dropout)      (None, 448)               0         
                                                                 
 dense_2287 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_572 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1815 (Dropout)      (None, 512)               0         
                                                                 
 dense_2288 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1816 (Dropout)      (None, 288)               0         
                                                                 
 dense_2289 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 473:
  Value: 0.0699
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0020765807167845

Model: "sequential_473"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_473 (Flatten)       (None, 784)               0         
                                                                 
 dense_2290 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1817 (Dropout)      (None, 512)               0         
                                                                 
 dense_2291 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1818 (Dropout)      (None, 448)               0         
                                                                 
 dense_2292 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_573 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1819 (Dropout)      (None, 512)               0         
                                                                 
 dense_2293 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1820 (Dropout)      (None, 288)               0         
                                                                 
 dense_2294 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 474:
  Value: 0.8799
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0022136217943812637

Model: "sequential_474"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_474 (Flatten)       (None, 784)               0         
                                                                 
 dense_2295 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1821 (Dropout)      (None, 512)               0         
                                                                 
 dense_2296 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1822 (Dropout)      (None, 448)               0         
                                                                 
 dense_2297 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_574 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1823 (Dropout)      (None, 512)               0         
                                                                 
 dense_2298 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1824 (Dropout)      (None, 288)               0         
                                                                 
 dense_2299 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 475:
  Value: 0.9200
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010871674825986618

Model: "sequential_475"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_475 (Flatten)       (None, 784)               0         
                                                                 
 dense_2300 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1825 (Dropout)      (None, 512)               0         
                                                                 
 dense_2301 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1826 (Dropout)      (None, 448)               0         
                                                                 
 dense_2302 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_575 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1827 (Dropout)      (None, 512)               0         
                                                                 
 dense_2303 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1828 (Dropout)      (None, 288)               0         
                                                                 
 dense_2304 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 476:
  Value: 0.9219
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010660894799773464

Model: "sequential_476"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_476 (Flatten)       (None, 784)               0         
                                                                 
 dense_2305 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1829 (Dropout)      (None, 512)               0         
                                                                 
 dense_2306 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1830 (Dropout)      (None, 448)               0         
                                                                 
 dense_2307 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_576 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1831 (Dropout)      (None, 512)               0         
                                                                 
 dense_2308 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1832 (Dropout)      (None, 288)               0         
                                                                 
 dense_2309 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 477:
  Value: 0.8814
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010441739952674854

Model: "sequential_477"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_477 (Flatten)       (None, 784)               0         
                                                                 
 dense_2310 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1833 (Dropout)      (None, 512)               0         
                                                                 
 dense_2311 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1834 (Dropout)      (None, 448)               0         
                                                                 
 dense_2312 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_577 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1835 (Dropout)      (None, 512)               0         
                                                                 
 dense_2313 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1836 (Dropout)      (None, 288)               0         
                                                                 
 dense_2314 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 478:
  Value: 0.7745
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0010499289738135442

Model: "sequential_478"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_478 (Flatten)       (None, 784)               0         
                                                                 
 dense_2315 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1837 (Dropout)      (None, 512)               0         
                                                                 
 dense_2316 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1838 (Dropout)      (None, 448)               0         
                                                                 
 dense_2317 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_578 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1839 (Dropout)      (None, 512)               0         
                                                                 
 dense_2318 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1840 (Dropout)      (None, 288)               0         
                                                                 
 dense_2319 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 479:
  Value: 0.8289
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001141284824125652

Model: "sequential_479"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_479 (Flatten)       (None, 784)               0         
                                                                 
 dense_2320 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1841 (Dropout)      (None, 512)               0         
                                                                 
 dense_2321 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1842 (Dropout)      (None, 416)               0         
                                                                 
 dense_2322 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1843 (Dropout)      (None, 512)               0         
                                                                 
 dense_2323 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1844 (Dropout)      (None, 288)               0         
                                                                 
 dense_2324 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 984090 (3.75 MB)
Trainable params: 984090 (3.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 480:
  Value: 0.8448
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011458370198603313

Model: "sequential_480"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_480 (Flatten)       (None, 784)               0         
                                                                 
 dense_2325 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_579 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1845 (Dropout)      (None, 512)               0         
                                                                 
 dense_2326 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1846 (Dropout)      (None, 448)               0         
                                                                 
 dense_2327 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_580 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1847 (Dropout)      (None, 512)               0         
                                                                 
 dense_2328 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1848 (Dropout)      (None, 288)               0         
                                                                 
 dense_2329 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1020986 (3.89 MB)
Trainable params: 1018938 (3.89 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 481:
  Value: 0.8161
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003341441534556069

Model: "sequential_481"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_481 (Flatten)       (None, 784)               0         
                                                                 
 dense_2330 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1849 (Dropout)      (None, 512)               0         
                                                                 
 dense_2331 (Dense)          (None, 448)               229824    
                                                                 
 dropout_1850 (Dropout)      (None, 448)               0         
                                                                 
 dense_2332 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 482:
  Value: 0.9214
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012164765299729364

Model: "sequential_482"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_482 (Flatten)       (None, 784)               0         
                                                                 
 dense_2333 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1851 (Dropout)      (None, 512)               0         
                                                                 
 dense_2334 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1852 (Dropout)      (None, 416)               0         
                                                                 
 dense_2335 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_581 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1853 (Dropout)      (None, 512)               0         
                                                                 
 dense_2336 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1854 (Dropout)      (None, 288)               0         
                                                                 
 dense_2337 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 483:
  Value: 0.9213
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012013968847250274

Model: "sequential_483"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_483 (Flatten)       (None, 784)               0         
                                                                 
 dense_2338 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1855 (Dropout)      (None, 512)               0         
                                                                 
 dense_2339 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1856 (Dropout)      (None, 416)               0         
                                                                 
 dense_2340 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_582 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1857 (Dropout)      (None, 512)               0         
                                                                 
 dense_2341 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1858 (Dropout)      (None, 288)               0         
                                                                 
 dense_2342 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 484:
  Value: 0.6310
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010308688837523182

Model: "sequential_484"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_484 (Flatten)       (None, 784)               0         
                                                                 
 dense_2343 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1859 (Dropout)      (None, 512)               0         
                                                                 
 dense_2344 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_583 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_1860 (Dropout)      (None, 384)               0         
                                                                 
 dense_2345 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_584 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1861 (Dropout)      (None, 512)               0         
                                                                 
 dense_2346 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1862 (Dropout)      (None, 288)               0         
                                                                 
 dense_2347 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 954874 (3.64 MB)
Trainable params: 953082 (3.64 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 485:
  Value: 0.9201
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001179204063049312

Model: "sequential_485"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_485 (Flatten)       (None, 784)               0         
                                                                 
 dense_2348 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1863 (Dropout)      (None, 512)               0         
                                                                 
 dense_2349 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1864 (Dropout)      (None, 416)               0         
                                                                 
 dense_2350 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_585 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1865 (Dropout)      (None, 512)               0         
                                                                 
 dense_2351 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1866 (Dropout)      (None, 320)               0         
                                                                 
 dense_2352 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 486:
  Value: 0.9232
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012269468733843855

Model: "sequential_486"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_486 (Flatten)       (None, 784)               0         
                                                                 
 dense_2353 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1867 (Dropout)      (None, 512)               0         
                                                                 
 dense_2354 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1868 (Dropout)      (None, 416)               0         
                                                                 
 dense_2355 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_586 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1869 (Dropout)      (None, 512)               0         
                                                                 
 dense_2356 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1870 (Dropout)      (None, 320)               0         
                                                                 
 dense_2357 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 487:
  Value: 0.0417
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0012466473256278394

Model: "sequential_487"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_487 (Flatten)       (None, 784)               0         
                                                                 
 dense_2358 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1871 (Dropout)      (None, 512)               0         
                                                                 
 dense_2359 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1872 (Dropout)      (None, 416)               0         
                                                                 
 dense_2360 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_587 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1873 (Dropout)      (None, 512)               0         
                                                                 
 dense_2361 (Dense)          (None, 352)               180576    
                                                                 
 dropout_1874 (Dropout)      (None, 352)               0         
                                                                 
 dense_2362 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1020634 (3.89 MB)
Trainable params: 1019610 (3.89 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 488:
  Value: 0.7751
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012179838911897621

Model: "sequential_488"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_488 (Flatten)       (None, 784)               0         
                                                                 
 dense_2363 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1875 (Dropout)      (None, 512)               0         
                                                                 
 dense_2364 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1876 (Dropout)      (None, 416)               0         
                                                                 
 dense_2365 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_588 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1877 (Dropout)      (None, 512)               0         
                                                                 
 dense_2366 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1878 (Dropout)      (None, 320)               0         
                                                                 
 dense_2367 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 489:
  Value: 0.7819
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0024491020974013295

Model: "sequential_489"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_489 (Flatten)       (None, 784)               0         
                                                                 
 dense_2368 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1879 (Dropout)      (None, 512)               0         
                                                                 
 dense_2369 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1880 (Dropout)      (None, 384)               0         
                                                                 
 dense_2370 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_589 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1881 (Dropout)      (None, 512)               0         
                                                                 
 dense_2371 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1882 (Dropout)      (None, 320)               0         
                                                                 
 dense_2372 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 490:
  Value: 0.9181
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010058987380313683

Model: "sequential_490"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_490 (Flatten)       (None, 784)               0         
                                                                 
 dense_2373 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1883 (Dropout)      (None, 512)               0         
                                                                 
 dense_2374 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1884 (Dropout)      (None, 416)               0         
                                                                 
 dense_2375 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_590 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1885 (Dropout)      (None, 512)               0         
                                                                 
 dense_2376 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1886 (Dropout)      (None, 320)               0         
                                                                 
 dense_2377 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 491:
  Value: 0.7788
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005159527680482046

Model: "sequential_491"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_491 (Flatten)       (None, 784)               0         
                                                                 
 dense_2378 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1887 (Dropout)      (None, 512)               0         
                                                                 
 dense_2379 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1888 (Dropout)      (None, 416)               0         
                                                                 
 dense_2380 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_591 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1889 (Dropout)      (None, 512)               0         
                                                                 
 dense_2381 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1890 (Dropout)      (None, 320)               0         
                                                                 
 dense_2382 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 492:
  Value: 0.0373
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.003507811271641884

Model: "sequential_492"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_492 (Flatten)       (None, 784)               0         
                                                                 
 dense_2383 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1891 (Dropout)      (None, 512)               0         
                                                                 
 dense_2384 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1892 (Dropout)      (None, 416)               0         
                                                                 
 dense_2385 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_592 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1893 (Dropout)      (None, 512)               0         
                                                                 
 dense_2386 (Dense)          (None, 352)               180576    
                                                                 
 dropout_1894 (Dropout)      (None, 352)               0         
                                                                 
 dense_2387 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1020634 (3.89 MB)
Trainable params: 1019610 (3.89 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 493:
  Value: 0.9085
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001727895859459323

Model: "sequential_493"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_493 (Flatten)       (None, 784)               0         
                                                                 
 dense_2388 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1895 (Dropout)      (None, 512)               0         
                                                                 
 dense_2389 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1896 (Dropout)      (None, 384)               0         
                                                                 
 dense_2390 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_593 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1897 (Dropout)      (None, 512)               0         
                                                                 
 dense_2391 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1898 (Dropout)      (None, 320)               0         
                                                                 
 dense_2392 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 494:
  Value: 0.9208
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0026237841049845567

Model: "sequential_494"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_494 (Flatten)       (None, 784)               0         
                                                                 
 dense_2393 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1899 (Dropout)      (None, 512)               0         
                                                                 
 dense_2394 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1900 (Dropout)      (None, 416)               0         
                                                                 
 dense_2395 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_594 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1901 (Dropout)      (None, 512)               0         
                                                                 
 dense_2396 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1902 (Dropout)      (None, 320)               0         
                                                                 
 dense_2397 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 495:
  Value: 0.9215
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012519848246691655

Model: "sequential_495"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_495 (Flatten)       (None, 784)               0         
                                                                 
 dense_2398 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1903 (Dropout)      (None, 512)               0         
                                                                 
 dense_2399 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1904 (Dropout)      (None, 416)               0         
                                                                 
 dense_2400 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_595 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1905 (Dropout)      (None, 512)               0         
                                                                 
 dense_2401 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1906 (Dropout)      (None, 320)               0         
                                                                 
 dense_2402 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 496:
  Value: 0.9192
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002975704965222089

Model: "sequential_496"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_496 (Flatten)       (None, 784)               0         
                                                                 
 dense_2403 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1907 (Dropout)      (None, 512)               0         
                                                                 
 dense_2404 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1908 (Dropout)      (None, 416)               0         
                                                                 
 dense_2405 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_596 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1909 (Dropout)      (None, 512)               0         
                                                                 
 dense_2406 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1910 (Dropout)      (None, 320)               0         
                                                                 
 dense_2407 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 497:
  Value: 0.9200
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002667271626657124

Model: "sequential_497"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_497 (Flatten)       (None, 784)               0         
                                                                 
 dense_2408 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1911 (Dropout)      (None, 512)               0         
                                                                 
 dense_2409 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1912 (Dropout)      (None, 384)               0         
                                                                 
 dense_2410 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_597 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1913 (Dropout)      (None, 512)               0         
                                                                 
 dense_2411 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1914 (Dropout)      (None, 320)               0         
                                                                 
 dense_2412 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 498:
  Value: 0.9175
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012778867512173524

Model: "sequential_498"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_498 (Flatten)       (None, 784)               0         
                                                                 
 dense_2413 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1915 (Dropout)      (None, 512)               0         
                                                                 
 dense_2414 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1916 (Dropout)      (None, 416)               0         
                                                                 
 dense_2415 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_598 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1917 (Dropout)      (None, 512)               0         
                                                                 
 dense_2416 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1918 (Dropout)      (None, 320)               0         
                                                                 
 dense_2417 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 499:
  Value: 0.8486
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0022256084202246004

Model: "sequential_499"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_499 (Flatten)       (None, 784)               0         
                                                                 
 dense_2418 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_599 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1919 (Dropout)      (None, 512)               0         
                                                                 
 dense_2419 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1920 (Dropout)      (None, 416)               0         
                                                                 
 dense_2420 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_600 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1921 (Dropout)      (None, 512)               0         
                                                                 
 dense_2421 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1922 (Dropout)      (None, 320)               0         
                                                                 
 dense_2422 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1005434 (3.84 MB)
Trainable params: 1003386 (3.83 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 500:
  Value: 0.8328
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002656229232841645

Model: "sequential_500"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_500 (Flatten)       (None, 784)               0         
                                                                 
 dense_2423 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1923 (Dropout)      (None, 512)               0         
                                                                 
 dense_2424 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1924 (Dropout)      (None, 416)               0         
                                                                 
 dense_2425 (Dense)          (None, 512)               213504    
                                                                 
 dropout_1925 (Dropout)      (None, 512)               0         
                                                                 
 dense_2426 (Dense)          (None, 352)               180576    
                                                                 
 dropout_1926 (Dropout)      (None, 352)               0         
                                                                 
 dense_2427 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1018586 (3.89 MB)
Trainable params: 1018586 (3.89 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 501:
  Value: 0.0709
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.004171177666351541

Model: "sequential_501"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_501 (Flatten)       (None, 784)               0         
                                                                 
 dense_2428 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1927 (Dropout)      (None, 512)               0         
                                                                 
 dense_2429 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1928 (Dropout)      (None, 416)               0         
                                                                 
 dense_2430 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_601 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1929 (Dropout)      (None, 512)               0         
                                                                 
 dense_2431 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1930 (Dropout)      (None, 320)               0         
                                                                 
 dense_2432 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 502:
  Value: 0.9208
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0021808694417959837

Model: "sequential_502"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_502 (Flatten)       (None, 784)               0         
                                                                 
 dense_2433 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1931 (Dropout)      (None, 512)               0         
                                                                 
 dense_2434 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1932 (Dropout)      (None, 384)               0         
                                                                 
 dense_2435 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_602 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1933 (Dropout)      (None, 512)               0         
                                                                 
 dense_2436 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1934 (Dropout)      (None, 288)               0         
                                                                 
 dense_2437 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 503:
  Value: 0.9192
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 192
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0022682283999556556

Model: "sequential_503"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_503 (Flatten)       (None, 784)               0         
                                                                 
 dense_2438 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1935 (Dropout)      (None, 512)               0         
                                                                 
 dense_2439 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1936 (Dropout)      (None, 384)               0         
                                                                 
 dense_2440 (Dense)          (None, 192)               73920     
                                                                 
 batch_normalization_603 (B  (None, 192)               768       
 atchNormalization)                                              
                                                                 
 dropout_1937 (Dropout)      (None, 192)               0         
                                                                 
 dense_2441 (Dense)          (None, 320)               61760     
                                                                 
 dropout_1938 (Dropout)      (None, 320)               0         
                                                                 
 dense_2442 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 743706 (2.84 MB)
Trainable params: 743322 (2.84 MB)
Non-trainable params: 384 (1.50 KB)
_________________________________________________________________



Trial 504:
  Value: 0.7200
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0018517068186577515

Model: "sequential_504"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_504 (Flatten)       (None, 784)               0         
                                                                 
 dense_2443 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1939 (Dropout)      (None, 512)               0         
                                                                 
 dense_2444 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_604 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_1940 (Dropout)      (None, 416)               0         
                                                                 
 dense_2445 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_605 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1941 (Dropout)      (None, 512)               0         
                                                                 
 dense_2446 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1942 (Dropout)      (None, 288)               0         
                                                                 
 dense_2447 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 987802 (3.77 MB)
Trainable params: 985946 (3.76 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 505:
  Value: 0.9183
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0020048320379970285

Model: "sequential_505"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_505 (Flatten)       (None, 784)               0         
                                                                 
 dense_2448 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1943 (Dropout)      (None, 512)               0         
                                                                 
 dense_2449 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1944 (Dropout)      (None, 384)               0         
                                                                 
 dense_2450 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_606 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1945 (Dropout)      (None, 512)               0         
                                                                 
 dense_2451 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1946 (Dropout)      (None, 288)               0         
                                                                 
 dense_2452 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 506:
  Value: 0.9196
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017916362164271502

Model: "sequential_506"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_506 (Flatten)       (None, 784)               0         
                                                                 
 dense_2453 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1947 (Dropout)      (None, 512)               0         
                                                                 
 dense_2454 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1948 (Dropout)      (None, 416)               0         
                                                                 
 dense_2455 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_607 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1949 (Dropout)      (None, 512)               0         
                                                                 
 dense_2456 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1950 (Dropout)      (None, 288)               0         
                                                                 
 dense_2457 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 507:
  Value: 0.9171
  num_layers: 4
  units_0: 512
  units_1: 288
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0024866274800323454

Model: "sequential_507"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_507 (Flatten)       (None, 784)               0         
                                                                 
 dense_2458 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1951 (Dropout)      (None, 512)               0         
                                                                 
 dense_2459 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1952 (Dropout)      (None, 288)               0         
                                                                 
 dense_2460 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_608 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1953 (Dropout)      (None, 512)               0         
                                                                 
 dense_2461 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1954 (Dropout)      (None, 320)               0         
                                                                 
 dense_2462 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 872186 (3.33 MB)
Trainable params: 871162 (3.32 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 508:
  Value: 0.7944
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.002410093494925672

Model: "sequential_508"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_508 (Flatten)       (None, 784)               0         
                                                                 
 dense_2463 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1955 (Dropout)      (None, 512)               0         
                                                                 
 dense_2464 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1956 (Dropout)      (None, 384)               0         
                                                                 
 dense_2465 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_609 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1957 (Dropout)      (None, 512)               0         
                                                                 
 dense_2466 (Dense)          (None, 352)               180576    
                                                                 
 dropout_1958 (Dropout)      (None, 352)               0         
                                                                 
 dense_2467 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 987834 (3.77 MB)
Trainable params: 986810 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 509:
  Value: 0.7498
  num_layers: 4
  units_0: 320
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0021979312737516014

Model: "sequential_509"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_509 (Flatten)       (None, 784)               0         
                                                                 
 dense_2468 (Dense)          (None, 320)               251200    
                                                                 
 dropout_1959 (Dropout)      (None, 320)               0         
                                                                 
 dense_2469 (Dense)          (None, 416)               133536    
                                                                 
 dropout_1960 (Dropout)      (None, 416)               0         
                                                                 
 dense_2470 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_610 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1961 (Dropout)      (None, 512)               0         
                                                                 
 dense_2471 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1962 (Dropout)      (None, 288)               0         
                                                                 
 dense_2472 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 755546 (2.88 MB)
Trainable params: 754522 (2.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 510:
  Value: 0.7928
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.0
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001629961758445365

Model: "sequential_510"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_510 (Flatten)       (None, 784)               0         
                                                                 
 dense_2473 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1963 (Dropout)      (None, 512)               0         
                                                                 
 dense_2474 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1964 (Dropout)      (None, 416)               0         
                                                                 
 dense_2475 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_611 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1965 (Dropout)      (None, 512)               0         
                                                                 
 dense_2476 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1966 (Dropout)      (None, 288)               0         
                                                                 
 dense_2477 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 511:
  Value: 0.7569
  num_layers: 4
  units_0: 64
  units_1: 128
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013109422474771738

Model: "sequential_511"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_511 (Flatten)       (None, 784)               0         
                                                                 
 dense_2478 (Dense)          (None, 64)                50240     
                                                                 
 dropout_1967 (Dropout)      (None, 64)                0         
                                                                 
 dense_2479 (Dense)          (None, 128)               8320      
                                                                 
 dropout_1968 (Dropout)      (None, 128)               0         
                                                                 
 dense_2480 (Dense)          (None, 512)               66048     
                                                                 
 batch_normalization_612 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1969 (Dropout)      (None, 512)               0         
                                                                 
 dense_2481 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1970 (Dropout)      (None, 320)               0         
                                                                 
 dense_2482 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 299162 (1.14 MB)
Trainable params: 298138 (1.14 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 512:
  Value: 0.9202
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0020679013419071164

Model: "sequential_512"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_512 (Flatten)       (None, 784)               0         
                                                                 
 dense_2483 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1971 (Dropout)      (None, 512)               0         
                                                                 
 dense_2484 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1972 (Dropout)      (None, 416)               0         
                                                                 
 dense_2485 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_613 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1973 (Dropout)      (None, 512)               0         
                                                                 
 dense_2486 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1974 (Dropout)      (None, 288)               0         
                                                                 
 dense_2487 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 513:
  Value: 0.9200
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011712485156667478

Model: "sequential_513"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_513 (Flatten)       (None, 784)               0         
                                                                 
 dense_2488 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1975 (Dropout)      (None, 512)               0         
                                                                 
 dense_2489 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1976 (Dropout)      (None, 416)               0         
                                                                 
 dense_2490 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_614 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1977 (Dropout)      (None, 512)               0         
                                                                 
 dense_2491 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1978 (Dropout)      (None, 288)               0         
                                                                 
 dense_2492 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 514:
  Value: 0.0384
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0037723303794937836

Model: "sequential_514"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_514 (Flatten)       (None, 784)               0         
                                                                 
 dense_2493 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1979 (Dropout)      (None, 512)               0         
                                                                 
 dense_2494 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1980 (Dropout)      (None, 384)               0         
                                                                 
 dense_2495 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_615 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1981 (Dropout)      (None, 512)               0         
                                                                 
 dense_2496 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1982 (Dropout)      (None, 288)               0         
                                                                 
 dense_2497 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 515:
  Value: 0.9100
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014128585608144811

Model: "sequential_515"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_515 (Flatten)       (None, 784)               0         
                                                                 
 dense_2498 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1983 (Dropout)      (None, 512)               0         
                                                                 
 dense_2499 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1984 (Dropout)      (None, 416)               0         
                                                                 
 dense_2500 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_616 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1985 (Dropout)      (None, 512)               0         
                                                                 
 dense_2501 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1986 (Dropout)      (None, 320)               0         
                                                                 
 dense_2502 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 516:
  Value: 0.9085
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0027476755210054673

Model: "sequential_516"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_516 (Flatten)       (None, 784)               0         
                                                                 
 dense_2503 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1987 (Dropout)      (None, 512)               0         
                                                                 
 dense_2504 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1988 (Dropout)      (None, 416)               0         
                                                                 
 dense_2505 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_617 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1989 (Dropout)      (None, 512)               0         
                                                                 
 dense_2506 (Dense)          (None, 320)               164160    
                                                                 
 dropout_1990 (Dropout)      (None, 320)               0         
                                                                 
 dense_2507 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 517:
  Value: 0.7906
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0045442855996381355

Model: "sequential_517"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_517 (Flatten)       (None, 784)               0         
                                                                 
 dense_2508 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1991 (Dropout)      (None, 512)               0         
                                                                 
 dense_2509 (Dense)          (None, 416)               213408    
                                                                 
 dropout_1992 (Dropout)      (None, 416)               0         
                                                                 
 dense_2510 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_618 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1993 (Dropout)      (None, 512)               0         
                                                                 
 dense_2511 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1994 (Dropout)      (None, 288)               0         
                                                                 
 dense_2512 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 518:
  Value: 0.8347
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001296929896976892

Model: "sequential_518"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_518 (Flatten)       (None, 784)               0         
                                                                 
 dense_2513 (Dense)          (None, 512)               401920    
                                                                 
 dropout_1995 (Dropout)      (None, 512)               0         
                                                                 
 dense_2514 (Dense)          (None, 384)               196992    
                                                                 
 dropout_1996 (Dropout)      (None, 384)               0         
                                                                 
 dense_2515 (Dense)          (None, 512)               197120    
                                                                 
 dropout_1997 (Dropout)      (None, 512)               0         
                                                                 
 dense_2516 (Dense)          (None, 288)               147744    
                                                                 
 dropout_1998 (Dropout)      (None, 288)               0         
                                                                 
 dense_2517 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 951290 (3.63 MB)
Trainable params: 951290 (3.63 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 519:
  Value: 0.8389
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009108121946146329

Model: "sequential_519"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_519 (Flatten)       (None, 784)               0         
                                                                 
 dense_2518 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_619 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_1999 (Dropout)      (None, 512)               0         
                                                                 
 dense_2519 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2000 (Dropout)      (None, 416)               0         
                                                                 
 dense_2520 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_620 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2001 (Dropout)      (None, 512)               0         
                                                                 
 dense_2521 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2002 (Dropout)      (None, 288)               0         
                                                                 
 dense_2522 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 988186 (3.77 MB)
Trainable params: 986138 (3.76 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 520:
  Value: 0.8375
  num_layers: 4
  units_0: 512
  units_1: 96
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016259825268025148

Model: "sequential_520"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_520 (Flatten)       (None, 784)               0         
                                                                 
 dense_2523 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2003 (Dropout)      (None, 512)               0         
                                                                 
 dense_2524 (Dense)          (None, 96)                49248     
                                                                 
 dropout_2004 (Dropout)      (None, 96)                0         
                                                                 
 dense_2525 (Dense)          (None, 512)               49664     
                                                                 
 batch_normalization_621 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2005 (Dropout)      (None, 512)               0         
                                                                 
 dense_2526 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2006 (Dropout)      (None, 288)               0         
                                                                 
 dense_2527 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 658138 (2.51 MB)
Trainable params: 657114 (2.51 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 521:
  Value: 0.9186
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002973405252569167

Model: "sequential_521"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_521 (Flatten)       (None, 784)               0         
                                                                 
 dense_2528 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2007 (Dropout)      (None, 512)               0         
                                                                 
 dense_2529 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2008 (Dropout)      (None, 416)               0         
                                                                 
 dense_2530 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_622 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2009 (Dropout)      (None, 512)               0         
                                                                 
 dense_2531 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2010 (Dropout)      (None, 320)               0         
                                                                 
 dense_2532 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 522:
  Value: 0.0417
  num_layers: 3
  units_0: 512
  units_1: 416
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: ftrl
  learning_rate: 0.0011514326725649195

Model: "sequential_522"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_522 (Flatten)       (None, 784)               0         
                                                                 
 dense_2533 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2011 (Dropout)      (None, 512)               0         
                                                                 
 dense_2534 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2012 (Dropout)      (None, 416)               0         
                                                                 
 dense_2535 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_623 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2013 (Dropout)      (None, 512)               0         
                                                                 
 dense_2536 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 844218 (3.22 MB)
Trainable params: 843194 (3.22 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 523:
  Value: 0.5373
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 160
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0018398428955722658

Model: "sequential_523"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_523 (Flatten)       (None, 784)               0         
                                                                 
 dense_2537 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2014 (Dropout)      (None, 512)               0         
                                                                 
 dense_2538 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_624 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2015 (Dropout)      (None, 448)               0         
                                                                 
 dense_2539 (Dense)          (None, 160)               71840     
                                                                 
 batch_normalization_625 (B  (None, 160)               640       
 atchNormalization)                                              
                                                                 
 dropout_2016 (Dropout)      (None, 160)               0         
                                                                 
 dense_2540 (Dense)          (None, 352)               56672     
                                                                 
 dropout_2017 (Dropout)      (None, 352)               0         
                                                                 
 dense_2541 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 771866 (2.94 MB)
Trainable params: 770650 (2.94 MB)
Non-trainable params: 1216 (4.75 KB)
_________________________________________________________________



Trial 524:
  Value: 0.7689
  num_layers: 4
  units_0: 96
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.006078914142246224

Model: "sequential_524"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_524 (Flatten)       (None, 784)               0         
                                                                 
 dense_2542 (Dense)          (None, 96)                75360     
                                                                 
 dropout_2018 (Dropout)      (None, 96)                0         
                                                                 
 dense_2543 (Dense)          (None, 416)               40352     
                                                                 
 dropout_2019 (Dropout)      (None, 416)               0         
                                                                 
 dense_2544 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_626 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2020 (Dropout)      (None, 512)               0         
                                                                 
 dense_2545 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2021 (Dropout)      (None, 288)               0         
                                                                 
 dense_2546 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 486522 (1.86 MB)
Trainable params: 485498 (1.85 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 525:
  Value: 0.9230
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014895575852087335

Model: "sequential_525"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_525 (Flatten)       (None, 784)               0         
                                                                 
 dense_2547 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2022 (Dropout)      (None, 512)               0         
                                                                 
 dense_2548 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2023 (Dropout)      (None, 384)               0         
                                                                 
 dense_2549 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_627 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2024 (Dropout)      (None, 480)               0         
                                                                 
 dense_2550 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2025 (Dropout)      (None, 288)               0         
                                                                 
 dense_2551 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 931674 (3.55 MB)
Trainable params: 930714 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 526:
  Value: 0.9189
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001514775909242667

Model: "sequential_526"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_526 (Flatten)       (None, 784)               0         
                                                                 
 dense_2552 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2026 (Dropout)      (None, 512)               0         
                                                                 
 dense_2553 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2027 (Dropout)      (None, 384)               0         
                                                                 
 dense_2554 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_628 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2028 (Dropout)      (None, 512)               0         
                                                                 
 dense_2555 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2029 (Dropout)      (None, 288)               0         
                                                                 
 dense_2556 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 527:
  Value: 0.9181
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002084127177389759

Model: "sequential_527"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_527 (Flatten)       (None, 784)               0         
                                                                 
 dense_2557 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2030 (Dropout)      (None, 512)               0         
                                                                 
 dense_2558 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2031 (Dropout)      (None, 384)               0         
                                                                 
 dense_2559 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_629 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2032 (Dropout)      (None, 480)               0         
                                                                 
 dense_2560 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2033 (Dropout)      (None, 320)               0         
                                                                 
 dense_2561 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 947898 (3.62 MB)
Trainable params: 946938 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 528:
  Value: 0.9213
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014408292505314428

Model: "sequential_528"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_528 (Flatten)       (None, 784)               0         
                                                                 
 dense_2562 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2034 (Dropout)      (None, 512)               0         
                                                                 
 dense_2563 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2035 (Dropout)      (None, 384)               0         
                                                                 
 dense_2564 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_630 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2036 (Dropout)      (None, 512)               0         
                                                                 
 dense_2565 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2037 (Dropout)      (None, 320)               0         
                                                                 
 dense_2566 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 529:
  Value: 0.8273
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.001424396198406918

Model: "sequential_529"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_529 (Flatten)       (None, 784)               0         
                                                                 
 dense_2567 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2038 (Dropout)      (None, 512)               0         
                                                                 
 dense_2568 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 530:
  Value: 0.0412
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0016152648241518617

Model: "sequential_530"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_530 (Flatten)       (None, 784)               0         
                                                                 
 dense_2569 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2039 (Dropout)      (None, 512)               0         
                                                                 
 dense_2570 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2040 (Dropout)      (None, 384)               0         
                                                                 
 dense_2571 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_631 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2041 (Dropout)      (None, 480)               0         
                                                                 
 dense_2572 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2042 (Dropout)      (None, 320)               0         
                                                                 
 dense_2573 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 947898 (3.62 MB)
Trainable params: 946938 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 531:
  Value: 0.7772
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 352
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.003359032881809095

Model: "sequential_531"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_531 (Flatten)       (None, 784)               0         
                                                                 
 dense_2574 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2043 (Dropout)      (None, 512)               0         
                                                                 
 dense_2575 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2044 (Dropout)      (None, 384)               0         
                                                                 
 dense_2576 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_632 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2045 (Dropout)      (None, 512)               0         
                                                                 
 dense_2577 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2046 (Dropout)      (None, 352)               0         
                                                                 
 dense_2578 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 987834 (3.77 MB)
Trainable params: 986810 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 532:
  Value: 0.9202
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014611758776180447

Model: "sequential_532"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_532 (Flatten)       (None, 784)               0         
                                                                 
 dense_2579 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2047 (Dropout)      (None, 512)               0         
                                                                 
 dense_2580 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2048 (Dropout)      (None, 384)               0         
                                                                 
 dense_2581 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_633 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2049 (Dropout)      (None, 512)               0         
                                                                 
 dense_2582 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2050 (Dropout)      (None, 320)               0         
                                                                 
 dense_2583 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 533:
  Value: 0.9166
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000967857522745203

Model: "sequential_533"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_533 (Flatten)       (None, 784)               0         
                                                                 
 dense_2584 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2051 (Dropout)      (None, 512)               0         
                                                                 
 dense_2585 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2052 (Dropout)      (None, 384)               0         
                                                                 
 dense_2586 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_634 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2053 (Dropout)      (None, 480)               0         
                                                                 
 dense_2587 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2054 (Dropout)      (None, 320)               0         
                                                                 
 dense_2588 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 947898 (3.62 MB)
Trainable params: 946938 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 534:
  Value: 0.7718
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0013347670736573829

Model: "sequential_534"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_534 (Flatten)       (None, 784)               0         
                                                                 
 dense_2589 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2055 (Dropout)      (None, 512)               0         
                                                                 
 dense_2590 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2056 (Dropout)      (None, 384)               0         
                                                                 
 dense_2591 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_635 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2057 (Dropout)      (None, 512)               0         
                                                                 
 dense_2592 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2058 (Dropout)      (None, 320)               0         
                                                                 
 dense_2593 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 535:
  Value: 0.8555
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012057144407326696

Model: "sequential_535"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_535 (Flatten)       (None, 784)               0         
                                                                 
 dense_2594 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2059 (Dropout)      (None, 512)               0         
                                                                 
 dense_2595 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2060 (Dropout)      (None, 384)               0         
                                                                 
 dense_2596 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_636 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2061 (Dropout)      (None, 480)               0         
                                                                 
 dense_2597 (Dense)          (None, 352)               169312    
                                                                 
 dropout_2062 (Dropout)      (None, 352)               0         
                                                                 
 dense_2598 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 964122 (3.68 MB)
Trainable params: 963162 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 536:
  Value: 0.9190
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010756441410188537

Model: "sequential_536"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_536 (Flatten)       (None, 784)               0         
                                                                 
 dense_2599 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2063 (Dropout)      (None, 512)               0         
                                                                 
 dense_2600 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2064 (Dropout)      (None, 416)               0         
                                                                 
 dense_2601 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_637 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2065 (Dropout)      (None, 512)               0         
                                                                 
 dense_2602 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2066 (Dropout)      (None, 320)               0         
                                                                 
 dense_2603 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 537:
  Value: 0.9183
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015483999766378932

Model: "sequential_537"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_537 (Flatten)       (None, 784)               0         
                                                                 
 dense_2604 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2067 (Dropout)      (None, 512)               0         
                                                                 
 dense_2605 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2068 (Dropout)      (None, 416)               0         
                                                                 
 dense_2606 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_638 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2069 (Dropout)      (None, 512)               0         
                                                                 
 dense_2607 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2070 (Dropout)      (None, 320)               0         
                                                                 
 dense_2608 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 538:
  Value: 0.8404
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017332801092804753

Model: "sequential_538"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_538 (Flatten)       (None, 784)               0         
                                                                 
 dense_2609 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2071 (Dropout)      (None, 512)               0         
                                                                 
 dense_2610 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2072 (Dropout)      (None, 416)               0         
                                                                 
 dense_2611 (Dense)          (None, 480)               200160    
                                                                 
 dropout_2073 (Dropout)      (None, 480)               0         
                                                                 
 dense_2612 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2074 (Dropout)      (None, 288)               0         
                                                                 
 dense_2613 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 961530 (3.67 MB)
Trainable params: 961530 (3.67 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 539:
  Value: 0.9123
  num_layers: 4
  units_0: 512
  units_1: 288
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0030667449368500335

Model: "sequential_539"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_539 (Flatten)       (None, 784)               0         
                                                                 
 dense_2614 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_639 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2075 (Dropout)      (None, 512)               0         
                                                                 
 dense_2615 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2076 (Dropout)      (None, 288)               0         
                                                                 
 dense_2616 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_640 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2077 (Dropout)      (None, 512)               0         
                                                                 
 dense_2617 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2078 (Dropout)      (None, 288)               0         
                                                                 
 dense_2618 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 856986 (3.27 MB)
Trainable params: 854938 (3.26 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 540:
  Value: 0.8528
  num_layers: 4
  units_0: 352
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013599129974332844

Model: "sequential_540"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_540 (Flatten)       (None, 784)               0         
                                                                 
 dense_2619 (Dense)          (None, 352)               276320    
                                                                 
 dropout_2079 (Dropout)      (None, 352)               0         
                                                                 
 dense_2620 (Dense)          (None, 384)               135552    
                                                                 
 dropout_2080 (Dropout)      (None, 384)               0         
                                                                 
 dense_2621 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_641 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2081 (Dropout)      (None, 480)               0         
                                                                 
 dense_2622 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2082 (Dropout)      (None, 288)               0         
                                                                 
 dense_2623 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 744634 (2.84 MB)
Trainable params: 743674 (2.84 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 541:
  Value: 0.8448
  num_layers: 4
  units_0: 320
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010871621893811247

Model: "sequential_541"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_541 (Flatten)       (None, 784)               0         
                                                                 
 dense_2624 (Dense)          (None, 320)               251200    
                                                                 
 dropout_2083 (Dropout)      (None, 320)               0         
                                                                 
 dense_2625 (Dense)          (None, 448)               143808    
                                                                 
 dropout_2084 (Dropout)      (None, 448)               0         
                                                                 
 dense_2626 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_642 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2085 (Dropout)      (None, 512)               0         
                                                                 
 dense_2627 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2086 (Dropout)      (None, 288)               0         
                                                                 
 dense_2628 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 782202 (2.98 MB)
Trainable params: 781178 (2.98 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 542:
  Value: 0.0329
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.5
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0009304264969297871

Model: "sequential_542"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_542 (Flatten)       (None, 784)               0         
                                                                 
 dense_2629 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2087 (Dropout)      (None, 512)               0         
                                                                 
 dense_2630 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2088 (Dropout)      (None, 416)               0         
                                                                 
 dense_2631 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_643 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2089 (Dropout)      (None, 512)               0         
                                                                 
 dense_2632 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2090 (Dropout)      (None, 320)               0         
                                                                 
 dense_2633 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 543:
  Value: 0.8820
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012434570633248583

Model: "sequential_543"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_543 (Flatten)       (None, 784)               0         
                                                                 
 dense_2634 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2091 (Dropout)      (None, 512)               0         
                                                                 
 dense_2635 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2092 (Dropout)      (None, 416)               0         
                                                                 
 dense_2636 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_644 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2093 (Dropout)      (None, 480)               0         
                                                                 
 dense_2637 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2094 (Dropout)      (None, 288)               0         
                                                                 
 dense_2638 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 544:
  Value: 0.6845
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015094828144595908

Model: "sequential_544"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_544 (Flatten)       (None, 784)               0         
                                                                 
 dense_2639 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2095 (Dropout)      (None, 512)               0         
                                                                 
 dense_2640 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_645 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_2096 (Dropout)      (None, 384)               0         
                                                                 
 dense_2641 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_646 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2097 (Dropout)      (None, 512)               0         
                                                                 
 dense_2642 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2098 (Dropout)      (None, 320)               0         
                                                                 
 dense_2643 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 972122 (3.71 MB)
Trainable params: 970330 (3.70 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 545:
  Value: 0.9210
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0026577625922491544

Model: "sequential_545"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_545 (Flatten)       (None, 784)               0         
                                                                 
 dense_2644 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2099 (Dropout)      (None, 512)               0         
                                                                 
 dense_2645 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2100 (Dropout)      (None, 448)               0         
                                                                 
 dense_2646 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_647 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2101 (Dropout)      (None, 480)               0         
                                                                 
 dense_2647 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2102 (Dropout)      (None, 288)               0         
                                                                 
 dense_2648 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 546:
  Value: 0.8054
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0025717993692459264

Model: "sequential_546"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_546 (Flatten)       (None, 784)               0         
                                                                 
 dense_2649 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2103 (Dropout)      (None, 512)               0         
                                                                 
 dense_2650 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2104 (Dropout)      (None, 448)               0         
                                                                 
 dense_2651 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_648 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2105 (Dropout)      (None, 480)               0         
                                                                 
 dense_2652 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2106 (Dropout)      (None, 288)               0         
                                                                 
 dense_2653 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 547:
  Value: 0.7288
  num_layers: 2
  units_0: 128
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0027977199862167256

Model: "sequential_547"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_547 (Flatten)       (None, 784)               0         
                                                                 
 dense_2654 (Dense)          (None, 128)               100480    
                                                                 
 dropout_2107 (Dropout)      (None, 128)               0         
                                                                 
 dense_2655 (Dense)          (None, 448)               57792     
                                                                 
 dropout_2108 (Dropout)      (None, 448)               0         
                                                                 
 dense_2656 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 169946 (663.85 KB)
Trainable params: 169946 (663.85 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 548:
  Value: 0.0378
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0024946375484001643

Model: "sequential_548"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_548 (Flatten)       (None, 784)               0         
                                                                 
 dense_2657 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2109 (Dropout)      (None, 512)               0         
                                                                 
 dense_2658 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2110 (Dropout)      (None, 448)               0         
                                                                 
 dense_2659 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_649 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2111 (Dropout)      (None, 480)               0         
                                                                 
 dense_2660 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2112 (Dropout)      (None, 288)               0         
                                                                 
 dense_2661 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 549:
  Value: 0.9194
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0023021279078692036

Model: "sequential_549"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_549 (Flatten)       (None, 784)               0         
                                                                 
 dense_2662 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2113 (Dropout)      (None, 512)               0         
                                                                 
 dense_2663 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2114 (Dropout)      (None, 416)               0         
                                                                 
 dense_2664 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_650 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2115 (Dropout)      (None, 480)               0         
                                                                 
 dense_2665 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2116 (Dropout)      (None, 288)               0         
                                                                 
 dense_2666 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 550:
  Value: 0.5612
  num_layers: 3
  units_0: 512
  units_1: 448
  units_2: 480
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.0
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0036497308928556986

Model: "sequential_550"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_550 (Flatten)       (None, 784)               0         
                                                                 
 dense_2667 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2117 (Dropout)      (None, 512)               0         
                                                                 
 dense_2668 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2118 (Dropout)      (None, 448)               0         
                                                                 
 dense_2669 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_651 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2119 (Dropout)      (None, 480)               0         
                                                                 
 dense_2670 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 861690 (3.29 MB)
Trainable params: 860730 (3.28 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 551:
  Value: 0.8196
  num_layers: 4
  units_0: 512
  units_1: 64
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00314115853892475

Model: "sequential_551"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_551 (Flatten)       (None, 784)               0         
                                                                 
 dense_2671 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2120 (Dropout)      (None, 512)               0         
                                                                 
 dense_2672 (Dense)          (None, 64)                32832     
                                                                 
 dropout_2121 (Dropout)      (None, 64)                0         
                                                                 
 dense_2673 (Dense)          (None, 480)               31200     
                                                                 
 batch_normalization_652 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2122 (Dropout)      (None, 480)               0         
                                                                 
 dense_2674 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2123 (Dropout)      (None, 288)               0         
                                                                 
 dense_2675 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 613914 (2.34 MB)
Trainable params: 612954 (2.34 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 552:
  Value: 0.8364
  num_layers: 4
  units_0: 256
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0029039742077245816

Model: "sequential_552"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_552 (Flatten)       (None, 784)               0         
                                                                 
 dense_2676 (Dense)          (None, 256)               200960    
                                                                 
 dropout_2124 (Dropout)      (None, 256)               0         
                                                                 
 dense_2677 (Dense)          (None, 416)               106912    
                                                                 
 dropout_2125 (Dropout)      (None, 416)               0         
                                                                 
 dense_2678 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_653 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2126 (Dropout)      (None, 480)               0         
                                                                 
 dense_2679 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2127 (Dropout)      (None, 320)               0         
                                                                 
 dense_2680 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 672218 (2.56 MB)
Trainable params: 671258 (2.56 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 553:
  Value: 0.7718
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0031586293958345405

Model: "sequential_553"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_553 (Flatten)       (None, 784)               0         
                                                                 
 dense_2681 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2128 (Dropout)      (None, 512)               0         
                                                                 
 dense_2682 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2129 (Dropout)      (None, 448)               0         
                                                                 
 dense_2683 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_654 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2130 (Dropout)      (None, 512)               0         
                                                                 
 dense_2684 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2131 (Dropout)      (None, 288)               0         
                                                                 
 dense_2685 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 554:
  Value: 0.9198
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0028459669783490447

Model: "sequential_554"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_554 (Flatten)       (None, 784)               0         
                                                                 
 dense_2686 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2132 (Dropout)      (None, 512)               0         
                                                                 
 dense_2687 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2133 (Dropout)      (None, 416)               0         
                                                                 
 dense_2688 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_655 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2134 (Dropout)      (None, 480)               0         
                                                                 
 dense_2689 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2135 (Dropout)      (None, 320)               0         
                                                                 
 dense_2690 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 979674 (3.74 MB)
Trainable params: 978714 (3.73 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 555:
  Value: 0.9163
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.003823434131438496

Model: "sequential_555"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_555 (Flatten)       (None, 784)               0         
                                                                 
 dense_2691 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2136 (Dropout)      (None, 512)               0         
                                                                 
 dense_2692 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2137 (Dropout)      (None, 416)               0         
                                                                 
 dense_2693 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_656 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2138 (Dropout)      (None, 512)               0         
                                                                 
 dense_2694 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2139 (Dropout)      (None, 288)               0         
                                                                 
 dense_2695 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 556:
  Value: 0.9184
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010107417356994936

Model: "sequential_556"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_556 (Flatten)       (None, 784)               0         
                                                                 
 dense_2696 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2140 (Dropout)      (None, 512)               0         
                                                                 
 dense_2697 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2141 (Dropout)      (None, 384)               0         
                                                                 
 dense_2698 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_657 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2142 (Dropout)      (None, 512)               0         
                                                                 
 dense_2699 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2143 (Dropout)      (None, 320)               0         
                                                                 
 dense_2700 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 557:
  Value: 0.8417
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013472549794346592

Model: "sequential_557"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_557 (Flatten)       (None, 784)               0         
                                                                 
 dense_2701 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_658 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2144 (Dropout)      (None, 512)               0         
                                                                 
 dense_2702 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2145 (Dropout)      (None, 448)               0         
                                                                 
 dense_2703 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_659 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2146 (Dropout)      (None, 480)               0         
                                                                 
 dense_2704 (Dense)          (None, 352)               169312    
                                                                 
 dropout_2147 (Dropout)      (None, 352)               0         
                                                                 
 dense_2705 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1029722 (3.93 MB)
Trainable params: 1027738 (3.92 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 558:
  Value: 0.1078
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.003317812447999144

Model: "sequential_558"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_558 (Flatten)       (None, 784)               0         
                                                                 
 dense_2706 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2148 (Dropout)      (None, 480)               0         
                                                                 
 dense_2707 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2149 (Dropout)      (None, 448)               0         
                                                                 
 dense_2708 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_660 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2150 (Dropout)      (None, 480)               0         
                                                                 
 dense_2709 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2151 (Dropout)      (None, 288)               0         
                                                                 
 dense_2710 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 559:
  Value: 0.8242
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011563423600990572

Model: "sequential_559"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_559 (Flatten)       (None, 784)               0         
                                                                 
 dense_2711 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2152 (Dropout)      (None, 512)               0         
                                                                 
 dense_2712 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2153 (Dropout)      (None, 416)               0         
                                                                 
 dense_2713 (Dense)          (None, 512)               213504    
                                                                 
 dropout_2154 (Dropout)      (None, 512)               0         
                                                                 
 dense_2714 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2155 (Dropout)      (None, 288)               0         
                                                                 
 dense_2715 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 984090 (3.75 MB)
Trainable params: 984090 (3.75 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 560:
  Value: 0.8606
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016266516053542322

Model: "sequential_560"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_560 (Flatten)       (None, 784)               0         
                                                                 
 dense_2716 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2156 (Dropout)      (None, 480)               0         
                                                                 
 dense_2717 (Dense)          (None, 384)               184704    
                                                                 
 dropout_2157 (Dropout)      (None, 384)               0         
                                                                 
 dense_2718 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_661 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2158 (Dropout)      (None, 512)               0         
                                                                 
 dense_2719 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2159 (Dropout)      (None, 320)               0         
                                                                 
 dense_2720 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 933178 (3.56 MB)
Trainable params: 932154 (3.56 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 561:
  Value: 0.9118
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017797934550130286

Model: "sequential_561"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_561 (Flatten)       (None, 784)               0         
                                                                 
 dense_2721 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2160 (Dropout)      (None, 512)               0         
                                                                 
 dense_2722 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2161 (Dropout)      (None, 448)               0         
                                                                 
 dense_2723 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_662 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2162 (Dropout)      (None, 480)               0         
                                                                 
 dense_2724 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2163 (Dropout)      (None, 288)               0         
                                                                 
 dense_2725 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 562:
  Value: 0.8816
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0025375702203104485

Model: "sequential_562"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_562 (Flatten)       (None, 784)               0         
                                                                 
 dense_2726 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2164 (Dropout)      (None, 480)               0         
                                                                 
 dense_2727 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2165 (Dropout)      (None, 416)               0         
                                                                 
 dense_2728 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_663 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2166 (Dropout)      (None, 512)               0         
                                                                 
 dense_2729 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2167 (Dropout)      (None, 288)               0         
                                                                 
 dense_2730 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 563:
  Value: 0.8222
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.002281115224980412

Model: "sequential_563"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_563 (Flatten)       (None, 784)               0         
                                                                 
 dense_2731 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2168 (Dropout)      (None, 512)               0         
                                                                 
 dense_2732 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_664 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2169 (Dropout)      (None, 448)               0         
                                                                 
 dense_2733 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_665 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2170 (Dropout)      (None, 512)               0         
                                                                 
 dense_2734 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2171 (Dropout)      (None, 320)               0         
                                                                 
 dense_2735 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1037978 (3.96 MB)
Trainable params: 1036058 (3.95 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 564:
  Value: 0.8609
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013034761326247979

Model: "sequential_564"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_564 (Flatten)       (None, 784)               0         
                                                                 
 dense_2736 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2172 (Dropout)      (None, 480)               0         
                                                                 
 dense_2737 (Dense)          (None, 384)               184704    
                                                                 
 dropout_2173 (Dropout)      (None, 384)               0         
                                                                 
 dense_2738 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_666 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2174 (Dropout)      (None, 480)               0         
                                                                 
 dense_2739 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2175 (Dropout)      (None, 288)               0         
                                                                 
 dense_2740 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 894266 (3.41 MB)
Trainable params: 893306 (3.41 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 565:
  Value: 0.9182
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.009684450914024773

Model: "sequential_565"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_565 (Flatten)       (None, 784)               0         
                                                                 
 dense_2741 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2176 (Dropout)      (None, 512)               0         
                                                                 
 dense_2742 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2177 (Dropout)      (None, 416)               0         
                                                                 
 dense_2743 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_667 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2178 (Dropout)      (None, 512)               0         
                                                                 
 dense_2744 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2179 (Dropout)      (None, 288)               0         
                                                                 
 dense_2745 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 566:
  Value: 0.8571
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001128165922362706

Model: "sequential_566"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_566 (Flatten)       (None, 784)               0         
                                                                 
 dense_2746 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2180 (Dropout)      (None, 480)               0         
                                                                 
 dense_2747 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2181 (Dropout)      (None, 416)               0         
                                                                 
 dense_2748 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_668 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2182 (Dropout)      (None, 480)               0         
                                                                 
 dense_2749 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2183 (Dropout)      (None, 256)               0         
                                                                 
 dense_2750 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 908794 (3.47 MB)
Trainable params: 907834 (3.46 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 567:
  Value: 0.9199
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014099771176028517

Model: "sequential_567"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_567 (Flatten)       (None, 784)               0         
                                                                 
 dense_2751 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2184 (Dropout)      (None, 512)               0         
                                                                 
 dense_2752 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2185 (Dropout)      (None, 448)               0         
                                                                 
 dense_2753 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_669 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2186 (Dropout)      (None, 512)               0         
                                                                 
 dense_2754 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2187 (Dropout)      (None, 320)               0         
                                                                 
 dense_2755 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1036186 (3.95 MB)
Trainable params: 1035162 (3.95 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 568:
  Value: 0.8583
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012510176127171332

Model: "sequential_568"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_568 (Flatten)       (None, 784)               0         
                                                                 
 dense_2756 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2188 (Dropout)      (None, 480)               0         
                                                                 
 dense_2757 (Dense)          (None, 352)               169312    
                                                                 
 dropout_2189 (Dropout)      (None, 352)               0         
                                                                 
 dense_2758 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_670 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2190 (Dropout)      (None, 512)               0         
                                                                 
 dense_2759 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2191 (Dropout)      (None, 288)               0         
                                                                 
 dense_2760 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 884154 (3.37 MB)
Trainable params: 883130 (3.37 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 569:
  Value: 0.9193
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00483333529827939

Model: "sequential_569"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_569 (Flatten)       (None, 784)               0         
                                                                 
 dense_2761 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2192 (Dropout)      (None, 512)               0         
                                                                 
 dense_2762 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2193 (Dropout)      (None, 416)               0         
                                                                 
 dense_2763 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_671 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2194 (Dropout)      (None, 480)               0         
                                                                 
 dense_2764 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2195 (Dropout)      (None, 256)               0         
                                                                 
 dense_2765 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 947226 (3.61 MB)
Trainable params: 946266 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 570:
  Value: 0.0411
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0018951113509486487

Model: "sequential_570"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_570 (Flatten)       (None, 784)               0         
                                                                 
 dense_2766 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2196 (Dropout)      (None, 480)               0         
                                                                 
 dense_2767 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2197 (Dropout)      (None, 448)               0         
                                                                 
 dense_2768 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_672 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2198 (Dropout)      (None, 512)               0         
                                                                 
 dense_2769 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2199 (Dropout)      (None, 320)               0         
                                                                 
 dense_2770 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 571:
  Value: 0.8735
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010235671014266932

Model: "sequential_571"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_571 (Flatten)       (None, 784)               0         
                                                                 
 dense_2771 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2200 (Dropout)      (None, 512)               0         
                                                                 
 dense_2772 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2201 (Dropout)      (None, 384)               0         
                                                                 
 dense_2773 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_673 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2202 (Dropout)      (None, 480)               0         
                                                                 
 dense_2774 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2203 (Dropout)      (None, 288)               0         
                                                                 
 dense_2775 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 931674 (3.55 MB)
Trainable params: 930714 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 572:
  Value: 0.8598
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008806615181575203

Model: "sequential_572"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_572 (Flatten)       (None, 784)               0         
                                                                 
 dense_2776 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2204 (Dropout)      (None, 480)               0         
                                                                 
 dense_2777 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2205 (Dropout)      (None, 416)               0         
                                                                 
 dense_2778 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_674 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2206 (Dropout)      (None, 512)               0         
                                                                 
 dense_2779 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2207 (Dropout)      (None, 288)               0         
                                                                 
 dense_2780 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 573:
  Value: 0.8373
  num_layers: 3
  units_0: 512
  units_1: 416
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: rmsprop
  learning_rate: 0.0015004816479543212

Model: "sequential_573"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_573 (Flatten)       (None, 784)               0         
                                                                 
 dense_2781 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2208 (Dropout)      (None, 512)               0         
                                                                 
 dense_2782 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2209 (Dropout)      (None, 416)               0         
                                                                 
 dense_2783 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_675 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2210 (Dropout)      (None, 512)               0         
                                                                 
 dense_2784 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 844218 (3.22 MB)
Trainable params: 843194 (3.22 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 574:
  Value: 0.7675
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.003999471628169767

Model: "sequential_574"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_574 (Flatten)       (None, 784)               0         
                                                                 
 dense_2785 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2211 (Dropout)      (None, 480)               0         
                                                                 
 dense_2786 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2212 (Dropout)      (None, 448)               0         
                                                                 
 dense_2787 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_676 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2213 (Dropout)      (None, 480)               0         
                                                                 
 dense_2788 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2214 (Dropout)      (None, 320)               0         
                                                                 
 dense_2789 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 971994 (3.71 MB)
Trainable params: 971034 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 575:
  Value: 0.8714
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.003566547404472348

Model: "sequential_575"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_575 (Flatten)       (None, 784)               0         
                                                                 
 dense_2790 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2215 (Dropout)      (None, 512)               0         
                                                                 
 dense_2791 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2216 (Dropout)      (None, 448)               0         
                                                                 
 dense_2792 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_677 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2217 (Dropout)      (None, 512)               0         
                                                                 
 dense_2793 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2218 (Dropout)      (None, 384)               0         
                                                                 
 dense_2794 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 1070682 (4.08 MB)
Trainable params: 1069658 (4.08 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 576:
  Value: 0.0393
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0026622792651550212

Model: "sequential_576"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_576 (Flatten)       (None, 784)               0         
                                                                 
 dense_2795 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2219 (Dropout)      (None, 512)               0         
                                                                 
 dense_2796 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2220 (Dropout)      (None, 384)               0         
                                                                 
 dense_2797 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_678 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2221 (Dropout)      (None, 480)               0         
                                                                 
 dense_2798 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2222 (Dropout)      (None, 288)               0         
                                                                 
 dense_2799 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 931674 (3.55 MB)
Trainable params: 930714 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 577:
  Value: 0.8458
  num_layers: 4
  units_0: 480
  units_1: 128
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011516630649565786

Model: "sequential_577"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_577 (Flatten)       (None, 784)               0         
                                                                 
 dense_2800 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_679 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2223 (Dropout)      (None, 480)               0         
                                                                 
 dense_2801 (Dense)          (None, 128)               61568     
                                                                 
 dropout_2224 (Dropout)      (None, 128)               0         
                                                                 
 dense_2802 (Dense)          (None, 512)               66048     
                                                                 
 batch_normalization_680 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2225 (Dropout)      (None, 512)               0         
                                                                 
 dense_2803 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2226 (Dropout)      (None, 256)               0         
                                                                 
 dense_2804 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 646394 (2.47 MB)
Trainable params: 644410 (2.46 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 578:
  Value: 0.8462
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005981234497283502

Model: "sequential_578"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_578 (Flatten)       (None, 784)               0         
                                                                 
 dense_2805 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2227 (Dropout)      (None, 512)               0         
                                                                 
 dense_2806 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2228 (Dropout)      (None, 416)               0         
                                                                 
 dense_2807 (Dense)          (None, 480)               200160    
                                                                 
 dropout_2229 (Dropout)      (None, 480)               0         
                                                                 
 dense_2808 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2230 (Dropout)      (None, 288)               0         
                                                                 
 dense_2809 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 961530 (3.67 MB)
Trainable params: 961530 (3.67 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 579:
  Value: 0.9137
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0023393626196051404

Model: "sequential_579"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_579 (Flatten)       (None, 784)               0         
                                                                 
 dense_2810 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2231 (Dropout)      (None, 480)               0         
                                                                 
 dense_2811 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2232 (Dropout)      (None, 416)               0         
                                                                 
 dense_2812 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_681 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2233 (Dropout)      (None, 512)               0         
                                                                 
 dense_2813 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2234 (Dropout)      (None, 288)               0         
                                                                 
 dense_2814 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 580:
  Value: 0.9194
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016445041820593856

Model: "sequential_580"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_580 (Flatten)       (None, 784)               0         
                                                                 
 dense_2815 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2235 (Dropout)      (None, 512)               0         
                                                                 
 dense_2816 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2236 (Dropout)      (None, 448)               0         
                                                                 
 dense_2817 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_682 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2237 (Dropout)      (None, 512)               0         
                                                                 
 dense_2818 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2238 (Dropout)      (None, 320)               0         
                                                                 
 dense_2819 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1036186 (3.95 MB)
Trainable params: 1035162 (3.95 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 581:
  Value: 0.9220
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012235530181847359

Model: "sequential_581"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_581 (Flatten)       (None, 784)               0         
                                                                 
 dense_2820 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2239 (Dropout)      (None, 480)               0         
                                                                 
 dense_2821 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2240 (Dropout)      (None, 416)               0         
                                                                 
 dense_2822 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_683 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2241 (Dropout)      (None, 480)               0         
                                                                 
 dense_2823 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2242 (Dropout)      (None, 256)               0         
                                                                 
 dense_2824 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 908794 (3.47 MB)
Trainable params: 907834 (3.46 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 582:
  Value: 0.4401
  num_layers: 4
  units_0: 224
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012242641202665232

Model: "sequential_582"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_582 (Flatten)       (None, 784)               0         
                                                                 
 dense_2825 (Dense)          (None, 224)               175840    
                                                                 
 dropout_2243 (Dropout)      (None, 224)               0         
                                                                 
 dense_2826 (Dense)          (None, 416)               93600     
                                                                 
 batch_normalization_684 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_2244 (Dropout)      (None, 416)               0         
                                                                 
 dense_2827 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_685 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2245 (Dropout)      (None, 512)               0         
                                                                 
 dense_2828 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2246 (Dropout)      (None, 288)               0         
                                                                 
 dense_2829 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 641914 (2.45 MB)
Trainable params: 640058 (2.44 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 583:
  Value: 0.9176
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009568812594312904

Model: "sequential_583"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_583 (Flatten)       (None, 784)               0         
                                                                 
 dense_2830 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2247 (Dropout)      (None, 512)               0         
                                                                 
 dense_2831 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2248 (Dropout)      (None, 416)               0         
                                                                 
 dense_2832 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_686 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2249 (Dropout)      (None, 480)               0         
                                                                 
 dense_2833 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2250 (Dropout)      (None, 288)               0         
                                                                 
 dense_2834 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 584:
  Value: 0.8418
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: relu
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013560158613182365

Model: "sequential_584"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_584 (Flatten)       (None, 784)               0         
                                                                 
 dense_2835 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2251 (Dropout)      (None, 480)               0         
                                                                 
 dense_2836 (Dense)          (None, 384)               184704    
                                                                 
 dropout_2252 (Dropout)      (None, 384)               0         
                                                                 
 dense_2837 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_687 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2253 (Dropout)      (None, 512)               0         
                                                                 
 dense_2838 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2254 (Dropout)      (None, 320)               0         
                                                                 
 dense_2839 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 933178 (3.56 MB)
Trainable params: 932154 (3.56 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 585:
  Value: 0.9081
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010947292945092779

Model: "sequential_585"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_585 (Flatten)       (None, 784)               0         
                                                                 
 dense_2840 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2255 (Dropout)      (None, 512)               0         
                                                                 
 dense_2841 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2256 (Dropout)      (None, 416)               0         
                                                                 
 dense_2842 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_688 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2257 (Dropout)      (None, 480)               0         
                                                                 
 dense_2843 (Dense)          (None, 352)               169312    
                                                                 
 dropout_2258 (Dropout)      (None, 352)               0         
                                                                 
 dense_2844 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 995898 (3.80 MB)
Trainable params: 994938 (3.80 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 586:
  Value: 0.7904
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012401005779781077

Model: "sequential_586"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_586 (Flatten)       (None, 784)               0         
                                                                 
 dense_2845 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2259 (Dropout)      (None, 480)               0         
                                                                 
 dense_2846 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2260 (Dropout)      (None, 416)               0         
                                                                 
 dense_2847 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_689 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2261 (Dropout)      (None, 512)               0         
                                                                 
 dense_2848 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2262 (Dropout)      (None, 256)               0         
                                                                 
 dense_2849 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 930458 (3.55 MB)
Trainable params: 929434 (3.55 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 587:
  Value: 0.0846
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 224
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.001445369759925178

Model: "sequential_587"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_587 (Flatten)       (None, 784)               0         
                                                                 
 dense_2850 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2263 (Dropout)      (None, 512)               0         
                                                                 
 dense_2851 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2264 (Dropout)      (None, 384)               0         
                                                                 
 dense_2852 (Dense)          (None, 224)               86240     
                                                                 
 batch_normalization_690 (B  (None, 224)               896       
 atchNormalization)                                              
                                                                 
 dropout_2265 (Dropout)      (None, 224)               0         
                                                                 
 dense_2853 (Dense)          (None, 288)               64800     
                                                                 
 dropout_2266 (Dropout)      (None, 288)               0         
                                                                 
 dense_2854 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 758362 (2.89 MB)
Trainable params: 757914 (2.89 MB)
Non-trainable params: 448 (1.75 KB)
_________________________________________________________________



Trial 588:
  Value: 0.9159
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001087438115997311

Model: "sequential_588"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_588 (Flatten)       (None, 784)               0         
                                                                 
 dense_2855 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2267 (Dropout)      (None, 480)               0         
                                                                 
 dense_2856 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2268 (Dropout)      (None, 416)               0         
                                                                 
 dense_2857 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_691 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2269 (Dropout)      (None, 512)               0         
                                                                 
 dense_2858 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2270 (Dropout)      (None, 320)               0         
                                                                 
 dense_2859 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 589:
  Value: 0.9206
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012961911515461883

Model: "sequential_589"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_589 (Flatten)       (None, 784)               0         
                                                                 
 dense_2860 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2271 (Dropout)      (None, 512)               0         
                                                                 
 dense_2861 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2272 (Dropout)      (None, 416)               0         
                                                                 
 dense_2862 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_692 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2273 (Dropout)      (None, 480)               0         
                                                                 
 dense_2863 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2274 (Dropout)      (None, 288)               0         
                                                                 
 dense_2864 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 590:
  Value: 0.9207
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001292780048821545

Model: "sequential_590"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_590 (Flatten)       (None, 784)               0         
                                                                 
 dense_2865 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2275 (Dropout)      (None, 512)               0         
                                                                 
 dense_2866 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2276 (Dropout)      (None, 416)               0         
                                                                 
 dense_2867 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_693 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2277 (Dropout)      (None, 480)               0         
                                                                 
 dense_2868 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2278 (Dropout)      (None, 288)               0         
                                                                 
 dense_2869 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 591:
  Value: 0.9209
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013131933892436012

Model: "sequential_591"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_591 (Flatten)       (None, 784)               0         
                                                                 
 dense_2870 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2279 (Dropout)      (None, 512)               0         
                                                                 
 dense_2871 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2280 (Dropout)      (None, 416)               0         
                                                                 
 dense_2872 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_694 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2281 (Dropout)      (None, 480)               0         
                                                                 
 dense_2873 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2282 (Dropout)      (None, 288)               0         
                                                                 
 dense_2874 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 592:
  Value: 0.7927
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0014220436622407432

Model: "sequential_592"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_592 (Flatten)       (None, 784)               0         
                                                                 
 dense_2875 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2283 (Dropout)      (None, 512)               0         
                                                                 
 dense_2876 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2284 (Dropout)      (None, 416)               0         
                                                                 
 dense_2877 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_695 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2285 (Dropout)      (None, 480)               0         
                                                                 
 dense_2878 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2286 (Dropout)      (None, 288)               0         
                                                                 
 dense_2879 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 593:
  Value: 0.9200
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001195317113666961

Model: "sequential_593"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_593 (Flatten)       (None, 784)               0         
                                                                 
 dense_2880 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2287 (Dropout)      (None, 512)               0         
                                                                 
 dense_2881 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2288 (Dropout)      (None, 416)               0         
                                                                 
 dense_2882 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_696 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2289 (Dropout)      (None, 480)               0         
                                                                 
 dense_2883 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2290 (Dropout)      (None, 288)               0         
                                                                 
 dense_2884 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 594:
  Value: 0.9195
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013204398025898525

Model: "sequential_594"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_594 (Flatten)       (None, 784)               0         
                                                                 
 dense_2885 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2291 (Dropout)      (None, 512)               0         
                                                                 
 dense_2886 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2292 (Dropout)      (None, 416)               0         
                                                                 
 dense_2887 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_697 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2293 (Dropout)      (None, 480)               0         
                                                                 
 dense_2888 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2294 (Dropout)      (None, 256)               0         
                                                                 
 dense_2889 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 947226 (3.61 MB)
Trainable params: 946266 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 595:
  Value: 0.9181
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001506737239308599

Model: "sequential_595"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_595 (Flatten)       (None, 784)               0         
                                                                 
 dense_2890 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2295 (Dropout)      (None, 512)               0         
                                                                 
 dense_2891 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2296 (Dropout)      (None, 384)               0         
                                                                 
 dense_2892 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_698 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2297 (Dropout)      (None, 480)               0         
                                                                 
 dense_2893 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2298 (Dropout)      (None, 320)               0         
                                                                 
 dense_2894 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 947898 (3.62 MB)
Trainable params: 946938 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 596:
  Value: 0.7501
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011723642881252326

Model: "sequential_596"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_596 (Flatten)       (None, 784)               0         
                                                                 
 dense_2895 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2299 (Dropout)      (None, 512)               0         
                                                                 
 dense_2896 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2300 (Dropout)      (None, 416)               0         
                                                                 
 dense_2897 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_699 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2301 (Dropout)      (None, 480)               0         
                                                                 
 dense_2898 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2302 (Dropout)      (None, 288)               0         
                                                                 
 dense_2899 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 597:
  Value: 0.8500
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010490779732246066

Model: "sequential_597"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_597 (Flatten)       (None, 784)               0         
                                                                 
 dense_2900 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_700 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2303 (Dropout)      (None, 512)               0         
                                                                 
 dense_2901 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2304 (Dropout)      (None, 384)               0         
                                                                 
 dense_2902 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_701 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2305 (Dropout)      (None, 480)               0         
                                                                 
 dense_2903 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2306 (Dropout)      (None, 256)               0         
                                                                 
 dense_2904 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 917498 (3.50 MB)
Trainable params: 915514 (3.49 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 598:
  Value: 0.8538
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013612652503690037

Model: "sequential_598"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_598 (Flatten)       (None, 784)               0         
                                                                 
 dense_2905 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2307 (Dropout)      (None, 512)               0         
                                                                 
 dense_2906 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2308 (Dropout)      (None, 416)               0         
                                                                 
 dense_2907 (Dense)          (None, 480)               200160    
                                                                 
 dropout_2309 (Dropout)      (None, 480)               0         
                                                                 
 dense_2908 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2310 (Dropout)      (None, 288)               0         
                                                                 
 dense_2909 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 961530 (3.67 MB)
Trainable params: 961530 (3.67 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 599:
  Value: 0.0389
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.000989749307706213

Model: "sequential_599"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_599 (Flatten)       (None, 784)               0         
                                                                 
 dense_2910 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2311 (Dropout)      (None, 512)               0         
                                                                 
 dense_2911 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2312 (Dropout)      (None, 416)               0         
                                                                 
 dense_2912 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_702 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2313 (Dropout)      (None, 480)               0         
                                                                 
 dense_2913 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2314 (Dropout)      (None, 288)               0         
                                                                 
 dense_2914 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 600:
  Value: 0.8015
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0012432382232450503

Model: "sequential_600"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_600 (Flatten)       (None, 784)               0         
                                                                 
 dense_2915 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2315 (Dropout)      (None, 512)               0         
                                                                 
 dense_2916 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2316 (Dropout)      (None, 416)               0         
                                                                 
 dense_2917 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_703 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2317 (Dropout)      (None, 480)               0         
                                                                 
 dense_2918 (Dense)          (None, 320)               153920    
                                                                 
 batch_normalization_704 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_2318 (Dropout)      (None, 320)               0         
                                                                 
 dense_2919 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 980954 (3.74 MB)
Trainable params: 979354 (3.74 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 601:
  Value: 0.9184
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015868498474077527

Model: "sequential_601"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_601 (Flatten)       (None, 784)               0         
                                                                 
 dense_2920 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2319 (Dropout)      (None, 512)               0         
                                                                 
 dense_2921 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2320 (Dropout)      (None, 352)               0         
                                                                 
 dense_2922 (Dense)          (None, 480)               169440    
                                                                 
 batch_normalization_705 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2321 (Dropout)      (None, 480)               0         
                                                                 
 dense_2923 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2322 (Dropout)      (None, 288)               0         
                                                                 
 dense_2924 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 899898 (3.43 MB)
Trainable params: 898938 (3.43 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 602:
  Value: 0.7913
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.001133246936091476

Model: "sequential_602"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_602 (Flatten)       (None, 784)               0         
                                                                 
 dense_2925 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2323 (Dropout)      (None, 512)               0         
                                                                 
 dense_2926 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2324 (Dropout)      (None, 448)               0         
                                                                 
 dense_2927 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_706 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2325 (Dropout)      (None, 480)               0         
                                                                 
 dense_2928 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2326 (Dropout)      (None, 320)               0         
                                                                 
 dense_2929 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1011450 (3.86 MB)
Trainable params: 1010490 (3.85 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 603:
  Value: 0.8184
  num_layers: 2
  units_0: 512
  units_1: 416
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013981456481728944

Model: "sequential_603"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_603 (Flatten)       (None, 784)               0         
                                                                 
 dense_2930 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2327 (Dropout)      (None, 512)               0         
                                                                 
 dense_2931 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2328 (Dropout)      (None, 416)               0         
                                                                 
 dense_2932 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 626170 (2.39 MB)
Trainable params: 626170 (2.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 604:
  Value: 0.5580
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001724436551028295

Model: "sequential_604"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_604 (Flatten)       (None, 784)               0         
                                                                 
 dense_2933 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2329 (Dropout)      (None, 512)               0         
                                                                 
 dense_2934 (Dense)          (None, 384)               196992    
                                                                 
 batch_normalization_707 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_2330 (Dropout)      (None, 384)               0         
                                                                 
 dense_2935 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_708 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2331 (Dropout)      (None, 512)               0         
                                                                 
 dense_2936 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2332 (Dropout)      (None, 256)               0         
                                                                 
 dense_2937 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 937626 (3.58 MB)
Trainable params: 935834 (3.57 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 605:
  Value: 0.0381
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0008509926829977347

Model: "sequential_605"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_605 (Flatten)       (None, 784)               0         
                                                                 
 dense_2938 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2333 (Dropout)      (None, 512)               0         
                                                                 
 dense_2939 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2334 (Dropout)      (None, 448)               0         
                                                                 
 dense_2940 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_709 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2335 (Dropout)      (None, 512)               0         
                                                                 
 dense_2941 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2336 (Dropout)      (None, 288)               0         
                                                                 
 dense_2942 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 606:
  Value: 0.9199
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001257826706820062

Model: "sequential_606"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_606 (Flatten)       (None, 784)               0         
                                                                 
 dense_2943 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2337 (Dropout)      (None, 512)               0         
                                                                 
 dense_2944 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2338 (Dropout)      (None, 416)               0         
                                                                 
 dense_2945 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_710 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2339 (Dropout)      (None, 480)               0         
                                                                 
 dense_2946 (Dense)          (None, 352)               169312    
                                                                 
 dropout_2340 (Dropout)      (None, 352)               0         
                                                                 
 dense_2947 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 995898 (3.80 MB)
Trainable params: 994938 (3.80 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 607:
  Value: 0.8517
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009255931977983161

Model: "sequential_607"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_607 (Flatten)       (None, 784)               0         
                                                                 
 dense_2948 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2341 (Dropout)      (None, 512)               0         
                                                                 
 dense_2949 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2342 (Dropout)      (None, 416)               0         
                                                                 
 dense_2950 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_711 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2343 (Dropout)      (None, 512)               0         
                                                                 
 dense_2951 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2344 (Dropout)      (None, 288)               0         
                                                                 
 dense_2952 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 608:
  Value: 0.9059
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001466520462576666

Model: "sequential_608"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_608 (Flatten)       (None, 784)               0         
                                                                 
 dense_2953 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2345 (Dropout)      (None, 480)               0         
                                                                 
 dense_2954 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2346 (Dropout)      (None, 448)               0         
                                                                 
 dense_2955 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_712 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2347 (Dropout)      (None, 480)               0         
                                                                 
 dense_2956 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2348 (Dropout)      (None, 288)               0         
                                                                 
 dense_2957 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 609:
  Value: 0.9193
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010523819642682646

Model: "sequential_609"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_609 (Flatten)       (None, 784)               0         
                                                                 
 dense_2958 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2349 (Dropout)      (None, 512)               0         
                                                                 
 dense_2959 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2350 (Dropout)      (None, 384)               0         
                                                                 
 dense_2960 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_713 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2351 (Dropout)      (None, 512)               0         
                                                                 
 dense_2961 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2352 (Dropout)      (None, 256)               0         
                                                                 
 dense_2962 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 936090 (3.57 MB)
Trainable params: 935066 (3.57 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 610:
  Value: 0.9185
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001193837335577152

Model: "sequential_610"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_610 (Flatten)       (None, 784)               0         
                                                                 
 dense_2963 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2353 (Dropout)      (None, 512)               0         
                                                                 
 dense_2964 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2354 (Dropout)      (None, 416)               0         
                                                                 
 dense_2965 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_714 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2355 (Dropout)      (None, 480)               0         
                                                                 
 dense_2966 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2356 (Dropout)      (None, 320)               0         
                                                                 
 dense_2967 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 979674 (3.74 MB)
Trainable params: 978714 (3.73 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 611:
  Value: 0.9209
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001329521746118515

Model: "sequential_611"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_611 (Flatten)       (None, 784)               0         
                                                                 
 dense_2968 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2357 (Dropout)      (None, 480)               0         
                                                                 
 dense_2969 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2358 (Dropout)      (None, 448)               0         
                                                                 
 dense_2970 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_715 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2359 (Dropout)      (None, 512)               0         
                                                                 
 dense_2971 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2360 (Dropout)      (None, 288)               0         
                                                                 
 dense_2972 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 612:
  Value: 0.9198
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016104757861093292

Model: "sequential_612"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_612 (Flatten)       (None, 784)               0         
                                                                 
 dense_2973 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2361 (Dropout)      (None, 480)               0         
                                                                 
 dense_2974 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2362 (Dropout)      (None, 448)               0         
                                                                 
 dense_2975 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_716 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2363 (Dropout)      (None, 512)               0         
                                                                 
 dense_2976 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2364 (Dropout)      (None, 320)               0         
                                                                 
 dense_2977 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 613:
  Value: 0.9200
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001836179134265173

Model: "sequential_613"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_613 (Flatten)       (None, 784)               0         
                                                                 
 dense_2978 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2365 (Dropout)      (None, 480)               0         
                                                                 
 dense_2979 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2366 (Dropout)      (None, 448)               0         
                                                                 
 dense_2980 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_717 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2367 (Dropout)      (None, 512)               0         
                                                                 
 dense_2981 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2368 (Dropout)      (None, 256)               0         
                                                                 
 dense_2982 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 962234 (3.67 MB)
Trainable params: 961210 (3.67 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 614:
  Value: 0.0814
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0014690179263165365

Model: "sequential_614"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_614 (Flatten)       (None, 784)               0         
                                                                 
 dense_2983 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2369 (Dropout)      (None, 480)               0         
                                                                 
 dense_2984 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2370 (Dropout)      (None, 448)               0         
                                                                 
 dense_2985 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_718 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2371 (Dropout)      (None, 512)               0         
                                                                 
 dense_2986 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2372 (Dropout)      (None, 288)               0         
                                                                 
 dense_2987 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 615:
  Value: 0.8368
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011227517566152225

Model: "sequential_615"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_615 (Flatten)       (None, 784)               0         
                                                                 
 dense_2988 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_719 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2373 (Dropout)      (None, 480)               0         
                                                                 
 dense_2989 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2374 (Dropout)      (None, 448)               0         
                                                                 
 dense_2990 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_720 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2375 (Dropout)      (None, 512)               0         
                                                                 
 dense_2991 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2376 (Dropout)      (None, 288)               0         
                                                                 
 dense_2992 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 981402 (3.74 MB)
Trainable params: 979418 (3.74 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 616:
  Value: 0.7535
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001360039227114205

Model: "sequential_616"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_616 (Flatten)       (None, 784)               0         
                                                                 
 dense_2993 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2377 (Dropout)      (None, 480)               0         
                                                                 
 dense_2994 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2378 (Dropout)      (None, 448)               0         
                                                                 
 dense_2995 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_721 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2379 (Dropout)      (None, 512)               0         
                                                                 
 dense_2996 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2380 (Dropout)      (None, 320)               0         
                                                                 
 dense_2997 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 617:
  Value: 0.8607
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009556401615284828

Model: "sequential_617"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_617 (Flatten)       (None, 784)               0         
                                                                 
 dense_2998 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2381 (Dropout)      (None, 480)               0         
                                                                 
 dense_2999 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2382 (Dropout)      (None, 448)               0         
                                                                 
 dense_3000 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_722 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2383 (Dropout)      (None, 512)               0         
                                                                 
 dense_3001 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2384 (Dropout)      (None, 256)               0         
                                                                 
 dense_3002 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 962234 (3.67 MB)
Trainable params: 961210 (3.67 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 618:
  Value: 0.8592
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010421557231723218

Model: "sequential_618"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_618 (Flatten)       (None, 784)               0         
                                                                 
 dense_3003 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2385 (Dropout)      (None, 480)               0         
                                                                 
 dense_3004 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2386 (Dropout)      (None, 448)               0         
                                                                 
 dense_3005 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_723 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2387 (Dropout)      (None, 512)               0         
                                                                 
 dense_3006 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2388 (Dropout)      (None, 288)               0         
                                                                 
 dense_3007 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 619:
  Value: 0.8271
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011970524372514563

Model: "sequential_619"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_619 (Flatten)       (None, 784)               0         
                                                                 
 dense_3008 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2389 (Dropout)      (None, 480)               0         
                                                                 
 dense_3009 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2390 (Dropout)      (None, 416)               0         
                                                                 
 dense_3010 (Dense)          (None, 512)               213504    
                                                                 
 dropout_2391 (Dropout)      (None, 512)               0         
                                                                 
 dense_3011 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2392 (Dropout)      (None, 288)               0         
                                                                 
 dense_3012 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 945658 (3.61 MB)
Trainable params: 945658 (3.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 620:
  Value: 0.9223
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015718009817694877

Model: "sequential_620"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_620 (Flatten)       (None, 784)               0         
                                                                 
 dense_3013 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2393 (Dropout)      (None, 480)               0         
                                                                 
 dense_3014 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2394 (Dropout)      (None, 448)               0         
                                                                 
 dense_3015 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_724 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2395 (Dropout)      (None, 512)               0         
                                                                 
 dense_3016 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2396 (Dropout)      (None, 320)               0         
                                                                 
 dense_3017 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 621:
  Value: 0.4366
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 160
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.001609465445581587

Model: "sequential_621"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_621 (Flatten)       (None, 784)               0         
                                                                 
 dense_3018 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2397 (Dropout)      (None, 480)               0         
                                                                 
 dense_3019 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_725 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2398 (Dropout)      (None, 448)               0         
                                                                 
 dense_3020 (Dense)          (None, 160)               71840     
                                                                 
 batch_normalization_726 (B  (None, 160)               640       
 atchNormalization)                                              
                                                                 
 dropout_2399 (Dropout)      (None, 160)               0         
                                                                 
 dense_3021 (Dense)          (None, 320)               51520     
                                                                 
 dropout_2400 (Dropout)      (None, 320)               0         
                                                                 
 dense_3022 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 726426 (2.77 MB)
Trainable params: 725210 (2.77 MB)
Non-trainable params: 1216 (4.75 KB)
_________________________________________________________________



Trial 622:
  Value: 0.8607
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0014946362203685226

Model: "sequential_622"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_622 (Flatten)       (None, 784)               0         
                                                                 
 dense_3023 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2401 (Dropout)      (None, 480)               0         
                                                                 
 dense_3024 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2402 (Dropout)      (None, 448)               0         
                                                                 
 dense_3025 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_727 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2403 (Dropout)      (None, 512)               0         
                                                                 
 dense_3026 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_728 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_2404 (Dropout)      (None, 352)               0         
                                                                 
 dense_3027 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1015386 (3.87 MB)
Trainable params: 1013658 (3.87 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 623:
  Value: 0.9134
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.4
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001353750981862142

Model: "sequential_623"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_623 (Flatten)       (None, 784)               0         
                                                                 
 dense_3028 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2405 (Dropout)      (None, 480)               0         
                                                                 
 dense_3029 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2406 (Dropout)      (None, 448)               0         
                                                                 
 dense_3030 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_729 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2407 (Dropout)      (None, 512)               0         
                                                                 
 dense_3031 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2408 (Dropout)      (None, 320)               0         
                                                                 
 dense_3032 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 624:
  Value: 0.9166
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016637146667679722

Model: "sequential_624"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_624 (Flatten)       (None, 784)               0         
                                                                 
 dense_3033 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2409 (Dropout)      (None, 480)               0         
                                                                 
 dense_3034 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2410 (Dropout)      (None, 448)               0         
                                                                 
 dense_3035 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_730 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2411 (Dropout)      (None, 512)               0         
                                                                 
 dense_3036 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2412 (Dropout)      (None, 320)               0         
                                                                 
 dense_3037 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 625:
  Value: 0.8749
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012885100504547776

Model: "sequential_625"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_625 (Flatten)       (None, 784)               0         
                                                                 
 dense_3038 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2413 (Dropout)      (None, 480)               0         
                                                                 
 dense_3039 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2414 (Dropout)      (None, 448)               0         
                                                                 
 dense_3040 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_731 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2415 (Dropout)      (None, 512)               0         
                                                                 
 dense_3041 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2416 (Dropout)      (None, 320)               0         
                                                                 
 dense_3042 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 626:
  Value: 0.9165
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001437273185987456

Model: "sequential_626"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_626 (Flatten)       (None, 784)               0         
                                                                 
 dense_3043 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2417 (Dropout)      (None, 480)               0         
                                                                 
 dense_3044 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2418 (Dropout)      (None, 448)               0         
                                                                 
 dense_3045 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_732 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2419 (Dropout)      (None, 480)               0         
                                                                 
 dense_3046 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2420 (Dropout)      (None, 320)               0         
                                                                 
 dense_3047 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 971994 (3.71 MB)
Trainable params: 971034 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 627:
  Value: 0.0357
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.00114083378102799

Model: "sequential_627"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_627 (Flatten)       (None, 784)               0         
                                                                 
 dense_3048 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2421 (Dropout)      (None, 480)               0         
                                                                 
 dense_3049 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2422 (Dropout)      (None, 448)               0         
                                                                 
 dense_3050 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_733 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2423 (Dropout)      (None, 512)               0         
                                                                 
 dense_3051 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2424 (Dropout)      (None, 352)               0         
                                                                 
 dense_3052 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1013978 (3.87 MB)
Trainable params: 1012954 (3.86 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 628:
  Value: 0.9159
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0018032358046096036

Model: "sequential_628"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_628 (Flatten)       (None, 784)               0         
                                                                 
 dense_3053 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2425 (Dropout)      (None, 480)               0         
                                                                 
 dense_3054 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2426 (Dropout)      (None, 416)               0         
                                                                 
 dense_3055 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_734 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2427 (Dropout)      (None, 512)               0         
                                                                 
 dense_3056 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2428 (Dropout)      (None, 320)               0         
                                                                 
 dense_3057 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 629:
  Value: 0.9168
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015474406844994282

Model: "sequential_629"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_629 (Flatten)       (None, 784)               0         
                                                                 
 dense_3058 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2429 (Dropout)      (None, 480)               0         
                                                                 
 dense_3059 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2430 (Dropout)      (None, 448)               0         
                                                                 
 dense_3060 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_735 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2431 (Dropout)      (None, 480)               0         
                                                                 
 dense_3061 (Dense)          (None, 352)               169312    
                                                                 
 dropout_2432 (Dropout)      (None, 352)               0         
                                                                 
 dense_3062 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 988218 (3.77 MB)
Trainable params: 987258 (3.77 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 630:
  Value: 0.8900
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0012611262025379317

Model: "sequential_630"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_630 (Flatten)       (None, 784)               0         
                                                                 
 dense_3063 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2433 (Dropout)      (None, 480)               0         
                                                                 
 dense_3064 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2434 (Dropout)      (None, 448)               0         
                                                                 
 dense_3065 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_736 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2435 (Dropout)      (None, 512)               0         
                                                                 
 dense_3066 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2436 (Dropout)      (None, 320)               0         
                                                                 
 dense_3067 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 631:
  Value: 0.7972
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010223126322834663

Model: "sequential_631"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_631 (Flatten)       (None, 784)               0         
                                                                 
 dense_3068 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2437 (Dropout)      (None, 480)               0         
                                                                 
 dense_3069 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2438 (Dropout)      (None, 416)               0         
                                                                 
 dense_3070 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_737 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2439 (Dropout)      (None, 480)               0         
                                                                 
 dense_3071 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2440 (Dropout)      (None, 256)               0         
                                                                 
 dense_3072 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 908794 (3.47 MB)
Trainable params: 907834 (3.46 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 632:
  Value: 0.9194
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013407719074842595

Model: "sequential_632"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_632 (Flatten)       (None, 784)               0         
                                                                 
 dense_3073 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2441 (Dropout)      (None, 480)               0         
                                                                 
 dense_3074 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2442 (Dropout)      (None, 416)               0         
                                                                 
 dense_3075 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_738 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2443 (Dropout)      (None, 512)               0         
                                                                 
 dense_3076 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2444 (Dropout)      (None, 288)               0         
                                                                 
 dense_3077 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 633:
  Value: 0.0364
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0008044804930578088

Model: "sequential_633"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_633 (Flatten)       (None, 784)               0         
                                                                 
 dense_3078 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2445 (Dropout)      (None, 480)               0         
                                                                 
 dense_3079 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2446 (Dropout)      (None, 416)               0         
                                                                 
 dense_3080 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_739 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2447 (Dropout)      (None, 448)               0         
                                                                 
 dense_3081 (Dense)          (None, 320)               143680    
                                                                 
 dropout_2448 (Dropout)      (None, 320)               0         
                                                                 
 dense_3082 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 917530 (3.50 MB)
Trainable params: 916634 (3.50 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 634:
  Value: 0.8381
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011397290201349292

Model: "sequential_634"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_634 (Flatten)       (None, 784)               0         
                                                                 
 dense_3083 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_740 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2449 (Dropout)      (None, 480)               0         
                                                                 
 dense_3084 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2450 (Dropout)      (None, 448)               0         
                                                                 
 dense_3085 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_741 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2451 (Dropout)      (None, 480)               0         
                                                                 
 dense_3086 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2452 (Dropout)      (None, 288)               0         
                                                                 
 dense_3087 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 957690 (3.65 MB)
Trainable params: 955770 (3.65 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 635:
  Value: 0.9186
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001458337323214191

Model: "sequential_635"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_635 (Flatten)       (None, 784)               0         
                                                                 
 dense_3088 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2453 (Dropout)      (None, 512)               0         
                                                                 
 dense_3089 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2454 (Dropout)      (None, 448)               0         
                                                                 
 dense_3090 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_742 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2455 (Dropout)      (None, 512)               0         
                                                                 
 dense_3091 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2456 (Dropout)      (None, 256)               0         
                                                                 
 dense_3092 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1001690 (3.82 MB)
Trainable params: 1000666 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 636:
  Value: 0.9203
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008869794009684482

Model: "sequential_636"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_636 (Flatten)       (None, 784)               0         
                                                                 
 dense_3093 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2457 (Dropout)      (None, 512)               0         
                                                                 
 dense_3094 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2458 (Dropout)      (None, 416)               0         
                                                                 
 dense_3095 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_743 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2459 (Dropout)      (None, 512)               0         
                                                                 
 dense_3096 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2460 (Dropout)      (None, 288)               0         
                                                                 
 dense_3097 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 637:
  Value: 0.8244
  num_layers: 1
  units_0: 480
  activation_0: relu
  dropout_0: 0.4
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0011989977477872148

Model: "sequential_637"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_637 (Flatten)       (None, 784)               0         
                                                                 
 dense_3098 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2461 (Dropout)      (None, 480)               0         
                                                                 
 dense_3099 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 389306 (1.49 MB)
Trainable params: 389306 (1.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 638:
  Value: 0.6753
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 96
  units_3: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019292843359268157

Model: "sequential_638"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_638 (Flatten)       (None, 784)               0         
                                                                 
 dense_3100 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2462 (Dropout)      (None, 512)               0         
                                                                 
 dense_3101 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2463 (Dropout)      (None, 416)               0         
                                                                 
 dense_3102 (Dense)          (None, 96)                40032     
                                                                 
 dropout_2464 (Dropout)      (None, 96)                0         
                                                                 
 dense_3103 (Dense)          (None, 320)               31040     
                                                                 
 dropout_2465 (Dropout)      (None, 320)               0         
                                                                 
 dense_3104 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 694746 (2.65 MB)
Trainable params: 694746 (2.65 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 639:
  Value: 0.8601
  num_layers: 3
  units_0: 480
  units_1: 448
  units_2: 480
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0016135059023547236

Model: "sequential_639"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_639 (Flatten)       (None, 784)               0         
                                                                 
 dense_3105 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2466 (Dropout)      (None, 480)               0         
                                                                 
 dense_3106 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2467 (Dropout)      (None, 448)               0         
                                                                 
 dense_3107 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_744 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2468 (Dropout)      (None, 480)               0         
                                                                 
 dense_3108 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 822234 (3.14 MB)
Trainable params: 821274 (3.13 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 640:
  Value: 0.9201
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013698491103328518

Model: "sequential_640"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_640 (Flatten)       (None, 784)               0         
                                                                 
 dense_3109 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2469 (Dropout)      (None, 512)               0         
                                                                 
 dense_3110 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2470 (Dropout)      (None, 416)               0         
                                                                 
 dense_3111 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_745 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2471 (Dropout)      (None, 512)               0         
                                                                 
 dense_3112 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2472 (Dropout)      (None, 288)               0         
                                                                 
 dense_3113 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 641:
  Value: 0.7898
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0017221739331646929

Model: "sequential_641"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_641 (Flatten)       (None, 784)               0         
                                                                 
 dense_3114 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2473 (Dropout)      (None, 480)               0         
                                                                 
 dense_3115 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2474 (Dropout)      (None, 448)               0         
                                                                 
 dense_3116 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_746 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2475 (Dropout)      (None, 480)               0         
                                                                 
 dense_3117 (Dense)          (None, 288)               138528    
                                                                 
 batch_normalization_747 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_2476 (Dropout)      (None, 288)               0         
                                                                 
 dense_3118 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 956922 (3.65 MB)
Trainable params: 955386 (3.64 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 642:
  Value: 0.1475
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0010585639135949174

Model: "sequential_642"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_642 (Flatten)       (None, 784)               0         
                                                                 
 dense_3119 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2477 (Dropout)      (None, 512)               0         
                                                                 
 dense_3120 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_748 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_2478 (Dropout)      (None, 416)               0         
                                                                 
 dense_3121 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_749 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2479 (Dropout)      (None, 448)               0         
                                                                 
 dense_3122 (Dense)          (None, 320)               143680    
                                                                 
 dropout_2480 (Dropout)      (None, 320)               0         
                                                                 
 dense_3123 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 957626 (3.65 MB)
Trainable params: 955898 (3.65 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 643:
  Value: 0.8607
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012683174530054712

Model: "sequential_643"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_643 (Flatten)       (None, 784)               0         
                                                                 
 dense_3124 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2481 (Dropout)      (None, 480)               0         
                                                                 
 dense_3125 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2482 (Dropout)      (None, 416)               0         
                                                                 
 dense_3126 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_750 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2483 (Dropout)      (None, 512)               0         
                                                                 
 dense_3127 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2484 (Dropout)      (None, 256)               0         
                                                                 
 dense_3128 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 930458 (3.55 MB)
Trainable params: 929434 (3.55 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 644:
  Value: 0.8603
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015067689569301852

Model: "sequential_644"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_644 (Flatten)       (None, 784)               0         
                                                                 
 dense_3129 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2485 (Dropout)      (None, 512)               0         
                                                                 
 dense_3130 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2486 (Dropout)      (None, 448)               0         
                                                                 
 dense_3131 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_751 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2487 (Dropout)      (None, 480)               0         
                                                                 
 dense_3132 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2488 (Dropout)      (None, 288)               0         
                                                                 
 dense_3133 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 645:
  Value: 0.8583
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011065912889197576

Model: "sequential_645"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_645 (Flatten)       (None, 784)               0         
                                                                 
 dense_3134 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2489 (Dropout)      (None, 480)               0         
                                                                 
 dense_3135 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2490 (Dropout)      (None, 448)               0         
                                                                 
 dense_3136 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_752 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2491 (Dropout)      (None, 512)               0         
                                                                 
 dense_3137 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2492 (Dropout)      (None, 320)               0         
                                                                 
 dense_3138 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 646:
  Value: 0.9200
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002720054208426623

Model: "sequential_646"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_646 (Flatten)       (None, 784)               0         
                                                                 
 dense_3139 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2493 (Dropout)      (None, 512)               0         
                                                                 
 dense_3140 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2494 (Dropout)      (None, 448)               0         
                                                                 
 dense_3141 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_753 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2495 (Dropout)      (None, 480)               0         
                                                                 
 dense_3142 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2496 (Dropout)      (None, 256)               0         
                                                                 
 dense_3143 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 979002 (3.73 MB)
Trainable params: 978042 (3.73 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 647:
  Value: 0.8597
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009659604897262643

Model: "sequential_647"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_647 (Flatten)       (None, 784)               0         
                                                                 
 dense_3144 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2497 (Dropout)      (None, 480)               0         
                                                                 
 dense_3145 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2498 (Dropout)      (None, 416)               0         
                                                                 
 dense_3146 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_754 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2499 (Dropout)      (None, 512)               0         
                                                                 
 dense_3147 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2500 (Dropout)      (None, 352)               0         
                                                                 
 dense_3148 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 982202 (3.75 MB)
Trainable params: 981178 (3.74 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 648:
  Value: 0.7784
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.001222615941729988

Model: "sequential_648"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_648 (Flatten)       (None, 784)               0         
                                                                 
 dense_3149 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2501 (Dropout)      (None, 512)               0         
                                                                 
 dense_3150 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2502 (Dropout)      (None, 416)               0         
                                                                 
 dense_3151 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_755 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2503 (Dropout)      (None, 512)               0         
                                                                 
 dense_3152 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2504 (Dropout)      (None, 288)               0         
                                                                 
 dense_3153 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 649:
  Value: 0.9177
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013803140808824044

Model: "sequential_649"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_649 (Flatten)       (None, 784)               0         
                                                                 
 dense_3154 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2505 (Dropout)      (None, 512)               0         
                                                                 
 dense_3155 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2506 (Dropout)      (None, 416)               0         
                                                                 
 dense_3156 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_756 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2507 (Dropout)      (None, 480)               0         
                                                                 
 dense_3157 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2508 (Dropout)      (None, 288)               0         
                                                                 
 dense_3158 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 650:
  Value: 0.8623
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015117799433239558

Model: "sequential_650"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_650 (Flatten)       (None, 784)               0         
                                                                 
 dense_3159 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2509 (Dropout)      (None, 480)               0         
                                                                 
 dense_3160 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2510 (Dropout)      (None, 448)               0         
                                                                 
 dense_3161 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_757 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2511 (Dropout)      (None, 512)               0         
                                                                 
 dense_3162 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2512 (Dropout)      (None, 320)               0         
                                                                 
 dense_3163 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 651:
  Value: 0.9034
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0020249144310406464

Model: "sequential_651"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_651 (Flatten)       (None, 784)               0         
                                                                 
 dense_3164 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2513 (Dropout)      (None, 512)               0         
                                                                 
 dense_3165 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2514 (Dropout)      (None, 416)               0         
                                                                 
 dense_3166 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_758 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2515 (Dropout)      (None, 448)               0         
                                                                 
 dense_3167 (Dense)          (None, 288)               129312    
                                                                 
 dropout_2516 (Dropout)      (None, 288)               0         
                                                                 
 dense_3168 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 940762 (3.59 MB)
Trainable params: 939866 (3.59 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 652:
  Value: 0.8504
  num_layers: 4
  units_0: 160
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007981998734757256

Model: "sequential_652"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_652 (Flatten)       (None, 784)               0         
                                                                 
 dense_3169 (Dense)          (None, 160)               125600    
                                                                 
 dropout_2517 (Dropout)      (None, 160)               0         
                                                                 
 dense_3170 (Dense)          (None, 448)               72128     
                                                                 
 dropout_2518 (Dropout)      (None, 448)               0         
                                                                 
 dense_3171 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_759 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2519 (Dropout)      (None, 480)               0         
                                                                 
 dense_3172 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2520 (Dropout)      (None, 256)               0         
                                                                 
 dense_3173 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 544986 (2.08 MB)
Trainable params: 544026 (2.08 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 653:
  Value: 0.7736
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011376319549713445

Model: "sequential_653"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_653 (Flatten)       (None, 784)               0         
                                                                 
 dense_3174 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_760 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2521 (Dropout)      (None, 448)               0         
                                                                 
 dense_3175 (Dense)          (None, 416)               186784    
                                                                 
 dropout_2522 (Dropout)      (None, 416)               0         
                                                                 
 dense_3176 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_761 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2523 (Dropout)      (None, 512)               0         
                                                                 
 dense_3177 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2524 (Dropout)      (None, 320)               0         
                                                                 
 dense_3178 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 928314 (3.54 MB)
Trainable params: 926394 (3.53 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 654:
  Value: 0.0410
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0012916093691207496

Model: "sequential_654"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_654 (Flatten)       (None, 784)               0         
                                                                 
 dense_3179 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2525 (Dropout)      (None, 480)               0         
                                                                 
 dense_3180 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2526 (Dropout)      (None, 448)               0         
                                                                 
 dense_3181 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_762 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2527 (Dropout)      (None, 512)               0         
                                                                 
 dense_3182 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2528 (Dropout)      (None, 288)               0         
                                                                 
 dense_3183 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 655:
  Value: 0.8836
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009869558476147604

Model: "sequential_655"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_655 (Flatten)       (None, 784)               0         
                                                                 
 dense_3184 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2529 (Dropout)      (None, 512)               0         
                                                                 
 dense_3185 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2530 (Dropout)      (None, 416)               0         
                                                                 
 dense_3186 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_763 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2531 (Dropout)      (None, 480)               0         
                                                                 
 dense_3187 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2532 (Dropout)      (None, 288)               0         
                                                                 
 dense_3188 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 656:
  Value: 0.8831
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 224
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001734895034151185

Model: "sequential_656"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_656 (Flatten)       (None, 784)               0         
                                                                 
 dense_3189 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2533 (Dropout)      (None, 480)               0         
                                                                 
 dense_3190 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2534 (Dropout)      (None, 448)               0         
                                                                 
 dense_3191 (Dense)          (None, 224)               100576    
                                                                 
 batch_normalization_764 (B  (None, 224)               896       
 atchNormalization)                                              
                                                                 
 dropout_2535 (Dropout)      (None, 224)               0         
                                                                 
 dense_3192 (Dense)          (None, 288)               64800     
                                                                 
 dropout_2536 (Dropout)      (None, 288)               0         
                                                                 
 dense_3193 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 766074 (2.92 MB)
Trainable params: 765626 (2.92 MB)
Non-trainable params: 448 (1.75 KB)
_________________________________________________________________



Trial 657:
  Value: 0.6043
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0012293310788737215

Model: "sequential_657"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_657 (Flatten)       (None, 784)               0         
                                                                 
 dense_3194 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2537 (Dropout)      (None, 512)               0         
                                                                 
 dense_3195 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2538 (Dropout)      (None, 416)               0         
                                                                 
 dense_3196 (Dense)          (None, 512)               213504    
                                                                 
 dropout_2539 (Dropout)      (None, 512)               0         
                                                                 
 dense_3197 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2540 (Dropout)      (None, 320)               0         
                                                                 
 dense_3198 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1001338 (3.82 MB)
Trainable params: 1001338 (3.82 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 658:
  Value: 0.8202
  num_layers: 2
  units_0: 448
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.003106089898689005

Model: "sequential_658"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_658 (Flatten)       (None, 784)               0         
                                                                 
 dense_3199 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2541 (Dropout)      (None, 448)               0         
                                                                 
 dense_3200 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2542 (Dropout)      (None, 448)               0         
                                                                 
 dense_3201 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 564506 (2.15 MB)
Trainable params: 564506 (2.15 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 659:
  Value: 0.6424
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 256
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013708141713655196

Model: "sequential_659"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_659 (Flatten)       (None, 784)               0         
                                                                 
 dense_3202 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2543 (Dropout)      (None, 512)               0         
                                                                 
 dense_3203 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2544 (Dropout)      (None, 416)               0         
                                                                 
 dense_3204 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_765 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2545 (Dropout)      (None, 448)               0         
                                                                 
 dense_3205 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2546 (Dropout)      (None, 256)               0         
                                                                 
 dense_3206 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 925562 (3.53 MB)
Trainable params: 924666 (3.53 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 660:
  Value: 0.8605
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010816453732917872

Model: "sequential_660"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_660 (Flatten)       (None, 784)               0         
                                                                 
 dense_3207 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2547 (Dropout)      (None, 480)               0         
                                                                 
 dense_3208 (Dense)          (None, 384)               184704    
                                                                 
 dropout_2548 (Dropout)      (None, 384)               0         
                                                                 
 dense_3209 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_766 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2549 (Dropout)      (None, 480)               0         
                                                                 
 dense_3210 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2550 (Dropout)      (None, 288)               0         
                                                                 
 dense_3211 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 894266 (3.41 MB)
Trainable params: 893306 (3.41 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 661:
  Value: 0.8046
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0072577101383561925

Model: "sequential_661"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_661 (Flatten)       (None, 784)               0         
                                                                 
 dense_3212 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2551 (Dropout)      (None, 480)               0         
                                                                 
 dense_3213 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2552 (Dropout)      (None, 448)               0         
                                                                 
 dense_3214 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_767 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2553 (Dropout)      (None, 512)               0         
                                                                 
 dense_3215 (Dense)          (None, 256)               131328    
                                                                 
 batch_normalization_768 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_2554 (Dropout)      (None, 256)               0         
                                                                 
 dense_3216 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 963258 (3.67 MB)
Trainable params: 961722 (3.67 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 662:
  Value: 0.0387
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.001609239294862929

Model: "sequential_662"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_662 (Flatten)       (None, 784)               0         
                                                                 
 dense_3217 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2555 (Dropout)      (None, 512)               0         
                                                                 
 dense_3218 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2556 (Dropout)      (None, 416)               0         
                                                                 
 dense_3219 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_769 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2557 (Dropout)      (None, 480)               0         
                                                                 
 dense_3220 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2558 (Dropout)      (None, 320)               0         
                                                                 
 dense_3221 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 979674 (3.74 MB)
Trainable params: 978714 (3.73 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 663:
  Value: 0.8839
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008779245936679184

Model: "sequential_663"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_663 (Flatten)       (None, 784)               0         
                                                                 
 dense_3222 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2559 (Dropout)      (None, 480)               0         
                                                                 
 dense_3223 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2560 (Dropout)      (None, 416)               0         
                                                                 
 dense_3224 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_770 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2561 (Dropout)      (None, 512)               0         
                                                                 
 dense_3225 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2562 (Dropout)      (None, 352)               0         
                                                                 
 dense_3226 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 982202 (3.75 MB)
Trainable params: 981178 (3.74 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 664:
  Value: 0.5347
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014372065517274787

Model: "sequential_664"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_664 (Flatten)       (None, 784)               0         
                                                                 
 dense_3227 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2563 (Dropout)      (None, 512)               0         
                                                                 
 dense_3228 (Dense)          (None, 320)               164160    
                                                                 
 batch_normalization_771 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_2564 (Dropout)      (None, 320)               0         
                                                                 
 dense_3229 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_772 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2565 (Dropout)      (None, 512)               0         
                                                                 
 dense_3230 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2566 (Dropout)      (None, 288)               0         
                                                                 
 dense_3231 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 889018 (3.39 MB)
Trainable params: 887354 (3.38 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 665:
  Value: 0.9201
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002582583803448046

Model: "sequential_665"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_665 (Flatten)       (None, 784)               0         
                                                                 
 dense_3232 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2567 (Dropout)      (None, 512)               0         
                                                                 
 dense_3233 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2568 (Dropout)      (None, 448)               0         
                                                                 
 dense_3234 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_773 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2569 (Dropout)      (None, 480)               0         
                                                                 
 dense_3235 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2570 (Dropout)      (None, 288)               0         
                                                                 
 dense_3236 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 666:
  Value: 0.8627
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00127466691343267

Model: "sequential_666"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_666 (Flatten)       (None, 784)               0         
                                                                 
 dense_3237 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2571 (Dropout)      (None, 480)               0         
                                                                 
 dense_3238 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2572 (Dropout)      (None, 416)               0         
                                                                 
 dense_3239 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_774 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2573 (Dropout)      (None, 512)               0         
                                                                 
 dense_3240 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2574 (Dropout)      (None, 320)               0         
                                                                 
 dense_3241 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 667:
  Value: 0.8586
  num_layers: 4
  units_0: 448
  units_1: 384
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011749994585378558

Model: "sequential_667"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_667 (Flatten)       (None, 784)               0         
                                                                 
 dense_3242 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2575 (Dropout)      (None, 448)               0         
                                                                 
 dense_3243 (Dense)          (None, 384)               172416    
                                                                 
 dropout_2576 (Dropout)      (None, 384)               0         
                                                                 
 dense_3244 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_775 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2577 (Dropout)      (None, 480)               0         
                                                                 
 dense_3245 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2578 (Dropout)      (None, 256)               0         
                                                                 
 dense_3246 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 840634 (3.21 MB)
Trainable params: 839674 (3.20 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 668:
  Value: 0.9204
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019142098069984542

Model: "sequential_668"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_668 (Flatten)       (None, 784)               0         
                                                                 
 dense_3247 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2579 (Dropout)      (None, 480)               0         
                                                                 
 dense_3248 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2580 (Dropout)      (None, 448)               0         
                                                                 
 dense_3249 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_776 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2581 (Dropout)      (None, 512)               0         
                                                                 
 dense_3250 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2582 (Dropout)      (None, 288)               0         
                                                                 
 dense_3251 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 669:
  Value: 0.9178
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001012905201523054

Model: "sequential_669"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_669 (Flatten)       (None, 784)               0         
                                                                 
 dense_3252 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2583 (Dropout)      (None, 512)               0         
                                                                 
 dense_3253 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2584 (Dropout)      (None, 416)               0         
                                                                 
 dense_3254 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_777 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2585 (Dropout)      (None, 480)               0         
                                                                 
 dense_3255 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2586 (Dropout)      (None, 288)               0         
                                                                 
 dense_3256 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 670:
  Value: 0.8280
  num_layers: 4
  units_0: 224
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002245035919438823

Model: "sequential_670"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_670 (Flatten)       (None, 784)               0         
                                                                 
 dense_3257 (Dense)          (None, 224)               175840    
                                                                 
 dropout_2587 (Dropout)      (None, 224)               0         
                                                                 
 dense_3258 (Dense)          (None, 448)               100800    
                                                                 
 dropout_2588 (Dropout)      (None, 448)               0         
                                                                 
 dense_3259 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_778 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2589 (Dropout)      (None, 512)               0         
                                                                 
 dense_3260 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2590 (Dropout)      (None, 320)               0         
                                                                 
 dense_3261 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 681082 (2.60 MB)
Trainable params: 680058 (2.59 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 671:
  Value: 0.9175
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0028466724298620997

Model: "sequential_671"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_671 (Flatten)       (None, 784)               0         
                                                                 
 dense_3262 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2591 (Dropout)      (None, 512)               0         
                                                                 
 dense_3263 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2592 (Dropout)      (None, 416)               0         
                                                                 
 dense_3264 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_779 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2593 (Dropout)      (None, 448)               0         
                                                                 
 dense_3265 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2594 (Dropout)      (None, 256)               0         
                                                                 
 dense_3266 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 925562 (3.53 MB)
Trainable params: 924666 (3.53 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 672:
  Value: 0.1604
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.00147732299087513

Model: "sequential_672"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_672 (Flatten)       (None, 784)               0         
                                                                 
 dense_3267 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_780 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2595 (Dropout)      (None, 480)               0         
                                                                 
 dense_3268 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2596 (Dropout)      (None, 448)               0         
                                                                 
 dense_3269 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_781 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2597 (Dropout)      (None, 512)               0         
                                                                 
 dense_3270 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2598 (Dropout)      (None, 320)               0         
                                                                 
 dense_3271 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 998650 (3.81 MB)
Trainable params: 996666 (3.80 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 673:
  Value: 0.8947
  num_layers: 4
  units_0: 320
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.4
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011057421348841347

Model: "sequential_673"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_673 (Flatten)       (None, 784)               0         
                                                                 
 dense_3272 (Dense)          (None, 320)               251200    
                                                                 
 dropout_2599 (Dropout)      (None, 320)               0         
                                                                 
 dense_3273 (Dense)          (None, 384)               123264    
                                                                 
 dropout_2600 (Dropout)      (None, 384)               0         
                                                                 
 dense_3274 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_782 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2601 (Dropout)      (None, 480)               0         
                                                                 
 dense_3275 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2602 (Dropout)      (None, 288)               0         
                                                                 
 dense_3276 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 707226 (2.70 MB)
Trainable params: 706266 (2.69 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 674:
  Value: 0.8562
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.004515897037441062

Model: "sequential_674"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_674 (Flatten)       (None, 784)               0         
                                                                 
 dense_3277 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2603 (Dropout)      (None, 480)               0         
                                                                 
 dense_3278 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2604 (Dropout)      (None, 416)               0         
                                                                 
 dense_3279 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_783 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2605 (Dropout)      (None, 512)               0         
                                                                 
 dense_3280 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2606 (Dropout)      (None, 288)               0         
                                                                 
 dense_3281 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 675:
  Value: 0.8532
  num_layers: 3
  units_0: 448
  units_1: 448
  units_2: 480
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0013514578081827448

Model: "sequential_675"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_675 (Flatten)       (None, 784)               0         
                                                                 
 dense_3282 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2607 (Dropout)      (None, 448)               0         
                                                                 
 dense_3283 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2608 (Dropout)      (None, 448)               0         
                                                                 
 dense_3284 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_784 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2609 (Dropout)      (None, 480)               0         
                                                                 
 dense_3285 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 782778 (2.99 MB)
Trainable params: 781818 (2.98 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 676:
  Value: 0.9198
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017055463369211239

Model: "sequential_676"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_676 (Flatten)       (None, 784)               0         
                                                                 
 dense_3286 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2610 (Dropout)      (None, 512)               0         
                                                                 
 dense_3287 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2611 (Dropout)      (None, 416)               0         
                                                                 
 dense_3288 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_785 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2612 (Dropout)      (None, 512)               0         
                                                                 
 dense_3289 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2613 (Dropout)      (None, 256)               0         
                                                                 
 dense_3290 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 968890 (3.70 MB)
Trainable params: 967866 (3.69 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 677:
  Value: 0.7944
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012214458485897725

Model: "sequential_677"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_677 (Flatten)       (None, 784)               0         
                                                                 
 dense_3291 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2614 (Dropout)      (None, 512)               0         
                                                                 
 dense_3292 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2615 (Dropout)      (None, 448)               0         
                                                                 
 dense_3293 (Dense)          (None, 480)               215520    
                                                                 
 dropout_2616 (Dropout)      (None, 480)               0         
                                                                 
 dense_3294 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2617 (Dropout)      (None, 320)               0         
                                                                 
 dense_3295 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1009530 (3.85 MB)
Trainable params: 1009530 (3.85 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 678:
  Value: 0.9172
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009341046721494788

Model: "sequential_678"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_678 (Flatten)       (None, 784)               0         
                                                                 
 dense_3296 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2618 (Dropout)      (None, 480)               0         
                                                                 
 dense_3297 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2619 (Dropout)      (None, 416)               0         
                                                                 
 dense_3298 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_786 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2620 (Dropout)      (None, 512)               0         
                                                                 
 dense_3299 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2621 (Dropout)      (None, 288)               0         
                                                                 
 dense_3300 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 679:
  Value: 0.4609
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015642898168639504

Model: "sequential_679"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_679 (Flatten)       (None, 784)               0         
                                                                 
 dense_3301 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2622 (Dropout)      (None, 480)               0         
                                                                 
 dense_3302 (Dense)          (None, 384)               184704    
                                                                 
 batch_normalization_787 (B  (None, 384)               1536      
 atchNormalization)                                              
                                                                 
 dropout_2623 (Dropout)      (None, 384)               0         
                                                                 
 dense_3303 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_788 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2624 (Dropout)      (None, 512)               0         
                                                                 
 dense_3304 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2625 (Dropout)      (None, 288)               0         
                                                                 
 dense_3305 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 917466 (3.50 MB)
Trainable params: 915674 (3.49 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 680:
  Value: 0.8408
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 32
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013487995800600223

Model: "sequential_680"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_680 (Flatten)       (None, 784)               0         
                                                                 
 dense_3306 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2626 (Dropout)      (None, 512)               0         
                                                                 
 dense_3307 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2627 (Dropout)      (None, 416)               0         
                                                                 
 dense_3308 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_789 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2628 (Dropout)      (None, 512)               0         
                                                                 
 dense_3309 (Dense)          (None, 32)                16416     
                                                                 
 dropout_2629 (Dropout)      (None, 32)                0         
                                                                 
 dense_3310 (Dense)          (None, 26)                858       
                                                                 
=================================================================
Total params: 848154 (3.24 MB)
Trainable params: 847130 (3.23 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 681:
  Value: 0.8062
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 448
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0020926935205897506

Model: "sequential_681"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_681 (Flatten)       (None, 784)               0         
                                                                 
 dense_3311 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2630 (Dropout)      (None, 512)               0         
                                                                 
 dense_3312 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2631 (Dropout)      (None, 448)               0         
                                                                 
 dense_3313 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_790 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2632 (Dropout)      (None, 448)               0         
                                                                 
 dense_3314 (Dense)          (None, 320)               143680    
                                                                 
 batch_normalization_791 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_2633 (Dropout)      (None, 320)               0         
                                                                 
 dense_3315 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 987994 (3.77 MB)
Trainable params: 986458 (3.76 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 682:
  Value: 0.0625
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0011524465997287984

Model: "sequential_682"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_682 (Flatten)       (None, 784)               0         
                                                                 
 dense_3316 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2634 (Dropout)      (None, 448)               0         
                                                                 
 dense_3317 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2635 (Dropout)      (None, 448)               0         
                                                                 
 dense_3318 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_792 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2636 (Dropout)      (None, 480)               0         
                                                                 
 dense_3319 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2637 (Dropout)      (None, 256)               0         
                                                                 
 dense_3320 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 900090 (3.43 MB)
Trainable params: 899130 (3.43 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 683:
  Value: 0.9195
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005028446882438374

Model: "sequential_683"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_683 (Flatten)       (None, 784)               0         
                                                                 
 dense_3321 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2638 (Dropout)      (None, 480)               0         
                                                                 
 dense_3322 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2639 (Dropout)      (None, 416)               0         
                                                                 
 dense_3323 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_793 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2640 (Dropout)      (None, 480)               0         
                                                                 
 dense_3324 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2641 (Dropout)      (None, 288)               0         
                                                                 
 dense_3325 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 684:
  Value: 0.9197
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010660966419492191

Model: "sequential_684"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_684 (Flatten)       (None, 784)               0         
                                                                 
 dense_3326 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2642 (Dropout)      (None, 512)               0         
                                                                 
 dense_3327 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2643 (Dropout)      (None, 416)               0         
                                                                 
 dense_3328 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_794 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2644 (Dropout)      (None, 512)               0         
                                                                 
 dense_3329 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2645 (Dropout)      (None, 320)               0         
                                                                 
 dense_3330 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 685:
  Value: 0.7941
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.002488875585509539

Model: "sequential_685"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_685 (Flatten)       (None, 784)               0         
                                                                 
 dense_3331 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2646 (Dropout)      (None, 480)               0         
                                                                 
 dense_3332 (Dense)          (None, 384)               184704    
                                                                 
 dropout_2647 (Dropout)      (None, 384)               0         
                                                                 
 dense_3333 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_795 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2648 (Dropout)      (None, 512)               0         
                                                                 
 dense_3334 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2649 (Dropout)      (None, 288)               0         
                                                                 
 dense_3335 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 915930 (3.49 MB)
Trainable params: 914906 (3.49 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 686:
  Value: 0.8464
  num_layers: 4
  units_0: 352
  units_1: 448
  units_2: 448
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014272770683479623

Model: "sequential_686"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_686 (Flatten)       (None, 784)               0         
                                                                 
 dense_3336 (Dense)          (None, 352)               276320    
                                                                 
 dropout_2650 (Dropout)      (None, 352)               0         
                                                                 
 dense_3337 (Dense)          (None, 448)               158144    
                                                                 
 dropout_2651 (Dropout)      (None, 448)               0         
                                                                 
 dense_3338 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_796 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2652 (Dropout)      (None, 448)               0         
                                                                 
 dense_3339 (Dense)          (None, 352)               158048    
                                                                 
 dropout_2653 (Dropout)      (None, 352)               0         
                                                                 
 dense_3340 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 804634 (3.07 MB)
Trainable params: 803738 (3.07 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 687:
  Value: 0.8198
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 32
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001798562932480116

Model: "sequential_687"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_687 (Flatten)       (None, 784)               0         
                                                                 
 dense_3341 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2654 (Dropout)      (None, 512)               0         
                                                                 
 dense_3342 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2655 (Dropout)      (None, 448)               0         
                                                                 
 dense_3343 (Dense)          (None, 32)                14368     
                                                                 
 batch_normalization_797 (B  (None, 32)                128       
 atchNormalization)                                              
                                                                 
 dropout_2656 (Dropout)      (None, 32)                0         
                                                                 
 dense_3344 (Dense)          (None, 256)               8448      
                                                                 
 dropout_2657 (Dropout)      (None, 256)               0         
                                                                 
 dense_3345 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 661370 (2.52 MB)
Trainable params: 661306 (2.52 MB)
Non-trainable params: 64 (256.00 Byte)
_________________________________________________________________



Trial 688:
  Value: 0.0410
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0012616284174072718

Model: "sequential_688"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_688 (Flatten)       (None, 784)               0         
                                                                 
 dense_3346 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2658 (Dropout)      (None, 480)               0         
                                                                 
 dense_3347 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2659 (Dropout)      (None, 416)               0         
                                                                 
 dense_3348 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_798 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2660 (Dropout)      (None, 480)               0         
                                                                 
 dense_3349 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2661 (Dropout)      (None, 288)               0         
                                                                 
 dense_3350 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 689:
  Value: 0.8738
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007731436707825105

Model: "sequential_689"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_689 (Flatten)       (None, 784)               0         
                                                                 
 dense_3351 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2662 (Dropout)      (None, 512)               0         
                                                                 
 dense_3352 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2663 (Dropout)      (None, 384)               0         
                                                                 
 dense_3353 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_799 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2664 (Dropout)      (None, 512)               0         
                                                                 
 dense_3354 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2665 (Dropout)      (None, 288)               0         
                                                                 
 dense_3355 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 690:
  Value: 0.8624
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015599309125789156

Model: "sequential_690"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_690 (Flatten)       (None, 784)               0         
                                                                 
 dense_3356 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2666 (Dropout)      (None, 480)               0         
                                                                 
 dense_3357 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2667 (Dropout)      (None, 416)               0         
                                                                 
 dense_3358 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_800 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2668 (Dropout)      (None, 480)               0         
                                                                 
 dense_3359 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2669 (Dropout)      (None, 320)               0         
                                                                 
 dense_3360 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 941242 (3.59 MB)
Trainable params: 940282 (3.59 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 691:
  Value: 0.9217
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009511728623697185

Model: "sequential_691"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_691 (Flatten)       (None, 784)               0         
                                                                 
 dense_3361 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2670 (Dropout)      (None, 512)               0         
                                                                 
 dense_3362 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2671 (Dropout)      (None, 448)               0         
                                                                 
 dense_3363 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_801 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2672 (Dropout)      (None, 512)               0         
                                                                 
 dense_3364 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2673 (Dropout)      (None, 288)               0         
                                                                 
 dense_3365 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 692:
  Value: 0.8367
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007632582629288734

Model: "sequential_692"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_692 (Flatten)       (None, 784)               0         
                                                                 
 dense_3366 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_802 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2674 (Dropout)      (None, 480)               0         
                                                                 
 dense_3367 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2675 (Dropout)      (None, 448)               0         
                                                                 
 dense_3368 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_803 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2676 (Dropout)      (None, 480)               0         
                                                                 
 dense_3369 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2677 (Dropout)      (None, 288)               0         
                                                                 
 dense_3370 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 957690 (3.65 MB)
Trainable params: 955770 (3.65 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 693:
  Value: 0.8570
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000874125619479695

Model: "sequential_693"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_693 (Flatten)       (None, 784)               0         
                                                                 
 dense_3371 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2678 (Dropout)      (None, 448)               0         
                                                                 
 dense_3372 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2679 (Dropout)      (None, 448)               0         
                                                                 
 dense_3373 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_804 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2680 (Dropout)      (None, 512)               0         
                                                                 
 dense_3374 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2681 (Dropout)      (None, 256)               0         
                                                                 
 dense_3375 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 922778 (3.52 MB)
Trainable params: 921754 (3.52 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 694:
  Value: 0.9206
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009776646097154327

Model: "sequential_694"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_694 (Flatten)       (None, 784)               0         
                                                                 
 dense_3376 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2682 (Dropout)      (None, 512)               0         
                                                                 
 dense_3377 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2683 (Dropout)      (None, 448)               0         
                                                                 
 dense_3378 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_805 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2684 (Dropout)      (None, 512)               0         
                                                                 
 dense_3379 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2685 (Dropout)      (None, 288)               0         
                                                                 
 dense_3380 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 695:
  Value: 0.9097
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001046605193027994

Model: "sequential_695"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_695 (Flatten)       (None, 784)               0         
                                                                 
 dense_3381 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2686 (Dropout)      (None, 480)               0         
                                                                 
 dense_3382 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2687 (Dropout)      (None, 448)               0         
                                                                 
 dense_3383 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_806 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2688 (Dropout)      (None, 512)               0         
                                                                 
 dense_3384 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2689 (Dropout)      (None, 288)               0         
                                                                 
 dense_3385 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 696:
  Value: 0.9165
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008474619407816016

Model: "sequential_696"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_696 (Flatten)       (None, 784)               0         
                                                                 
 dense_3386 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2690 (Dropout)      (None, 512)               0         
                                                                 
 dense_3387 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2691 (Dropout)      (None, 448)               0         
                                                                 
 dense_3388 (Dense)          (None, 480)               215520    
                                                                 
 dropout_2692 (Dropout)      (None, 480)               0         
                                                                 
 dense_3389 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2693 (Dropout)      (None, 256)               0         
                                                                 
 dense_3390 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 977082 (3.73 MB)
Trainable params: 977082 (3.73 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 697:
  Value: 0.9206
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009438824086706308

Model: "sequential_697"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_697 (Flatten)       (None, 784)               0         
                                                                 
 dense_3391 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2694 (Dropout)      (None, 480)               0         
                                                                 
 dense_3392 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2695 (Dropout)      (None, 448)               0         
                                                                 
 dense_3393 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_807 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2696 (Dropout)      (None, 448)               0         
                                                                 
 dense_3394 (Dense)          (None, 288)               129312    
                                                                 
 dropout_2697 (Dropout)      (None, 288)               0         
                                                                 
 dense_3395 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 932058 (3.56 MB)
Trainable params: 931162 (3.55 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 698:
  Value: 0.2942
  num_layers: 4
  units_0: 128
  units_1: 480
  units_2: 256
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011642756484501239

Model: "sequential_698"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_698 (Flatten)       (None, 784)               0         
                                                                 
 dense_3396 (Dense)          (None, 128)               100480    
                                                                 
 dropout_2698 (Dropout)      (None, 128)               0         
                                                                 
 dense_3397 (Dense)          (None, 480)               61920     
                                                                 
 batch_normalization_808 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2699 (Dropout)      (None, 480)               0         
                                                                 
 dense_3398 (Dense)          (None, 256)               123136    
                                                                 
 batch_normalization_809 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_2700 (Dropout)      (None, 256)               0         
                                                                 
 dense_3399 (Dense)          (None, 288)               74016     
                                                                 
 dropout_2701 (Dropout)      (None, 288)               0         
                                                                 
 dense_3400 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 370010 (1.41 MB)
Trainable params: 368538 (1.41 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 699:
  Value: 0.0375
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0012969283481964289

Model: "sequential_699"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_699 (Flatten)       (None, 784)               0         
                                                                 
 dense_3401 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2702 (Dropout)      (None, 512)               0         
                                                                 
 dense_3402 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2703 (Dropout)      (None, 448)               0         
                                                                 
 dense_3403 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_810 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2704 (Dropout)      (None, 512)               0         
                                                                 
 dense_3404 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2705 (Dropout)      (None, 288)               0         
                                                                 
 dense_3405 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 700:
  Value: 0.8620
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012113461495429259

Model: "sequential_700"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_700 (Flatten)       (None, 784)               0         
                                                                 
 dense_3406 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2706 (Dropout)      (None, 512)               0         
                                                                 
 dense_3407 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2707 (Dropout)      (None, 352)               0         
                                                                 
 dense_3408 (Dense)          (None, 480)               169440    
                                                                 
 batch_normalization_811 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2708 (Dropout)      (None, 480)               0         
                                                                 
 dense_3409 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2709 (Dropout)      (None, 256)               0         
                                                                 
 dense_3410 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 883674 (3.37 MB)
Trainable params: 882714 (3.37 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 701:
  Value: 0.7925
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0014334307169269521

Model: "sequential_701"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_701 (Flatten)       (None, 784)               0         
                                                                 
 dense_3411 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2710 (Dropout)      (None, 480)               0         
                                                                 
 dense_3412 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2711 (Dropout)      (None, 448)               0         
                                                                 
 dense_3413 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_812 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2712 (Dropout)      (None, 512)               0         
                                                                 
 dense_3414 (Dense)          (None, 288)               147744    
                                                                 
 batch_normalization_813 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_2713 (Dropout)      (None, 288)               0         
                                                                 
 dense_3415 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 980634 (3.74 MB)
Trainable params: 979034 (3.73 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 702:
  Value: 0.6049
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.00108947769842565

Model: "sequential_702"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_702 (Flatten)       (None, 784)               0         
                                                                 
 dense_3416 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2714 (Dropout)      (None, 448)               0         
                                                                 
 dense_3417 (Dense)          (None, 480)               215520    
                                                                 
 dropout_2715 (Dropout)      (None, 480)               0         
                                                                 
 dense_3418 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_814 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2716 (Dropout)      (None, 480)               0         
                                                                 
 dense_3419 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2717 (Dropout)      (None, 256)               0         
                                                                 
 dense_3420 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 929818 (3.55 MB)
Trainable params: 928858 (3.54 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 703:
  Value: 0.5794
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001667595467156365

Model: "sequential_703"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_703 (Flatten)       (None, 784)               0         
                                                                 
 dense_3421 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2718 (Dropout)      (None, 480)               0         
                                                                 
 dense_3422 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2719 (Dropout)      (None, 448)               0         
                                                                 
 dense_3423 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_815 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2720 (Dropout)      (None, 512)               0         
                                                                 
 dense_3424 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2721 (Dropout)      (None, 288)               0         
                                                                 
 dense_3425 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 704:
  Value: 0.9204
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009204532271907927

Model: "sequential_704"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_704 (Flatten)       (None, 784)               0         
                                                                 
 dense_3426 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2722 (Dropout)      (None, 512)               0         
                                                                 
 dense_3427 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2723 (Dropout)      (None, 448)               0         
                                                                 
 dense_3428 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_816 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2724 (Dropout)      (None, 480)               0         
                                                                 
 dense_3429 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2725 (Dropout)      (None, 288)               0         
                                                                 
 dense_3430 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 705:
  Value: 0.8139
  num_layers: 2
  units_0: 480
  units_1: 480
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0013281466407479715

Model: "sequential_705"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_705 (Flatten)       (None, 784)               0         
                                                                 
 dense_3431 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2726 (Dropout)      (None, 480)               0         
                                                                 
 dense_3432 (Dense)          (None, 480)               230880    
                                                                 
 dropout_2727 (Dropout)      (None, 480)               0         
                                                                 
 dense_3433 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 620186 (2.37 MB)
Trainable params: 620186 (2.37 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 706:
  Value: 0.9201
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015089294539565453

Model: "sequential_706"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_706 (Flatten)       (None, 784)               0         
                                                                 
 dense_3434 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2728 (Dropout)      (None, 512)               0         
                                                                 
 dense_3435 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2729 (Dropout)      (None, 448)               0         
                                                                 
 dense_3436 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_817 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2730 (Dropout)      (None, 512)               0         
                                                                 
 dense_3437 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2731 (Dropout)      (None, 384)               0         
                                                                 
 dense_3438 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 1070682 (4.08 MB)
Trainable params: 1069658 (4.08 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 707:
  Value: 0.8203
  num_layers: 4
  units_0: 480
  units_1: 32
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010415350717562794

Model: "sequential_707"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_707 (Flatten)       (None, 784)               0         
                                                                 
 dense_3439 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2732 (Dropout)      (None, 480)               0         
                                                                 
 dense_3440 (Dense)          (None, 32)                15392     
                                                                 
 dropout_2733 (Dropout)      (None, 32)                0         
                                                                 
 dense_3441 (Dense)          (None, 512)               16896     
                                                                 
 batch_normalization_818 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2734 (Dropout)      (None, 512)               0         
                                                                 
 dense_3442 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2735 (Dropout)      (None, 256)               0         
                                                                 
 dense_3443 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 549146 (2.09 MB)
Trainable params: 548122 (2.09 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 708:
  Value: 0.8536
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008009583254466699

Model: "sequential_708"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_708 (Flatten)       (None, 784)               0         
                                                                 
 dense_3444 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2736 (Dropout)      (None, 512)               0         
                                                                 
 dense_3445 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2737 (Dropout)      (None, 416)               0         
                                                                 
 dense_3446 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_819 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2738 (Dropout)      (None, 480)               0         
                                                                 
 dense_3447 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2739 (Dropout)      (None, 288)               0         
                                                                 
 dense_3448 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 709:
  Value: 0.8584
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011657563714601055

Model: "sequential_709"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_709 (Flatten)       (None, 784)               0         
                                                                 
 dense_3449 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2740 (Dropout)      (None, 448)               0         
                                                                 
 dense_3450 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2741 (Dropout)      (None, 448)               0         
                                                                 
 dense_3451 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_820 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2742 (Dropout)      (None, 512)               0         
                                                                 
 dense_3452 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2743 (Dropout)      (None, 288)               0         
                                                                 
 dense_3453 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 940026 (3.59 MB)
Trainable params: 939002 (3.58 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 710:
  Value: 0.8399
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001860640738666906

Model: "sequential_710"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_710 (Flatten)       (None, 784)               0         
                                                                 
 dense_3454 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_821 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2744 (Dropout)      (None, 480)               0         
                                                                 
 dense_3455 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2745 (Dropout)      (None, 416)               0         
                                                                 
 dense_3456 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_822 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2746 (Dropout)      (None, 448)               0         
                                                                 
 dense_3457 (Dense)          (None, 288)               129312    
                                                                 
 dropout_2747 (Dropout)      (None, 288)               0         
                                                                 
 dense_3458 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 904250 (3.45 MB)
Trainable params: 902394 (3.44 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 711:
  Value: 0.8278
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0013935411713020818

Model: "sequential_711"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_711 (Flatten)       (None, 784)               0         
                                                                 
 dense_3459 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2748 (Dropout)      (None, 512)               0         
                                                                 
 dense_3460 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 712:
  Value: 0.0419
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0012676287584431557

Model: "sequential_712"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_712 (Flatten)       (None, 784)               0         
                                                                 
 dense_3461 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2749 (Dropout)      (None, 512)               0         
                                                                 
 dense_3462 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2750 (Dropout)      (None, 416)               0         
                                                                 
 dense_3463 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_823 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2751 (Dropout)      (None, 480)               0         
                                                                 
 dense_3464 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2752 (Dropout)      (None, 256)               0         
                                                                 
 dense_3465 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 947226 (3.61 MB)
Trainable params: 946266 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 713:
  Value: 0.8589
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015999772818354662

Model: "sequential_713"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_713 (Flatten)       (None, 784)               0         
                                                                 
 dense_3466 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2753 (Dropout)      (None, 480)               0         
                                                                 
 dense_3467 (Dense)          (None, 480)               230880    
                                                                 
 dropout_2754 (Dropout)      (None, 480)               0         
                                                                 
 dense_3468 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_824 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2755 (Dropout)      (None, 512)               0         
                                                                 
 dense_3469 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2756 (Dropout)      (None, 288)               0         
                                                                 
 dense_3470 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1011258 (3.86 MB)
Trainable params: 1010234 (3.85 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 714:
  Value: 0.8567
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000689518188929742

Model: "sequential_714"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_714 (Flatten)       (None, 784)               0         
                                                                 
 dense_3471 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2757 (Dropout)      (None, 448)               0         
                                                                 
 dense_3472 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2758 (Dropout)      (None, 448)               0         
                                                                 
 dense_3473 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_825 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2759 (Dropout)      (None, 512)               0         
                                                                 
 dense_3474 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2760 (Dropout)      (None, 288)               0         
                                                                 
 dense_3475 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 940026 (3.59 MB)
Trainable params: 939002 (3.58 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 715:
  Value: 0.8035
  num_layers: 4
  units_0: 288
  units_1: 384
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0007329016342249899

Model: "sequential_715"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_715 (Flatten)       (None, 784)               0         
                                                                 
 dense_3476 (Dense)          (None, 288)               226080    
                                                                 
 dropout_2761 (Dropout)      (None, 288)               0         
                                                                 
 dense_3477 (Dense)          (None, 384)               110976    
                                                                 
 dropout_2762 (Dropout)      (None, 384)               0         
                                                                 
 dense_3478 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_826 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2763 (Dropout)      (None, 480)               0         
                                                                 
 dense_3479 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2764 (Dropout)      (None, 256)               0         
                                                                 
 dense_3480 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 653594 (2.49 MB)
Trainable params: 652634 (2.49 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 716:
  Value: 0.9196
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009894702008921513

Model: "sequential_716"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_716 (Flatten)       (None, 784)               0         
                                                                 
 dense_3481 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2765 (Dropout)      (None, 512)               0         
                                                                 
 dense_3482 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2766 (Dropout)      (None, 416)               0         
                                                                 
 dense_3483 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_827 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2767 (Dropout)      (None, 512)               0         
                                                                 
 dense_3484 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2768 (Dropout)      (None, 288)               0         
                                                                 
 dense_3485 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 717:
  Value: 0.0389
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.003964385402042109

Model: "sequential_717"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_717 (Flatten)       (None, 784)               0         
                                                                 
 dense_3486 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2769 (Dropout)      (None, 480)               0         
                                                                 
 dense_3487 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2770 (Dropout)      (None, 448)               0         
                                                                 
 dense_3488 (Dense)          (None, 480)               215520    
                                                                 
 dropout_2771 (Dropout)      (None, 480)               0         
                                                                 
 dense_3489 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2772 (Dropout)      (None, 320)               0         
                                                                 
 dense_3490 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970074 (3.70 MB)
Trainable params: 970074 (3.70 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 718:
  Value: 0.9062
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011302459162464396

Model: "sequential_718"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_718 (Flatten)       (None, 784)               0         
                                                                 
 dense_3491 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2773 (Dropout)      (None, 512)               0         
                                                                 
 dense_3492 (Dense)          (None, 480)               246240    
                                                                 
 batch_normalization_828 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2774 (Dropout)      (None, 480)               0         
                                                                 
 dense_3493 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_829 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2775 (Dropout)      (None, 512)               0         
                                                                 
 dense_3494 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2776 (Dropout)      (None, 288)               0         
                                                                 
 dense_3495 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1053658 (4.02 MB)
Trainable params: 1051674 (4.01 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 719:
  Value: 0.8565
  num_layers: 4
  units_0: 192
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008574643341581149

Model: "sequential_719"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_719 (Flatten)       (None, 784)               0         
                                                                 
 dense_3496 (Dense)          (None, 192)               150720    
                                                                 
 dropout_2777 (Dropout)      (None, 192)               0         
                                                                 
 dense_3497 (Dense)          (None, 416)               80288     
                                                                 
 dropout_2778 (Dropout)      (None, 416)               0         
                                                                 
 dense_3498 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_830 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2779 (Dropout)      (None, 480)               0         
                                                                 
 dense_3499 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2780 (Dropout)      (None, 256)               0         
                                                                 
 dense_3500 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 562906 (2.15 MB)
Trainable params: 561946 (2.14 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 720:
  Value: 0.9194
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001408509660158145

Model: "sequential_720"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_720 (Flatten)       (None, 784)               0         
                                                                 
 dense_3501 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2781 (Dropout)      (None, 480)               0         
                                                                 
 dense_3502 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2782 (Dropout)      (None, 448)               0         
                                                                 
 dense_3503 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_831 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2783 (Dropout)      (None, 512)               0         
                                                                 
 dense_3504 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2784 (Dropout)      (None, 320)               0         
                                                                 
 dense_3505 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 996730 (3.80 MB)
Trainable params: 995706 (3.80 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 721:
  Value: 0.8610
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012334134262693326

Model: "sequential_721"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_721 (Flatten)       (None, 784)               0         
                                                                 
 dense_3506 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2785 (Dropout)      (None, 512)               0         
                                                                 
 dense_3507 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2786 (Dropout)      (None, 384)               0         
                                                                 
 dense_3508 (Dense)          (None, 448)               172480    
                                                                 
 batch_normalization_832 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2787 (Dropout)      (None, 448)               0         
                                                                 
 dense_3509 (Dense)          (None, 288)               129312    
                                                                 
 dropout_2788 (Dropout)      (None, 288)               0         
                                                                 
 dense_3510 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 910010 (3.47 MB)
Trainable params: 909114 (3.47 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 722:
  Value: 0.5093
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016778516033743036

Model: "sequential_722"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_722 (Flatten)       (None, 784)               0         
                                                                 
 dense_3511 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2789 (Dropout)      (None, 480)               0         
                                                                 
 dense_3512 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2790 (Dropout)      (None, 416)               0         
                                                                 
 dense_3513 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_833 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2791 (Dropout)      (None, 480)               0         
                                                                 
 dense_3514 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2792 (Dropout)      (None, 288)               0         
                                                                 
 dense_3515 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 723:
  Value: 0.7249
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 192
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0010787664031665948

Model: "sequential_723"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_723 (Flatten)       (None, 784)               0         
                                                                 
 dense_3516 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2793 (Dropout)      (None, 448)               0         
                                                                 
 dense_3517 (Dense)          (None, 480)               215520    
                                                                 
 dropout_2794 (Dropout)      (None, 480)               0         
                                                                 
 dense_3518 (Dense)          (None, 192)               92352     
                                                                 
 batch_normalization_834 (B  (None, 192)               768       
 atchNormalization)                                              
                                                                 
 dropout_2795 (Dropout)      (None, 192)               0         
                                                                 
 dense_3519 (Dense)          (None, 256)               49408     
                                                                 
 batch_normalization_835 (B  (None, 256)               1024      
 atchNormalization)                                              
                                                                 
 dropout_2796 (Dropout)      (None, 256)               0         
                                                                 
 dense_3520 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 717434 (2.74 MB)
Trainable params: 716538 (2.73 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 724:
  Value: 0.6017
  num_layers: 3
  units_0: 32
  units_1: 448
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.004349040232333788

Model: "sequential_724"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_724 (Flatten)       (None, 784)               0         
                                                                 
 dense_3521 (Dense)          (None, 32)                25120     
                                                                 
 dropout_2797 (Dropout)      (None, 32)                0         
                                                                 
 dense_3522 (Dense)          (None, 448)               14784     
                                                                 
 dropout_2798 (Dropout)      (None, 448)               0         
                                                                 
 dense_3523 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_836 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2799 (Dropout)      (None, 512)               0         
                                                                 
 dense_3524 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 285178 (1.09 MB)
Trainable params: 284154 (1.08 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 725:
  Value: 0.0539
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0013226084499512079

Model: "sequential_725"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_725 (Flatten)       (None, 784)               0         
                                                                 
 dense_3525 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2800 (Dropout)      (None, 512)               0         
                                                                 
 dense_3526 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2801 (Dropout)      (None, 416)               0         
                                                                 
 dense_3527 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_837 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2802 (Dropout)      (None, 512)               0         
                                                                 
 dense_3528 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2803 (Dropout)      (None, 320)               0         
                                                                 
 dense_3529 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 726:
  Value: 0.8605
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0033380808927329954

Model: "sequential_726"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_726 (Flatten)       (None, 784)               0         
                                                                 
 dense_3530 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2804 (Dropout)      (None, 480)               0         
                                                                 
 dense_3531 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2805 (Dropout)      (None, 448)               0         
                                                                 
 dense_3532 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_838 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2806 (Dropout)      (None, 480)               0         
                                                                 
 dense_3533 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2807 (Dropout)      (None, 288)               0         
                                                                 
 dense_3534 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 955770 (3.65 MB)
Trainable params: 954810 (3.64 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 727:
  Value: 0.9226
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015184073200884204

Model: "sequential_727"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_727 (Flatten)       (None, 784)               0         
                                                                 
 dense_3535 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2808 (Dropout)      (None, 512)               0         
                                                                 
 dense_3536 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2809 (Dropout)      (None, 448)               0         
                                                                 
 dense_3537 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_839 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2810 (Dropout)      (None, 512)               0         
                                                                 
 dense_3538 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2811 (Dropout)      (None, 288)               0         
                                                                 
 dense_3539 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 728:
  Value: 0.8616
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017467032210356872

Model: "sequential_728"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_728 (Flatten)       (None, 784)               0         
                                                                 
 dense_3540 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2812 (Dropout)      (None, 512)               0         
                                                                 
 dense_3541 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2813 (Dropout)      (None, 416)               0         
                                                                 
 dense_3542 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_840 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2814 (Dropout)      (None, 512)               0         
                                                                 
 dense_3543 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2815 (Dropout)      (None, 320)               0         
                                                                 
 dense_3544 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 729:
  Value: 0.8421
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.009002379250207696

Model: "sequential_729"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_729 (Flatten)       (None, 784)               0         
                                                                 
 dense_3545 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_841 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2816 (Dropout)      (None, 512)               0         
                                                                 
 dense_3546 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2817 (Dropout)      (None, 416)               0         
                                                                 
 dense_3547 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_842 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2818 (Dropout)      (None, 480)               0         
                                                                 
 dense_3548 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2819 (Dropout)      (None, 288)               0         
                                                                 
 dense_3549 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 965498 (3.68 MB)
Trainable params: 963514 (3.68 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 730:
  Value: 0.7919
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0015292984816896284

Model: "sequential_730"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_730 (Flatten)       (None, 784)               0         
                                                                 
 dense_3550 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2820 (Dropout)      (None, 512)               0         
                                                                 
 dense_3551 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2821 (Dropout)      (None, 448)               0         
                                                                 
 dense_3552 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_843 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2822 (Dropout)      (None, 448)               0         
                                                                 
 dense_3553 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2823 (Dropout)      (None, 256)               0         
                                                                 
 dense_3554 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 956314 (3.65 MB)
Trainable params: 955418 (3.64 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 731:
  Value: 0.8598
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019830177684510737

Model: "sequential_731"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_731 (Flatten)       (None, 784)               0         
                                                                 
 dense_3555 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2824 (Dropout)      (None, 512)               0         
                                                                 
 dense_3556 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2825 (Dropout)      (None, 352)               0         
                                                                 
 dense_3557 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_844 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2826 (Dropout)      (None, 512)               0         
                                                                 
 dense_3558 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2827 (Dropout)      (None, 320)               0         
                                                                 
 dense_3559 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 937786 (3.58 MB)
Trainable params: 936762 (3.57 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 732:
  Value: 0.8567
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015300537241833476

Model: "sequential_732"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_732 (Flatten)       (None, 784)               0         
                                                                 
 dense_3560 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2828 (Dropout)      (None, 512)               0         
                                                                 
 dense_3561 (Dense)          (None, 480)               246240    
                                                                 
 dropout_2829 (Dropout)      (None, 480)               0         
                                                                 
 dense_3562 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_845 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2830 (Dropout)      (None, 480)               0         
                                                                 
 dense_3563 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2831 (Dropout)      (None, 288)               0         
                                                                 
 dense_3564 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1027002 (3.92 MB)
Trainable params: 1026042 (3.91 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 733:
  Value: 0.9203
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000914442994955292

Model: "sequential_733"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_733 (Flatten)       (None, 784)               0         
                                                                 
 dense_3565 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2832 (Dropout)      (None, 512)               0         
                                                                 
 dense_3566 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2833 (Dropout)      (None, 384)               0         
                                                                 
 dense_3567 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_846 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2834 (Dropout)      (None, 512)               0         
                                                                 
 dense_3568 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2835 (Dropout)      (None, 288)               0         
                                                                 
 dense_3569 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 734:
  Value: 0.9186
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011777817988002932

Model: "sequential_734"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_734 (Flatten)       (None, 784)               0         
                                                                 
 dense_3570 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2836 (Dropout)      (None, 512)               0         
                                                                 
 dense_3571 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2837 (Dropout)      (None, 416)               0         
                                                                 
 dense_3572 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_847 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2838 (Dropout)      (None, 480)               0         
                                                                 
 dense_3573 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2839 (Dropout)      (None, 256)               0         
                                                                 
 dense_3574 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 947226 (3.61 MB)
Trainable params: 946266 (3.61 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 735:
  Value: 0.8599
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.008202975304150954

Model: "sequential_735"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_735 (Flatten)       (None, 784)               0         
                                                                 
 dense_3575 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2840 (Dropout)      (None, 512)               0         
                                                                 
 dense_3576 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2841 (Dropout)      (None, 448)               0         
                                                                 
 dense_3577 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_848 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2842 (Dropout)      (None, 512)               0         
                                                                 
 dense_3578 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2843 (Dropout)      (None, 320)               0         
                                                                 
 dense_3579 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1036186 (3.95 MB)
Trainable params: 1035162 (3.95 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 736:
  Value: 0.8294
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019039305672712192

Model: "sequential_736"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_736 (Flatten)       (None, 784)               0         
                                                                 
 dense_3580 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2844 (Dropout)      (None, 512)               0         
                                                                 
 dense_3581 (Dense)          (None, 480)               246240    
                                                                 
 dropout_2845 (Dropout)      (None, 480)               0         
                                                                 
 dense_3582 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2846 (Dropout)      (None, 448)               0         
                                                                 
 dense_3583 (Dense)          (None, 288)               129312    
                                                                 
 dropout_2847 (Dropout)      (None, 288)               0         
                                                                 
 dense_3584 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1000474 (3.82 MB)
Trainable params: 1000474 (3.82 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 737:
  Value: 0.7222
  num_layers: 4
  units_0: 512
  units_1: 288
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009907466520663267

Model: "sequential_737"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_737 (Flatten)       (None, 784)               0         
                                                                 
 dense_3585 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2848 (Dropout)      (None, 512)               0         
                                                                 
 dense_3586 (Dense)          (None, 288)               147744    
                                                                 
 batch_normalization_849 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_2849 (Dropout)      (None, 288)               0         
                                                                 
 dense_3587 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_850 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2850 (Dropout)      (None, 512)               0         
                                                                 
 dense_3588 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2851 (Dropout)      (None, 288)               0         
                                                                 
 dense_3589 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 856090 (3.27 MB)
Trainable params: 854490 (3.26 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 738:
  Value: 0.0441
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0014422453224809196

Model: "sequential_738"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_738 (Flatten)       (None, 784)               0         
                                                                 
 dense_3590 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2852 (Dropout)      (None, 512)               0         
                                                                 
 dense_3591 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2853 (Dropout)      (None, 416)               0         
                                                                 
 dense_3592 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_851 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2854 (Dropout)      (None, 480)               0         
                                                                 
 dense_3593 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2855 (Dropout)      (None, 320)               0         
                                                                 
 dense_3594 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 979674 (3.74 MB)
Trainable params: 978714 (3.73 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 739:
  Value: 0.9197
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016376467697433816

Model: "sequential_739"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_739 (Flatten)       (None, 784)               0         
                                                                 
 dense_3595 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2856 (Dropout)      (None, 512)               0         
                                                                 
 dense_3596 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2857 (Dropout)      (None, 448)               0         
                                                                 
 dense_3597 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_852 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2858 (Dropout)      (None, 512)               0         
                                                                 
 dense_3598 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2859 (Dropout)      (None, 256)               0         
                                                                 
 dense_3599 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1001690 (3.82 MB)
Trainable params: 1000666 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 740:
  Value: 0.9090
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 128
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002170010989693381

Model: "sequential_740"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_740 (Flatten)       (None, 784)               0         
                                                                 
 dense_3600 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2860 (Dropout)      (None, 512)               0         
                                                                 
 dense_3601 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2861 (Dropout)      (None, 416)               0         
                                                                 
 dense_3602 (Dense)          (None, 128)               53376     
                                                                 
 batch_normalization_853 (B  (None, 128)               512       
 atchNormalization)                                              
                                                                 
 dropout_2862 (Dropout)      (None, 128)               0         
                                                                 
 dense_3603 (Dense)          (None, 288)               37152     
                                                                 
 dropout_2863 (Dropout)      (None, 288)               0         
                                                                 
 dense_3604 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 713882 (2.72 MB)
Trainable params: 713626 (2.72 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________



Trial 741:
  Value: 0.9134
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.001224943376228902

Model: "sequential_741"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_741 (Flatten)       (None, 784)               0         
                                                                 
 dense_3605 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2864 (Dropout)      (None, 512)               0         
                                                                 
 dense_3606 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2865 (Dropout)      (None, 416)               0         
                                                                 
 dense_3607 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_854 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2866 (Dropout)      (None, 512)               0         
                                                                 
 dense_3608 (Dense)          (None, 320)               164160    
                                                                 
 batch_normalization_855 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_2867 (Dropout)      (None, 320)               0         
                                                                 
 dense_3609 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1004666 (3.83 MB)
Trainable params: 1003002 (3.83 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 742:
  Value: 0.9196
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011198824435788754

Model: "sequential_742"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_742 (Flatten)       (None, 784)               0         
                                                                 
 dense_3610 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2868 (Dropout)      (None, 480)               0         
                                                                 
 dense_3611 (Dense)          (None, 384)               184704    
                                                                 
 dropout_2869 (Dropout)      (None, 384)               0         
                                                                 
 dense_3612 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_856 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2870 (Dropout)      (None, 480)               0         
                                                                 
 dense_3613 (Dense)          (None, 352)               169312    
                                                                 
 dropout_2871 (Dropout)      (None, 352)               0         
                                                                 
 dense_3614 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 926714 (3.54 MB)
Trainable params: 925754 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 743:
  Value: 0.7608
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.5
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002270160917733664

Model: "sequential_743"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_743 (Flatten)       (None, 784)               0         
                                                                 
 dense_3615 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2872 (Dropout)      (None, 512)               0         
                                                                 
 dense_3616 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2873 (Dropout)      (None, 448)               0         
                                                                 
 dense_3617 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_857 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2874 (Dropout)      (None, 512)               0         
                                                                 
 dense_3618 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2875 (Dropout)      (None, 288)               0         
                                                                 
 dense_3619 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 744:
  Value: 0.8008
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0014043856248609514

Model: "sequential_744"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_744 (Flatten)       (None, 784)               0         
                                                                 
 dense_3620 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2876 (Dropout)      (None, 480)               0         
                                                                 
 dense_3621 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2877 (Dropout)      (None, 448)               0         
                                                                 
 dense_3622 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_858 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2878 (Dropout)      (None, 480)               0         
                                                                 
 dense_3623 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2879 (Dropout)      (None, 256)               0         
                                                                 
 dense_3624 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 939546 (3.58 MB)
Trainable params: 938586 (3.58 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 745:
  Value: 0.0381
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0017924617180414052

Model: "sequential_745"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_745 (Flatten)       (None, 784)               0         
                                                                 
 dense_3625 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2880 (Dropout)      (None, 512)               0         
                                                                 
 dense_3626 (Dense)          (None, 480)               246240    
                                                                 
 dropout_2881 (Dropout)      (None, 480)               0         
                                                                 
 dense_3627 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_859 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2882 (Dropout)      (None, 512)               0         
                                                                 
 dense_3628 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2883 (Dropout)      (None, 288)               0         
                                                                 
 dense_3629 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1051738 (4.01 MB)
Trainable params: 1050714 (4.01 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 746:
  Value: 0.9192
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006604246551845331

Model: "sequential_746"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_746 (Flatten)       (None, 784)               0         
                                                                 
 dense_3630 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2884 (Dropout)      (None, 512)               0         
                                                                 
 dense_3631 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2885 (Dropout)      (None, 416)               0         
                                                                 
 dense_3632 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_860 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2886 (Dropout)      (None, 480)               0         
                                                                 
 dense_3633 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2887 (Dropout)      (None, 288)               0         
                                                                 
 dense_3634 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 747:
  Value: 0.8619
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005530617316819129

Model: "sequential_747"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_747 (Flatten)       (None, 784)               0         
                                                                 
 dense_3635 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2888 (Dropout)      (None, 480)               0         
                                                                 
 dense_3636 (Dense)          (None, 384)               184704    
                                                                 
 dropout_2889 (Dropout)      (None, 384)               0         
                                                                 
 dense_3637 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_861 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2890 (Dropout)      (None, 512)               0         
                                                                 
 dense_3638 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2891 (Dropout)      (None, 320)               0         
                                                                 
 dense_3639 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 933178 (3.56 MB)
Trainable params: 932154 (3.56 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 748:
  Value: 0.8416
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00081454207053585

Model: "sequential_748"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_748 (Flatten)       (None, 784)               0         
                                                                 
 dense_3640 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_862 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2892 (Dropout)      (None, 512)               0         
                                                                 
 dense_3641 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2893 (Dropout)      (None, 448)               0         
                                                                 
 dense_3642 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_863 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2894 (Dropout)      (None, 480)               0         
                                                                 
 dense_3643 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2895 (Dropout)      (None, 288)               0         
                                                                 
 dense_3644 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 997274 (3.80 MB)
Trainable params: 995290 (3.80 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 749:
  Value: 0.8603
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007312048893980343

Model: "sequential_749"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_749 (Flatten)       (None, 784)               0         
                                                                 
 dense_3645 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2896 (Dropout)      (None, 480)               0         
                                                                 
 dense_3646 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2897 (Dropout)      (None, 416)               0         
                                                                 
 dense_3647 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_864 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2898 (Dropout)      (None, 448)               0         
                                                                 
 dense_3648 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2899 (Dropout)      (None, 256)               0         
                                                                 
 dense_3649 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 887130 (3.38 MB)
Trainable params: 886234 (3.38 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 750:
  Value: 0.9189
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001665013877247765

Model: "sequential_750"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_750 (Flatten)       (None, 784)               0         
                                                                 
 dense_3650 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2900 (Dropout)      (None, 512)               0         
                                                                 
 dense_3651 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2901 (Dropout)      (None, 448)               0         
                                                                 
 dense_3652 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_865 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2902 (Dropout)      (None, 512)               0         
                                                                 
 dense_3653 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2903 (Dropout)      (None, 288)               0         
                                                                 
 dense_3654 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 751:
  Value: 0.6346
  num_layers: 4
  units_0: 64
  units_1: 480
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010207315498411073

Model: "sequential_751"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_751 (Flatten)       (None, 784)               0         
                                                                 
 dense_3655 (Dense)          (None, 64)                50240     
                                                                 
 dropout_2904 (Dropout)      (None, 64)                0         
                                                                 
 dense_3656 (Dense)          (None, 480)               31200     
                                                                 
 dropout_2905 (Dropout)      (None, 480)               0         
                                                                 
 dense_3657 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_866 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2906 (Dropout)      (None, 480)               0         
                                                                 
 dense_3658 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2907 (Dropout)      (None, 320)               0         
                                                                 
 dense_3659 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 476506 (1.82 MB)
Trainable params: 475546 (1.81 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 752:
  Value: 0.8615
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001536487864798348

Model: "sequential_752"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_752 (Flatten)       (None, 784)               0         
                                                                 
 dense_3660 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2908 (Dropout)      (None, 480)               0         
                                                                 
 dense_3661 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2909 (Dropout)      (None, 416)               0         
                                                                 
 dense_3662 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_867 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2910 (Dropout)      (None, 512)               0         
                                                                 
 dense_3663 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2911 (Dropout)      (None, 256)               0         
                                                                 
 dense_3664 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 930458 (3.55 MB)
Trainable params: 929434 (3.55 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 753:
  Value: 0.8607
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012785169120443196

Model: "sequential_753"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_753 (Flatten)       (None, 784)               0         
                                                                 
 dense_3665 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2912 (Dropout)      (None, 448)               0         
                                                                 
 dense_3666 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2913 (Dropout)      (None, 448)               0         
                                                                 
 dense_3667 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_868 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2914 (Dropout)      (None, 512)               0         
                                                                 
 dense_3668 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2915 (Dropout)      (None, 288)               0         
                                                                 
 dense_3669 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 940026 (3.59 MB)
Trainable params: 939002 (3.58 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 754:
  Value: 0.1204
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0011352360983173334

Model: "sequential_754"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_754 (Flatten)       (None, 784)               0         
                                                                 
 dense_3670 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2916 (Dropout)      (None, 512)               0         
                                                                 
 dense_3671 (Dense)          (None, 416)               213408    
                                                                 
 dropout_2917 (Dropout)      (None, 416)               0         
                                                                 
 dense_3672 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_869 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2918 (Dropout)      (None, 512)               0         
                                                                 
 dense_3673 (Dense)          (None, 288)               147744    
                                                                 
 dropout_2919 (Dropout)      (None, 288)               0         
                                                                 
 dense_3674 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 755:
  Value: 0.8258
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013856952649408862

Model: "sequential_755"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_755 (Flatten)       (None, 784)               0         
                                                                 
 dense_3675 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2920 (Dropout)      (None, 480)               0         
                                                                 
 dense_3676 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2921 (Dropout)      (None, 416)               0         
                                                                 
 dense_3677 (Dense)          (None, 480)               200160    
                                                                 
 dropout_2922 (Dropout)      (None, 480)               0         
                                                                 
 dense_3678 (Dense)          (None, 320)               153920    
                                                                 
 dropout_2923 (Dropout)      (None, 320)               0         
                                                                 
 dense_3679 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 939322 (3.58 MB)
Trainable params: 939322 (3.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 756:
  Value: 0.6056
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016808900561095684

Model: "sequential_756"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_756 (Flatten)       (None, 784)               0         
                                                                 
 dense_3680 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2924 (Dropout)      (None, 512)               0         
                                                                 
 dense_3681 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_870 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2925 (Dropout)      (None, 448)               0         
                                                                 
 dense_3682 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_871 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2926 (Dropout)      (None, 480)               0         
                                                                 
 dense_3683 (Dense)          (None, 256)               123136    
                                                                 
 dropout_2927 (Dropout)      (None, 256)               0         
                                                                 
 dense_3684 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 980794 (3.74 MB)
Trainable params: 978938 (3.73 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 757:
  Value: 0.8332
  num_layers: 4
  units_0: 256
  units_1: 480
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.5
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0073230979673030855

Model: "sequential_757"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_757 (Flatten)       (None, 784)               0         
                                                                 
 dense_3685 (Dense)          (None, 256)               200960    
                                                                 
 dropout_2928 (Dropout)      (None, 256)               0         
                                                                 
 dense_3686 (Dense)          (None, 480)               123360    
                                                                 
 dropout_2929 (Dropout)      (None, 480)               0         
                                                                 
 dense_3687 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_872 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2930 (Dropout)      (None, 512)               0         
                                                                 
 dense_3688 (Dense)          (None, 352)               180576    
                                                                 
 dropout_2931 (Dropout)      (None, 352)               0         
                                                                 
 dense_3689 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 762394 (2.91 MB)
Trainable params: 761370 (2.90 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 758:
  Value: 0.7703
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0036462185770277473

Model: "sequential_758"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_758 (Flatten)       (None, 784)               0         
                                                                 
 dense_3690 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2932 (Dropout)      (None, 480)               0         
                                                                 
 dense_3691 (Dense)          (None, 416)               200096    
                                                                 
 dropout_2933 (Dropout)      (None, 416)               0         
                                                                 
 dense_3692 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_873 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2934 (Dropout)      (None, 512)               0         
                                                                 
 dense_3693 (Dense)          (None, 320)               164160    
                                                                 
 dropout_2935 (Dropout)      (None, 320)               0         
                                                                 
 dense_3694 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 759:
  Value: 0.8625
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009168739729433276

Model: "sequential_759"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_759 (Flatten)       (None, 784)               0         
                                                                 
 dense_3695 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2936 (Dropout)      (None, 512)               0         
                                                                 
 dense_3696 (Dense)          (None, 384)               196992    
                                                                 
 dropout_2937 (Dropout)      (None, 384)               0         
                                                                 
 dense_3697 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_874 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2938 (Dropout)      (None, 480)               0         
                                                                 
 dense_3698 (Dense)          (None, 288)               138528    
                                                                 
 dropout_2939 (Dropout)      (None, 288)               0         
                                                                 
 dense_3699 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 931674 (3.55 MB)
Trainable params: 930714 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 760:
  Value: 0.8011
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0012860863860693326

Model: "sequential_760"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_760 (Flatten)       (None, 784)               0         
                                                                 
 dense_3700 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2940 (Dropout)      (None, 480)               0         
                                                                 
 dense_3701 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2941 (Dropout)      (None, 448)               0         
                                                                 
 dense_3702 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_875 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2942 (Dropout)      (None, 512)               0         
                                                                 
 dense_3703 (Dense)          (None, 288)               147744    
                                                                 
 batch_normalization_876 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_2943 (Dropout)      (None, 288)               0         
                                                                 
 dense_3704 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 980634 (3.74 MB)
Trainable params: 979034 (3.73 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 761:
  Value: 0.9212
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0020209000008677654

Model: "sequential_761"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_761 (Flatten)       (None, 784)               0         
                                                                 
 dense_3705 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2944 (Dropout)      (None, 512)               0         
                                                                 
 dense_3706 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2945 (Dropout)      (None, 448)               0         
                                                                 
 dense_3707 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_877 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2946 (Dropout)      (None, 448)               0         
                                                                 
 dense_3708 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2947 (Dropout)      (None, 256)               0         
                                                                 
 dense_3709 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 956314 (3.65 MB)
Trainable params: 955418 (3.64 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 762:
  Value: 0.9155
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0020181434899637094

Model: "sequential_762"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_762 (Flatten)       (None, 784)               0         
                                                                 
 dense_3710 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2948 (Dropout)      (None, 448)               0         
                                                                 
 dense_3711 (Dense)          (None, 448)               201152    
                                                                 
 dropout_2949 (Dropout)      (None, 448)               0         
                                                                 
 dense_3712 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_878 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2950 (Dropout)      (None, 448)               0         
                                                                 
 dense_3713 (Dense)          (None, 224)               100576    
                                                                 
 dropout_2951 (Dropout)      (None, 224)               0         
                                                                 
 dense_3714 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 862202 (3.29 MB)
Trainable params: 861306 (3.29 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 763:
  Value: 0.8608
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002362330362430547

Model: "sequential_763"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_763 (Flatten)       (None, 784)               0         
                                                                 
 dense_3715 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2952 (Dropout)      (None, 480)               0         
                                                                 
 dense_3716 (Dense)          (None, 480)               230880    
                                                                 
 dropout_2953 (Dropout)      (None, 480)               0         
                                                                 
 dense_3717 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_879 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2954 (Dropout)      (None, 448)               0         
                                                                 
 dense_3718 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2955 (Dropout)      (None, 256)               0         
                                                                 
 dense_3719 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 946586 (3.61 MB)
Trainable params: 945690 (3.61 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 764:
  Value: 0.7800
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 448
  units_3: 256
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016789428184794924

Model: "sequential_764"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_764 (Flatten)       (None, 784)               0         
                                                                 
 dense_3720 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2956 (Dropout)      (None, 512)               0         
                                                                 
 dense_3721 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2957 (Dropout)      (None, 448)               0         
                                                                 
 dense_3722 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_880 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2958 (Dropout)      (None, 448)               0         
                                                                 
 dense_3723 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2959 (Dropout)      (None, 256)               0         
                                                                 
 dense_3724 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 956314 (3.65 MB)
Trainable params: 955418 (3.64 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 765:
  Value: 0.9140
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00195386005088636

Model: "sequential_765"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_765 (Flatten)       (None, 784)               0         
                                                                 
 dense_3725 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2960 (Dropout)      (None, 512)               0         
                                                                 
 dense_3726 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2961 (Dropout)      (None, 448)               0         
                                                                 
 dense_3727 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_881 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2962 (Dropout)      (None, 448)               0         
                                                                 
 dense_3728 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2963 (Dropout)      (None, 256)               0         
                                                                 
 dense_3729 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 956314 (3.65 MB)
Trainable params: 955418 (3.64 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 766:
  Value: 0.0394
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0023605876245725924

Model: "sequential_766"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_766 (Flatten)       (None, 784)               0         
                                                                 
 dense_3730 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2964 (Dropout)      (None, 480)               0         
                                                                 
 dense_3731 (Dense)          (None, 480)               230880    
                                                                 
 dropout_2965 (Dropout)      (None, 480)               0         
                                                                 
 dense_3732 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_882 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2966 (Dropout)      (None, 512)               0         
                                                                 
 dense_3733 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2967 (Dropout)      (None, 256)               0         
                                                                 
 dense_3734 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 994010 (3.79 MB)
Trainable params: 992986 (3.79 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 767:
  Value: 0.9193
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002956927667663819

Model: "sequential_767"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_767 (Flatten)       (None, 784)               0         
                                                                 
 dense_3735 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2968 (Dropout)      (None, 512)               0         
                                                                 
 dense_3736 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2969 (Dropout)      (None, 448)               0         
                                                                 
 dense_3737 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_883 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2970 (Dropout)      (None, 512)               0         
                                                                 
 dense_3738 (Dense)          (None, 224)               114912    
                                                                 
 dropout_2971 (Dropout)      (None, 224)               0         
                                                                 
 dense_3739 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 984442 (3.76 MB)
Trainable params: 983418 (3.75 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 768:
  Value: 0.8044
  num_layers: 3
  units_0: 480
  units_1: 448
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.001797256623555474

Model: "sequential_768"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_768 (Flatten)       (None, 784)               0         
                                                                 
 dense_3740 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_884 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_2972 (Dropout)      (None, 480)               0         
                                                                 
 dense_3741 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2973 (Dropout)      (None, 448)               0         
                                                                 
 dense_3742 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_885 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2974 (Dropout)      (None, 512)               0         
                                                                 
 dense_3743 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 839482 (3.20 MB)
Trainable params: 837498 (3.19 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 769:
  Value: 0.9197
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005666891307736305

Model: "sequential_769"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_769 (Flatten)       (None, 784)               0         
                                                                 
 dense_3744 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2975 (Dropout)      (None, 512)               0         
                                                                 
 dense_3745 (Dense)          (None, 480)               246240    
                                                                 
 dropout_2976 (Dropout)      (None, 480)               0         
                                                                 
 dense_3746 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_886 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2977 (Dropout)      (None, 512)               0         
                                                                 
 dense_3747 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2978 (Dropout)      (None, 256)               0         
                                                                 
 dense_3748 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1034490 (3.95 MB)
Trainable params: 1033466 (3.94 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 770:
  Value: 0.7259
  num_layers: 4
  units_0: 448
  units_1: 64
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.00210555870304313

Model: "sequential_770"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_770 (Flatten)       (None, 784)               0         
                                                                 
 dense_3749 (Dense)          (None, 448)               351680    
                                                                 
 dropout_2979 (Dropout)      (None, 448)               0         
                                                                 
 dense_3750 (Dense)          (None, 64)                28736     
                                                                 
 dropout_2980 (Dropout)      (None, 64)                0         
                                                                 
 dense_3751 (Dense)          (None, 512)               33280     
                                                                 
 batch_normalization_887 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2981 (Dropout)      (None, 512)               0         
                                                                 
 dense_3752 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2982 (Dropout)      (None, 256)               0         
                                                                 
 dense_3753 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 553754 (2.11 MB)
Trainable params: 552730 (2.11 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 771:
  Value: 0.0364
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.001604906575624679

Model: "sequential_771"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_771 (Flatten)       (None, 784)               0         
                                                                 
 dense_3754 (Dense)          (None, 480)               376800    
                                                                 
 dropout_2983 (Dropout)      (None, 480)               0         
                                                                 
 dense_3755 (Dense)          (None, 448)               215488    
                                                                 
 dropout_2984 (Dropout)      (None, 448)               0         
                                                                 
 dense_3756 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_888 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_2985 (Dropout)      (None, 448)               0         
                                                                 
 dense_3757 (Dense)          (None, 256)               114944    
                                                                 
 dropout_2986 (Dropout)      (None, 256)               0         
                                                                 
 dense_3758 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 916858 (3.50 MB)
Trainable params: 915962 (3.49 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 772:
  Value: 0.9212
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0021541667941147122

Model: "sequential_772"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_772 (Flatten)       (None, 784)               0         
                                                                 
 dense_3759 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2987 (Dropout)      (None, 512)               0         
                                                                 
 dense_3760 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2988 (Dropout)      (None, 448)               0         
                                                                 
 dense_3761 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_889 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2989 (Dropout)      (None, 512)               0         
                                                                 
 dense_3762 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2990 (Dropout)      (None, 256)               0         
                                                                 
 dense_3763 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1001690 (3.82 MB)
Trainable params: 1000666 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 773:
  Value: 0.8991
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017354665639049223

Model: "sequential_773"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_773 (Flatten)       (None, 784)               0         
                                                                 
 dense_3764 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2991 (Dropout)      (None, 512)               0         
                                                                 
 dense_3765 (Dense)          (None, 448)               229824    
                                                                 
 dropout_2992 (Dropout)      (None, 448)               0         
                                                                 
 dense_3766 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_890 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_2993 (Dropout)      (None, 512)               0         
                                                                 
 dense_3767 (Dense)          (None, 224)               114912    
                                                                 
 dropout_2994 (Dropout)      (None, 224)               0         
                                                                 
 dense_3768 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 984442 (3.76 MB)
Trainable params: 983418 (3.75 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 774:
  Value: 0.8475
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0020759533983580125

Model: "sequential_774"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_774 (Flatten)       (None, 784)               0         
                                                                 
 dense_3769 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2995 (Dropout)      (None, 512)               0         
                                                                 
 dense_3770 (Dense)          (None, 480)               246240    
                                                                 
 dropout_2996 (Dropout)      (None, 480)               0         
                                                                 
 dense_3771 (Dense)          (None, 512)               246272    
                                                                 
 dropout_2997 (Dropout)      (None, 512)               0         
                                                                 
 dense_3772 (Dense)          (None, 256)               131328    
                                                                 
 dropout_2998 (Dropout)      (None, 256)               0         
                                                                 
 dense_3773 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1032442 (3.94 MB)
Trainable params: 1032442 (3.94 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 775:
  Value: 0.8209
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.4
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0020909736901187897

Model: "sequential_775"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_775 (Flatten)       (None, 784)               0         
                                                                 
 dense_3774 (Dense)          (None, 512)               401920    
                                                                 
 dropout_2999 (Dropout)      (None, 512)               0         
                                                                 
 dense_3775 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 776:
  Value: 0.8998
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0022314814769365046

Model: "sequential_776"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_776 (Flatten)       (None, 784)               0         
                                                                 
 dense_3776 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3000 (Dropout)      (None, 512)               0         
                                                                 
 dense_3777 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3001 (Dropout)      (None, 448)               0         
                                                                 
 dense_3778 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_891 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3002 (Dropout)      (None, 512)               0         
                                                                 
 dense_3779 (Dense)          (None, 224)               114912    
                                                                 
 dropout_3003 (Dropout)      (None, 224)               0         
                                                                 
 dense_3780 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 984442 (3.76 MB)
Trainable params: 983418 (3.75 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 777:
  Value: 0.5258
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0026880998934484274

Model: "sequential_777"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_777 (Flatten)       (None, 784)               0         
                                                                 
 dense_3781 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3004 (Dropout)      (None, 512)               0         
                                                                 
 dense_3782 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_892 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3005 (Dropout)      (None, 448)               0         
                                                                 
 dense_3783 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_893 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3006 (Dropout)      (None, 512)               0         
                                                                 
 dense_3784 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3007 (Dropout)      (None, 256)               0         
                                                                 
 dense_3785 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1003482 (3.83 MB)
Trainable params: 1001562 (3.82 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 778:
  Value: 0.8942
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.4
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002464421537218722

Model: "sequential_778"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_778 (Flatten)       (None, 784)               0         
                                                                 
 dense_3786 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3008 (Dropout)      (None, 512)               0         
                                                                 
 dense_3787 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3009 (Dropout)      (None, 480)               0         
                                                                 
 dense_3788 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_894 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3010 (Dropout)      (None, 512)               0         
                                                                 
 dense_3789 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3011 (Dropout)      (None, 256)               0         
                                                                 
 dense_3790 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1034490 (3.95 MB)
Trainable params: 1033466 (3.94 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 779:
  Value: 0.8835
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0018931838823827152

Model: "sequential_779"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_779 (Flatten)       (None, 784)               0         
                                                                 
 dense_3791 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3012 (Dropout)      (None, 512)               0         
                                                                 
 dense_3792 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3013 (Dropout)      (None, 320)               0         
                                                                 
 dense_3793 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_895 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3014 (Dropout)      (None, 512)               0         
                                                                 
 dense_3794 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3015 (Dropout)      (None, 256)               0         
                                                                 
 dense_3795 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 870490 (3.32 MB)
Trainable params: 869466 (3.32 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 780:
  Value: 0.9197
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002117114869799226

Model: "sequential_780"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_780 (Flatten)       (None, 784)               0         
                                                                 
 dense_3796 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3016 (Dropout)      (None, 512)               0         
                                                                 
 dense_3797 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3017 (Dropout)      (None, 448)               0         
                                                                 
 dense_3798 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_896 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3018 (Dropout)      (None, 512)               0         
                                                                 
 dense_3799 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3019 (Dropout)      (None, 256)               0         
                                                                 
 dense_3800 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1001690 (3.82 MB)
Trainable params: 1000666 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 781:
  Value: 0.0917
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: sgd
  learning_rate: 0.0023472336441410107

Model: "sequential_781"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_781 (Flatten)       (None, 784)               0         
                                                                 
 dense_3801 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3020 (Dropout)      (None, 512)               0         
                                                                 
 dense_3802 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3021 (Dropout)      (None, 448)               0         
                                                                 
 dense_3803 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_897 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3022 (Dropout)      (None, 512)               0         
                                                                 
 dense_3804 (Dense)          (None, 224)               114912    
                                                                 
 batch_normalization_898 (B  (None, 224)               896       
 atchNormalization)                                              
                                                                 
 dropout_3023 (Dropout)      (None, 224)               0         
                                                                 
 dense_3805 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 985338 (3.76 MB)
Trainable params: 983866 (3.75 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 782:
  Value: 0.9002
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019096655143710011

Model: "sequential_782"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_782 (Flatten)       (None, 784)               0         
                                                                 
 dense_3806 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3024 (Dropout)      (None, 512)               0         
                                                                 
 dense_3807 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3025 (Dropout)      (None, 480)               0         
                                                                 
 dense_3808 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_899 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3026 (Dropout)      (None, 512)               0         
                                                                 
 dense_3809 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3027 (Dropout)      (None, 256)               0         
                                                                 
 dense_3810 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1034490 (3.95 MB)
Trainable params: 1033466 (3.94 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 783:
  Value: 0.8594
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 64
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002302259556048276

Model: "sequential_783"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_783 (Flatten)       (None, 784)               0         
                                                                 
 dense_3811 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3028 (Dropout)      (None, 512)               0         
                                                                 
 dense_3812 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3029 (Dropout)      (None, 448)               0         
                                                                 
 dense_3813 (Dense)          (None, 64)                28736     
                                                                 
 batch_normalization_900 (B  (None, 64)                256       
 atchNormalization)                                              
                                                                 
 dropout_3030 (Dropout)      (None, 64)                0         
                                                                 
 dense_3814 (Dense)          (None, 256)               16640     
                                                                 
 dropout_3031 (Dropout)      (None, 256)               0         
                                                                 
 dense_3815 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 684058 (2.61 MB)
Trainable params: 683930 (2.61 MB)
Non-trainable params: 128 (512.00 Byte)
_________________________________________________________________



Trial 784:
  Value: 0.9051
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009989746160692966

Model: "sequential_784"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_784 (Flatten)       (None, 784)               0         
                                                                 
 dense_3816 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3032 (Dropout)      (None, 512)               0         
                                                                 
 dense_3817 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3033 (Dropout)      (None, 448)               0         
                                                                 
 dense_3818 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_901 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3034 (Dropout)      (None, 512)               0         
                                                                 
 dense_3819 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3035 (Dropout)      (None, 256)               0         
                                                                 
 dense_3820 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1001690 (3.82 MB)
Trainable params: 1000666 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 785:
  Value: 0.9186
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008269073517388974

Model: "sequential_785"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_785 (Flatten)       (None, 784)               0         
                                                                 
 dense_3821 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3036 (Dropout)      (None, 512)               0         
                                                                 
 dense_3822 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3037 (Dropout)      (None, 480)               0         
                                                                 
 dense_3823 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_902 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3038 (Dropout)      (None, 512)               0         
                                                                 
 dense_3824 (Dense)          (None, 224)               114912    
                                                                 
 dropout_3039 (Dropout)      (None, 224)               0         
                                                                 
 dense_3825 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 1017242 (3.88 MB)
Trainable params: 1016218 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 786:
  Value: 0.7495
  num_layers: 2
  units_0: 512
  units_1: 448
  activation_0: sigmoid
  activation_1: relu
  dropout_0: 0.4
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.009717581949170708

Model: "sequential_786"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_786 (Flatten)       (None, 784)               0         
                                                                 
 dense_3826 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3040 (Dropout)      (None, 512)               0         
                                                                 
 dense_3827 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3041 (Dropout)      (None, 448)               0         
                                                                 
 dense_3828 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 643418 (2.45 MB)
Trainable params: 643418 (2.45 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 787:
  Value: 0.8364
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.006931507118477073

Model: "sequential_787"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_787 (Flatten)       (None, 784)               0         
                                                                 
 dense_3829 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_903 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3042 (Dropout)      (None, 512)               0         
                                                                 
 dense_3830 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3043 (Dropout)      (None, 448)               0         
                                                                 
 dense_3831 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_904 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3044 (Dropout)      (None, 512)               0         
                                                                 
 dense_3832 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3045 (Dropout)      (None, 320)               0         
                                                                 
 dense_3833 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1038234 (3.96 MB)
Trainable params: 1036186 (3.95 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 788:
  Value: 0.9038
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.003274621814108403

Model: "sequential_788"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_788 (Flatten)       (None, 784)               0         
                                                                 
 dense_3834 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3046 (Dropout)      (None, 512)               0         
                                                                 
 dense_3835 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3047 (Dropout)      (None, 448)               0         
                                                                 
 dense_3836 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_905 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3048 (Dropout)      (None, 512)               0         
                                                                 
 dense_3837 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3049 (Dropout)      (None, 256)               0         
                                                                 
 dense_3838 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1001690 (3.82 MB)
Trainable params: 1000666 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 789:
  Value: 0.8521
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0018877131293116387

Model: "sequential_789"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_789 (Flatten)       (None, 784)               0         
                                                                 
 dense_3839 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3050 (Dropout)      (None, 480)               0         
                                                                 
 dense_3840 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3051 (Dropout)      (None, 448)               0         
                                                                 
 dense_3841 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_906 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3052 (Dropout)      (None, 512)               0         
                                                                 
 dense_3842 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3053 (Dropout)      (None, 352)               0         
                                                                 
 dense_3843 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1013978 (3.87 MB)
Trainable params: 1012954 (3.86 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 790:
  Value: 0.8560
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002156244285021504

Model: "sequential_790"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_790 (Flatten)       (None, 784)               0         
                                                                 
 dense_3844 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3054 (Dropout)      (None, 512)               0         
                                                                 
 dense_3845 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3055 (Dropout)      (None, 480)               0         
                                                                 
 dense_3846 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_907 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3056 (Dropout)      (None, 512)               0         
                                                                 
 dense_3847 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3057 (Dropout)      (None, 288)               0         
                                                                 
 dense_3848 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1051738 (4.01 MB)
Trainable params: 1050714 (4.01 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 791:
  Value: 0.8759
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006400343033539294

Model: "sequential_791"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_791 (Flatten)       (None, 784)               0         
                                                                 
 dense_3849 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3058 (Dropout)      (None, 512)               0         
                                                                 
 dense_3850 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3059 (Dropout)      (None, 448)               0         
                                                                 
 dense_3851 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_908 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3060 (Dropout)      (None, 512)               0         
                                                                 
 dense_3852 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3061 (Dropout)      (None, 320)               0         
                                                                 
 dense_3853 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1036186 (3.95 MB)
Trainable params: 1035162 (3.95 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 792:
  Value: 0.8634
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010747652047022563

Model: "sequential_792"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_792 (Flatten)       (None, 784)               0         
                                                                 
 dense_3854 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3062 (Dropout)      (None, 480)               0         
                                                                 
 dense_3855 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3063 (Dropout)      (None, 448)               0         
                                                                 
 dense_3856 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_909 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3064 (Dropout)      (None, 512)               0         
                                                                 
 dense_3857 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3065 (Dropout)      (None, 256)               0         
                                                                 
 dense_3858 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 962234 (3.67 MB)
Trainable params: 961210 (3.67 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 793:
  Value: 0.8180
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004664754024260981

Model: "sequential_793"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_793 (Flatten)       (None, 784)               0         
                                                                 
 dense_3859 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3066 (Dropout)      (None, 512)               0         
                                                                 
 dense_3860 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3067 (Dropout)      (None, 480)               0         
                                                                 
 dense_3861 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_910 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3068 (Dropout)      (None, 480)               0         
                                                                 
 dense_3862 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3069 (Dropout)      (None, 288)               0         
                                                                 
 dense_3863 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1027002 (3.92 MB)
Trainable params: 1026042 (3.91 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 794:
  Value: 0.0318
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0007603074250816129

Model: "sequential_794"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_794 (Flatten)       (None, 784)               0         
                                                                 
 dense_3864 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3070 (Dropout)      (None, 480)               0         
                                                                 
 dense_3865 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3071 (Dropout)      (None, 448)               0         
                                                                 
 dense_3866 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_911 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3072 (Dropout)      (None, 480)               0         
                                                                 
 dense_3867 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3073 (Dropout)      (None, 320)               0         
                                                                 
 dense_3868 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 971994 (3.71 MB)
Trainable params: 971034 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 795:
  Value: 0.8176
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002795665650115645

Model: "sequential_795"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_795 (Flatten)       (None, 784)               0         
                                                                 
 dense_3869 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3074 (Dropout)      (None, 480)               0         
                                                                 
 dense_3870 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3075 (Dropout)      (None, 448)               0         
                                                                 
 dense_3871 (Dense)          (None, 512)               229888    
                                                                 
 dropout_3076 (Dropout)      (None, 512)               0         
                                                                 
 dense_3872 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3077 (Dropout)      (None, 256)               0         
                                                                 
 dense_3873 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 960186 (3.66 MB)
Trainable params: 960186 (3.66 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 796:
  Value: 0.5654
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009173266305975425

Model: "sequential_796"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_796 (Flatten)       (None, 784)               0         
                                                                 
 dense_3874 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3078 (Dropout)      (None, 512)               0         
                                                                 
 dense_3875 (Dense)          (None, 352)               180576    
                                                                 
 batch_normalization_912 (B  (None, 352)               1408      
 atchNormalization)                                              
                                                                 
 dropout_3079 (Dropout)      (None, 352)               0         
                                                                 
 dense_3876 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_913 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3080 (Dropout)      (None, 512)               0         
                                                                 
 dense_3877 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3081 (Dropout)      (None, 288)               0         
                                                                 
 dense_3878 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 921946 (3.52 MB)
Trainable params: 920218 (3.51 MB)
Non-trainable params: 1728 (6.75 KB)
_________________________________________________________________



Trial 797:
  Value: 0.8601
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015616396426374442

Model: "sequential_797"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_797 (Flatten)       (None, 784)               0         
                                                                 
 dense_3879 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3082 (Dropout)      (None, 448)               0         
                                                                 
 dense_3880 (Dense)          (None, 480)               215520    
                                                                 
 dropout_3083 (Dropout)      (None, 480)               0         
                                                                 
 dense_3881 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_914 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3084 (Dropout)      (None, 480)               0         
                                                                 
 dense_3882 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3085 (Dropout)      (None, 320)               0         
                                                                 
 dense_3883 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 962266 (3.67 MB)
Trainable params: 961306 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 798:
  Value: 0.7334
  num_layers: 4
  units_0: 96
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.004244415947750128

Model: "sequential_798"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_798 (Flatten)       (None, 784)               0         
                                                                 
 dense_3884 (Dense)          (None, 96)                75360     
                                                                 
 dropout_3086 (Dropout)      (None, 96)                0         
                                                                 
 dense_3885 (Dense)          (None, 448)               43456     
                                                                 
 dropout_3087 (Dropout)      (None, 448)               0         
                                                                 
 dense_3886 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_915 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3088 (Dropout)      (None, 512)               0         
                                                                 
 dense_3887 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3089 (Dropout)      (None, 288)               0         
                                                                 
 dense_3888 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 506010 (1.93 MB)
Trainable params: 504986 (1.93 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 799:
  Value: 0.9202
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014699017858518803

Model: "sequential_799"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_799 (Flatten)       (None, 784)               0         
                                                                 
 dense_3889 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3090 (Dropout)      (None, 512)               0         
                                                                 
 dense_3890 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3091 (Dropout)      (None, 448)               0         
                                                                 
 dense_3891 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_916 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3092 (Dropout)      (None, 512)               0         
                                                                 
 dense_3892 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3093 (Dropout)      (None, 288)               0         
                                                                 
 dense_3893 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 800:
  Value: 0.0393
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0011641824591424373

Model: "sequential_800"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_800 (Flatten)       (None, 784)               0         
                                                                 
 dense_3894 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3094 (Dropout)      (None, 480)               0         
                                                                 
 dense_3895 (Dense)          (None, 480)               230880    
                                                                 
 dropout_3095 (Dropout)      (None, 480)               0         
                                                                 
 dense_3896 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_917 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3096 (Dropout)      (None, 480)               0         
                                                                 
 dense_3897 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3097 (Dropout)      (None, 256)               0         
                                                                 
 dense_3898 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 970298 (3.70 MB)
Trainable params: 969338 (3.70 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 801:
  Value: 0.2334
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0017914842620574314

Model: "sequential_801"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_801 (Flatten)       (None, 784)               0         
                                                                 
 dense_3899 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3098 (Dropout)      (None, 512)               0         
                                                                 
 dense_3900 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3099 (Dropout)      (None, 448)               0         
                                                                 
 dense_3901 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_918 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3100 (Dropout)      (None, 512)               0         
                                                                 
 dense_3902 (Dense)          (None, 288)               147744    
                                                                 
 batch_normalization_919 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_3101 (Dropout)      (None, 288)               0         
                                                                 
 dense_3903 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1020090 (3.89 MB)
Trainable params: 1018490 (3.89 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 802:
  Value: 0.8634
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010132726337350687

Model: "sequential_802"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_802 (Flatten)       (None, 784)               0         
                                                                 
 dense_3904 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3102 (Dropout)      (None, 480)               0         
                                                                 
 dense_3905 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3103 (Dropout)      (None, 416)               0         
                                                                 
 dense_3906 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_920 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3104 (Dropout)      (None, 448)               0         
                                                                 
 dense_3907 (Dense)          (None, 320)               143680    
                                                                 
 dropout_3105 (Dropout)      (None, 320)               0         
                                                                 
 dense_3908 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 917530 (3.50 MB)
Trainable params: 916634 (3.50 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 803:
  Value: 0.8607
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007018968153072552

Model: "sequential_803"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_803 (Flatten)       (None, 784)               0         
                                                                 
 dense_3909 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3106 (Dropout)      (None, 512)               0         
                                                                 
 dense_3910 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3107 (Dropout)      (None, 480)               0         
                                                                 
 dense_3911 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_921 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3108 (Dropout)      (None, 480)               0         
                                                                 
 dense_3912 (Dense)          (None, 224)               107744    
                                                                 
 dropout_3109 (Dropout)      (None, 224)               0         
                                                                 
 dense_3913 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 994554 (3.79 MB)
Trainable params: 993594 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 804:
  Value: 0.8579
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00011372124957168795

Model: "sequential_804"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_804 (Flatten)       (None, 784)               0         
                                                                 
 dense_3914 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3110 (Dropout)      (None, 512)               0         
                                                                 
 dense_3915 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3111 (Dropout)      (None, 448)               0         
                                                                 
 dense_3916 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_922 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3112 (Dropout)      (None, 512)               0         
                                                                 
 dense_3917 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3113 (Dropout)      (None, 256)               0         
                                                                 
 dense_3918 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1001690 (3.82 MB)
Trainable params: 1000666 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 805:
  Value: 0.9182
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.002009831878795538

Model: "sequential_805"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_805 (Flatten)       (None, 784)               0         
                                                                 
 dense_3919 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3114 (Dropout)      (None, 480)               0         
                                                                 
 dense_3920 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3115 (Dropout)      (None, 416)               0         
                                                                 
 dense_3921 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_923 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3116 (Dropout)      (None, 512)               0         
                                                                 
 dense_3922 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3117 (Dropout)      (None, 320)               0         
                                                                 
 dense_3923 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 806:
  Value: 0.3245
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 480
  units_3: 352
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0025158162792809856

Model: "sequential_806"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_806 (Flatten)       (None, 784)               0         
                                                                 
 dense_3924 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_924 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3118 (Dropout)      (None, 480)               0         
                                                                 
 dense_3925 (Dense)          (None, 352)               169312    
                                                                 
 dropout_3119 (Dropout)      (None, 352)               0         
                                                                 
 dense_3926 (Dense)          (None, 480)               169440    
                                                                 
 batch_normalization_925 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3120 (Dropout)      (None, 480)               0         
                                                                 
 dense_3927 (Dense)          (None, 352)               169312    
                                                                 
 dropout_3121 (Dropout)      (None, 352)               0         
                                                                 
 dense_3928 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 897882 (3.43 MB)
Trainable params: 895962 (3.42 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 807:
  Value: 0.8616
  num_layers: 3
  units_0: 512
  units_1: 448
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.0014832520313060673

Model: "sequential_807"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_807 (Flatten)       (None, 784)               0         
                                                                 
 dense_3929 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3122 (Dropout)      (None, 512)               0         
                                                                 
 dense_3930 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3123 (Dropout)      (None, 448)               0         
                                                                 
 dense_3931 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_926 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3124 (Dropout)      (None, 512)               0         
                                                                 
 dense_3932 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 877018 (3.35 MB)
Trainable params: 875994 (3.34 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 808:
  Value: 0.8954
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00019821763184888676

Model: "sequential_808"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_808 (Flatten)       (None, 784)               0         
                                                                 
 dense_3933 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3125 (Dropout)      (None, 448)               0         
                                                                 
 dense_3934 (Dense)          (None, 448)               201152    
                                                                 
 dropout_3126 (Dropout)      (None, 448)               0         
                                                                 
 dense_3935 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_927 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3127 (Dropout)      (None, 480)               0         
                                                                 
 dense_3936 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3128 (Dropout)      (None, 288)               0         
                                                                 
 dense_3937 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 916314 (3.50 MB)
Trainable params: 915354 (3.49 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 809:
  Value: 0.9170
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011917868942276733

Model: "sequential_809"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_809 (Flatten)       (None, 784)               0         
                                                                 
 dense_3938 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3129 (Dropout)      (None, 512)               0         
                                                                 
 dense_3939 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3130 (Dropout)      (None, 416)               0         
                                                                 
 dense_3940 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_928 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3131 (Dropout)      (None, 512)               0         
                                                                 
 dense_3941 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3132 (Dropout)      (None, 288)               0         
                                                                 
 dense_3942 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 810:
  Value: 0.0435
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 480
  units_3: 64
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.00010377213410369021

Model: "sequential_810"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_810 (Flatten)       (None, 784)               0         
                                                                 
 dense_3943 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3133 (Dropout)      (None, 480)               0         
                                                                 
 dense_3944 (Dense)          (None, 480)               230880    
                                                                 
 dropout_3134 (Dropout)      (None, 480)               0         
                                                                 
 dense_3945 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_929 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3135 (Dropout)      (None, 480)               0         
                                                                 
 dense_3946 (Dense)          (None, 64)                30784     
                                                                 
 dropout_3136 (Dropout)      (None, 64)                0         
                                                                 
 dense_3947 (Dense)          (None, 26)                1690      
                                                                 
=================================================================
Total params: 872954 (3.33 MB)
Trainable params: 871994 (3.33 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 811:
  Value: 0.8634
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008794539454392234

Model: "sequential_811"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_811 (Flatten)       (None, 784)               0         
                                                                 
 dense_3948 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3137 (Dropout)      (None, 512)               0         
                                                                 
 dense_3949 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3138 (Dropout)      (None, 416)               0         
                                                                 
 dense_3950 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_930 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3139 (Dropout)      (None, 512)               0         
                                                                 
 dense_3951 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3140 (Dropout)      (None, 256)               0         
                                                                 
 dense_3952 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 968890 (3.70 MB)
Trainable params: 967866 (3.69 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 812:
  Value: 0.8618
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010830189370255416

Model: "sequential_812"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_812 (Flatten)       (None, 784)               0         
                                                                 
 dense_3953 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3141 (Dropout)      (None, 480)               0         
                                                                 
 dense_3954 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3142 (Dropout)      (None, 448)               0         
                                                                 
 dense_3955 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_931 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3143 (Dropout)      (None, 448)               0         
                                                                 
 dense_3956 (Dense)          (None, 288)               129312    
                                                                 
 dropout_3144 (Dropout)      (None, 288)               0         
                                                                 
 dense_3957 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 932058 (3.56 MB)
Trainable params: 931162 (3.55 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 813:
  Value: 0.7282
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016935154301891291

Model: "sequential_813"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_813 (Flatten)       (None, 784)               0         
                                                                 
 dense_3958 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3145 (Dropout)      (None, 512)               0         
                                                                 
 dense_3959 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3146 (Dropout)      (None, 384)               0         
                                                                 
 dense_3960 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_932 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3147 (Dropout)      (None, 512)               0         
                                                                 
 dense_3961 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3148 (Dropout)      (None, 320)               0         
                                                                 
 dense_3962 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 814:
  Value: 0.7082
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.006373868894673878

Model: "sequential_814"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_814 (Flatten)       (None, 784)               0         
                                                                 
 dense_3963 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3149 (Dropout)      (None, 480)               0         
                                                                 
 dense_3964 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3150 (Dropout)      (None, 448)               0         
                                                                 
 dense_3965 (Dense)          (None, 512)               229888    
                                                                 
 dropout_3151 (Dropout)      (None, 512)               0         
                                                                 
 dense_3966 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3152 (Dropout)      (None, 288)               0         
                                                                 
 dense_3967 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 977434 (3.73 MB)
Trainable params: 977434 (3.73 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 815:
  Value: 0.8993
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0021894711303224903

Model: "sequential_815"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_815 (Flatten)       (None, 784)               0         
                                                                 
 dense_3968 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3153 (Dropout)      (None, 512)               0         
                                                                 
 dense_3969 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3154 (Dropout)      (None, 480)               0         
                                                                 
 dense_3970 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_933 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3155 (Dropout)      (None, 480)               0         
                                                                 
 dense_3971 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3156 (Dropout)      (None, 256)               0         
                                                                 
 dense_3972 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1010778 (3.86 MB)
Trainable params: 1009818 (3.85 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 816:
  Value: 0.5465
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014121890739297797

Model: "sequential_816"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_816 (Flatten)       (None, 784)               0         
                                                                 
 dense_3973 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3157 (Dropout)      (None, 512)               0         
                                                                 
 dense_3974 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_934 (B  (None, 416)               1664      
 atchNormalization)                                              
                                                                 
 dropout_3158 (Dropout)      (None, 416)               0         
                                                                 
 dense_3975 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_935 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3159 (Dropout)      (None, 512)               0         
                                                                 
 dense_3976 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3160 (Dropout)      (None, 288)               0         
                                                                 
 dense_3977 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 987802 (3.77 MB)
Trainable params: 985946 (3.76 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 817:
  Value: 0.8160
  num_layers: 2
  units_0: 480
  units_1: 448
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.00010056077231388137

Model: "sequential_817"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_817 (Flatten)       (None, 784)               0         
                                                                 
 dense_3978 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3161 (Dropout)      (None, 480)               0         
                                                                 
 dense_3979 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3162 (Dropout)      (None, 448)               0         
                                                                 
 dense_3980 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 603962 (2.30 MB)
Trainable params: 603962 (2.30 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 818:
  Value: 0.8480
  num_layers: 4
  units_0: 352
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004073245052712152

Model: "sequential_818"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_818 (Flatten)       (None, 784)               0         
                                                                 
 dense_3981 (Dense)          (None, 352)               276320    
                                                                 
 dropout_3163 (Dropout)      (None, 352)               0         
                                                                 
 dense_3982 (Dense)          (None, 448)               158144    
                                                                 
 dropout_3164 (Dropout)      (None, 448)               0         
                                                                 
 dense_3983 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_936 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3165 (Dropout)      (None, 480)               0         
                                                                 
 dense_3984 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3166 (Dropout)      (None, 256)               0         
                                                                 
 dense_3985 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 781722 (2.98 MB)
Trainable params: 780762 (2.98 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 819:
  Value: 0.8543
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000624284907542031

Model: "sequential_819"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_819 (Flatten)       (None, 784)               0         
                                                                 
 dense_3986 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3167 (Dropout)      (None, 448)               0         
                                                                 
 dense_3987 (Dense)          (None, 416)               186784    
                                                                 
 dropout_3168 (Dropout)      (None, 416)               0         
                                                                 
 dense_3988 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_937 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3169 (Dropout)      (None, 512)               0         
                                                                 
 dense_3989 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3170 (Dropout)      (None, 320)               0         
                                                                 
 dense_3990 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 926522 (3.53 MB)
Trainable params: 925498 (3.53 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 820:
  Value: 0.8752
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001247020950238579

Model: "sequential_820"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_820 (Flatten)       (None, 784)               0         
                                                                 
 dense_3991 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3171 (Dropout)      (None, 512)               0         
                                                                 
 dense_3992 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3172 (Dropout)      (None, 480)               0         
                                                                 
 dense_3993 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_938 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3173 (Dropout)      (None, 480)               0         
                                                                 
 dense_3994 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3174 (Dropout)      (None, 288)               0         
                                                                 
 dense_3995 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1027002 (3.92 MB)
Trainable params: 1026042 (3.91 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 821:
  Value: 0.0474
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0009749047790746559

Model: "sequential_821"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_821 (Flatten)       (None, 784)               0         
                                                                 
 dense_3996 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3175 (Dropout)      (None, 480)               0         
                                                                 
 dense_3997 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3176 (Dropout)      (None, 448)               0         
                                                                 
 dense_3998 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_939 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3177 (Dropout)      (None, 512)               0         
                                                                 
 dense_3999 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3178 (Dropout)      (None, 288)               0         
                                                                 
 dense_4000 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 822:
  Value: 0.8613
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001517268528560101

Model: "sequential_822"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_822 (Flatten)       (None, 784)               0         
                                                                 
 dense_4001 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3179 (Dropout)      (None, 512)               0         
                                                                 
 dense_4002 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3180 (Dropout)      (None, 416)               0         
                                                                 
 dense_4003 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_940 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3181 (Dropout)      (None, 448)               0         
                                                                 
 dense_4004 (Dense)          (None, 224)               100576    
                                                                 
 dropout_3182 (Dropout)      (None, 224)               0         
                                                                 
 dense_4005 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 910362 (3.47 MB)
Trainable params: 909466 (3.47 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 823:
  Value: 0.9194
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010923880091768252

Model: "sequential_823"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_823 (Flatten)       (None, 784)               0         
                                                                 
 dense_4006 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3183 (Dropout)      (None, 480)               0         
                                                                 
 dense_4007 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3184 (Dropout)      (None, 384)               0         
                                                                 
 dense_4008 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_941 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3185 (Dropout)      (None, 512)               0         
                                                                 
 dense_4009 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3186 (Dropout)      (None, 256)               0         
                                                                 
 dense_4010 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 898682 (3.43 MB)
Trainable params: 897658 (3.42 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 824:
  Value: 0.7071
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0018340911001099962

Model: "sequential_824"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_824 (Flatten)       (None, 784)               0         
                                                                 
 dense_4011 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_942 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3187 (Dropout)      (None, 512)               0         
                                                                 
 dense_4012 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3188 (Dropout)      (None, 448)               0         
                                                                 
 dense_4013 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_943 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3189 (Dropout)      (None, 480)               0         
                                                                 
 dense_4014 (Dense)          (None, 320)               153920    
                                                                 
 batch_normalization_944 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_3190 (Dropout)      (None, 320)               0         
                                                                 
 dense_4015 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1014778 (3.87 MB)
Trainable params: 1012154 (3.86 MB)
Non-trainable params: 2624 (10.25 KB)
_________________________________________________________________



Trial 825:
  Value: 0.8324
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0013315760645518301

Model: "sequential_825"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_825 (Flatten)       (None, 784)               0         
                                                                 
 dense_4016 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3191 (Dropout)      (None, 480)               0         
                                                                 
 dense_4017 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3192 (Dropout)      (None, 416)               0         
                                                                 
 dense_4018 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_945 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3193 (Dropout)      (None, 512)               0         
                                                                 
 dense_4019 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3194 (Dropout)      (None, 288)               0         
                                                                 
 dense_4020 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 826:
  Value: 0.9196
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0030344136903636206

Model: "sequential_826"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_826 (Flatten)       (None, 784)               0         
                                                                 
 dense_4021 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3195 (Dropout)      (None, 512)               0         
                                                                 
 dense_4022 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3196 (Dropout)      (None, 480)               0         
                                                                 
 dense_4023 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_946 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3197 (Dropout)      (None, 512)               0         
                                                                 
 dense_4024 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3198 (Dropout)      (None, 288)               0         
                                                                 
 dense_4025 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1051738 (4.01 MB)
Trainable params: 1050714 (4.01 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 827:
  Value: 0.7444
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004886409471023749

Model: "sequential_827"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_827 (Flatten)       (None, 784)               0         
                                                                 
 dense_4026 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3199 (Dropout)      (None, 448)               0         
                                                                 
 dense_4027 (Dense)          (None, 416)               186784    
                                                                 
 dropout_3200 (Dropout)      (None, 416)               0         
                                                                 
 dense_4028 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_947 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3201 (Dropout)      (None, 480)               0         
                                                                 
 dense_4029 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3202 (Dropout)      (None, 320)               0         
                                                                 
 dense_4030 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 902810 (3.44 MB)
Trainable params: 901850 (3.44 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 828:
  Value: 0.0410
  num_layers: 4
  units_0: 288
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0012177134388244575

Model: "sequential_828"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_828 (Flatten)       (None, 784)               0         
                                                                 
 dense_4031 (Dense)          (None, 288)               226080    
                                                                 
 dropout_3203 (Dropout)      (None, 288)               0         
                                                                 
 dense_4032 (Dense)          (None, 448)               129472    
                                                                 
 dropout_3204 (Dropout)      (None, 448)               0         
                                                                 
 dense_4033 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_948 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3205 (Dropout)      (None, 512)               0         
                                                                 
 dense_4034 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3206 (Dropout)      (None, 256)               0         
                                                                 
 dense_4035 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 725498 (2.77 MB)
Trainable params: 724474 (2.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 829:
  Value: 0.9189
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0002301626342006385

Model: "sequential_829"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_829 (Flatten)       (None, 784)               0         
                                                                 
 dense_4036 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3207 (Dropout)      (None, 512)               0         
                                                                 
 dense_4037 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3208 (Dropout)      (None, 448)               0         
                                                                 
 dense_4038 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_949 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3209 (Dropout)      (None, 480)               0         
                                                                 
 dense_4039 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3210 (Dropout)      (None, 288)               0         
                                                                 
 dense_4040 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 830:
  Value: 0.9072
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015900249333890139

Model: "sequential_830"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_830 (Flatten)       (None, 784)               0         
                                                                 
 dense_4041 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3211 (Dropout)      (None, 480)               0         
                                                                 
 dense_4042 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3212 (Dropout)      (None, 416)               0         
                                                                 
 dense_4043 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_950 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3213 (Dropout)      (None, 448)               0         
                                                                 
 dense_4044 (Dense)          (None, 320)               143680    
                                                                 
 dropout_3214 (Dropout)      (None, 320)               0         
                                                                 
 dense_4045 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 917530 (3.50 MB)
Trainable params: 916634 (3.50 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 831:
  Value: 0.9166
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0024855174158232387

Model: "sequential_831"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_831 (Flatten)       (None, 784)               0         
                                                                 
 dense_4046 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3215 (Dropout)      (None, 512)               0         
                                                                 
 dense_4047 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3216 (Dropout)      (None, 384)               0         
                                                                 
 dense_4048 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_951 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3217 (Dropout)      (None, 512)               0         
                                                                 
 dense_4049 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3218 (Dropout)      (None, 352)               0         
                                                                 
 dense_4050 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 987834 (3.77 MB)
Trainable params: 986810 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 832:
  Value: 0.9153
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0074280152996776755

Model: "sequential_832"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_832 (Flatten)       (None, 784)               0         
                                                                 
 dense_4051 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3219 (Dropout)      (None, 480)               0         
                                                                 
 dense_4052 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3220 (Dropout)      (None, 448)               0         
                                                                 
 dense_4053 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_952 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3221 (Dropout)      (None, 512)               0         
                                                                 
 dense_4054 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3222 (Dropout)      (None, 256)               0         
                                                                 
 dense_4055 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 962234 (3.67 MB)
Trainable params: 961210 (3.67 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 833:
  Value: 0.6409
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00017314558950560127

Model: "sequential_833"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_833 (Flatten)       (None, 784)               0         
                                                                 
 dense_4056 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3223 (Dropout)      (None, 512)               0         
                                                                 
 dense_4057 (Dense)          (None, 480)               246240    
                                                                 
 batch_normalization_953 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3224 (Dropout)      (None, 480)               0         
                                                                 
 dense_4058 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_954 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3225 (Dropout)      (None, 480)               0         
                                                                 
 dense_4059 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3226 (Dropout)      (None, 288)               0         
                                                                 
 dense_4060 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1028922 (3.93 MB)
Trainable params: 1027002 (3.92 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 834:
  Value: 0.8258
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008772406209197645

Model: "sequential_834"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_834 (Flatten)       (None, 784)               0         
                                                                 
 dense_4061 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3227 (Dropout)      (None, 480)               0         
                                                                 
 dense_4062 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3228 (Dropout)      (None, 416)               0         
                                                                 
 dense_4063 (Dense)          (None, 512)               213504    
                                                                 
 dropout_3229 (Dropout)      (None, 512)               0         
                                                                 
 dense_4064 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3230 (Dropout)      (None, 256)               0         
                                                                 
 dense_4065 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 928410 (3.54 MB)
Trainable params: 928410 (3.54 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 835:
  Value: 0.8755
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010359803738457206

Model: "sequential_835"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_835 (Flatten)       (None, 784)               0         
                                                                 
 dense_4066 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3231 (Dropout)      (None, 512)               0         
                                                                 
 dense_4067 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3232 (Dropout)      (None, 480)               0         
                                                                 
 dense_4068 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_955 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3233 (Dropout)      (None, 480)               0         
                                                                 
 dense_4069 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3234 (Dropout)      (None, 288)               0         
                                                                 
 dense_4070 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1027002 (3.92 MB)
Trainable params: 1026042 (3.91 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 836:
  Value: 0.7980
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001388831867377709

Model: "sequential_836"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_836 (Flatten)       (None, 784)               0         
                                                                 
 dense_4071 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3235 (Dropout)      (None, 512)               0         
                                                                 
 dense_4072 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3236 (Dropout)      (None, 448)               0         
                                                                 
 dense_4073 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_956 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3237 (Dropout)      (None, 512)               0         
                                                                 
 dense_4074 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3238 (Dropout)      (None, 288)               0         
                                                                 
 dense_4075 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 837:
  Value: 0.8607
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007660977343490538

Model: "sequential_837"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_837 (Flatten)       (None, 784)               0         
                                                                 
 dense_4076 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3239 (Dropout)      (None, 480)               0         
                                                                 
 dense_4077 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3240 (Dropout)      (None, 416)               0         
                                                                 
 dense_4078 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_957 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3241 (Dropout)      (None, 512)               0         
                                                                 
 dense_4079 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3242 (Dropout)      (None, 320)               0         
                                                                 
 dense_4080 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 838:
  Value: 0.8575
  num_layers: 4
  units_0: 448
  units_1: 256
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011773339688224854

Model: "sequential_838"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_838 (Flatten)       (None, 784)               0         
                                                                 
 dense_4081 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3243 (Dropout)      (None, 448)               0         
                                                                 
 dense_4082 (Dense)          (None, 256)               114944    
                                                                 
 dropout_3244 (Dropout)      (None, 256)               0         
                                                                 
 dense_4083 (Dense)          (None, 480)               123360    
                                                                 
 batch_normalization_958 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3245 (Dropout)      (None, 480)               0         
                                                                 
 dense_4084 (Dense)          (None, 224)               107744    
                                                                 
 dropout_3246 (Dropout)      (None, 224)               0         
                                                                 
 dense_4085 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 705498 (2.69 MB)
Trainable params: 704538 (2.69 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 839:
  Value: 0.9043
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00013030107736330742

Model: "sequential_839"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_839 (Flatten)       (None, 784)               0         
                                                                 
 dense_4086 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3247 (Dropout)      (None, 512)               0         
                                                                 
 dense_4087 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3248 (Dropout)      (None, 448)               0         
                                                                 
 dense_4088 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_959 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3249 (Dropout)      (None, 448)               0         
                                                                 
 dense_4089 (Dense)          (None, 288)               129312    
                                                                 
 dropout_3250 (Dropout)      (None, 288)               0         
                                                                 
 dense_4090 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 971514 (3.71 MB)
Trainable params: 970618 (3.70 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 840:
  Value: 0.7842
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.00205570043802878

Model: "sequential_840"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_840 (Flatten)       (None, 784)               0         
                                                                 
 dense_4091 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3251 (Dropout)      (None, 480)               0         
                                                                 
 dense_4092 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3252 (Dropout)      (None, 384)               0         
                                                                 
 dense_4093 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_960 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3253 (Dropout)      (None, 512)               0         
                                                                 
 dense_4094 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3254 (Dropout)      (None, 320)               0         
                                                                 
 dense_4095 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 933178 (3.56 MB)
Trainable params: 932154 (3.56 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 841:
  Value: 0.8557
  num_layers: 4
  units_0: 320
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0039320439601842234

Model: "sequential_841"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_841 (Flatten)       (None, 784)               0         
                                                                 
 dense_4096 (Dense)          (None, 320)               251200    
                                                                 
 dropout_3255 (Dropout)      (None, 320)               0         
                                                                 
 dense_4097 (Dense)          (None, 448)               143808    
                                                                 
 dropout_3256 (Dropout)      (None, 448)               0         
                                                                 
 dense_4098 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_961 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3257 (Dropout)      (None, 512)               0         
                                                                 
 dense_4099 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3258 (Dropout)      (None, 256)               0         
                                                                 
 dense_4100 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 764954 (2.92 MB)
Trainable params: 763930 (2.91 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 842:
  Value: 0.0383
  num_layers: 4
  units_0: 192
  units_1: 416
  units_2: 480
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.000595777520932789

Model: "sequential_842"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_842 (Flatten)       (None, 784)               0         
                                                                 
 dense_4101 (Dense)          (None, 192)               150720    
                                                                 
 dropout_3259 (Dropout)      (None, 192)               0         
                                                                 
 dense_4102 (Dense)          (None, 416)               80288     
                                                                 
 dropout_3260 (Dropout)      (None, 416)               0         
                                                                 
 dense_4103 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_962 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3261 (Dropout)      (None, 480)               0         
                                                                 
 dense_4104 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3262 (Dropout)      (None, 384)               0         
                                                                 
 dense_4105 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 627802 (2.39 MB)
Trainable params: 626842 (2.39 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 843:
  Value: 0.7504
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0034456070636242737

Model: "sequential_843"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_843 (Flatten)       (None, 784)               0         
                                                                 
 dense_4106 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_963 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3263 (Dropout)      (None, 512)               0         
                                                                 
 dense_4107 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3264 (Dropout)      (None, 448)               0         
                                                                 
 dense_4108 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_964 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3265 (Dropout)      (None, 512)               0         
                                                                 
 dense_4109 (Dense)          (None, 288)               147744    
                                                                 
 batch_normalization_965 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_3266 (Dropout)      (None, 288)               0         
                                                                 
 dense_4110 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1022138 (3.90 MB)
Trainable params: 1019514 (3.89 MB)
Non-trainable params: 2624 (10.25 KB)
_________________________________________________________________



Trial 844:
  Value: 0.8608
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016926393780179435

Model: "sequential_844"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_844 (Flatten)       (None, 784)               0         
                                                                 
 dense_4111 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3267 (Dropout)      (None, 480)               0         
                                                                 
 dense_4112 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3268 (Dropout)      (None, 416)               0         
                                                                 
 dense_4113 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_966 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3269 (Dropout)      (None, 480)               0         
                                                                 
 dense_4114 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3270 (Dropout)      (None, 288)               0         
                                                                 
 dense_4115 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 845:
  Value: 0.9194
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000964666478516366

Model: "sequential_845"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_845 (Flatten)       (None, 784)               0         
                                                                 
 dense_4116 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3271 (Dropout)      (None, 512)               0         
                                                                 
 dense_4117 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3272 (Dropout)      (None, 480)               0         
                                                                 
 dense_4118 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_967 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3273 (Dropout)      (None, 512)               0         
                                                                 
 dense_4119 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3274 (Dropout)      (None, 320)               0         
                                                                 
 dense_4120 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1068986 (4.08 MB)
Trainable params: 1067962 (4.07 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 846:
  Value: 0.8514
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 448
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.5
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014729157904414113

Model: "sequential_846"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_846 (Flatten)       (None, 784)               0         
                                                                 
 dense_4121 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3275 (Dropout)      (None, 448)               0         
                                                                 
 dense_4122 (Dense)          (None, 448)               201152    
                                                                 
 dropout_3276 (Dropout)      (None, 448)               0         
                                                                 
 dense_4123 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_968 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3277 (Dropout)      (None, 448)               0         
                                                                 
 dense_4124 (Dense)          (None, 256)               114944    
                                                                 
 dropout_3278 (Dropout)      (None, 256)               0         
                                                                 
 dense_4125 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 877402 (3.35 MB)
Trainable params: 876506 (3.34 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 847:
  Value: 0.9208
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001431208779731008

Model: "sequential_847"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_847 (Flatten)       (None, 784)               0         
                                                                 
 dense_4126 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3279 (Dropout)      (None, 480)               0         
                                                                 
 dense_4127 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3280 (Dropout)      (None, 416)               0         
                                                                 
 dense_4128 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_969 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3281 (Dropout)      (None, 480)               0         
                                                                 
 dense_4129 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3282 (Dropout)      (None, 288)               0         
                                                                 
 dense_4130 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 848:
  Value: 0.0903
  num_layers: 3
  units_0: 512
  units_1: 384
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adagrad
  learning_rate: 0.0013114224145749026

Model: "sequential_848"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_848 (Flatten)       (None, 784)               0         
                                                                 
 dense_4131 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3283 (Dropout)      (None, 512)               0         
                                                                 
 dense_4132 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3284 (Dropout)      (None, 384)               0         
                                                                 
 dense_4133 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_970 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3285 (Dropout)      (None, 512)               0         
                                                                 
 dense_4134 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 811418 (3.10 MB)
Trainable params: 810394 (3.09 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 849:
  Value: 0.7602
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 96
  units_3: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0026823125156662923

Model: "sequential_849"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_849 (Flatten)       (None, 784)               0         
                                                                 
 dense_4135 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3286 (Dropout)      (None, 512)               0         
                                                                 
 dense_4136 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3287 (Dropout)      (None, 448)               0         
                                                                 
 dense_4137 (Dense)          (None, 96)                43104     
                                                                 
 batch_normalization_971 (B  (None, 96)                384       
 atchNormalization)                                              
                                                                 
 dropout_3288 (Dropout)      (None, 96)                0         
                                                                 
 dense_4138 (Dense)          (None, 320)               31040     
                                                                 
 dropout_3289 (Dropout)      (None, 320)               0         
                                                                 
 dense_4139 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 714618 (2.73 MB)
Trainable params: 714426 (2.73 MB)
Non-trainable params: 192 (768.00 Byte)
_________________________________________________________________



Trial 850:
  Value: 0.9207
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011355271686979674

Model: "sequential_850"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_850 (Flatten)       (None, 784)               0         
                                                                 
 dense_4140 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3290 (Dropout)      (None, 480)               0         
                                                                 
 dense_4141 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3291 (Dropout)      (None, 416)               0         
                                                                 
 dense_4142 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_972 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3292 (Dropout)      (None, 512)               0         
                                                                 
 dense_4143 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3293 (Dropout)      (None, 256)               0         
                                                                 
 dense_4144 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 930458 (3.55 MB)
Trainable params: 929434 (3.55 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 851:
  Value: 0.9119
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.006034433934549746

Model: "sequential_851"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_851 (Flatten)       (None, 784)               0         
                                                                 
 dense_4145 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3294 (Dropout)      (None, 512)               0         
                                                                 
 dense_4146 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3295 (Dropout)      (None, 480)               0         
                                                                 
 dense_4147 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_973 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3296 (Dropout)      (None, 480)               0         
                                                                 
 dense_4148 (Dense)          (None, 224)               107744    
                                                                 
 dropout_3297 (Dropout)      (None, 224)               0         
                                                                 
 dense_4149 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 994554 (3.79 MB)
Trainable params: 993594 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 852:
  Value: 0.7513
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0022965933421787606

Model: "sequential_852"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_852 (Flatten)       (None, 784)               0         
                                                                 
 dense_4150 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3298 (Dropout)      (None, 480)               0         
                                                                 
 dense_4151 (Dense)          (None, 448)               215488    
                                                                 
 batch_normalization_974 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3299 (Dropout)      (None, 448)               0         
                                                                 
 dense_4152 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_975 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3300 (Dropout)      (None, 512)               0         
                                                                 
 dense_4153 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3301 (Dropout)      (None, 288)               0         
                                                                 
 dense_4154 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 981274 (3.74 MB)
Trainable params: 979354 (3.74 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 853:
  Value: 0.8603
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000703700693944143

Model: "sequential_853"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_853 (Flatten)       (None, 784)               0         
                                                                 
 dense_4155 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3302 (Dropout)      (None, 448)               0         
                                                                 
 dense_4156 (Dense)          (None, 416)               186784    
                                                                 
 dropout_3303 (Dropout)      (None, 416)               0         
                                                                 
 dense_4157 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_976 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3304 (Dropout)      (None, 512)               0         
                                                                 
 dense_4158 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3305 (Dropout)      (None, 256)               0         
                                                                 
 dense_4159 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 892026 (3.40 MB)
Trainable params: 891002 (3.40 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 854:
  Value: 0.8346
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003867219507653139

Model: "sequential_854"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_854 (Flatten)       (None, 784)               0         
                                                                 
 dense_4160 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3306 (Dropout)      (None, 512)               0         
                                                                 
 dense_4161 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3307 (Dropout)      (None, 480)               0         
                                                                 
 dense_4162 (Dense)          (None, 480)               230880    
                                                                 
 dropout_3308 (Dropout)      (None, 480)               0         
                                                                 
 dense_4163 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3309 (Dropout)      (None, 288)               0         
                                                                 
 dense_4164 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1025082 (3.91 MB)
Trainable params: 1025082 (3.91 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 855:
  Value: 0.0389
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0018287630623667478

Model: "sequential_855"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_855 (Flatten)       (None, 784)               0         
                                                                 
 dense_4165 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3310 (Dropout)      (None, 480)               0         
                                                                 
 dense_4166 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3311 (Dropout)      (None, 448)               0         
                                                                 
 dense_4167 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_977 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3312 (Dropout)      (None, 512)               0         
                                                                 
 dense_4168 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3313 (Dropout)      (None, 352)               0         
                                                                 
 dense_4169 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1013978 (3.87 MB)
Trainable params: 1012954 (3.86 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 856:
  Value: 0.9178
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012266532361556602

Model: "sequential_856"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_856 (Flatten)       (None, 784)               0         
                                                                 
 dense_4170 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3314 (Dropout)      (None, 512)               0         
                                                                 
 dense_4171 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3315 (Dropout)      (None, 416)               0         
                                                                 
 dense_4172 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_978 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3316 (Dropout)      (None, 480)               0         
                                                                 
 dense_4173 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3317 (Dropout)      (None, 288)               0         
                                                                 
 dense_4174 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 857:
  Value: 0.8759
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0016101362281975003

Model: "sequential_857"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_857 (Flatten)       (None, 784)               0         
                                                                 
 dense_4175 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3318 (Dropout)      (None, 512)               0         
                                                                 
 dense_4176 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3319 (Dropout)      (None, 384)               0         
                                                                 
 dense_4177 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_979 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3320 (Dropout)      (None, 512)               0         
                                                                 
 dense_4178 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3321 (Dropout)      (None, 320)               0         
                                                                 
 dense_4179 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 858:
  Value: 0.9087
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010478114510528676

Model: "sequential_858"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_858 (Flatten)       (None, 784)               0         
                                                                 
 dense_4180 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3322 (Dropout)      (None, 480)               0         
                                                                 
 dense_4181 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3323 (Dropout)      (None, 448)               0         
                                                                 
 dense_4182 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_980 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3324 (Dropout)      (None, 448)               0         
                                                                 
 dense_4183 (Dense)          (None, 288)               129312    
                                                                 
 dropout_3325 (Dropout)      (None, 288)               0         
                                                                 
 dense_4184 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 932058 (3.56 MB)
Trainable params: 931162 (3.55 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 859:
  Value: 0.7336
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0013668431316070967

Model: "sequential_859"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_859 (Flatten)       (None, 784)               0         
                                                                 
 dense_4185 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3326 (Dropout)      (None, 512)               0         
                                                                 
 dense_4186 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3327 (Dropout)      (None, 352)               0         
                                                                 
 dense_4187 (Dense)          (None, 480)               169440    
                                                                 
 batch_normalization_981 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3328 (Dropout)      (None, 480)               0         
                                                                 
 dense_4188 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3329 (Dropout)      (None, 256)               0         
                                                                 
 dense_4189 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 883674 (3.37 MB)
Trainable params: 882714 (3.37 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 860:
  Value: 0.9202
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.006593344361047853

Model: "sequential_860"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_860 (Flatten)       (None, 784)               0         
                                                                 
 dense_4190 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3330 (Dropout)      (None, 480)               0         
                                                                 
 dense_4191 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3331 (Dropout)      (None, 416)               0         
                                                                 
 dense_4192 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_982 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3332 (Dropout)      (None, 512)               0         
                                                                 
 dense_4193 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3333 (Dropout)      (None, 320)               0         
                                                                 
 dense_4194 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 861:
  Value: 0.8000
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0019902097834997197

Model: "sequential_861"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_861 (Flatten)       (None, 784)               0         
                                                                 
 dense_4195 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3334 (Dropout)      (None, 512)               0         
                                                                 
 dense_4196 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3335 (Dropout)      (None, 448)               0         
                                                                 
 dense_4197 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_983 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3336 (Dropout)      (None, 512)               0         
                                                                 
 dense_4198 (Dense)          (None, 288)               147744    
                                                                 
 batch_normalization_984 (B  (None, 288)               1152      
 atchNormalization)                                              
                                                                 
 dropout_3337 (Dropout)      (None, 288)               0         
                                                                 
 dense_4199 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1020090 (3.89 MB)
Trainable params: 1018490 (3.89 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 862:
  Value: 0.8635
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00046781992844577964

Model: "sequential_862"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_862 (Flatten)       (None, 784)               0         
                                                                 
 dense_4200 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3338 (Dropout)      (None, 480)               0         
                                                                 
 dense_4201 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3339 (Dropout)      (None, 416)               0         
                                                                 
 dense_4202 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_985 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3340 (Dropout)      (None, 480)               0         
                                                                 
 dense_4203 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3341 (Dropout)      (None, 288)               0         
                                                                 
 dense_4204 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 863:
  Value: 0.8542
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.4
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008420493274091883

Model: "sequential_863"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_863 (Flatten)       (None, 784)               0         
                                                                 
 dense_4205 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3342 (Dropout)      (None, 512)               0         
                                                                 
 dense_4206 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3343 (Dropout)      (None, 480)               0         
                                                                 
 dense_4207 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_986 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3344 (Dropout)      (None, 512)               0         
                                                                 
 dense_4208 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3345 (Dropout)      (None, 256)               0         
                                                                 
 dense_4209 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1034490 (3.95 MB)
Trainable params: 1033466 (3.94 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 864:
  Value: 0.2459
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0011175432743015467

Model: "sequential_864"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_864 (Flatten)       (None, 784)               0         
                                                                 
 dense_4210 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_987 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3346 (Dropout)      (None, 512)               0         
                                                                 
 dense_4211 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3347 (Dropout)      (None, 448)               0         
                                                                 
 dense_4212 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_988 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3348 (Dropout)      (None, 512)               0         
                                                                 
 dense_4213 (Dense)          (None, 224)               114912    
                                                                 
 dropout_3349 (Dropout)      (None, 224)               0         
                                                                 
 dense_4214 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 986490 (3.76 MB)
Trainable params: 984442 (3.76 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 865:
  Value: 0.8569
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014732071785609898

Model: "sequential_865"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_865 (Flatten)       (None, 784)               0         
                                                                 
 dense_4215 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3350 (Dropout)      (None, 480)               0         
                                                                 
 dense_4216 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3351 (Dropout)      (None, 384)               0         
                                                                 
 dense_4217 (Dense)          (None, 448)               172480    
                                                                 
 batch_normalization_989 (B  (None, 448)               1792      
 atchNormalization)                                              
                                                                 
 dropout_3352 (Dropout)      (None, 448)               0         
                                                                 
 dense_4218 (Dense)          (None, 288)               129312    
                                                                 
 dropout_3353 (Dropout)      (None, 288)               0         
                                                                 
 dense_4219 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 872602 (3.33 MB)
Trainable params: 871706 (3.33 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 866:
  Value: 0.8535
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005517330307079132

Model: "sequential_866"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_866 (Flatten)       (None, 784)               0         
                                                                 
 dense_4220 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3354 (Dropout)      (None, 480)               0         
                                                                 
 dense_4221 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3355 (Dropout)      (None, 416)               0         
                                                                 
 dense_4222 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_990 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3356 (Dropout)      (None, 480)               0         
                                                                 
 dense_4223 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3357 (Dropout)      (None, 320)               0         
                                                                 
 dense_4224 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 941242 (3.59 MB)
Trainable params: 940282 (3.59 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 867:
  Value: 0.8961
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005540647026722906

Model: "sequential_867"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_867 (Flatten)       (None, 784)               0         
                                                                 
 dense_4225 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3358 (Dropout)      (None, 448)               0         
                                                                 
 dense_4226 (Dense)          (None, 448)               201152    
                                                                 
 dropout_3359 (Dropout)      (None, 448)               0         
                                                                 
 dense_4227 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_991 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3360 (Dropout)      (None, 512)               0         
                                                                 
 dense_4228 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3361 (Dropout)      (None, 320)               0         
                                                                 
 dense_4229 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 957274 (3.65 MB)
Trainable params: 956250 (3.65 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 868:
  Value: 0.8590
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0029132709961361357

Model: "sequential_868"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_868 (Flatten)       (None, 784)               0         
                                                                 
 dense_4230 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3362 (Dropout)      (None, 512)               0         
                                                                 
 dense_4231 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3363 (Dropout)      (None, 480)               0         
                                                                 
 dense_4232 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_992 (B  (None, 480)               1920      
 atchNormalization)                                              
                                                                 
 dropout_3364 (Dropout)      (None, 480)               0         
                                                                 
 dense_4233 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3365 (Dropout)      (None, 288)               0         
                                                                 
 dense_4234 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1027002 (3.92 MB)
Trainable params: 1026042 (3.91 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 869:
  Value: 0.5755
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.001254550836789623

Model: "sequential_869"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_869 (Flatten)       (None, 784)               0         
                                                                 
 dense_4235 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3366 (Dropout)      (None, 480)               0         
                                                                 
 dense_4236 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3367 (Dropout)      (None, 448)               0         
                                                                 
 dense_4237 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_993 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3368 (Dropout)      (None, 512)               0         
                                                                 
 dense_4238 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3369 (Dropout)      (None, 256)               0         
                                                                 
 dense_4239 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 962234 (3.67 MB)
Trainable params: 961210 (3.67 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 870:
  Value: 0.9213
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009683354986918813

Model: "sequential_870"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_870 (Flatten)       (None, 784)               0         
                                                                 
 dense_4240 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3370 (Dropout)      (None, 512)               0         
                                                                 
 dense_4241 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3371 (Dropout)      (None, 320)               0         
                                                                 
 dense_4242 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_994 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3372 (Dropout)      (None, 512)               0         
                                                                 
 dense_4243 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3373 (Dropout)      (None, 288)               0         
                                                                 
 dense_4244 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 887738 (3.39 MB)
Trainable params: 886714 (3.38 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 871:
  Value: 0.9194
  num_layers: 4
  units_0: 512
  units_1: 320
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008698999212885988

Model: "sequential_871"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_871 (Flatten)       (None, 784)               0         
                                                                 
 dense_4245 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3374 (Dropout)      (None, 512)               0         
                                                                 
 dense_4246 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3375 (Dropout)      (None, 320)               0         
                                                                 
 dense_4247 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_995 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3376 (Dropout)      (None, 512)               0         
                                                                 
 dense_4248 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3377 (Dropout)      (None, 256)               0         
                                                                 
 dense_4249 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 870490 (3.32 MB)
Trainable params: 869466 (3.32 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 872:
  Value: 0.8277
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 192
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007904119715855675

Model: "sequential_872"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_872 (Flatten)       (None, 784)               0         
                                                                 
 dense_4250 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3378 (Dropout)      (None, 480)               0         
                                                                 
 dense_4251 (Dense)          (None, 320)               153920    
                                                                 
 batch_normalization_996 (B  (None, 320)               1280      
 atchNormalization)                                              
                                                                 
 dropout_3379 (Dropout)      (None, 320)               0         
                                                                 
 dense_4252 (Dense)          (None, 192)               61632     
                                                                 
 dropout_3380 (Dropout)      (None, 192)               0         
                                                                 
 dense_4253 (Dense)          (None, 288)               55584     
                                                                 
 dropout_3381 (Dropout)      (None, 288)               0         
                                                                 
 dense_4254 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 656730 (2.51 MB)
Trainable params: 656090 (2.50 MB)
Non-trainable params: 640 (2.50 KB)
_________________________________________________________________



Trial 873:
  Value: 0.8638
  num_layers: 4
  units_0: 448
  units_1: 256
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009392426814425213

Model: "sequential_873"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_873 (Flatten)       (None, 784)               0         
                                                                 
 dense_4255 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3382 (Dropout)      (None, 448)               0         
                                                                 
 dense_4256 (Dense)          (None, 256)               114944    
                                                                 
 dropout_3383 (Dropout)      (None, 256)               0         
                                                                 
 dense_4257 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_997 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3384 (Dropout)      (None, 512)               0         
                                                                 
 dense_4258 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3385 (Dropout)      (None, 320)               0         
                                                                 
 dense_4259 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 772762 (2.95 MB)
Trainable params: 771738 (2.94 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 874:
  Value: 0.9104
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.009958753249703656

Model: "sequential_874"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_874 (Flatten)       (None, 784)               0         
                                                                 
 dense_4260 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3386 (Dropout)      (None, 512)               0         
                                                                 
 dense_4261 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3387 (Dropout)      (None, 352)               0         
                                                                 
 dense_4262 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_998 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3388 (Dropout)      (None, 512)               0         
                                                                 
 dense_4263 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3389 (Dropout)      (None, 288)               0         
                                                                 
 dense_4264 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 920538 (3.51 MB)
Trainable params: 919514 (3.51 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 875:
  Value: 0.9063
  num_layers: 4
  units_0: 512
  units_1: 288
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: tanh
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009956208903997598

Model: "sequential_875"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_875 (Flatten)       (None, 784)               0         
                                                                 
 dense_4265 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3390 (Dropout)      (None, 512)               0         
                                                                 
 dense_4266 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3391 (Dropout)      (None, 288)               0         
                                                                 
 dense_4267 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_999 (B  (None, 512)               2048      
 atchNormalization)                                              
                                                                 
 dropout_3392 (Dropout)      (None, 512)               0         
                                                                 
 dense_4268 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3393 (Dropout)      (None, 352)               0         
                                                                 
 dense_4269 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 889434 (3.39 MB)
Trainable params: 888410 (3.39 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 876:
  Value: 0.0639
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.008386554254482885

Model: "sequential_876"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_876 (Flatten)       (None, 784)               0         
                                                                 
 dense_4270 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3394 (Dropout)      (None, 480)               0         
                                                                 
 dense_4271 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3395 (Dropout)      (None, 384)               0         
                                                                 
 dense_4272 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1000 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3396 (Dropout)      (None, 512)               0         
                                                                 
 dense_4273 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3397 (Dropout)      (None, 288)               0         
                                                                 
 dense_4274 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 915930 (3.49 MB)
Trainable params: 914906 (3.49 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 877:
  Value: 0.8045
  num_layers: 4
  units_0: 128
  units_1: 288
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009326831917460717

Model: "sequential_877"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_877 (Flatten)       (None, 784)               0         
                                                                 
 dense_4275 (Dense)          (None, 128)               100480    
                                                                 
 dropout_3398 (Dropout)      (None, 128)               0         
                                                                 
 dense_4276 (Dense)          (None, 288)               37152     
                                                                 
 dropout_3399 (Dropout)      (None, 288)               0         
                                                                 
 dense_4277 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_1001 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3400 (Dropout)      (None, 512)               0         
                                                                 
 dense_4278 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3401 (Dropout)      (None, 256)               0         
                                                                 
 dense_4279 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 425658 (1.62 MB)
Trainable params: 424634 (1.62 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 878:
  Value: 0.9202
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001102668400035677

Model: "sequential_878"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_878 (Flatten)       (None, 784)               0         
                                                                 
 dense_4280 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3402 (Dropout)      (None, 512)               0         
                                                                 
 dense_4281 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3403 (Dropout)      (None, 384)               0         
                                                                 
 dense_4282 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1002 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3404 (Dropout)      (None, 512)               0         
                                                                 
 dense_4283 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3405 (Dropout)      (None, 320)               0         
                                                                 
 dense_4284 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 970586 (3.70 MB)
Trainable params: 969562 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 879:
  Value: 0.9203
  num_layers: 4
  units_0: 480
  units_1: 288
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001069033917255247

Model: "sequential_879"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_879 (Flatten)       (None, 784)               0         
                                                                 
 dense_4285 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3406 (Dropout)      (None, 480)               0         
                                                                 
 dense_4286 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3407 (Dropout)      (None, 288)               0         
                                                                 
 dense_4287 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_1003 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3408 (Dropout)      (None, 512)               0         
                                                                 
 dense_4288 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3409 (Dropout)      (None, 288)               0         
                                                                 
 dense_4289 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 820602 (3.13 MB)
Trainable params: 819578 (3.13 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 880:
  Value: 0.4052
  num_layers: 4
  units_0: 512
  units_1: 96
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: rmsprop
  learning_rate: 0.0011742684903821728

Model: "sequential_880"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_880 (Flatten)       (None, 784)               0         
                                                                 
 dense_4290 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3410 (Dropout)      (None, 512)               0         
                                                                 
 dense_4291 (Dense)          (None, 96)                49248     
                                                                 
 dropout_3411 (Dropout)      (None, 96)                0         
                                                                 
 dense_4292 (Dense)          (None, 512)               49664     
                                                                 
 batch_normalization_1004 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3412 (Dropout)      (None, 512)               0         
                                                                 
 dense_4293 (Dense)          (None, 256)               131328    
                                                                 
 batch_normalization_1005 (  (None, 256)               1024      
 BatchNormalization)                                             
                                                                 
 dropout_3413 (Dropout)      (None, 256)               0         
                                                                 
 dense_4294 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 641914 (2.45 MB)
Trainable params: 640378 (2.44 MB)
Non-trainable params: 1536 (6.00 KB)
_________________________________________________________________



Trial 881:
  Value: 0.9169
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 512
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.000746671335144345

Model: "sequential_881"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_881 (Flatten)       (None, 784)               0         
                                                                 
 dense_4295 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3414 (Dropout)      (None, 480)               0         
                                                                 
 dense_4296 (Dense)          (None, 352)               169312    
                                                                 
 dropout_3415 (Dropout)      (None, 352)               0         
                                                                 
 dense_4297 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_1006 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3416 (Dropout)      (None, 512)               0         
                                                                 
 dense_4298 (Dense)          (None, 224)               114912    
                                                                 
 dropout_3417 (Dropout)      (None, 224)               0         
                                                                 
 dense_4299 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 849658 (3.24 MB)
Trainable params: 848634 (3.24 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 882:
  Value: 0.8243
  num_layers: 1
  units_0: 448
  activation_0: relu
  dropout_0: 0.2
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.0010182428803022351

Model: "sequential_882"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_882 (Flatten)       (None, 784)               0         
                                                                 
 dense_4300 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3418 (Dropout)      (None, 448)               0         
                                                                 
 dense_4301 (Dense)          (None, 26)                11674     
                                                                 
=================================================================
Total params: 363354 (1.39 MB)
Trainable params: 363354 (1.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 883:
  Value: 0.9193
  num_layers: 3
  units_0: 512
  units_1: 352
  units_2: 512
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.001343381180964411

Model: "sequential_883"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_883 (Flatten)       (None, 784)               0         
                                                                 
 dense_4302 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3419 (Dropout)      (None, 512)               0         
                                                                 
 dense_4303 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3420 (Dropout)      (None, 352)               0         
                                                                 
 dense_4304 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_1007 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3421 (Dropout)      (None, 512)               0         
                                                                 
 dense_4305 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 778618 (2.97 MB)
Trainable params: 777594 (2.97 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 884:
  Value: 0.9137
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008172488731285802

Model: "sequential_884"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_884 (Flatten)       (None, 784)               0         
                                                                 
 dense_4306 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3422 (Dropout)      (None, 512)               0         
                                                                 
 dense_4307 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3423 (Dropout)      (None, 384)               0         
                                                                 
 dense_4308 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1008 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3424 (Dropout)      (None, 512)               0         
                                                                 
 dense_4309 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3425 (Dropout)      (None, 288)               0         
                                                                 
 dense_4310 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 885:
  Value: 0.0384
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0009459266720505579

Model: "sequential_885"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_885 (Flatten)       (None, 784)               0         
                                                                 
 dense_4311 (Dense)          (None, 480)               376800    
                                                                 
 batch_normalization_1009 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3426 (Dropout)      (None, 480)               0         
                                                                 
 dense_4312 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3427 (Dropout)      (None, 320)               0         
                                                                 
 dense_4313 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_1010 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3428 (Dropout)      (None, 512)               0         
                                                                 
 dense_4314 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3429 (Dropout)      (None, 320)               0         
                                                                 
 dense_4315 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 871546 (3.32 MB)
Trainable params: 869562 (3.32 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 886:
  Value: 0.9176
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0069501651444020636

Model: "sequential_886"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_886 (Flatten)       (None, 784)               0         
                                                                 
 dense_4316 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3430 (Dropout)      (None, 512)               0         
                                                                 
 dense_4317 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3431 (Dropout)      (None, 416)               0         
                                                                 
 dense_4318 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1011 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3432 (Dropout)      (None, 512)               0         
                                                                 
 dense_4319 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3433 (Dropout)      (None, 288)               0         
                                                                 
 dense_4320 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 887:
  Value: 0.9188
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006528971242669202

Model: "sequential_887"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_887 (Flatten)       (None, 784)               0         
                                                                 
 dense_4321 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3434 (Dropout)      (None, 480)               0         
                                                                 
 dense_4322 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3435 (Dropout)      (None, 320)               0         
                                                                 
 dense_4323 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_1012 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3436 (Dropout)      (None, 512)               0         
                                                                 
 dense_4324 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3437 (Dropout)      (None, 256)               0         
                                                                 
 dense_4325 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 835130 (3.19 MB)
Trainable params: 834106 (3.18 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 888:
  Value: 0.9191
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005113581271687004

Model: "sequential_888"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_888 (Flatten)       (None, 784)               0         
                                                                 
 dense_4326 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3438 (Dropout)      (None, 512)               0         
                                                                 
 dense_4327 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3439 (Dropout)      (None, 352)               0         
                                                                 
 dense_4328 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_1013 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3440 (Dropout)      (None, 512)               0         
                                                                 
 dense_4329 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3441 (Dropout)      (None, 288)               0         
                                                                 
 dense_4330 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 920538 (3.51 MB)
Trainable params: 919514 (3.51 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 889:
  Value: 0.8446
  num_layers: 4
  units_0: 480
  units_1: 320
  units_2: 512
  units_3: 32
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0015937195689973008

Model: "sequential_889"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_889 (Flatten)       (None, 784)               0         
                                                                 
 dense_4331 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3442 (Dropout)      (None, 480)               0         
                                                                 
 dense_4332 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3443 (Dropout)      (None, 320)               0         
                                                                 
 dense_4333 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_1014 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3444 (Dropout)      (None, 512)               0         
                                                                 
 dense_4334 (Dense)          (None, 32)                16416     
                                                                 
 dropout_3445 (Dropout)      (None, 32)                0         
                                                                 
 dense_4335 (Dense)          (None, 26)                858       
                                                                 
=================================================================
Total params: 714394 (2.73 MB)
Trainable params: 713370 (2.72 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 890:
  Value: 0.7815
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011781575747279228

Model: "sequential_890"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_890 (Flatten)       (None, 784)               0         
                                                                 
 dense_4336 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3446 (Dropout)      (None, 512)               0         
                                                                 
 dense_4337 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3447 (Dropout)      (None, 416)               0         
                                                                 
 dense_4338 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1015 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3448 (Dropout)      (None, 512)               0         
                                                                 
 dense_4339 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3449 (Dropout)      (None, 320)               0         
                                                                 
 dense_4340 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 891:
  Value: 0.4620
  num_layers: 4
  units_0: 448
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0014522634102749905

Model: "sequential_891"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_891 (Flatten)       (None, 784)               0         
                                                                 
 dense_4341 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3450 (Dropout)      (None, 448)               0         
                                                                 
 dense_4342 (Dense)          (None, 384)               172416    
                                                                 
 batch_normalization_1016 (  (None, 384)               1536      
 BatchNormalization)                                             
                                                                 
 dropout_3451 (Dropout)      (None, 384)               0         
                                                                 
 dense_4343 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1017 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3452 (Dropout)      (None, 512)               0         
                                                                 
 dense_4344 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3453 (Dropout)      (None, 288)               0         
                                                                 
 dense_4345 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 880058 (3.36 MB)
Trainable params: 878266 (3.35 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 892:
  Value: 0.0420
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.001254826986807592

Model: "sequential_892"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_892 (Flatten)       (None, 784)               0         
                                                                 
 dense_4346 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3454 (Dropout)      (None, 512)               0         
                                                                 
 dense_4347 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3455 (Dropout)      (None, 416)               0         
                                                                 
 dense_4348 (Dense)          (None, 480)               200160    
                                                                 
 dropout_3456 (Dropout)      (None, 480)               0         
                                                                 
 dense_4349 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3457 (Dropout)      (None, 256)               0         
                                                                 
 dense_4350 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 945306 (3.61 MB)
Trainable params: 945306 (3.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 893:
  Value: 0.8609
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010523018583669262

Model: "sequential_893"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_893 (Flatten)       (None, 784)               0         
                                                                 
 dense_4351 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3458 (Dropout)      (None, 480)               0         
                                                                 
 dense_4352 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3459 (Dropout)      (None, 416)               0         
                                                                 
 dense_4353 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1018 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3460 (Dropout)      (None, 512)               0         
                                                                 
 dense_4354 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3461 (Dropout)      (None, 288)               0         
                                                                 
 dense_4355 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 947706 (3.62 MB)
Trainable params: 946682 (3.61 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 894:
  Value: 0.8326
  num_layers: 4
  units_0: 256
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00178740068671595

Model: "sequential_894"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_894 (Flatten)       (None, 784)               0         
                                                                 
 dense_4356 (Dense)          (None, 256)               200960    
                                                                 
 dropout_3462 (Dropout)      (None, 256)               0         
                                                                 
 dense_4357 (Dense)          (None, 384)               98688     
                                                                 
 dropout_3463 (Dropout)      (None, 384)               0         
                                                                 
 dense_4358 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1019 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3464 (Dropout)      (None, 512)               0         
                                                                 
 dense_4359 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3465 (Dropout)      (None, 320)               0         
                                                                 
 dense_4360 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 671322 (2.56 MB)
Trainable params: 670298 (2.56 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 895:
  Value: 0.9185
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001375318102147659

Model: "sequential_895"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_895 (Flatten)       (None, 784)               0         
                                                                 
 dense_4361 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3466 (Dropout)      (None, 512)               0         
                                                                 
 dense_4362 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3467 (Dropout)      (None, 416)               0         
                                                                 
 dense_4363 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_1020 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3468 (Dropout)      (None, 480)               0         
                                                                 
 dense_4364 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3469 (Dropout)      (None, 288)               0         
                                                                 
 dense_4365 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 963450 (3.68 MB)
Trainable params: 962490 (3.67 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 896:
  Value: 0.8552
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.007476613019349054

Model: "sequential_896"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_896 (Flatten)       (None, 784)               0         
                                                                 
 dense_4366 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3470 (Dropout)      (None, 480)               0         
                                                                 
 dense_4367 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3471 (Dropout)      (None, 416)               0         
                                                                 
 dense_4368 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1021 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3472 (Dropout)      (None, 512)               0         
                                                                 
 dense_4369 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3473 (Dropout)      (None, 256)               0         
                                                                 
 dense_4370 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 930458 (3.55 MB)
Trainable params: 929434 (3.55 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 897:
  Value: 0.8764
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0004250257286449876

Model: "sequential_897"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_897 (Flatten)       (None, 784)               0         
                                                                 
 dense_4371 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3474 (Dropout)      (None, 512)               0         
                                                                 
 dense_4372 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3475 (Dropout)      (None, 480)               0         
                                                                 
 dense_4373 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_1022 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3476 (Dropout)      (None, 416)               0         
                                                                 
 dense_4374 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3477 (Dropout)      (None, 320)               0         
                                                                 
 dense_4375 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 991706 (3.78 MB)
Trainable params: 990874 (3.78 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 898:
  Value: 0.9134
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011612749285325344

Model: "sequential_898"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_898 (Flatten)       (None, 784)               0         
                                                                 
 dense_4376 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3478 (Dropout)      (None, 480)               0         
                                                                 
 dense_4377 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3479 (Dropout)      (None, 416)               0         
                                                                 
 dense_4378 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_1023 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3480 (Dropout)      (None, 480)               0         
                                                                 
 dense_4379 (Dense)          (None, 352)               169312    
                                                                 
 dropout_3481 (Dropout)      (None, 352)               0         
                                                                 
 dense_4380 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 957466 (3.65 MB)
Trainable params: 956506 (3.65 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 899:
  Value: 0.9192
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001292235935727733

Model: "sequential_899"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_899 (Flatten)       (None, 784)               0         
                                                                 
 dense_4381 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3482 (Dropout)      (None, 512)               0         
                                                                 
 dense_4382 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3483 (Dropout)      (None, 384)               0         
                                                                 
 dense_4383 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1024 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3484 (Dropout)      (None, 512)               0         
                                                                 
 dense_4384 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3485 (Dropout)      (None, 288)               0         
                                                                 
 dense_4385 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 900:
  Value: 0.8050
  num_layers: 2
  units_0: 448
  units_1: 416
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.0001613570254203003

Model: "sequential_900"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_900 (Flatten)       (None, 784)               0         
                                                                 
 dense_4386 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3486 (Dropout)      (None, 448)               0         
                                                                 
 dense_4387 (Dense)          (None, 416)               186784    
                                                                 
 dropout_3487 (Dropout)      (None, 416)               0         
                                                                 
 dense_4388 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 549306 (2.10 MB)
Trainable params: 549306 (2.10 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 901:
  Value: 0.8432
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.009244309863777708

Model: "sequential_901"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_901 (Flatten)       (None, 784)               0         
                                                                 
 dense_4389 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_1025 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3488 (Dropout)      (None, 512)               0         
                                                                 
 dense_4390 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3489 (Dropout)      (None, 480)               0         
                                                                 
 dense_4391 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_1026 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3490 (Dropout)      (None, 512)               0         
                                                                 
 dense_4392 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3491 (Dropout)      (None, 256)               0         
                                                                 
 dense_4393 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1036538 (3.95 MB)
Trainable params: 1034490 (3.95 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 902:
  Value: 0.8128
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 224
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0015656231296385717

Model: "sequential_902"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_902 (Flatten)       (None, 784)               0         
                                                                 
 dense_4394 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3492 (Dropout)      (None, 480)               0         
                                                                 
 dense_4395 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3493 (Dropout)      (None, 448)               0         
                                                                 
 dense_4396 (Dense)          (None, 224)               100576    
                                                                 
 batch_normalization_1027 (  (None, 224)               896       
 BatchNormalization)                                             
                                                                 
 dropout_3494 (Dropout)      (None, 224)               0         
                                                                 
 dense_4397 (Dense)          (None, 288)               64800     
                                                                 
 batch_normalization_1028 (  (None, 288)               1152      
 BatchNormalization)                                             
                                                                 
 dropout_3495 (Dropout)      (None, 288)               0         
                                                                 
 dense_4398 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 767226 (2.93 MB)
Trainable params: 766202 (2.92 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 903:
  Value: 0.9190
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009200349600645472

Model: "sequential_903"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_903 (Flatten)       (None, 784)               0         
                                                                 
 dense_4399 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3496 (Dropout)      (None, 512)               0         
                                                                 
 dense_4400 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3497 (Dropout)      (None, 416)               0         
                                                                 
 dense_4401 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_1029 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3498 (Dropout)      (None, 480)               0         
                                                                 
 dense_4402 (Dense)          (None, 224)               107744    
                                                                 
 dropout_3499 (Dropout)      (None, 224)               0         
                                                                 
 dense_4403 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 931002 (3.55 MB)
Trainable params: 930042 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 904:
  Value: 0.9015
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00019306344281273675

Model: "sequential_904"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_904 (Flatten)       (None, 784)               0         
                                                                 
 dense_4404 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3500 (Dropout)      (None, 480)               0         
                                                                 
 dense_4405 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3501 (Dropout)      (None, 448)               0         
                                                                 
 dense_4406 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_1030 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3502 (Dropout)      (None, 512)               0         
                                                                 
 dense_4407 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3503 (Dropout)      (None, 288)               0         
                                                                 
 dense_4408 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 905:
  Value: 0.0384
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0005712788298607646

Model: "sequential_905"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_905 (Flatten)       (None, 784)               0         
                                                                 
 dense_4409 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3504 (Dropout)      (None, 512)               0         
                                                                 
 dense_4410 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3505 (Dropout)      (None, 416)               0         
                                                                 
 dense_4411 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_1031 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3506 (Dropout)      (None, 480)               0         
                                                                 
 dense_4412 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3507 (Dropout)      (None, 320)               0         
                                                                 
 dense_4413 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 979674 (3.74 MB)
Trainable params: 978714 (3.73 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 906:
  Value: 0.9155
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0003555550893923527

Model: "sequential_906"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_906 (Flatten)       (None, 784)               0         
                                                                 
 dense_4414 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3508 (Dropout)      (None, 480)               0         
                                                                 
 dense_4415 (Dense)          (None, 480)               230880    
                                                                 
 dropout_3509 (Dropout)      (None, 480)               0         
                                                                 
 dense_4416 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_1032 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3510 (Dropout)      (None, 512)               0         
                                                                 
 dense_4417 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3511 (Dropout)      (None, 256)               0         
                                                                 
 dense_4418 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 994010 (3.79 MB)
Trainable params: 992986 (3.79 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 907:
  Value: 0.8515
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008500994981903932

Model: "sequential_907"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_907 (Flatten)       (None, 784)               0         
                                                                 
 dense_4419 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3512 (Dropout)      (None, 448)               0         
                                                                 
 dense_4420 (Dense)          (None, 448)               201152    
                                                                 
 dropout_3513 (Dropout)      (None, 448)               0         
                                                                 
 dense_4421 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_1033 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3514 (Dropout)      (None, 512)               0         
                                                                 
 dense_4422 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3515 (Dropout)      (None, 320)               0         
                                                                 
 dense_4423 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 957274 (3.65 MB)
Trainable params: 956250 (3.65 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 908:
  Value: 0.8628
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.006434945946893654

Model: "sequential_908"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_908 (Flatten)       (None, 784)               0         
                                                                 
 dense_4424 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3516 (Dropout)      (None, 512)               0         
                                                                 
 dense_4425 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3517 (Dropout)      (None, 384)               0         
                                                                 
 dense_4426 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_1034 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3518 (Dropout)      (None, 480)               0         
                                                                 
 dense_4427 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3519 (Dropout)      (None, 288)               0         
                                                                 
 dense_4428 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 931674 (3.55 MB)
Trainable params: 930714 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 909:
  Value: 0.0387
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0010212346424222842

Model: "sequential_909"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_909 (Flatten)       (None, 784)               0         
                                                                 
 dense_4429 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3520 (Dropout)      (None, 480)               0         
                                                                 
 dense_4430 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3521 (Dropout)      (None, 416)               0         
                                                                 
 dense_4431 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1035 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3522 (Dropout)      (None, 512)               0         
                                                                 
 dense_4432 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3523 (Dropout)      (None, 256)               0         
                                                                 
 dense_4433 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 930458 (3.55 MB)
Trainable params: 929434 (3.55 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 910:
  Value: 0.2433
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0014195457546244052

Model: "sequential_910"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_910 (Flatten)       (None, 784)               0         
                                                                 
 dense_4434 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3524 (Dropout)      (None, 512)               0         
                                                                 
 dense_4435 (Dense)          (None, 448)               229824    
                                                                 
 batch_normalization_1036 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3525 (Dropout)      (None, 448)               0         
                                                                 
 dense_4436 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_1037 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3526 (Dropout)      (None, 448)               0         
                                                                 
 dense_4437 (Dense)          (None, 288)               129312    
                                                                 
 dropout_3527 (Dropout)      (None, 288)               0         
                                                                 
 dense_4438 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 973306 (3.71 MB)
Trainable params: 971514 (3.71 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 911:
  Value: 0.7630
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 256
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0004977655821242959

Model: "sequential_911"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_911 (Flatten)       (None, 784)               0         
                                                                 
 dense_4439 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3528 (Dropout)      (None, 480)               0         
                                                                 
 dense_4440 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3529 (Dropout)      (None, 416)               0         
                                                                 
 dense_4441 (Dense)          (None, 256)               106752    
                                                                 
 batch_normalization_1038 (  (None, 256)               1024      
 BatchNormalization)                                             
                                                                 
 dropout_3530 (Dropout)      (None, 256)               0         
                                                                 
 dense_4442 (Dense)          (None, 288)               74016     
                                                                 
 dropout_3531 (Dropout)      (None, 288)               0         
                                                                 
 dense_4443 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 766202 (2.92 MB)
Trainable params: 765690 (2.92 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________



Trial 912:
  Value: 0.8453
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012118993697039357

Model: "sequential_912"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_912 (Flatten)       (None, 784)               0         
                                                                 
 dense_4444 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3532 (Dropout)      (None, 512)               0         
                                                                 
 dense_4445 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3533 (Dropout)      (None, 448)               0         
                                                                 
 dense_4446 (Dense)          (None, 512)               229888    
                                                                 
 dropout_3534 (Dropout)      (None, 512)               0         
                                                                 
 dense_4447 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3535 (Dropout)      (None, 320)               0         
                                                                 
 dense_4448 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1034138 (3.94 MB)
Trainable params: 1034138 (3.94 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 913:
  Value: 0.9215
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010833722258973858

Model: "sequential_913"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_913 (Flatten)       (None, 784)               0         
                                                                 
 dense_4449 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3536 (Dropout)      (None, 480)               0         
                                                                 
 dense_4450 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3537 (Dropout)      (None, 416)               0         
                                                                 
 dense_4451 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_1039 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3538 (Dropout)      (None, 480)               0         
                                                                 
 dense_4452 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3539 (Dropout)      (None, 288)               0         
                                                                 
 dense_4453 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 925018 (3.53 MB)
Trainable params: 924058 (3.53 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 914:
  Value: 0.8609
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 160
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010787455149047775

Model: "sequential_914"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_914 (Flatten)       (None, 784)               0         
                                                                 
 dense_4454 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3540 (Dropout)      (None, 512)               0         
                                                                 
 dense_4455 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3541 (Dropout)      (None, 480)               0         
                                                                 
 dense_4456 (Dense)          (None, 160)               76960     
                                                                 
 batch_normalization_1040 (  (None, 160)               640       
 BatchNormalization)                                             
                                                                 
 dropout_3542 (Dropout)      (None, 160)               0         
                                                                 
 dense_4457 (Dense)          (None, 256)               41216     
                                                                 
 dropout_3543 (Dropout)      (None, 256)               0         
                                                                 
 dense_4458 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 773658 (2.95 MB)
Trainable params: 773338 (2.95 MB)
Non-trainable params: 320 (1.25 KB)
_________________________________________________________________



Trial 915:
  Value: 0.8621
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009778876084066694

Model: "sequential_915"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_915 (Flatten)       (None, 784)               0         
                                                                 
 dense_4459 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3544 (Dropout)      (None, 480)               0         
                                                                 
 dense_4460 (Dense)          (None, 352)               169312    
                                                                 
 dropout_3545 (Dropout)      (None, 352)               0         
                                                                 
 dense_4461 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_1041 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3546 (Dropout)      (None, 512)               0         
                                                                 
 dense_4462 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3547 (Dropout)      (None, 352)               0         
                                                                 
 dense_4463 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 918650 (3.50 MB)
Trainable params: 917626 (3.50 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 916:
  Value: 0.8849
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001093219436727376

Model: "sequential_916"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_916 (Flatten)       (None, 784)               0         
                                                                 
 dense_4464 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3548 (Dropout)      (None, 512)               0         
                                                                 
 dense_4465 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3549 (Dropout)      (None, 416)               0         
                                                                 
 dense_4466 (Dense)          (None, 480)               200160    
                                                                 
 batch_normalization_1042 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3550 (Dropout)      (None, 480)               0         
                                                                 
 dense_4467 (Dense)          (None, 224)               107744    
                                                                 
 dropout_3551 (Dropout)      (None, 224)               0         
                                                                 
 dense_4468 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 931002 (3.55 MB)
Trainable params: 930042 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 917:
  Value: 0.8630
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008968401998263314

Model: "sequential_917"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_917 (Flatten)       (None, 784)               0         
                                                                 
 dense_4469 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3552 (Dropout)      (None, 512)               0         
                                                                 
 dense_4470 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3553 (Dropout)      (None, 448)               0         
                                                                 
 dense_4471 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_1043 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3554 (Dropout)      (None, 512)               0         
                                                                 
 dense_4472 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3555 (Dropout)      (None, 288)               0         
                                                                 
 dense_4473 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 1018938 (3.89 MB)
Trainable params: 1017914 (3.88 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 918:
  Value: 0.8538
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 480
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006932340477858019

Model: "sequential_918"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_918 (Flatten)       (None, 784)               0         
                                                                 
 dense_4474 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3556 (Dropout)      (None, 480)               0         
                                                                 
 dense_4475 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3557 (Dropout)      (None, 384)               0         
                                                                 
 dense_4476 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_1044 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3558 (Dropout)      (None, 480)               0         
                                                                 
 dense_4477 (Dense)          (None, 320)               153920    
                                                                 
 dropout_3559 (Dropout)      (None, 320)               0         
                                                                 
 dense_4478 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 910490 (3.47 MB)
Trainable params: 909530 (3.47 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 919:
  Value: 0.8576
  num_layers: 4
  units_0: 448
  units_1: 480
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00023949529749695692

Model: "sequential_919"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_919 (Flatten)       (None, 784)               0         
                                                                 
 dense_4479 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3560 (Dropout)      (None, 448)               0         
                                                                 
 dense_4480 (Dense)          (None, 480)               215520    
                                                                 
 dropout_3561 (Dropout)      (None, 480)               0         
                                                                 
 dense_4481 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_1045 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3562 (Dropout)      (None, 512)               0         
                                                                 
 dense_4482 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3563 (Dropout)      (None, 288)               0         
                                                                 
 dense_4483 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 970778 (3.70 MB)
Trainable params: 969754 (3.70 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 920:
  Value: 0.3163
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.0009990174296115124

Model: "sequential_920"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_920 (Flatten)       (None, 784)               0         
                                                                 
 dense_4484 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_1046 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3564 (Dropout)      (None, 512)               0         
                                                                 
 dense_4485 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3565 (Dropout)      (None, 448)               0         
                                                                 
 dense_4486 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_1047 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3566 (Dropout)      (None, 512)               0         
                                                                 
 dense_4487 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3567 (Dropout)      (None, 256)               0         
                                                                 
 dense_4488 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 1003738 (3.83 MB)
Trainable params: 1001690 (3.82 MB)
Non-trainable params: 2048 (8.00 KB)
_________________________________________________________________



Trial 921:
  Value: 0.8327
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0011347298071109865

Model: "sequential_921"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_921 (Flatten)       (None, 784)               0         
                                                                 
 dense_4489 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3568 (Dropout)      (None, 480)               0         
                                                                 
 dense_4490 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3569 (Dropout)      (None, 416)               0         
                                                                 
 dense_4491 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1048 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3570 (Dropout)      (None, 448)               0         
                                                                 
 dense_4492 (Dense)          (None, 288)               129312    
                                                                 
 batch_normalization_1049 (  (None, 288)               1152      
 BatchNormalization)                                             
                                                                 
 dropout_3571 (Dropout)      (None, 288)               0         
                                                                 
 dense_4493 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 903482 (3.45 MB)
Trainable params: 902010 (3.44 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 922:
  Value: 0.9159
  num_layers: 4
  units_0: 512
  units_1: 448
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008236465489399626

Model: "sequential_922"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_922 (Flatten)       (None, 784)               0         
                                                                 
 dense_4494 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3572 (Dropout)      (None, 512)               0         
                                                                 
 dense_4495 (Dense)          (None, 448)               229824    
                                                                 
 dropout_3573 (Dropout)      (None, 448)               0         
                                                                 
 dense_4496 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_1050 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3574 (Dropout)      (None, 480)               0         
                                                                 
 dense_4497 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3575 (Dropout)      (None, 288)               0         
                                                                 
 dense_4498 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 995226 (3.80 MB)
Trainable params: 994266 (3.79 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 923:
  Value: 0.9118
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0012102771603498812

Model: "sequential_923"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_923 (Flatten)       (None, 784)               0         
                                                                 
 dense_4499 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3576 (Dropout)      (None, 480)               0         
                                                                 
 dense_4500 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3577 (Dropout)      (None, 416)               0         
                                                                 
 dense_4501 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1051 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3578 (Dropout)      (None, 512)               0         
                                                                 
 dense_4502 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3579 (Dropout)      (None, 320)               0         
                                                                 
 dense_4503 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 964954 (3.68 MB)
Trainable params: 963930 (3.68 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 924:
  Value: 0.9188
  num_layers: 4
  units_0: 512
  units_1: 224
  units_2: 416
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.1
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010365607045794158

Model: "sequential_924"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_924 (Flatten)       (None, 784)               0         
                                                                 
 dense_4504 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3580 (Dropout)      (None, 512)               0         
                                                                 
 dense_4505 (Dense)          (None, 224)               114912    
                                                                 
 dropout_3581 (Dropout)      (None, 224)               0         
                                                                 
 dense_4506 (Dense)          (None, 416)               93600     
                                                                 
 batch_normalization_1052 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3582 (Dropout)      (None, 416)               0         
                                                                 
 dense_4507 (Dense)          (None, 256)               106752    
                                                                 
 dropout_3583 (Dropout)      (None, 256)               0         
                                                                 
 dense_4508 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 725530 (2.77 MB)
Trainable params: 724698 (2.76 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 925:
  Value: 0.8711
  num_layers: 4
  units_0: 480
  units_1: 480
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0009279438612604121

Model: "sequential_925"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_925 (Flatten)       (None, 784)               0         
                                                                 
 dense_4509 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3584 (Dropout)      (None, 480)               0         
                                                                 
 dense_4510 (Dense)          (None, 480)               230880    
                                                                 
 dropout_3585 (Dropout)      (None, 480)               0         
                                                                 
 dense_4511 (Dense)          (None, 512)               246272    
                                                                 
 batch_normalization_1053 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3586 (Dropout)      (None, 512)               0         
                                                                 
 dense_4512 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3587 (Dropout)      (None, 256)               0         
                                                                 
 dense_4513 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 994010 (3.79 MB)
Trainable params: 992986 (3.79 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 926:
  Value: 0.8149
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007374839559787457

Model: "sequential_926"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_926 (Flatten)       (None, 784)               0         
                                                                 
 dense_4514 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3588 (Dropout)      (None, 512)               0         
                                                                 
 dense_4515 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3589 (Dropout)      (None, 384)               0         
                                                                 
 dense_4516 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_1054 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3590 (Dropout)      (None, 480)               0         
                                                                 
 dense_4517 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3591 (Dropout)      (None, 288)               0         
                                                                 
 dense_4518 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 931674 (3.55 MB)
Trainable params: 930714 (3.55 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 927:
  Value: 0.8617
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 448
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.008585473834832363

Model: "sequential_927"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_927 (Flatten)       (None, 784)               0         
                                                                 
 dense_4519 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3592 (Dropout)      (None, 448)               0         
                                                                 
 dense_4520 (Dense)          (None, 448)               201152    
                                                                 
 dropout_3593 (Dropout)      (None, 448)               0         
                                                                 
 dense_4521 (Dense)          (None, 448)               201152    
                                                                 
 batch_normalization_1055 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3594 (Dropout)      (None, 448)               0         
                                                                 
 dense_4522 (Dense)          (None, 320)               143680    
                                                                 
 dropout_3595 (Dropout)      (None, 320)               0         
                                                                 
 dense_4523 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 907802 (3.46 MB)
Trainable params: 906906 (3.46 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 928:
  Value: 0.6232
  num_layers: 4
  units_0: 64
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.0012891970941834344

Model: "sequential_928"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_928 (Flatten)       (None, 784)               0         
                                                                 
 dense_4524 (Dense)          (None, 64)                50240     
                                                                 
 dropout_3596 (Dropout)      (None, 64)                0         
                                                                 
 dense_4525 (Dense)          (None, 416)               27040     
                                                                 
 dropout_3597 (Dropout)      (None, 416)               0         
                                                                 
 dense_4526 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1056 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3598 (Dropout)      (None, 512)               0         
                                                                 
 dense_4527 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3599 (Dropout)      (None, 288)               0         
                                                                 
 dense_4528 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 448090 (1.71 MB)
Trainable params: 447066 (1.71 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 929:
  Value: 0.9193
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 480
  units_3: 224
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00025837443838624946

Model: "sequential_929"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_929 (Flatten)       (None, 784)               0         
                                                                 
 dense_4529 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3600 (Dropout)      (None, 480)               0         
                                                                 
 dense_4530 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3601 (Dropout)      (None, 448)               0         
                                                                 
 dense_4531 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_1057 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3602 (Dropout)      (None, 480)               0         
                                                                 
 dense_4532 (Dense)          (None, 224)               107744    
                                                                 
 dropout_3603 (Dropout)      (None, 224)               0         
                                                                 
 dense_4533 (Dense)          (None, 26)                5850      
                                                                 
=================================================================
Total params: 923322 (3.52 MB)
Trainable params: 922362 (3.52 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 930:
  Value: 0.6516
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.4
  dropout_1: 0.4
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00043857290838963204

Model: "sequential_930"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_930 (Flatten)       (None, 784)               0         
                                                                 
 dense_4534 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3604 (Dropout)      (None, 512)               0         
                                                                 
 dense_4535 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_1058 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3605 (Dropout)      (None, 416)               0         
                                                                 
 dense_4536 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1059 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3606 (Dropout)      (None, 512)               0         
                                                                 
 dense_4537 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3607 (Dropout)      (None, 320)               0         
                                                                 
 dense_4538 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1005050 (3.83 MB)
Trainable params: 1003194 (3.83 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 931:
  Value: 0.8209
  num_layers: 4
  units_0: 448
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0006517246347034988

Model: "sequential_931"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_931 (Flatten)       (None, 784)               0         
                                                                 
 dense_4539 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3608 (Dropout)      (None, 448)               0         
                                                                 
 dense_4540 (Dense)          (None, 448)               201152    
                                                                 
 dropout_3609 (Dropout)      (None, 448)               0         
                                                                 
 dense_4541 (Dense)          (None, 512)               229888    
                                                                 
 dropout_3610 (Dropout)      (None, 512)               0         
                                                                 
 dense_4542 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3611 (Dropout)      (None, 288)               0         
                                                                 
 dense_4543 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 937978 (3.58 MB)
Trainable params: 937978 (3.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 932:
  Value: 0.8742
  num_layers: 4
  units_0: 512
  units_1: 352
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0011137952757033834

Model: "sequential_932"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_932 (Flatten)       (None, 784)               0         
                                                                 
 dense_4544 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3612 (Dropout)      (None, 512)               0         
                                                                 
 dense_4545 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3613 (Dropout)      (None, 352)               0         
                                                                 
 dense_4546 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_1060 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3614 (Dropout)      (None, 512)               0         
                                                                 
 dense_4547 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3615 (Dropout)      (None, 256)               0         
                                                                 
 dense_4548 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 903290 (3.45 MB)
Trainable params: 902266 (3.44 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 933:
  Value: 0.0381
  num_layers: 3
  units_0: 480
  units_1: 480
  units_2: 480
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adagrad
  learning_rate: 0.0020988121829183873

Model: "sequential_933"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_933 (Flatten)       (None, 784)               0         
                                                                 
 dense_4549 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3616 (Dropout)      (None, 480)               0         
                                                                 
 dense_4550 (Dense)          (None, 480)               230880    
                                                                 
 dropout_3617 (Dropout)      (None, 480)               0         
                                                                 
 dense_4551 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_1061 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3618 (Dropout)      (None, 480)               0         
                                                                 
 dense_4552 (Dense)          (None, 26)                12506     
                                                                 
=================================================================
Total params: 852986 (3.25 MB)
Trainable params: 852026 (3.25 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 934:
  Value: 0.8747
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0017174373219830024

Model: "sequential_934"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_934 (Flatten)       (None, 784)               0         
                                                                 
 dense_4553 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3619 (Dropout)      (None, 512)               0         
                                                                 
 dense_4554 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3620 (Dropout)      (None, 416)               0         
                                                                 
 dense_4555 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1062 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3621 (Dropout)      (None, 512)               0         
                                                                 
 dense_4556 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3622 (Dropout)      (None, 288)               0         
                                                                 
 dense_4557 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 935:
  Value: 0.8018
  num_layers: 4
  units_0: 352
  units_1: 448
  units_2: 480
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.5
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0011748536055365244

Model: "sequential_935"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_935 (Flatten)       (None, 784)               0         
                                                                 
 dense_4558 (Dense)          (None, 352)               276320    
                                                                 
 dropout_3623 (Dropout)      (None, 352)               0         
                                                                 
 dense_4559 (Dense)          (None, 448)               158144    
                                                                 
 dropout_3624 (Dropout)      (None, 448)               0         
                                                                 
 dense_4560 (Dense)          (None, 480)               215520    
                                                                 
 batch_normalization_1063 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3625 (Dropout)      (None, 480)               0         
                                                                 
 dense_4561 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3626 (Dropout)      (None, 256)               0         
                                                                 
 dense_4562 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 781722 (2.98 MB)
Trainable params: 780762 (2.98 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 936:
  Value: 0.8570
  num_layers: 4
  units_0: 480
  units_1: 288
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005240842469201222

Model: "sequential_936"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_936 (Flatten)       (None, 784)               0         
                                                                 
 dense_4563 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3627 (Dropout)      (None, 480)               0         
                                                                 
 dense_4564 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3628 (Dropout)      (None, 288)               0         
                                                                 
 dense_4565 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_1064 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3629 (Dropout)      (None, 512)               0         
                                                                 
 dense_4566 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3630 (Dropout)      (None, 320)               0         
                                                                 
 dense_4567 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 837850 (3.20 MB)
Trainable params: 836826 (3.19 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 937:
  Value: 0.8754
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0019456797663637366

Model: "sequential_937"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_937 (Flatten)       (None, 784)               0         
                                                                 
 dense_4568 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3631 (Dropout)      (None, 512)               0         
                                                                 
 dense_4569 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3632 (Dropout)      (None, 416)               0         
                                                                 
 dense_4570 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1065 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3633 (Dropout)      (None, 512)               0         
                                                                 
 dense_4571 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3634 (Dropout)      (None, 288)               0         
                                                                 
 dense_4572 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 938:
  Value: 0.0393
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0009870736091800864

Model: "sequential_938"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_938 (Flatten)       (None, 784)               0         
                                                                 
 dense_4573 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3635 (Dropout)      (None, 480)               0         
                                                                 
 dense_4574 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3636 (Dropout)      (None, 384)               0         
                                                                 
 dense_4575 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_1066 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3637 (Dropout)      (None, 480)               0         
                                                                 
 dense_4576 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3638 (Dropout)      (None, 288)               0         
                                                                 
 dense_4577 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 894266 (3.41 MB)
Trainable params: 893306 (3.41 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 939:
  Value: 0.8545
  num_layers: 4
  units_0: 224
  units_1: 448
  units_2: 512
  units_3: 256
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: relu
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.001267589418022407

Model: "sequential_939"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_939 (Flatten)       (None, 784)               0         
                                                                 
 dense_4578 (Dense)          (None, 224)               175840    
                                                                 
 dropout_3639 (Dropout)      (None, 224)               0         
                                                                 
 dense_4579 (Dense)          (None, 448)               100800    
                                                                 
 dropout_3640 (Dropout)      (None, 448)               0         
                                                                 
 dense_4580 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_1067 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3641 (Dropout)      (None, 512)               0         
                                                                 
 dense_4581 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3642 (Dropout)      (None, 256)               0         
                                                                 
 dense_4582 (Dense)          (None, 26)                6682      
                                                                 
=================================================================
Total params: 646586 (2.47 MB)
Trainable params: 645562 (2.46 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 940:
  Value: 0.8348
  num_layers: 4
  units_0: 512
  units_1: 480
  units_2: 480
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.2
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0005866649622120917

Model: "sequential_940"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_940 (Flatten)       (None, 784)               0         
                                                                 
 dense_4583 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_1068 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3643 (Dropout)      (None, 512)               0         
                                                                 
 dense_4584 (Dense)          (None, 480)               246240    
                                                                 
 dropout_3644 (Dropout)      (None, 480)               0         
                                                                 
 dense_4585 (Dense)          (None, 480)               230880    
                                                                 
 batch_normalization_1069 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3645 (Dropout)      (None, 480)               0         
                                                                 
 dense_4586 (Dense)          (None, 352)               169312    
                                                                 
 dropout_3646 (Dropout)      (None, 352)               0         
                                                                 
 dense_4587 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1061498 (4.05 MB)
Trainable params: 1059514 (4.04 MB)
Non-trainable params: 1984 (7.75 KB)
_________________________________________________________________



Trial 941:
  Value: 0.8637
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0015256668216903563

Model: "sequential_941"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_941 (Flatten)       (None, 784)               0         
                                                                 
 dense_4588 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3647 (Dropout)      (None, 512)               0         
                                                                 
 dense_4589 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3648 (Dropout)      (None, 416)               0         
                                                                 
 dense_4590 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1070 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3649 (Dropout)      (None, 448)               0         
                                                                 
 dense_4591 (Dense)          (None, 288)               129312    
                                                                 
 batch_normalization_1071 (  (None, 288)               1152      
 BatchNormalization)                                             
                                                                 
 dropout_3650 (Dropout)      (None, 288)               0         
                                                                 
 dense_4592 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 941914 (3.59 MB)
Trainable params: 940442 (3.59 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 942:
  Value: 0.8629
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0007967766199731416

Model: "sequential_942"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_942 (Flatten)       (None, 784)               0         
                                                                 
 dense_4593 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3651 (Dropout)      (None, 480)               0         
                                                                 
 dense_4594 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3652 (Dropout)      (None, 384)               0         
                                                                 
 dense_4595 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1072 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3653 (Dropout)      (None, 512)               0         
                                                                 
 dense_4596 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3654 (Dropout)      (None, 320)               0         
                                                                 
 dense_4597 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 933178 (3.56 MB)
Trainable params: 932154 (3.56 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 943:
  Value: 0.9049
  num_layers: 4
  units_0: 480
  units_1: 448
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: tanh
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004785079789475231

Model: "sequential_943"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_943 (Flatten)       (None, 784)               0         
                                                                 
 dense_4598 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3655 (Dropout)      (None, 480)               0         
                                                                 
 dense_4599 (Dense)          (None, 448)               215488    
                                                                 
 dropout_3656 (Dropout)      (None, 448)               0         
                                                                 
 dense_4600 (Dense)          (None, 512)               229888    
                                                                 
 batch_normalization_1073 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3657 (Dropout)      (None, 512)               0         
                                                                 
 dense_4601 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3658 (Dropout)      (None, 288)               0         
                                                                 
 dense_4602 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 979482 (3.74 MB)
Trainable params: 978458 (3.73 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 944:
  Value: 0.9235
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004949684095721288

Model: "sequential_944"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_944 (Flatten)       (None, 784)               0         
                                                                 
 dense_4603 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3659 (Dropout)      (None, 512)               0         
                                                                 
 dense_4604 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3660 (Dropout)      (None, 416)               0         
                                                                 
 dense_4605 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1074 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3661 (Dropout)      (None, 416)               0         
                                                                 
 dense_4606 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3662 (Dropout)      (None, 320)               0         
                                                                 
 dense_4607 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 932250 (3.56 MB)
Trainable params: 931418 (3.55 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 945:
  Value: 0.8620
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.003737416098635886

Model: "sequential_945"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_945 (Flatten)       (None, 784)               0         
                                                                 
 dense_4608 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3663 (Dropout)      (None, 512)               0         
                                                                 
 dense_4609 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3664 (Dropout)      (None, 416)               0         
                                                                 
 dense_4610 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1075 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3665 (Dropout)      (None, 448)               0         
                                                                 
 dense_4611 (Dense)          (None, 352)               158048    
                                                                 
 dropout_3666 (Dropout)      (None, 352)               0         
                                                                 
 dense_4612 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 971162 (3.70 MB)
Trainable params: 970266 (3.70 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 946:
  Value: 0.9218
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004113776871686126

Model: "sequential_946"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_946 (Flatten)       (None, 784)               0         
                                                                 
 dense_4613 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3667 (Dropout)      (None, 512)               0         
                                                                 
 dense_4614 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3668 (Dropout)      (None, 416)               0         
                                                                 
 dense_4615 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1076 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3669 (Dropout)      (None, 416)               0         
                                                                 
 dense_4616 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3670 (Dropout)      (None, 352)               0         
                                                                 
 dense_4617 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 946426 (3.61 MB)
Trainable params: 945594 (3.61 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 947:
  Value: 0.9178
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005549950390373115

Model: "sequential_947"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_947 (Flatten)       (None, 784)               0         
                                                                 
 dense_4618 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3671 (Dropout)      (None, 512)               0         
                                                                 
 dense_4619 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3672 (Dropout)      (None, 384)               0         
                                                                 
 dense_4620 (Dense)          (None, 416)               160160    
                                                                 
 batch_normalization_1077 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3673 (Dropout)      (None, 416)               0         
                                                                 
 dense_4621 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3674 (Dropout)      (None, 352)               0         
                                                                 
 dense_4622 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 916698 (3.50 MB)
Trainable params: 915866 (3.49 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 948:
  Value: 0.0438
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.004569947454952

Model: "sequential_948"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_948 (Flatten)       (None, 784)               0         
                                                                 
 dense_4623 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3675 (Dropout)      (None, 512)               0         
                                                                 
 dense_4624 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3676 (Dropout)      (None, 416)               0         
                                                                 
 dense_4625 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1078 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3677 (Dropout)      (None, 416)               0         
                                                                 
 dense_4626 (Dense)          (None, 384)               160128    
                                                                 
 dropout_3678 (Dropout)      (None, 384)               0         
                                                                 
 dense_4627 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 960602 (3.66 MB)
Trainable params: 959770 (3.66 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 949:
  Value: 0.5506
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.30000000000000004
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005154259142580628

Model: "sequential_949"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_949 (Flatten)       (None, 784)               0         
                                                                 
 dense_4628 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3679 (Dropout)      (None, 512)               0         
                                                                 
 dense_4629 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_1079 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3680 (Dropout)      (None, 416)               0         
                                                                 
 dense_4630 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1080 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3681 (Dropout)      (None, 416)               0         
                                                                 
 dense_4631 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3682 (Dropout)      (None, 352)               0         
                                                                 
 dense_4632 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 948090 (3.62 MB)
Trainable params: 946426 (3.61 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 950:
  Value: 0.8536
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 416
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005204932276010968

Model: "sequential_950"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_950 (Flatten)       (None, 784)               0         
                                                                 
 dense_4633 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3683 (Dropout)      (None, 512)               0         
                                                                 
 dense_4634 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3684 (Dropout)      (None, 416)               0         
                                                                 
 dense_4635 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1081 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3685 (Dropout)      (None, 416)               0         
                                                                 
 dense_4636 (Dense)          (None, 416)               173472    
                                                                 
 dropout_3686 (Dropout)      (None, 416)               0         
                                                                 
 dense_4637 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 974778 (3.72 MB)
Trainable params: 973946 (3.72 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 951:
  Value: 0.8370
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0001250627220342388

Model: "sequential_951"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_951 (Flatten)       (None, 784)               0         
                                                                 
 dense_4638 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3687 (Dropout)      (None, 512)               0         
                                                                 
 dense_4639 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3688 (Dropout)      (None, 384)               0         
                                                                 
 dense_4640 (Dense)          (None, 416)               160160    
                                                                 
 dropout_3689 (Dropout)      (None, 416)               0         
                                                                 
 dense_4641 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3690 (Dropout)      (None, 320)               0         
                                                                 
 dense_4642 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 900858 (3.44 MB)
Trainable params: 900858 (3.44 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 952:
  Value: 0.8851
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004749437867947158

Model: "sequential_952"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_952 (Flatten)       (None, 784)               0         
                                                                 
 dense_4643 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3691 (Dropout)      (None, 512)               0         
                                                                 
 dense_4644 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3692 (Dropout)      (None, 416)               0         
                                                                 
 dense_4645 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1082 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3693 (Dropout)      (None, 416)               0         
                                                                 
 dense_4646 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3694 (Dropout)      (None, 352)               0         
                                                                 
 dense_4647 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 946426 (3.61 MB)
Trainable params: 945594 (3.61 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 953:
  Value: 0.7737
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.004637212123744483

Model: "sequential_953"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_953 (Flatten)       (None, 784)               0         
                                                                 
 dense_4648 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3695 (Dropout)      (None, 512)               0         
                                                                 
 dense_4649 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3696 (Dropout)      (None, 384)               0         
                                                                 
 dense_4650 (Dense)          (None, 416)               160160    
                                                                 
 batch_normalization_1083 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3697 (Dropout)      (None, 416)               0         
                                                                 
 dense_4651 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3698 (Dropout)      (None, 352)               0         
                                                                 
 dense_4652 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 916698 (3.50 MB)
Trainable params: 915866 (3.49 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 954:
  Value: 0.8630
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.008762257776193123

Model: "sequential_954"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_954 (Flatten)       (None, 784)               0         
                                                                 
 dense_4653 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3699 (Dropout)      (None, 512)               0         
                                                                 
 dense_4654 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3700 (Dropout)      (None, 416)               0         
                                                                 
 dense_4655 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1084 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3701 (Dropout)      (None, 448)               0         
                                                                 
 dense_4656 (Dense)          (None, 384)               172416    
                                                                 
 dropout_3702 (Dropout)      (None, 384)               0         
                                                                 
 dense_4657 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 986362 (3.76 MB)
Trainable params: 985466 (3.76 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 955:
  Value: 0.7794
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 352
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005060625493296535

Model: "sequential_955"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_955 (Flatten)       (None, 784)               0         
                                                                 
 dense_4658 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3703 (Dropout)      (None, 512)               0         
                                                                 
 dense_4659 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3704 (Dropout)      (None, 416)               0         
                                                                 
 dense_4660 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1085 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3705 (Dropout)      (None, 416)               0         
                                                                 
 dense_4661 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3706 (Dropout)      (None, 352)               0         
                                                                 
 dense_4662 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 946426 (3.61 MB)
Trainable params: 945594 (3.61 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 956:
  Value: 0.8269
  num_layers: 1
  units_0: 512
  activation_0: relu
  dropout_0: 0.30000000000000004
  batch_norm_0: False
  optimizer: adam
  learning_rate: 0.005614836656377883

Model: "sequential_956"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_956 (Flatten)       (None, 784)               0         
                                                                 
 dense_4663 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3707 (Dropout)      (None, 512)               0         
                                                                 
 dense_4664 (Dense)          (None, 26)                13338     
                                                                 
=================================================================
Total params: 415258 (1.58 MB)
Trainable params: 415258 (1.58 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 957:
  Value: 0.8638
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004439180245975774

Model: "sequential_957"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_957 (Flatten)       (None, 784)               0         
                                                                 
 dense_4665 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3708 (Dropout)      (None, 512)               0         
                                                                 
 dense_4666 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3709 (Dropout)      (None, 416)               0         
                                                                 
 dense_4667 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1086 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3710 (Dropout)      (None, 416)               0         
                                                                 
 dense_4668 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3711 (Dropout)      (None, 352)               0         
                                                                 
 dense_4669 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 946426 (3.61 MB)
Trainable params: 945594 (3.61 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 958:
  Value: 0.8392
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.006017371055826544

Model: "sequential_958"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_958 (Flatten)       (None, 784)               0         
                                                                 
 dense_4670 (Dense)          (None, 512)               401920    
                                                                 
 batch_normalization_1087 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3712 (Dropout)      (None, 512)               0         
                                                                 
 dense_4671 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3713 (Dropout)      (None, 416)               0         
                                                                 
 dense_4672 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1088 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3714 (Dropout)      (None, 416)               0         
                                                                 
 dense_4673 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3715 (Dropout)      (None, 320)               0         
                                                                 
 dense_4674 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 934298 (3.56 MB)
Trainable params: 932442 (3.56 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 959:
  Value: 0.8632
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 416
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00457847549032997

Model: "sequential_959"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_959 (Flatten)       (None, 784)               0         
                                                                 
 dense_4675 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3716 (Dropout)      (None, 512)               0         
                                                                 
 dense_4676 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3717 (Dropout)      (None, 384)               0         
                                                                 
 dense_4677 (Dense)          (None, 416)               160160    
                                                                 
 batch_normalization_1089 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3718 (Dropout)      (None, 416)               0         
                                                                 
 dense_4678 (Dense)          (None, 352)               146784    
                                                                 
 dropout_3719 (Dropout)      (None, 352)               0         
                                                                 
 dense_4679 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 916698 (3.50 MB)
Trainable params: 915866 (3.49 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 960:
  Value: 0.0404
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.0
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.0033732220862446533

Model: "sequential_960"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_960 (Flatten)       (None, 784)               0         
                                                                 
 dense_4680 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3720 (Dropout)      (None, 512)               0         
                                                                 
 dense_4681 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3721 (Dropout)      (None, 416)               0         
                                                                 
 dense_4682 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1090 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3722 (Dropout)      (None, 448)               0         
                                                                 
 dense_4683 (Dense)          (None, 352)               158048    
                                                                 
 dropout_3723 (Dropout)      (None, 352)               0         
                                                                 
 dense_4684 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 971162 (3.70 MB)
Trainable params: 970266 (3.70 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 961:
  Value: 0.9186
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005435703604784879

Model: "sequential_961"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_961 (Flatten)       (None, 784)               0         
                                                                 
 dense_4685 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3724 (Dropout)      (None, 512)               0         
                                                                 
 dense_4686 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3725 (Dropout)      (None, 416)               0         
                                                                 
 dense_4687 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1091 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3726 (Dropout)      (None, 448)               0         
                                                                 
 dense_4688 (Dense)          (None, 384)               172416    
                                                                 
 dropout_3727 (Dropout)      (None, 384)               0         
                                                                 
 dense_4689 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 986362 (3.76 MB)
Trainable params: 985466 (3.76 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 962:
  Value: 0.8596
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0077776548217445415

Model: "sequential_962"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_962 (Flatten)       (None, 784)               0         
                                                                 
 dense_4690 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3728 (Dropout)      (None, 512)               0         
                                                                 
 dense_4691 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3729 (Dropout)      (None, 416)               0         
                                                                 
 dense_4692 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1092 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3730 (Dropout)      (None, 416)               0         
                                                                 
 dense_4693 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3731 (Dropout)      (None, 320)               0         
                                                                 
 dense_4694 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 932250 (3.56 MB)
Trainable params: 931418 (3.55 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 963:
  Value: 0.8042
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.0054534684782815155

Model: "sequential_963"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_963 (Flatten)       (None, 784)               0         
                                                                 
 dense_4695 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3732 (Dropout)      (None, 512)               0         
                                                                 
 dense_4696 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3733 (Dropout)      (None, 384)               0         
                                                                 
 dense_4697 (Dense)          (None, 416)               160160    
                                                                 
 batch_normalization_1093 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3734 (Dropout)      (None, 416)               0         
                                                                 
 dense_4698 (Dense)          (None, 320)               133440    
                                                                 
 batch_normalization_1094 (  (None, 320)               1280      
 BatchNormalization)                                             
                                                                 
 dropout_3735 (Dropout)      (None, 320)               0         
                                                                 
 dense_4699 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 903802 (3.45 MB)
Trainable params: 902330 (3.44 MB)
Non-trainable params: 1472 (5.75 KB)
_________________________________________________________________



Trial 964:
  Value: 0.7362
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 448
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.004132188510082782

Model: "sequential_964"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_964 (Flatten)       (None, 784)               0         
                                                                 
 dense_4700 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3736 (Dropout)      (None, 512)               0         
                                                                 
 dense_4701 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3737 (Dropout)      (None, 416)               0         
                                                                 
 dense_4702 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1095 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3738 (Dropout)      (None, 448)               0         
                                                                 
 dense_4703 (Dense)          (None, 320)               143680    
                                                                 
 dropout_3739 (Dropout)      (None, 320)               0         
                                                                 
 dense_4704 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 955962 (3.65 MB)
Trainable params: 955066 (3.64 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 965:
  Value: 0.9085
  num_layers: 3
  units_0: 512
  units_1: 416
  units_2: 416
  activation_0: relu
  activation_1: relu
  activation_2: relu
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  optimizer: adam
  learning_rate: 0.005095999372474521

Model: "sequential_965"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_965 (Flatten)       (None, 784)               0         
                                                                 
 dense_4705 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3740 (Dropout)      (None, 512)               0         
                                                                 
 dense_4706 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3741 (Dropout)      (None, 416)               0         
                                                                 
 dense_4707 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1096 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3742 (Dropout)      (None, 416)               0         
                                                                 
 dense_4708 (Dense)          (None, 26)                10842     
                                                                 
=================================================================
Total params: 801306 (3.06 MB)
Trainable params: 800474 (3.05 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 966:
  Value: 0.9063
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.4
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0028996482963000126

Model: "sequential_966"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_966 (Flatten)       (None, 784)               0         
                                                                 
 dense_4709 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3743 (Dropout)      (None, 480)               0         
                                                                 
 dense_4710 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3744 (Dropout)      (None, 384)               0         
                                                                 
 dense_4711 (Dense)          (None, 416)               160160    
                                                                 
 batch_normalization_1097 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3745 (Dropout)      (None, 416)               0         
                                                                 
 dense_4712 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3746 (Dropout)      (None, 320)               0         
                                                                 
 dense_4713 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 865114 (3.30 MB)
Trainable params: 864282 (3.30 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 967:
  Value: 0.0364
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0037000513791072788

Model: "sequential_967"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_967 (Flatten)       (None, 784)               0         
                                                                 
 dense_4714 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3747 (Dropout)      (None, 512)               0         
                                                                 
 dense_4715 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3748 (Dropout)      (None, 416)               0         
                                                                 
 dense_4716 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1098 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3749 (Dropout)      (None, 416)               0         
                                                                 
 dense_4717 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3750 (Dropout)      (None, 320)               0         
                                                                 
 dense_4718 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 932250 (3.56 MB)
Trainable params: 931418 (3.55 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 968:
  Value: 0.9196
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.006035888350807416

Model: "sequential_968"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_968 (Flatten)       (None, 784)               0         
                                                                 
 dense_4719 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3751 (Dropout)      (None, 512)               0         
                                                                 
 dense_4720 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3752 (Dropout)      (None, 384)               0         
                                                                 
 dense_4721 (Dense)          (None, 416)               160160    
                                                                 
 batch_normalization_1099 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3753 (Dropout)      (None, 416)               0         
                                                                 
 dense_4722 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3754 (Dropout)      (None, 320)               0         
                                                                 
 dense_4723 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 902522 (3.44 MB)
Trainable params: 901690 (3.44 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 969:
  Value: 0.8730
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008978703620351391

Model: "sequential_969"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_969 (Flatten)       (None, 784)               0         
                                                                 
 dense_4724 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3755 (Dropout)      (None, 480)               0         
                                                                 
 dense_4725 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3756 (Dropout)      (None, 416)               0         
                                                                 
 dense_4726 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1100 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3757 (Dropout)      (None, 448)               0         
                                                                 
 dense_4727 (Dense)          (None, 384)               172416    
                                                                 
 dropout_3758 (Dropout)      (None, 384)               0         
                                                                 
 dense_4728 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 947930 (3.62 MB)
Trainable params: 947034 (3.61 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 970:
  Value: 0.6622
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004026360938610555

Model: "sequential_970"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_970 (Flatten)       (None, 784)               0         
                                                                 
 dense_4729 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3759 (Dropout)      (None, 512)               0         
                                                                 
 dense_4730 (Dense)          (None, 416)               213408    
                                                                 
 batch_normalization_1101 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3760 (Dropout)      (None, 416)               0         
                                                                 
 dense_4731 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1102 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3761 (Dropout)      (None, 416)               0         
                                                                 
 dense_4732 (Dense)          (None, 384)               160128    
                                                                 
 dropout_3762 (Dropout)      (None, 384)               0         
                                                                 
 dense_4733 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 962266 (3.67 MB)
Trainable params: 960602 (3.66 MB)
Non-trainable params: 1664 (6.50 KB)
_________________________________________________________________



Trial 971:
  Value: 0.7991
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 320
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004349286389266493

Model: "sequential_971"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_971 (Flatten)       (None, 784)               0         
                                                                 
 dense_4734 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3763 (Dropout)      (None, 480)               0         
                                                                 
 dense_4735 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3764 (Dropout)      (None, 416)               0         
                                                                 
 dense_4736 (Dense)          (None, 448)               186816    
                                                                 
 dropout_3765 (Dropout)      (None, 448)               0         
                                                                 
 dense_4737 (Dense)          (None, 320)               143680    
                                                                 
 dropout_3766 (Dropout)      (None, 320)               0         
                                                                 
 dense_4738 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 915738 (3.49 MB)
Trainable params: 915738 (3.49 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 972:
  Value: 0.9200
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005003485554164742

Model: "sequential_972"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_972 (Flatten)       (None, 784)               0         
                                                                 
 dense_4739 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3767 (Dropout)      (None, 512)               0         
                                                                 
 dense_4740 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3768 (Dropout)      (None, 416)               0         
                                                                 
 dense_4741 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1103 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3769 (Dropout)      (None, 512)               0         
                                                                 
 dense_4742 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3770 (Dropout)      (None, 352)               0         
                                                                 
 dense_4743 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 1020634 (3.89 MB)
Trainable params: 1019610 (3.89 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 973:
  Value: 0.7772
  num_layers: 4
  units_0: 480
  units_1: 352
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004047791467762601

Model: "sequential_973"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_973 (Flatten)       (None, 784)               0         
                                                                 
 dense_4744 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3771 (Dropout)      (None, 480)               0         
                                                                 
 dense_4745 (Dense)          (None, 352)               169312    
                                                                 
 dropout_3772 (Dropout)      (None, 352)               0         
                                                                 
 dense_4746 (Dense)          (None, 512)               180736    
                                                                 
 batch_normalization_1104 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3773 (Dropout)      (None, 512)               0         
                                                                 
 dense_4747 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3774 (Dropout)      (None, 320)               0         
                                                                 
 dense_4748 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 901402 (3.44 MB)
Trainable params: 900378 (3.43 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 974:
  Value: 0.8124
  num_layers: 2
  units_0: 512
  units_1: 384
  activation_0: relu
  activation_1: sigmoid
  dropout_0: 0.1
  dropout_1: 0.30000000000000004
  batch_norm_0: False
  batch_norm_1: False
  optimizer: adam
  learning_rate: 0.006338119095699004

Model: "sequential_974"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_974 (Flatten)       (None, 784)               0         
                                                                 
 dense_4749 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3775 (Dropout)      (None, 512)               0         
                                                                 
 dense_4750 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3776 (Dropout)      (None, 384)               0         
                                                                 
 dense_4751 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 608922 (2.32 MB)
Trainable params: 608922 (2.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 975:
  Value: 0.8562
  num_layers: 4
  units_0: 448
  units_1: 416
  units_2: 384
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.30000000000000004
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.009327904843958257

Model: "sequential_975"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_975 (Flatten)       (None, 784)               0         
                                                                 
 dense_4752 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3777 (Dropout)      (None, 448)               0         
                                                                 
 dense_4753 (Dense)          (None, 416)               186784    
                                                                 
 dropout_3778 (Dropout)      (None, 416)               0         
                                                                 
 dense_4754 (Dense)          (None, 384)               160128    
                                                                 
 batch_normalization_1105 (  (None, 384)               1536      
 BatchNormalization)                                             
                                                                 
 dropout_3779 (Dropout)      (None, 384)               0         
                                                                 
 dense_4755 (Dense)          (None, 320)               123200    
                                                                 
 dropout_3780 (Dropout)      (None, 320)               0         
                                                                 
 dense_4756 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 831674 (3.17 MB)
Trainable params: 830906 (3.17 MB)
Non-trainable params: 768 (3.00 KB)
_________________________________________________________________



Trial 976:
  Value: 0.0699
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 416
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.5
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: sgd
  learning_rate: 0.003761172338200145

Model: "sequential_976"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_976 (Flatten)       (None, 784)               0         
                                                                 
 dense_4757 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3781 (Dropout)      (None, 512)               0         
                                                                 
 dense_4758 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3782 (Dropout)      (None, 416)               0         
                                                                 
 dense_4759 (Dense)          (None, 416)               173472    
                                                                 
 batch_normalization_1106 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3783 (Dropout)      (None, 416)               0         
                                                                 
 dense_4760 (Dense)          (None, 320)               133440    
                                                                 
 dropout_3784 (Dropout)      (None, 320)               0         
                                                                 
 dense_4761 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 932250 (3.56 MB)
Trainable params: 931418 (3.55 MB)
Non-trainable params: 832 (3.25 KB)
_________________________________________________________________



Trial 977:
  Value: 0.8432
  num_layers: 4
  units_0: 384
  units_1: 320
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0067253767752882025

Model: "sequential_977"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_977 (Flatten)       (None, 784)               0         
                                                                 
 dense_4762 (Dense)          (None, 384)               301440    
                                                                 
 batch_normalization_1107 (  (None, 384)               1536      
 BatchNormalization)                                             
                                                                 
 dropout_3785 (Dropout)      (None, 384)               0         
                                                                 
 dense_4763 (Dense)          (None, 320)               123200    
                                                                 
 dropout_3786 (Dropout)      (None, 320)               0         
                                                                 
 dense_4764 (Dense)          (None, 512)               164352    
                                                                 
 batch_normalization_1108 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3787 (Dropout)      (None, 512)               0         
                                                                 
 dense_4765 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3788 (Dropout)      (None, 320)               0         
                                                                 
 dense_4766 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 765082 (2.92 MB)
Trainable params: 763290 (2.91 MB)
Non-trainable params: 1792 (7.00 KB)
_________________________________________________________________



Trial 978:
  Value: 0.7759
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 448
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005684711423790815

Model: "sequential_978"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_978 (Flatten)       (None, 784)               0         
                                                                 
 dense_4767 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3789 (Dropout)      (None, 480)               0         
                                                                 
 dense_4768 (Dense)          (None, 416)               200096    
                                                                 
 dropout_3790 (Dropout)      (None, 416)               0         
                                                                 
 dense_4769 (Dense)          (None, 448)               186816    
                                                                 
 batch_normalization_1109 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3791 (Dropout)      (None, 448)               0         
                                                                 
 dense_4770 (Dense)          (None, 288)               129312    
                                                                 
 dropout_3792 (Dropout)      (None, 288)               0         
                                                                 
 dense_4771 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 902330 (3.44 MB)
Trainable params: 901434 (3.44 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________



Trial 979:
  Value: 0.8746
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 384
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0037912757983451424

Model: "sequential_979"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_979 (Flatten)       (None, 784)               0         
                                                                 
 dense_4772 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3793 (Dropout)      (None, 512)               0         
                                                                 
 dense_4773 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3794 (Dropout)      (None, 416)               0         
                                                                 
 dense_4774 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1110 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3795 (Dropout)      (None, 512)               0         
                                                                 
 dense_4775 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3796 (Dropout)      (None, 384)               0         
                                                                 
 dense_4776 (Dense)          (None, 26)                10010     
                                                                 
=================================================================
Total params: 1037882 (3.96 MB)
Trainable params: 1036858 (3.96 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 980:
  Value: 0.8634
  num_layers: 4
  units_0: 480
  units_1: 384
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.006046567730998655

Model: "sequential_980"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_980 (Flatten)       (None, 784)               0         
                                                                 
 dense_4777 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3797 (Dropout)      (None, 480)               0         
                                                                 
 dense_4778 (Dense)          (None, 384)               184704    
                                                                 
 dropout_3798 (Dropout)      (None, 384)               0         
                                                                 
 dense_4779 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1111 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3799 (Dropout)      (None, 512)               0         
                                                                 
 dense_4780 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3800 (Dropout)      (None, 352)               0         
                                                                 
 dense_4781 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 950426 (3.63 MB)
Trainable params: 949402 (3.62 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 981:
  Value: 0.7938
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.30000000000000004
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adamax
  learning_rate: 0.003485703740073901

Model: "sequential_981"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_981 (Flatten)       (None, 784)               0         
                                                                 
 dense_4782 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3801 (Dropout)      (None, 512)               0         
                                                                 
 dense_4783 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3802 (Dropout)      (None, 416)               0         
                                                                 
 dense_4784 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1112 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3803 (Dropout)      (None, 512)               0         
                                                                 
 dense_4785 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3804 (Dropout)      (None, 320)               0         
                                                                 
 dense_4786 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 1003386 (3.83 MB)
Trainable params: 1002362 (3.82 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 982:
  Value: 0.8056
  num_layers: 4
  units_0: 160
  units_1: 384
  units_2: 480
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.4
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0010525111437378254

Model: "sequential_982"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_982 (Flatten)       (None, 784)               0         
                                                                 
 dense_4787 (Dense)          (None, 160)               125600    
                                                                 
 dropout_3805 (Dropout)      (None, 160)               0         
                                                                 
 dense_4788 (Dense)          (None, 384)               61824     
                                                                 
 dropout_3806 (Dropout)      (None, 384)               0         
                                                                 
 dense_4789 (Dense)          (None, 480)               184800    
                                                                 
 batch_normalization_1113 (  (None, 480)               1920      
 BatchNormalization)                                             
                                                                 
 dropout_3807 (Dropout)      (None, 480)               0         
                                                                 
 dense_4790 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3808 (Dropout)      (None, 288)               0         
                                                                 
 dense_4791 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 520186 (1.98 MB)
Trainable params: 519226 (1.98 MB)
Non-trainable params: 960 (3.75 KB)
_________________________________________________________________



Trial 983:
  Value: 0.9214
  num_layers: 4
  units_0: 512
  units_1: 256
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0034139828275590823

Model: "sequential_983"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_983 (Flatten)       (None, 784)               0         
                                                                 
 dense_4792 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3809 (Dropout)      (None, 512)               0         
                                                                 
 dense_4793 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3810 (Dropout)      (None, 256)               0         
                                                                 
 dense_4794 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1114 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3811 (Dropout)      (None, 512)               0         
                                                                 
 dense_4795 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3812 (Dropout)      (None, 288)               0         
                                                                 
 dense_4796 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 822138 (3.14 MB)
Trainable params: 821114 (3.13 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 984:
  Value: 0.7944
  num_layers: 4
  units_0: 480
  units_1: 256
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: True
  optimizer: adam
  learning_rate: 0.004095047858025288

Model: "sequential_984"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_984 (Flatten)       (None, 784)               0         
                                                                 
 dense_4797 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3813 (Dropout)      (None, 480)               0         
                                                                 
 dense_4798 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3814 (Dropout)      (None, 256)               0         
                                                                 
 dense_4799 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1115 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3815 (Dropout)      (None, 512)               0         
                                                                 
 dense_4800 (Dense)          (None, 288)               147744    
                                                                 
 batch_normalization_1116 (  (None, 288)               1152      
 BatchNormalization)                                             
                                                                 
 dropout_3816 (Dropout)      (None, 288)               0         
                                                                 
 dense_4801 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 789978 (3.01 MB)
Trainable params: 788378 (3.01 MB)
Non-trainable params: 1600 (6.25 KB)
_________________________________________________________________



Trial 985:
  Value: 0.9191
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0040698992845828435

Model: "sequential_985"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_985 (Flatten)       (None, 784)               0         
                                                                 
 dense_4802 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3817 (Dropout)      (None, 512)               0         
                                                                 
 dense_4803 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3818 (Dropout)      (None, 384)               0         
                                                                 
 dense_4804 (Dense)          (None, 512)               197120    
                                                                 
 batch_normalization_1117 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3819 (Dropout)      (None, 512)               0         
                                                                 
 dense_4805 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3820 (Dropout)      (None, 288)               0         
                                                                 
 dense_4806 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 953338 (3.64 MB)
Trainable params: 952314 (3.63 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 986:
  Value: 0.9199
  num_layers: 4
  units_0: 480
  units_1: 256
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0037791929561514586

Model: "sequential_986"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_986 (Flatten)       (None, 784)               0         
                                                                 
 dense_4807 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3821 (Dropout)      (None, 480)               0         
                                                                 
 dense_4808 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3822 (Dropout)      (None, 256)               0         
                                                                 
 dense_4809 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1118 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3823 (Dropout)      (None, 512)               0         
                                                                 
 dense_4810 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3824 (Dropout)      (None, 288)               0         
                                                                 
 dense_4811 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 788826 (3.01 MB)
Trainable params: 787802 (3.01 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 987:
  Value: 0.9072
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: relu
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004474807416540139

Model: "sequential_987"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_987 (Flatten)       (None, 784)               0         
                                                                 
 dense_4812 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3825 (Dropout)      (None, 512)               0         
                                                                 
 dense_4813 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3826 (Dropout)      (None, 416)               0         
                                                                 
 dense_4814 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1119 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3827 (Dropout)      (None, 512)               0         
                                                                 
 dense_4815 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3828 (Dropout)      (None, 288)               0         
                                                                 
 dense_4816 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 988:
  Value: 0.8995
  num_layers: 4
  units_0: 448
  units_1: 256
  units_2: 512
  units_3: 96
  activation_0: relu
  activation_1: tanh
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0030341461650343704

Model: "sequential_988"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_988 (Flatten)       (None, 784)               0         
                                                                 
 dense_4817 (Dense)          (None, 448)               351680    
                                                                 
 dropout_3829 (Dropout)      (None, 448)               0         
                                                                 
 dense_4818 (Dense)          (None, 256)               114944    
                                                                 
 dropout_3830 (Dropout)      (None, 256)               0         
                                                                 
 dense_4819 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1120 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3831 (Dropout)      (None, 512)               0         
                                                                 
 dense_4820 (Dense)          (None, 96)                49248     
                                                                 
 dropout_3832 (Dropout)      (None, 96)                0         
                                                                 
 dense_4821 (Dense)          (None, 26)                2522      
                                                                 
=================================================================
Total params: 652026 (2.49 MB)
Trainable params: 651002 (2.48 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 989:
  Value: 0.7410
  num_layers: 4
  units_0: 480
  units_1: 416
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: True
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004304425021822373

Model: "sequential_989"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_989 (Flatten)       (None, 784)               0         
                                                                 
 dense_4822 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3833 (Dropout)      (None, 480)               0         
                                                                 
 dense_4823 (Dense)          (None, 416)               200096    
                                                                 
 batch_normalization_1121 (  (None, 416)               1664      
 BatchNormalization)                                             
                                                                 
 dropout_3834 (Dropout)      (None, 416)               0         
                                                                 
 dense_4824 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1122 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3835 (Dropout)      (None, 512)               0         
                                                                 
 dense_4825 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3836 (Dropout)      (None, 320)               0         
                                                                 
 dense_4826 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 966618 (3.69 MB)
Trainable params: 964762 (3.68 MB)
Non-trainable params: 1856 (7.25 KB)
_________________________________________________________________



Trial 990:
  Value: 0.0457
  num_layers: 4
  units_0: 512
  units_1: 416
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: tanh
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adagrad
  learning_rate: 0.003817513703250503

Model: "sequential_990"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_990 (Flatten)       (None, 784)               0         
                                                                 
 dense_4827 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3837 (Dropout)      (None, 512)               0         
                                                                 
 dense_4828 (Dense)          (None, 416)               213408    
                                                                 
 dropout_3838 (Dropout)      (None, 416)               0         
                                                                 
 dense_4829 (Dense)          (None, 512)               213504    
                                                                 
 batch_normalization_1123 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3839 (Dropout)      (None, 512)               0         
                                                                 
 dense_4830 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3840 (Dropout)      (None, 288)               0         
                                                                 
 dense_4831 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 986138 (3.76 MB)
Trainable params: 985114 (3.76 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 991:
  Value: 0.5555
  num_layers: 4
  units_0: 512
  units_1: 256
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: False
  batch_norm_3: False
  optimizer: rmsprop
  learning_rate: 0.0009550134187793086

Model: "sequential_991"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_991 (Flatten)       (None, 784)               0         
                                                                 
 dense_4832 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3841 (Dropout)      (None, 512)               0         
                                                                 
 dense_4833 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3842 (Dropout)      (None, 256)               0         
                                                                 
 dense_4834 (Dense)          (None, 512)               131584    
                                                                 
 dropout_3843 (Dropout)      (None, 512)               0         
                                                                 
 dense_4835 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3844 (Dropout)      (None, 320)               0         
                                                                 
 dense_4836 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 837338 (3.19 MB)
Trainable params: 837338 (3.19 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________



Trial 992:
  Value: 0.9200
  num_layers: 4
  units_0: 480
  units_1: 256
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0046826712582833715

Model: "sequential_992"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_992 (Flatten)       (None, 784)               0         
                                                                 
 dense_4837 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3845 (Dropout)      (None, 480)               0         
                                                                 
 dense_4838 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3846 (Dropout)      (None, 256)               0         
                                                                 
 dense_4839 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1124 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3847 (Dropout)      (None, 512)               0         
                                                                 
 dense_4840 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3848 (Dropout)      (None, 288)               0         
                                                                 
 dense_4841 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 788826 (3.01 MB)
Trainable params: 787802 (3.01 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 993:
  Value: 0.8532
  num_layers: 4
  units_0: 512
  units_1: 256
  units_2: 512
  units_3: 288
  activation_0: tanh
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.004761105246698583

Model: "sequential_993"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_993 (Flatten)       (None, 784)               0         
                                                                 
 dense_4842 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3849 (Dropout)      (None, 512)               0         
                                                                 
 dense_4843 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3850 (Dropout)      (None, 256)               0         
                                                                 
 dense_4844 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1125 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3851 (Dropout)      (None, 512)               0         
                                                                 
 dense_4845 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3852 (Dropout)      (None, 288)               0         
                                                                 
 dense_4846 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 822138 (3.14 MB)
Trainable params: 821114 (3.13 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 994:
  Value: 0.8587
  num_layers: 4
  units_0: 480
  units_1: 288
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.003639584201307131

Model: "sequential_994"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_994 (Flatten)       (None, 784)               0         
                                                                 
 dense_4847 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3853 (Dropout)      (None, 480)               0         
                                                                 
 dense_4848 (Dense)          (None, 288)               138528    
                                                                 
 dropout_3854 (Dropout)      (None, 288)               0         
                                                                 
 dense_4849 (Dense)          (None, 512)               147968    
                                                                 
 batch_normalization_1126 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3855 (Dropout)      (None, 512)               0         
                                                                 
 dense_4850 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3856 (Dropout)      (None, 320)               0         
                                                                 
 dense_4851 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 837850 (3.20 MB)
Trainable params: 836826 (3.19 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 995:
  Value: 0.0378
  num_layers: 4
  units_0: 512
  units_1: 384
  units_2: 256
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.2
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: ftrl
  learning_rate: 0.0011052958750792513

Model: "sequential_995"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_995 (Flatten)       (None, 784)               0         
                                                                 
 dense_4852 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3857 (Dropout)      (None, 512)               0         
                                                                 
 dense_4853 (Dense)          (None, 384)               196992    
                                                                 
 dropout_3858 (Dropout)      (None, 384)               0         
                                                                 
 dense_4854 (Dense)          (None, 256)               98560     
                                                                 
 batch_normalization_1127 (  (None, 256)               1024      
 BatchNormalization)                                             
                                                                 
 dropout_3859 (Dropout)      (None, 256)               0         
                                                                 
 dense_4855 (Dense)          (None, 288)               74016     
                                                                 
 dropout_3860 (Dropout)      (None, 288)               0         
                                                                 
 dense_4856 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 780026 (2.98 MB)
Trainable params: 779514 (2.97 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________



Trial 996:
  Value: 0.7211
  num_layers: 4
  units_0: 448
  units_1: 256
  units_2: 512
  units_3: 288
  activation_0: relu
  activation_1: sigmoid
  activation_2: sigmoid
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.5
  dropout_3: 0.0
  batch_norm_0: True
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.00717358272924863

Model: "sequential_996"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_996 (Flatten)       (None, 784)               0         
                                                                 
 dense_4857 (Dense)          (None, 448)               351680    
                                                                 
 batch_normalization_1128 (  (None, 448)               1792      
 BatchNormalization)                                             
                                                                 
 dropout_3861 (Dropout)      (None, 448)               0         
                                                                 
 dense_4858 (Dense)          (None, 256)               114944    
                                                                 
 dropout_3862 (Dropout)      (None, 256)               0         
                                                                 
 dense_4859 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1129 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3863 (Dropout)      (None, 512)               0         
                                                                 
 dense_4860 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3864 (Dropout)      (None, 288)               0         
                                                                 
 dense_4861 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 757306 (2.89 MB)
Trainable params: 755386 (2.88 MB)
Non-trainable params: 1920 (7.50 KB)
_________________________________________________________________



Trial 997:
  Value: 0.8641
  num_layers: 4
  units_0: 512
  units_1: 256
  units_2: 512
  units_3: 320
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.005026548382531209

Model: "sequential_997"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_997 (Flatten)       (None, 784)               0         
                                                                 
 dense_4862 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3865 (Dropout)      (None, 512)               0         
                                                                 
 dense_4863 (Dense)          (None, 256)               131328    
                                                                 
 dropout_3866 (Dropout)      (None, 256)               0         
                                                                 
 dense_4864 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1130 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3867 (Dropout)      (None, 512)               0         
                                                                 
 dense_4865 (Dense)          (None, 320)               164160    
                                                                 
 dropout_3868 (Dropout)      (None, 320)               0         
                                                                 
 dense_4866 (Dense)          (None, 26)                8346      
                                                                 
=================================================================
Total params: 839386 (3.20 MB)
Trainable params: 838362 (3.20 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 998:
  Value: 0.8019
  num_layers: 4
  units_0: 480
  units_1: 256
  units_2: 512
  units_3: 352
  activation_0: relu
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.0
  dropout_2: 0.2
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0008657463435751672

Model: "sequential_998"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_998 (Flatten)       (None, 784)               0         
                                                                 
 dense_4867 (Dense)          (None, 480)               376800    
                                                                 
 dropout_3869 (Dropout)      (None, 480)               0         
                                                                 
 dense_4868 (Dense)          (None, 256)               123136    
                                                                 
 dropout_3870 (Dropout)      (None, 256)               0         
                                                                 
 dense_4869 (Dense)          (None, 512)               131584    
                                                                 
 batch_normalization_1131 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3871 (Dropout)      (None, 512)               0         
                                                                 
 dense_4870 (Dense)          (None, 352)               180576    
                                                                 
 dropout_3872 (Dropout)      (None, 352)               0         
                                                                 
 dense_4871 (Dense)          (None, 26)                9178      
                                                                 
=================================================================
Total params: 823322 (3.14 MB)
Trainable params: 822298 (3.14 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________



Trial 999:
  Value: 0.7433
  num_layers: 4
  units_0: 512
  units_1: 224
  units_2: 512
  units_3: 288
  activation_0: sigmoid
  activation_1: sigmoid
  activation_2: relu
  activation_3: sigmoid
  dropout_0: 0.2
  dropout_1: 0.2
  dropout_2: 0.1
  dropout_3: 0.0
  batch_norm_0: False
  batch_norm_1: False
  batch_norm_2: True
  batch_norm_3: False
  optimizer: adam
  learning_rate: 0.0031270983510563767

Model: "sequential_999"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_999 (Flatten)       (None, 784)               0         
                                                                 
 dense_4872 (Dense)          (None, 512)               401920    
                                                                 
 dropout_3873 (Dropout)      (None, 512)               0         
                                                                 
 dense_4873 (Dense)          (None, 224)               114912    
                                                                 
 dropout_3874 (Dropout)      (None, 224)               0         
                                                                 
 dense_4874 (Dense)          (None, 512)               115200    
                                                                 
 batch_normalization_1132 (  (None, 512)               2048      
 BatchNormalization)                                             
                                                                 
 dropout_3875 (Dropout)      (None, 512)               0         
                                                                 
 dense_4875 (Dense)          (None, 288)               147744    
                                                                 
 dropout_3876 (Dropout)      (None, 288)               0         
                                                                 
 dense_4876 (Dense)          (None, 26)                7514      
                                                                 
=================================================================
Total params: 789338 (3.01 MB)
Trainable params: 788314 (3.01 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________


